<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0"/>
    <meta charset="utf-8" />
    <title>Re-Evaluating the Efficiency of Physical Visualizations: A Simple Multiverse Analysis</title>
    <meta property="og:title" content="Re-Evaluating the Efficiency of Physical Visualizations: A Simple Multiverse Analysis" />
    <meta property="og:type" content="article" />
    <meta property="og:description" content="Re-Evaluating the Efficiency of Physical Visualizations: A Simple Multiverse Analysis" />
    <meta property="description" content="Re-Evaluating the Efficiency of Physical Visualizations: A Simple Multiverse Analysis" />
    <link rel="stylesheet" href="./bundle.css" />
  </head>
  <body>
    <article><header><h1 role="banner">Re-Evaluating the Efficiency of Physical Visualizations: A Simple Multiverse Analysis</h1><div class="author"><span class="author-name">Pierre Dragicevic</span><span class="author-org">Inria</span></div><div class="author"><span class="author-name">Yvonne Jansen</span><span class="author-org">CNRS &amp; Sorbonne Université</span></div></header><aside><p>Replica of the <a href="https://explorablemultiverse.github.io/examples/frequentist/">Frequentist example</a> in the Explorable Multiverse Analyses paper.</p><p><a href="https://github.com/explorablemultiverse/explorablemultiverse.github.io/blob/master/examples/frequentist/index.html">Original source</a></p></aside><h1 nonumber="true">Abstract</h1><p>A previous study has shown that moving 3D data visualizations to the physical world can improve users’ efficiency at information retrieval tasks. Here, we re-analyze a subset of the experimental data using a multiverse analysis approach. Results from this multiverse analysis are presented as explorable explanations, and can be interactively explored in this paper. The study’s findings appear to be robust to choices in statistical analysis.</p><h1 id="introduction" data-counter="1">Introduction</h1><p>Whereas traditional visualizations map data to pixels or ink, physical visualizations (or <q>data physicalizations</q>) map data to physical form. While physical visualizations are compelling as an art form, it is unclear whether they can help users carry out actual information visualization tasks.</p><p>Five years ago, a study was published comparing physical to on-screen visualizations in their ability to support basic information retrieval tasks <span class="cite-list">[<cite-ref key="Jansen2013" index="5"></cite-ref>]</span>. Interactive 2D representations were clearly the fastest, but a gain in speed was observed when transitioning from on-screen to physical 3D representations. Overall, the study suggested that features unique to physical objects – such as their ability to be directly touched – can facilitate information retrieval.</p><p>These results however only hold for the particular data analysis that was conducted. A group of statisticians and methodologists recently argued that results from a single analysis can be unreliable <span class="cite-list">[<cite-ref key="Steegen2016" index="9"></cite-ref>]</span>. They recommended researchers to conduct instead <em>multiverse analyses</em>, i.e., to perform all reasonable analyses of their data and report a summary of their outcomes. While Steegen et al. show how to summarize all outcomes using p-values, here we use an interactive approach based on Bret Victor’s concept of <em>explorable explanation</em> <span class="cite-list">[<cite-ref key="Victor2011" index="10"></cite-ref>]</span>.</p><figure id="bar-charts" class="figure center" data-counter="1"><img src="assets/bar-charts.jpg"></img><figcaption data-counter="1">3D bar chart, on-screen and physical.</figcaption></figure><h1 id="experiment" data-counter="2">Experiment</h1><p>The study consisted of two experiments. In the first experiment, participants were presented with 3D bar charts showing country indicator data, and were asked simple questions about the data. The 3D bar charts were presented both on a screen and in physical form (see <cross-ref type="fig" xref="bar-charts" index="1"></cross-ref>). The on-screen bar chart could be rotated in all directions with the mouse. Both a regular and a stereoscopic display were tested. An interactive 2D bar chart was also used as a control condition. Accuracy was high across all conditions, but average completion time was lower with physical 3D bar charts than with on-screen 3D bar charts.</p><p>Here we only re-analyze the second experiment, whose goal was to better understand why physical visualizations appear to be superior. The experiment involved an <q>enhanced</q> version of the on-screen 3D chart and an <q>impoverished</q> version of the physical 3D chart. The enhanced on-screen chart was rotated using a 3D-tracked tangible prop instead of a mouse. The impoverished physical chart consisted of the same physical object but participants were instructed not to use their fingers for marking. There were 4 conditions:</p><ul><li><em>physical touch</em>: physical 3D bar charts where touch was explicitly encouraged in the instructions.</li><li><em>physical no touch</em>: same charts as above except subjects were told not to use their fingers to mark points of interest (labels and bars).</li><li><em>virtual prop</em>: on-screen 3D bar charts with a tangible prop for controlling 3D rotation.</li><li><em>virtual mouse</em>: same charts as above, but 3D rotation was mouse-controlled.</li></ul><p>These manipulations were meant to answer three questions: <em>1)</em> how important is direct touch in the physical condition? <em>2)</em> how important is rotation by direct manipulation? <em>3)</em> how important is visual realism? Visual realism referred to the higher perceptual richness of physical objects compared to on-screen objects, especially concerning depth cues. Figure 2 summarizes the three effects of interest.</p><figure id="comparisons" class="figure center" data-counter="2"><img src="assets/comparisons.png"></img><figcaption data-counter="2">Effects of interest.</figcaption></figure><p>Sixteen participants were recruited, all of whom saw the four conditions in counterbalanced order. For more details about the experiment, please refer to <span class="cite-list">[<cite-ref key="Jansen2013" index="5"></cite-ref>]</span>.</p><h1 id="results" data-counter="3">Results</h1><p>Like the original paper we use an estimation approach, meaning that we report and interpret all results based on (unstandardized) effect sizes and their interval estimates <span class="cite-list">[<cite-ref key="Dragicevic2016" index="4"></cite-ref>]</span>. We explain how to translate the results into statistical significance language to provide a point of reference, but we warn the reader against the pitfalls of dichotomous interpretations <span class="cite-list">[<cite-ref key="Amrhein2017" index="1"></cite-ref>]</span>.</p><figure id="figA" class="figure center" data-counter="3"><div class="center"><p><img data-attr="1"></img></p></div><figcaption data-counter="3">Average task completion time (<cell-view inline="true" data-cell="15"></cell-view> mean) per condition. Error bars are <cell-view inline="true" data-cell="16"></cell-view> t-based CIs.</figcaption></figure><p>We focus our analysis on task completion times, reported in <cross-ref type="fig" xref="figA" index="3"></cross-ref> and <cross-ref type="fig" xref="figB" index="4"></cross-ref>.
Dots indicate sample means, while error bars are
<option-text options="[50,68,80,90,95,99,99.9]" suffix="%" span="5" data-bind="confidence_level"></option-text>
confidence intervals computed on
<toggle-text data-bind="log_transform">
<span>untransformed data</span>
<span>log-transformed data <span class="cite-list">[<cite-ref key="Sauro2010" index="8"></cite-ref>]</span></span></toggle-text> using the
<toggle-text data-bind="bootstrap"><span>BCa bootstrap</span> <span>t-distribution</span></toggle-text> method.</p><p>Strictly speaking, all we can assert about each interval is that it comes from a procedure designed to capture the population mean <cell-view inline="true" data-cell="17"></cell-view> of the time across replications, under some assumptions <span class="cite-list">[<cite-ref key="Morey2016" index="7"></cite-ref>]</span>.
In practice, if we assume we have very little prior knowledge about population means, each interval can be informally interpreted as a range of plausible values for the population mean, with the midpoint being <cell-view inline="true" data-cell="18"></cell-view> more likely than the endpoints <span class="cite-list">[<cite-ref key="Cumming2012" index="3"></cite-ref>]</span>.</p><p><cross-ref type="fig" xref="figA" index="3"></cross-ref> shows the <cell-view inline="true" data-cell="19"></cell-view> completion time for each condition.
At first sight, <em>physical touch</em> appears to be faster than the other conditions.
However, since condition is a within-subject factor, it is preferable to examine within-subject differences <span class="cite-list">[<cite-ref key="Cumming2012" index="3"></cite-ref>]</span>, shown in <cross-ref type="fig" xref="figB" index="4"></cross-ref>.</p><p><cross-ref type="fig" xref="figB" index="4"></cross-ref> shows the pairwise <cell-view inline="true" data-cell="20"></cell-view> between mean completion times.
A value lower than <cell-view inline="true" data-cell="21"></cell-view> (i.e., on the left side of the dark line) means the condition on the left is faster than the condition on the right.
The confidence intervals are
<toggle-text data-bind="bonferroni">
<span>Bonferroni-corrected.</span>
<span>not corrected for multiplicity,</span></toggle-text>
<toggle-text data-attr="2" data-bind="bonferroni">
<span>Since the individual confidence level is <cell-view inline="true" data-cell="22"></cell-view>,</span>
<span>meaning they are effectively <cell-view inline="true" data-cell="23"></cell-view> CIs <span class="cite-list">[<cite-ref key="Baguley2012" index="2"></cite-ref>]</span>. Thus,</span></toggle-text>
an interval that does not contain the value <cell-view inline="true" data-cell="24"></cell-view> indicates a statistically significant difference at the α=<cell-view inline="true" data-cell="25"></cell-view> level.
The probability of getting at least one such interval if all <cell-view inline="true" data-cell="26"></cell-view> population means were zero (i.e., the familywise error rate) is α=<cell-view inline="true" data-cell="27"></cell-view>.
Likewise, the simultaneous confidence level is <cell-view inline="true" data-cell="28"></cell-view>, meaning that if we replicate our experiment over and over, we should expect the <cell-view inline="true" data-cell="29"></cell-view> confidence intervals to capture all <cell-view inline="true" data-cell="30"></cell-view> population means <cell-view inline="true" data-cell="31"></cell-view> of the time.</p><figure id="figB" class="figure center" data-counter="4"><img data-attr="3"></img><figcaption data-counter="4"><toggle-text data-bind="log_transform" clickable="false"><span>Differences between mean completion times (arithmetic means)</span><span>Ratios between average task completion times (geometric means)</span></toggle-text> between conditions. Error bars are <cell-view inline="true" data-cell="32"></cell-view> <cell-view inline="true" data-cell="33"></cell-view> CIs.</figcaption></figure><p><cross-ref type="fig" xref="figB" index="4"></cross-ref> provides good evidence that <em>i)</em> <em>physical touch</em> is faster on average than <em>physical no touch</em>, and that <em>ii)</em> <em>physical no touch</em> is faster than <em>virtual prop</em>. This suggests that both visual realism (e.g., rich depth cues) and physical touch can facilitate basic information retrieval. Importantly, these two properties are unique to physical objects and are hard to faithfully reproduce in virtual setups. In contrast, we could not find evidence that physical object rotation (as opposed to mouse-operated rotation) provides a performance advantage for information retrieval.</p><h1 id="conclusion" data-counter="4">Discussion and Conclusion</h1><p>Our findings for experiment 2 are in line with the previously published study <span class="cite-list">[<cite-ref key="Jansen2013" index="5"></cite-ref>]</span>. In the present article, the default analysis options reflect the choices made in the previously published analysis – thus, the figures are by default identical. On top of this, we consider alternative choices in statistical analysis and presentation, which together yield a total 56 unique analyses and results. The conclusions are largely robust to these choices. Results are less clean with untransformed data, likely because abnormally high completion times are given as much weight as other observations. The use of a log transformation addresses this issue without the need for outlier removal <span class="cite-list">[<cite-ref key="Sauro2010" index="8"></cite-ref>]</span>.</p><p>Meanwhile, the use of bootstrap CIs makes the results slightly stronger, although this is likely because bootstrap CIs are slightly too liberal for small sample sizes <span class="cite-list">[<cite-ref key="Kirby2013" index="6"></cite-ref>]</span>.</p><p>We did not re-analyze experiment 1 to keep this article simple. Since experiment 1 used four conditions and the reported analysis included a figure with seven comparisons <span class="cite-list">[<cite-ref key="Jansen2013" index="5"></cite-ref>]</span>, it is possible that some of the effects become much less conclusive after correcting for multiplicity. Multiplicity correction is however a contested practice <span class="cite-list">[<cite-ref key="Baguley2012" index="2"></cite-ref>]</span>, thus it is generally best to consider both corrected and uncorrected interval estimates.</p><p>The goal of this article was to illustrate how the ideas of <em>multiverse analysis</em> <span class="cite-list">[<cite-ref key="Steegen2016" index="9"></cite-ref>]</span> and of <em>explorable explanation</em> <span class="cite-list">[<cite-ref key="Victor2011" index="10"></cite-ref>]</span> can be combined to produce more transparent and more compelling statistical reports. We only provided a few analysis options, and many more options could have been included. In addition, our choice of analysis options was highly personal and subjective. Steegen et al. have argued that multiverse analyses are necessarily incomplete and subjective, but are nonetheless way more transparent than conventional analyses where no information is provided about the robustness or fragility of researchers’ findings <span class="cite-list">[<cite-ref key="Steegen2016" index="9"></cite-ref>]</span>.</p><h1 nonumber="true">References</h1><ol class="references"><li id="ref-0">Amrhein, V., Korner-Nievergelt, F., &amp; Roth, T. (2017). The earth is flat (p&gt; 0.05): significance thresholds and the crisis of unreplicable research. PeerJ, 5, e3544. <a href="https://peerj.com/articles/3544/?utm_source=TrendMD&amp;utm_campaign=PeerJ_TrendMD_0&amp;utm_medium=TrendMD">https://peerj.com/articles/3544/?utm_source=TrendMD&amp;utm_campaign=PeerJ_TrendMD_0&amp;utm_medium=TrendMD</a></li><li id="ref-1">Baguley, T. (2012). Serious Stats: A Guide to Advanced Statistics for the Behavioral Science. Palgrave Macmillan.</li><li id="ref-2">Cumming, G. (2012). Understanding the New Statistics: Effect Sizes, Confidence Intervals, and Meta-analysis. Routledge. <a href="https://market.android.com/details?id=book-AVBDYgEACAAJ">https://market.android.com/details?id=book-AVBDYgEACAAJ</a></li><li id="ref-3">Dragicevic, P. (2016). Fair Statistical Communication in HCI. In J. Robertson &amp; M. Kaptein (Eds.), Modern Statistical Methods for HCI (pp. 291–330). Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-26633-6\_13">https://doi.org/10.1007/978-3-319-26633-6\_13</a></li><li id="ref-4">Jansen, Y., Dragicevic, P., &amp; Fekete, J.-D. (2013). Evaluating the Efficiency of Physical Visualizations. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 2593–2602. <a href="https://doi.org/10.1145/2470654.2481359">https://doi.org/10.1145/2470654.2481359</a></li><li id="ref-5">Kirby, K. N., &amp; Gerlanc, D. (2013). BootES: an R package for bootstrap confidence intervals on effect sizes. Behavior Research Methods, 45(4), 905–927. <a href="https://doi.org/10.3758/s13428-013-0330-5">https://doi.org/10.3758/s13428-013-0330-5</a></li><li id="ref-6">Morey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., &amp; Wagenmakers, E.-J. (2016). The fallacy of placing confidence in confidence intervals. Psychonomic Bulletin &amp; Review, 23(1), 103–123. <a href="https://doi.org/10.3758/s13423-015-0947-8">https://doi.org/10.3758/s13423-015-0947-8</a></li><li id="ref-7">Sauro, J., &amp; Lewis, J. R. (2010). Average task times in usability tests: what to report? Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 2347–2350. <a href="https://doi.org/10.1145/1753326.1753679">https://doi.org/10.1145/1753326.1753679</a></li><li id="ref-8">Steegen, S., Tuerlinckx, F., Gelman, A., &amp; Vanpaemel, W. (2016). Increasing Transparency Through a Multiverse Analysis. Perspectives on Psychological Science: A Journal of the Association for Psychological Science, 11(5), 702–712. <a href="https://doi.org/10.1177/1745691616658637">https://doi.org/10.1177/1745691616658637</a></li><li id="ref-9">Victor, B. (2011). Explorable explanations. Bret Victor, 10.</li></ol></article>
    <script type="module" src="./bundle.js"></script>
</html>