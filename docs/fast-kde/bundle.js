/**
 * @license
 * Copyright 2019 Google LLC
 * SPDX-License-Identifier: BSD-3-Clause
 */
const e=window,t=e.ShadowRoot&&(void 0===e.ShadyCSS||e.ShadyCSS.nativeShadow)&&"adoptedStyleSheets"in Document.prototype&&"replace"in CSSStyleSheet.prototype,i=Symbol(),n=new WeakMap;const a=e=>new class{constructor(e,t,n){if(this._$cssResult$=!0,n!==i)throw Error("CSSResult is not constructable. Use `unsafeCSS` or `css` instead.");this.cssText=e,this.t=t}get styleSheet(){let e=this.o;const i=this.t;if(t&&void 0===e){const t=void 0!==i&&1===i.length;t&&(e=n.get(i)),void 0===e&&((this.o=e=new CSSStyleSheet).replaceSync(this.cssText),t&&n.set(i,e))}return e}toString(){return this.cssText}}("string"==typeof e?e:e+"",void 0,i),s=t?e=>e:e=>e instanceof CSSStyleSheet?(e=>{let t="";for(const i of e.cssRules)t+=i.cssText;return a(t)})(e):e
/**
 * @license
 * Copyright 2017 Google LLC
 * SPDX-License-Identifier: BSD-3-Clause
 */;var o;const r=window,l=r.trustedTypes,c=l?l.emptyScript:"",d=r.reactiveElementPolyfillSupport,h={toAttribute(e,t){switch(t){case Boolean:e=e?c:null;break;case Object:case Array:e=null==e?e:JSON.stringify(e)}return e},fromAttribute(e,t){let i=e;switch(t){case Boolean:i=null!==e;break;case Number:i=null===e?null:Number(e);break;case Object:case Array:try{i=JSON.parse(e)}catch(e){i=null}}return i}},u=(e,t)=>t!==e&&(t==t||e==e),p={attribute:!0,type:String,converter:h,reflect:!1,hasChanged:u};let m=class extends HTMLElement{constructor(){super(),this._$Ei=new Map,this.isUpdatePending=!1,this.hasUpdated=!1,this._$El=null,this.u()}static addInitializer(e){var t;this.finalize(),(null!==(t=this.h)&&void 0!==t?t:this.h=[]).push(e)}static get observedAttributes(){this.finalize();const e=[];return this.elementProperties.forEach(((t,i)=>{const n=this._$Ep(i,t);void 0!==n&&(this._$Ev.set(n,i),e.push(n))})),e}static createProperty(e,t=p){if(t.state&&(t.attribute=!1),this.finalize(),this.elementProperties.set(e,t),!t.noAccessor&&!this.prototype.hasOwnProperty(e)){const i="symbol"==typeof e?Symbol():"__"+e,n=this.getPropertyDescriptor(e,i,t);void 0!==n&&Object.defineProperty(this.prototype,e,n)}}static getPropertyDescriptor(e,t,i){return{get(){return this[t]},set(n){const a=this[e];this[t]=n,this.requestUpdate(e,a,i)},configurable:!0,enumerable:!0}}static getPropertyOptions(e){return this.elementProperties.get(e)||p}static finalize(){if(this.hasOwnProperty("finalized"))return!1;this.finalized=!0;const e=Object.getPrototypeOf(this);if(e.finalize(),void 0!==e.h&&(this.h=[...e.h]),this.elementProperties=new Map(e.elementProperties),this._$Ev=new Map,this.hasOwnProperty("properties")){const e=this.properties,t=[...Object.getOwnPropertyNames(e),...Object.getOwnPropertySymbols(e)];for(const i of t)this.createProperty(i,e[i])}return this.elementStyles=this.finalizeStyles(this.styles),!0}static finalizeStyles(e){const t=[];if(Array.isArray(e)){const i=new Set(e.flat(1/0).reverse());for(const e of i)t.unshift(s(e))}else void 0!==e&&t.push(s(e));return t}static _$Ep(e,t){const i=t.attribute;return!1===i?void 0:"string"==typeof i?i:"string"==typeof e?e.toLowerCase():void 0}u(){var e;this._$E_=new Promise((e=>this.enableUpdating=e)),this._$AL=new Map,this._$Eg(),this.requestUpdate(),null===(e=this.constructor.h)||void 0===e||e.forEach((e=>e(this)))}addController(e){var t,i;(null!==(t=this._$ES)&&void 0!==t?t:this._$ES=[]).push(e),void 0!==this.renderRoot&&this.isConnected&&(null===(i=e.hostConnected)||void 0===i||i.call(e))}removeController(e){var t;null===(t=this._$ES)||void 0===t||t.splice(this._$ES.indexOf(e)>>>0,1)}_$Eg(){this.constructor.elementProperties.forEach(((e,t)=>{this.hasOwnProperty(t)&&(this._$Ei.set(t,this[t]),delete this[t])}))}createRenderRoot(){var i;const n=null!==(i=this.shadowRoot)&&void 0!==i?i:this.attachShadow(this.constructor.shadowRootOptions);return((i,n)=>{t?i.adoptedStyleSheets=n.map((e=>e instanceof CSSStyleSheet?e:e.styleSheet)):n.forEach((t=>{const n=document.createElement("style"),a=e.litNonce;void 0!==a&&n.setAttribute("nonce",a),n.textContent=t.cssText,i.appendChild(n)}))})(n,this.constructor.elementStyles),n}connectedCallback(){var e;void 0===this.renderRoot&&(this.renderRoot=this.createRenderRoot()),this.enableUpdating(!0),null===(e=this._$ES)||void 0===e||e.forEach((e=>{var t;return null===(t=e.hostConnected)||void 0===t?void 0:t.call(e)}))}enableUpdating(e){}disconnectedCallback(){var e;null===(e=this._$ES)||void 0===e||e.forEach((e=>{var t;return null===(t=e.hostDisconnected)||void 0===t?void 0:t.call(e)}))}attributeChangedCallback(e,t,i){this._$AK(e,i)}_$EO(e,t,i=p){var n;const a=this.constructor._$Ep(e,i);if(void 0!==a&&!0===i.reflect){const s=(void 0!==(null===(n=i.converter)||void 0===n?void 0:n.toAttribute)?i.converter:h).toAttribute(t,i.type);this._$El=e,null==s?this.removeAttribute(a):this.setAttribute(a,s),this._$El=null}}_$AK(e,t){var i;const n=this.constructor,a=n._$Ev.get(e);if(void 0!==a&&this._$El!==a){const e=n.getPropertyOptions(a),s="function"==typeof e.converter?{fromAttribute:e.converter}:void 0!==(null===(i=e.converter)||void 0===i?void 0:i.fromAttribute)?e.converter:h;this._$El=a,this[a]=s.fromAttribute(t,e.type),this._$El=null}}requestUpdate(e,t,i){let n=!0;void 0!==e&&(((i=i||this.constructor.getPropertyOptions(e)).hasChanged||u)(this[e],t)?(this._$AL.has(e)||this._$AL.set(e,t),!0===i.reflect&&this._$El!==e&&(void 0===this._$EC&&(this._$EC=new Map),this._$EC.set(e,i))):n=!1),!this.isUpdatePending&&n&&(this._$E_=this._$Ej())}async _$Ej(){this.isUpdatePending=!0;try{await this._$E_}catch(e){Promise.reject(e)}const e=this.scheduleUpdate();return null!=e&&await e,!this.isUpdatePending}scheduleUpdate(){return this.performUpdate()}performUpdate(){var e;if(!this.isUpdatePending)return;this.hasUpdated,this._$Ei&&(this._$Ei.forEach(((e,t)=>this[t]=e)),this._$Ei=void 0);let t=!1;const i=this._$AL;try{t=this.shouldUpdate(i),t?(this.willUpdate(i),null===(e=this._$ES)||void 0===e||e.forEach((e=>{var t;return null===(t=e.hostUpdate)||void 0===t?void 0:t.call(e)})),this.update(i)):this._$Ek()}catch(e){throw t=!1,this._$Ek(),e}t&&this._$AE(i)}willUpdate(e){}_$AE(e){var t;null===(t=this._$ES)||void 0===t||t.forEach((e=>{var t;return null===(t=e.hostUpdated)||void 0===t?void 0:t.call(e)})),this.hasUpdated||(this.hasUpdated=!0,this.firstUpdated(e)),this.updated(e)}_$Ek(){this._$AL=new Map,this.isUpdatePending=!1}get updateComplete(){return this.getUpdateComplete()}getUpdateComplete(){return this._$E_}shouldUpdate(e){return!0}update(e){void 0!==this._$EC&&(this._$EC.forEach(((e,t)=>this._$EO(t,this[t],e))),this._$EC=void 0),this._$Ek()}updated(e){}firstUpdated(e){}};
/**
 * @license
 * Copyright 2017 Google LLC
 * SPDX-License-Identifier: BSD-3-Clause
 */
var f;m.finalized=!0,m.elementProperties=new Map,m.elementStyles=[],m.shadowRootOptions={mode:"open"},null==d||d({ReactiveElement:m}),(null!==(o=r.reactiveElementVersions)&&void 0!==o?o:r.reactiveElementVersions=[]).push("1.6.1");const g=window,y=g.trustedTypes,v=y?y.createPolicy("lit-html",{createHTML:e=>e}):void 0,b="$lit$",w=`lit$${(Math.random()+"").slice(9)}$`,S="?"+w,A=`<${S}>`,E=document,$=()=>E.createComment(""),C=e=>null===e||"object"!=typeof e&&"function"!=typeof e,_=Array.isArray,k="[ \t\n\f\r]",D=/<(?:(!--|\/[^a-zA-Z])|(\/?[a-zA-Z][^>\s]*)|(\/?$))/g,x=/-->/g,M=/>/g,T=RegExp(`>|${k}(?:([^\\s"'>=/]+)(${k}*=${k}*(?:[^ \t\n\f\r"'\`<>=]|("|')|))|$)`,"g"),I=/'/g,P=/"/g,R=/^(?:script|style|textarea|title)$/i,G=(e=>(t,...i)=>({_$litType$:e,strings:t,values:i}))(1),z=Symbol.for("lit-noChange"),O=Symbol.for("lit-nothing"),W=new WeakMap,H=E.createTreeWalker(E,129,null,!1),V=(e,t)=>{const i=e.length-1,n=[];let a,s=2===t?"<svg>":"",o=D;for(let t=0;t<i;t++){const i=e[t];let r,l,c=-1,d=0;for(;d<i.length&&(o.lastIndex=d,l=o.exec(i),null!==l);)d=o.lastIndex,o===D?"!--"===l[1]?o=x:void 0!==l[1]?o=M:void 0!==l[2]?(R.test(l[2])&&(a=RegExp("</"+l[2],"g")),o=T):void 0!==l[3]&&(o=T):o===T?">"===l[0]?(o=null!=a?a:D,c=-1):void 0===l[1]?c=-2:(c=o.lastIndex-l[2].length,r=l[1],o=void 0===l[3]?T:'"'===l[3]?P:I):o===P||o===I?o=T:o===x||o===M?o=D:(o=T,a=void 0);const h=o===T&&e[t+1].startsWith("/>")?" ":"";s+=o===D?i+A:c>=0?(n.push(r),i.slice(0,c)+b+i.slice(c)+w+h):i+w+(-2===c?(n.push(void 0),t):h)}const r=s+(e[i]||"<?>")+(2===t?"</svg>":"");if(!Array.isArray(e)||!e.hasOwnProperty("raw"))throw Error("invalid template strings array");return[void 0!==v?v.createHTML(r):r,n]};class L{constructor({strings:e,_$litType$:t},i){let n;this.parts=[];let a=0,s=0;const o=e.length-1,r=this.parts,[l,c]=V(e,t);if(this.el=L.createElement(l,i),H.currentNode=this.el.content,2===t){const e=this.el.content,t=e.firstChild;t.remove(),e.append(...t.childNodes)}for(;null!==(n=H.nextNode())&&r.length<o;){if(1===n.nodeType){if(n.hasAttributes()){const e=[];for(const t of n.getAttributeNames())if(t.endsWith(b)||t.startsWith(w)){const i=c[s++];if(e.push(t),void 0!==i){const e=n.getAttribute(i.toLowerCase()+b).split(w),t=/([.?@])?(.*)/.exec(i);r.push({type:1,index:a,name:t[2],strings:e,ctor:"."===t[1]?F:"?"===t[1]?q:"@"===t[1]?K:U})}else r.push({type:6,index:a})}for(const t of e)n.removeAttribute(t)}if(R.test(n.tagName)){const e=n.textContent.split(w),t=e.length-1;if(t>0){n.textContent=y?y.emptyScript:"";for(let i=0;i<t;i++)n.append(e[i],$()),H.nextNode(),r.push({type:2,index:++a});n.append(e[t],$())}}}else if(8===n.nodeType)if(n.data===S)r.push({type:2,index:a});else{let e=-1;for(;-1!==(e=n.data.indexOf(w,e+1));)r.push({type:7,index:a}),e+=w.length-1}a++}}static createElement(e,t){const i=E.createElement("template");return i.innerHTML=e,i}}function j(e,t,i=e,n){var a,s,o,r;if(t===z)return t;let l=void 0!==n?null===(a=i._$Co)||void 0===a?void 0:a[n]:i._$Cl;const c=C(t)?void 0:t._$litDirective$;return(null==l?void 0:l.constructor)!==c&&(null===(s=null==l?void 0:l._$AO)||void 0===s||s.call(l,!1),void 0===c?l=void 0:(l=new c(e),l._$AT(e,i,n)),void 0!==n?(null!==(o=(r=i)._$Co)&&void 0!==o?o:r._$Co=[])[n]=l:i._$Cl=l),void 0!==l&&(t=j(e,l._$AS(e,t.values),l,n)),t}class N{constructor(e,t){this.u=[],this._$AN=void 0,this._$AD=e,this._$AM=t}get parentNode(){return this._$AM.parentNode}get _$AU(){return this._$AM._$AU}v(e){var t;const{el:{content:i},parts:n}=this._$AD,a=(null!==(t=null==e?void 0:e.creationScope)&&void 0!==t?t:E).importNode(i,!0);H.currentNode=a;let s=H.nextNode(),o=0,r=0,l=n[0];for(;void 0!==l;){if(o===l.index){let t;2===l.type?t=new B(s,s.nextSibling,this,e):1===l.type?t=new l.ctor(s,l.name,l.strings,this,e):6===l.type&&(t=new X(s,this,e)),this.u.push(t),l=n[++r]}o!==(null==l?void 0:l.index)&&(s=H.nextNode(),o++)}return a}p(e){let t=0;for(const i of this.u)void 0!==i&&(void 0!==i.strings?(i._$AI(e,i,t),t+=i.strings.length-2):i._$AI(e[t])),t++}}class B{constructor(e,t,i,n){var a;this.type=2,this._$AH=O,this._$AN=void 0,this._$AA=e,this._$AB=t,this._$AM=i,this.options=n,this._$Cm=null===(a=null==n?void 0:n.isConnected)||void 0===a||a}get _$AU(){var e,t;return null!==(t=null===(e=this._$AM)||void 0===e?void 0:e._$AU)&&void 0!==t?t:this._$Cm}get parentNode(){let e=this._$AA.parentNode;const t=this._$AM;return void 0!==t&&11===(null==e?void 0:e.nodeType)&&(e=t.parentNode),e}get startNode(){return this._$AA}get endNode(){return this._$AB}_$AI(e,t=this){e=j(this,e,t),C(e)?e===O||null==e||""===e?(this._$AH!==O&&this._$AR(),this._$AH=O):e!==this._$AH&&e!==z&&this.g(e):void 0!==e._$litType$?this.$(e):void 0!==e.nodeType?this.T(e):(e=>_(e)||"function"==typeof(null==e?void 0:e[Symbol.iterator]))(e)?this.k(e):this.g(e)}S(e){return this._$AA.parentNode.insertBefore(e,this._$AB)}T(e){this._$AH!==e&&(this._$AR(),this._$AH=this.S(e))}g(e){this._$AH!==O&&C(this._$AH)?this._$AA.nextSibling.data=e:this.T(E.createTextNode(e)),this._$AH=e}$(e){var t;const{values:i,_$litType$:n}=e,a="number"==typeof n?this._$AC(e):(void 0===n.el&&(n.el=L.createElement(n.h,this.options)),n);if((null===(t=this._$AH)||void 0===t?void 0:t._$AD)===a)this._$AH.p(i);else{const e=new N(a,this),t=e.v(this.options);e.p(i),this.T(t),this._$AH=e}}_$AC(e){let t=W.get(e.strings);return void 0===t&&W.set(e.strings,t=new L(e)),t}k(e){_(this._$AH)||(this._$AH=[],this._$AR());const t=this._$AH;let i,n=0;for(const a of e)n===t.length?t.push(i=new B(this.S($()),this.S($()),this,this.options)):i=t[n],i._$AI(a),n++;n<t.length&&(this._$AR(i&&i._$AB.nextSibling,n),t.length=n)}_$AR(e=this._$AA.nextSibling,t){var i;for(null===(i=this._$AP)||void 0===i||i.call(this,!1,!0,t);e&&e!==this._$AB;){const t=e.nextSibling;e.remove(),e=t}}setConnected(e){var t;void 0===this._$AM&&(this._$Cm=e,null===(t=this._$AP)||void 0===t||t.call(this,e))}}class U{constructor(e,t,i,n,a){this.type=1,this._$AH=O,this._$AN=void 0,this.element=e,this.name=t,this._$AM=n,this.options=a,i.length>2||""!==i[0]||""!==i[1]?(this._$AH=Array(i.length-1).fill(new String),this.strings=i):this._$AH=O}get tagName(){return this.element.tagName}get _$AU(){return this._$AM._$AU}_$AI(e,t=this,i,n){const a=this.strings;let s=!1;if(void 0===a)e=j(this,e,t,0),s=!C(e)||e!==this._$AH&&e!==z,s&&(this._$AH=e);else{const n=e;let o,r;for(e=a[0],o=0;o<a.length-1;o++)r=j(this,n[i+o],t,o),r===z&&(r=this._$AH[o]),s||(s=!C(r)||r!==this._$AH[o]),r===O?e=O:e!==O&&(e+=(null!=r?r:"")+a[o+1]),this._$AH[o]=r}s&&!n&&this.j(e)}j(e){e===O?this.element.removeAttribute(this.name):this.element.setAttribute(this.name,null!=e?e:"")}}class F extends U{constructor(){super(...arguments),this.type=3}j(e){this.element[this.name]=e===O?void 0:e}}const J=y?y.emptyScript:"";class q extends U{constructor(){super(...arguments),this.type=4}j(e){e&&e!==O?this.element.setAttribute(this.name,J):this.element.removeAttribute(this.name)}}class K extends U{constructor(e,t,i,n,a){super(e,t,i,n,a),this.type=5}_$AI(e,t=this){var i;if((e=null!==(i=j(this,e,t,0))&&void 0!==i?i:O)===z)return;const n=this._$AH,a=e===O&&n!==O||e.capture!==n.capture||e.once!==n.once||e.passive!==n.passive,s=e!==O&&(n===O||a);a&&this.element.removeEventListener(this.name,this,n),s&&this.element.addEventListener(this.name,this,e),this._$AH=e}handleEvent(e){var t,i;"function"==typeof this._$AH?this._$AH.call(null!==(i=null===(t=this.options)||void 0===t?void 0:t.host)&&void 0!==i?i:this.element,e):this._$AH.handleEvent(e)}}class X{constructor(e,t,i){this.element=e,this.type=6,this._$AN=void 0,this._$AM=t,this.options=i}get _$AU(){return this._$AM._$AU}_$AI(e){j(this,e)}}const Z=g.litHtmlPolyfillSupport;null==Z||Z(L,B),(null!==(f=g.litHtmlVersions)&&void 0!==f?f:g.litHtmlVersions=[]).push("2.7.0");
/**
 * @license
 * Copyright 2017 Google LLC
 * SPDX-License-Identifier: BSD-3-Clause
 */
var Q,Y;class ee extends m{constructor(){super(...arguments),this.renderOptions={host:this},this._$Do=void 0}createRenderRoot(){var e,t;const i=super.createRenderRoot();return null!==(e=(t=this.renderOptions).renderBefore)&&void 0!==e||(t.renderBefore=i.firstChild),i}update(e){const t=this.render();this.hasUpdated||(this.renderOptions.isConnected=this.isConnected),super.update(e),this._$Do=((e,t,i)=>{var n,a;const s=null!==(n=null==i?void 0:i.renderBefore)&&void 0!==n?n:t;let o=s._$litPart$;if(void 0===o){const e=null!==(a=null==i?void 0:i.renderBefore)&&void 0!==a?a:null;s._$litPart$=o=new B(t.insertBefore($(),e),e,void 0,null!=i?i:{})}return o._$AI(e),o})(t,this.renderRoot,this.renderOptions)}connectedCallback(){var e;super.connectedCallback(),null===(e=this._$Do)||void 0===e||e.setConnected(!0)}disconnectedCallback(){var e;super.disconnectedCallback(),null===(e=this._$Do)||void 0===e||e.setConnected(!1)}render(){return z}}ee.finalized=!0,ee._$litElement$=!0,null===(Q=globalThis.litElementHydrateSupport)||void 0===Q||Q.call(globalThis,{LitElement:ee});const te=globalThis.litElementPolyfillSupport;null==te||te({LitElement:ee}),(null!==(Y=globalThis.litElementVersions)&&void 0!==Y?Y:globalThis.litElementVersions=[]).push("3.3.0");class ie extends ee{createRenderRoot(){return this}connectedCallback(){this.__initchildnodes||(this.__initchildnodes=!0,this.initialChildNodes(Array.from(this.childNodes,(e=>(e.__element=this,e)))),function(e,t=0){const i=e.childNodes;let n=i.length;for(;n>t;)e.removeChild(i[--n])}(this)),super.connectedCallback()}initialChildNodes(e){this.__children=e}articleData(){let e=this;for(;"ARTICLE"!==e.tagName;e=e.parentNode||e.__element);return e?.__data}}class ne extends ie{constructor(){super(),this.visible=!1,this.addEventListener("keydown",this.keyDown),this.addEventListener("mousedown",this.mouseDown)}mouseDownClose=e=>{this.contains(e.target)||this.hide()};keyDownClose=e=>{se(e.key)&&this.hide()};keyDown(e){ae(e.key)&&!this.visible&&this.show()}mouseDown(){this.visible||this.show()}hide(){this.querySelector(".tooltip").style.display="none",this.visible=!1,document.removeEventListener("keydown",this.keyDownClose),document.removeEventListener("mousedown",this.mouseDownClose)}show(){const e=this.getBoundingClientRect(),t=this.querySelector(".tooltip");t.style.display="inline-block",this.visible=!0,function(e,t){t.style.transform="translate(0, 0)";const i=t.getBoundingClientRect(),n=i.width,a=i.left,s=e.left,o=document.body.clientWidth-16,r=n>o?-a:s+n>o?o-(a+n):s-a,l=e.bottom-i.top+2;t.style.transform=`translate(${r}px, ${l}px)`}(e,t),document.addEventListener("keydown",this.keyDownClose),document.addEventListener("mousedown",this.mouseDownClose)}renderWithTooltip(e,t,i){const n=G`<div class="tooltip">${i}</div>`;return G`<span class=${e} tabindex=0>${n}${t}</span>`}}const ae=(e,t="Enter")=>e===t,se=(e,t="Escape")=>e===t;function oe(e){return(e||[]).map((({given:e,family:t})=>e?`${e.includes(".")?e:e[0]+"."} ${t}`:t))}function re(){this.querySelector(".cite-author-expand").style.display="none",this.querySelector(".cite-author-hidden").style.display="inline"}function le(){this.querySelector(".cite-author-expand").style.display="inline",this.querySelector(".cite-author-hidden").style.display="none"}const ce="tag";function de(e,t){if(t.className===ce)return;const i=t.cloneNode();if(i.id&&i.removeAttribute("id"),e.append(i),!pe(t))for(const e of t.childNodes)de(i,e)}const he={SECTION:"sec",FIGURE:"fig",TABLE:"tbl",EQUATION:"eqn"},ue=new Set(["CITE-REF","CODE-BLOCK","CROSS-REF","INLINE-NOTE","RANGE-TEXT","TEX-MATH"]),pe=e=>ue.has(e.tagName);let me=0;const fe=new Map,ge=[],ye=ge.map,ve=ge.some,be=ge.hasOwnProperty,we=/^((?:@[^/@]+\/)?[^/@]+)(?:@([^/]+))?(?:\/(.*))?$/,Se=/^\d+\.\d+\.\d+(-[\w-.+]+)?$/,Ae=/(?:\.[^/]*|\/)$/;class Ee extends Error{constructor(e){super(e)}}function $e(e){const t=we.exec(e);return t&&{name:t[1],version:t[2],path:t[3]}}Ee.prototype.name=Ee.name;var Ce=function e(t){const i=new Map,n=s(null);function a(e){if("string"!=typeof e)return e;let t=i.get(e);return t||i.set(e,t=new Promise(((t,i)=>{const n=document.createElement("script");n.onload=()=>{try{t(ge.pop()(s(e)))}catch(e){i(new Ee("invalid module"))}n.remove()},n.onerror=()=>{i(new Ee("unable to load module")),n.remove()},n.async=!0,n.src=e,window.define=xe,document.head.appendChild(n)}))),t}function s(e){return i=>Promise.resolve(t(i,e)).then(a)}function o(i){return e(((e,n)=>e in i&&(n=null,"string"!=typeof(e=i[e]))?e:t(e,n)))}function r(e){return arguments.length>1?Promise.all(ye.call(arguments,n)).then(_e):n(e)}return r.alias=o,r.resolve=t,r}(function(e="https://cdn.jsdelivr.net/npm/",t=["unpkg","jsdelivr","browser","main"]){if(!/\/$/.test(e))throw new Error("origin lacks trailing slash");function i(t){const i=`${e}${t.name}${t.version?`@${t.version}`:""}/package.json`;let n=fe.get(i);return n||fe.set(i,n=fetch(i).then((e=>{if(!e.ok)throw new Ee("unable to load package.json");return e.redirected&&!fe.has(e.url)&&fe.set(e.url,n),e.json()}))),n}return async function(n,a){if(n.startsWith(e)&&(n=n.substring(e.length)),/^(\w+:)|\/\//i.test(n))return n;if(/^[.]{0,2}\//i.test(n))return new URL(n,a??location).href;if(!n.length||/^[\s._]/.test(n)||/\s$/.test(n))throw new Ee("illegal name");const s=$e(n);if(!s)return`${e}${n}`;if(!s.version&&null!=a&&a.startsWith(e)){const t=await i($e(a.substring(e.length)));s.version=t.dependencies&&t.dependencies[s.name]||t.peerDependencies&&t.peerDependencies[s.name]}if(s.path&&!Ae.test(s.path)&&(s.path+=".js"),s.path&&s.version&&Se.test(s.version))return`${e}${s.name}@${s.version}/${s.path}`;const o=await i(s);return`${e}${o.name}@${o.version}/${s.path||function(e){for(const i of t){let t=e[i];if("string"==typeof t)return t.startsWith("./")&&(t=t.slice(2)),Ae.test(t)?t:`${t}.js`}}(o)||"index.js"}`}}());function _e(e){const t={};for(const i of e)for(const e in i)be.call(i,e)&&(null==i[e]?Object.defineProperty(t,e,{get:ke(i,e)}):t[e]=i[e]);return t}function ke(e,t){return()=>e[t]}function De(e){return"exports"===(e+="")||"module"===e}function xe(e,t,i){const n=arguments.length;n<2?(i=e,t=[]):n<3&&(i=t,t="string"==typeof e?[]:e),ge.push(ve.call(t,De)?e=>{const n={},a={exports:n};return Promise.all(ye.call(t,(t=>"exports"===(t+="")?n:"module"===t?a:e(t)))).then((e=>(i.apply(null,e),a.exports)))}:e=>Promise.all(ye.call(t,e)).then((e=>"function"==typeof i?i.apply(null,e):i)))}xe.amd={};const Me="dependencies",Te=Symbol("dependencies"),Ie=Symbol("load"),Pe=Promise.resolve(!0),Re=new Map;function Ge(e){let t="undefined"!=typeof HTMLElement&&e instanceof HTMLElement?e.constructor:e;for(;t&&!Object.hasOwn(t,Me);)if(t=Object.getPrototypeOf(t),t&&"HTMLElement"===t.name)return null;return t}function ze(e){const t=Ge(e);if(!t)return Pe;const i=t[Te]||(t[Te]={});if(i[Ie])return i[Ie];const n={main:[],css:[]},a=t[Me];return a.forEach((({name:t,version:i,main:a,css:s})=>{const o=function(e,t){return i=>`https://cdn.jsdelivr.net/npm/${e}@${t}/${i}`}(t,i),r=o(a),l=o(s),c=Re.get(r)||Ce(r);Re.set(r,c),n.main.push(c),s&&!Re.has(l)&&(Re.set(l,!0),n.css.push(function(e,t=globalThis.document){return new Promise((function(i,n){const a=t.createElement("link");a.rel="stylesheet",a.href=e,a.onerror=n,a.onload=i,t.head.appendChild(a)}))}(l,e.ownerDocument)))})),i[Ie]=Promise.all(n.main.concat(n.css)).then((e=>{const i=a.reduce(((t,i,n)=>(t[i.name]=e[n],t)),{});!function(e,t){const i=Ge(e);if(i){const e=i[Te]||(i[Te]={});for(const i in t)e[i]=t[i];e[Ie]=Pe}}(t,i)}))}class Oe extends ie{getDependency(e){return function(e,t){return Ge(e)?.[Te]?.[t]}(this,e)}shouldUpdate(){return!!function(e){const t=Ge(e);return!t||t[Te]?.[Ie]===Pe}(this)||(ze(this).then((()=>{this.requestUpdate()})),!1)}}class We extends Oe{static get dependencies(){return[{name:"katex",version:"0.15.3",module:"dist/katex.mjs",main:"dist/katex.min.js",css:"dist/katex.min.css"}]}static get properties(){return{mode:{type:String},code:{type:String},leqno:{type:Boolean},fleqn:{type:Boolean,converter:e=>"false"!==e},minRuleThickness:{type:Number}}}constructor(){super(),this.mode="display",this.leqno=!1,this.fleqn=!1}initialChildNodes(e){!this.hasAttribute("code")&&e.length&&(this.code=e[0].textContent)}prepareMath(){return this.code}render(){const e=this.getDependency("katex");if(!e||!this.code)return;const t="display"===this.mode,i={throwOnError:!1,displayMode:t,leqno:this.leqno,fleqn:this.fleqn,minRuleThickness:this.minRuleThickness},n=document.createElement(t?"div":"span");return e.render(this.prepareMath(),n,i),n}}document.querySelector("article").__data={citations:{bibtex:["@article{Bostock:2011,\n\tauthor = {Bostock, Michael and Ogievetsky, Vadim and Heer, Jeffrey},\n\tjournal = {IEEE Transactions on Visualization and Computer Graphics},\n\tnumber = {12},\n\tyear = {2011},\n\tpages = {2301--2309},\n\tpublisher = {IEEE},\n\ttitle = {D3: Data-{Driven} {Documents}},\n\tvolume = {17},\n}","@inproceedings{Bullman:2018,\n\tauthor = {Bullmann, M. and Fetzer, T. and Ebner, F. and Deinzer, F. and Grzegorzek, M.},\n\tbooktitle = {Proc. {International} {Conference} on {Information} {Fusion} ({FUSION})},\n\tyear = {2018},\n\tpages = {1233--1240},\n\ttitle = {Fast {Kernel} {Density} {Estimation} {Using} {Gaussian} {Filter} {Approximation}},\n}","@article{Correll:2014,\n\tauthor = {Correll, Michael and Gleicher, Michael},\n\tjournal = {IEEE Transactions on Visualization and Computer Graphics},\n\tnumber = {12},\n\tyear = {2014},\n\tpages = {2142--2151},\n\tpublisher = {IEEE},\n\ttitle = {Error {Bars} {Considered} {Harmful}: Exploring {Alternate} {Encodings} for {Mean} and {Error}},\n\tvolume = {20},\n}","@article{Deriche:1990,\n\tauthor = {Deriche, R.},\n\tjournal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n\tnumber = {1},\n\tyear = {1990},\n\tpages = {78--87},\n\ttitle = {Fast {Algorithms} for {Low}-{Level} {Vision}},\n\tvolume = {12},\n}","@techreport{Deriche:1993,\n\tauthor = {Deriche, R.},\n\tyear = {1993},\n\tinstitution = {INRIA},\n\ttitle = {Recursively implementing the {Gaussian} and its derivatives},\n\ttype = {techreport},\n}","@article{Getreuer:2013,\n\tauthor = {Getreuer, P.},\n\tjournal = {Image Processing On Line},\n\tyear = {2013},\n\tpages = {286--310},\n\ttitle = {A {Survey} of {Gaussian} {Convolution} {Algorithms}},\n\tvolume = {3},\n}","@inproceedings{Gray:2003,\n\tauthor = {Gray, Alexander G and Moore, Andrew W},\n\tbooktitle = {Proc. 2003 {SIAM} {International} {Conference} on {Data} {Mining}},\n\tyear = {2003},\n\tpages = {203--211},\n\ttitle = {Nonparametric density estimation: Toward computational tractability},\n}","@inproceedings{Gwosdek:2011,\n\tauthor = {Gwosdek, P. and Grewenig, S. and Bruhn, A. and Weickert, J.},\n\tbooktitle = {Proc. {International} {Conference} on {Scale} {Space} and {Variational} {Methods} in {Computer} {Vision}},\n\tyear = {2011},\n\tpages = {447--458},\n\ttitle = {Theoretical foundations of {Gaussian} convolution by extended box filtering},\n}","@article{Hintzel:1998,\n\tauthor = {Hintze, Jerry L and Nelson, Ray D},\n\tjournal = {The American Statistician},\n\tnumber = {2},\n\tyear = {1998},\n\tpages = {181--184},\n\tpublisher = {Taylor & Francis},\n\ttitle = {Violin {Plots}: A {Box} {Plot}-{Density} {Trace} {Synergism}},\n\tvolume = {52},\n}","@techreport{Horst:2020,\n\tauthor = {Horst, Allison Marie and Hill, Alison Presmanes and Gorman, Kristen B},\n\tyear = {2020},\n\tnote = {R package version 0.1.0},\n\ttitle = {palmerpenguins: Palmer {Archipelago} ({Antarctica}) penguin data},\n\thowpublished = {https://allisonhorst.github.io/palmerpenguins/},\n}","@article{Jones:1983,\n\tauthor = {Jones, M. C. and Lotwick, H. W.},\n\tjournal = {Journal of Statistical Computation and Simulation},\n\tnumber = {2},\n\tyear = {1983},\n\tpages = {133--149},\n\ttitle = {On the errors involved in computing the empirical characteristic function},\n\tvolume = {17},\n}","@article{Kindlmann:2014,\n\tauthor = {Kindlmann, Gordon and Scheidegger, Carlos},\n\tjournal = {IEEE Transactions on Visualization and Computer Graphics},\n\tnumber = {12},\n\tyear = {2014},\n\tpages = {2181--2190},\n\ttitle = {An {Algebraic} {Process} for {Visualization} {Design}},\n\tvolume = {20},\n}","@article{Lorensen:1987:MCA,\n\tauthor = {Lorensen, William E. and Cline, Harvey E.},\n\tjournal = {SIGGRAPH Computer Graphics},\n\tnumber = {4},\n\tyear = {1987},\n\tmonth = {8},\n\tpages = {163--169},\n\ttitle = {Marching {Cubes}: A {High} {Resolution} 3D {Surface} {Construction} {Algorithm}},\n\tvolume = {21},\n}","@article{Parzen:1962,\n\tauthor = {Parzen, Emanuel},\n\tjournal = {The Annals of Mathematical Statistics},\n\tnumber = {3},\n\tyear = {1962},\n\tpages = {1065 -- 1076},\n\tpublisher = {Institute of Mathematical Statistics},\n\ttitle = {On {Estimation} of a {Probability} {Density} {Function} and {Mode}},\n\tvolume = {33},\n}","@article{ScikitLearn,\n\tauthor = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n\tjournal = {Journal of Machine Learning Research},\n\tyear = {2011},\n\tpages = {2825--2830},\n\ttitle = {Scikit-learn: Machine {Learning} in {Python}},\n\tvolume = {12},\n}","@misc{CarsData,\n\tauthor = {Ramos, Ernesto and Donoho, David},\n\tyear = {1983},\n\tpublisher = {http://stat-computing.org/dataexpo/1983.html},\n\ttitle = {ASA {Data} {Exposition} {Dataset}},\n}","@article{Rosenblatt:1956,\n\tauthor = {Rosenblatt, Murray},\n\tjournal = {The Annals of Mathematical Statistics},\n\tnumber = {3},\n\tyear = {1956},\n\tpages = {832--837},\n\tpublisher = {Institute of Mathematical Statistics},\n\ttitle = {Remarks on {Some} {Nonparametric} {Estimates} of a {Density} {Function}},\n\tvolume = {27},\n}","@article{Satyanarayan:2015,\n\tauthor = {Satyanarayan, Arvind and Russell, Ryan and Hoffswell, Jane and Heer, Jeffrey},\n\tjournal = {IEEE Transactions on Visualization and Computer Graphics},\n\tnumber = {1},\n\tyear = {2015},\n\tpages = {659--668},\n\tpublisher = {IEEE},\n\ttitle = {Reactive {Vega}: A streaming dataflow architecture for declarative interactive visualization},\n\tvolume = {22},\n}","@article{Satyanarayan:2016,\n\tauthor = {Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat, Kanit and Heer, Jeffrey},\n\tjournal = {IEEE Transactions on Visualization and Computer Graphics},\n\tnumber = {1},\n\tyear = {2016},\n\tpages = {341--350},\n\tpublisher = {IEEE},\n\ttitle = {Vega-{Lite}: A grammar of interactive graphics},\n\tvolume = {23},\n}","@article{Scott:1985,\n\tauthor = {Scott, D. W. and Sheather, S. J.},\n\tjournal = {Communications in Statistics - Theory and Methods},\n\tnumber = {6},\n\tyear = {1985},\n\tpages = {1353--1359},\n\ttitle = {Kernel density estimation with binned data},\n\tvolume = {14},\n}","@book{Scott:1992,\n\tauthor = {Scott, David W},\n\tyear = {1992},\n\tpublisher = {John Wiley & Sons},\n\ttitle = {Multivariate {Density} {Estimation}: Theory, {Practice}, and {Visualization}},\n}","@article{Sheather:1991,\n\tauthor = {Sheather, S. J. and Jones, M. C.},\n\tjournal = {Journal of the Royal Statistical Society, Series B (Methodological)},\n\tnumber = {3},\n\tyear = {1991},\n\tpages = {683--690},\n\ttitle = {A reliable data-based bandwidth selection method for kernel density estimation},\n\tvolume = {53},\n}","@article{Silverman:1982,\n\tauthor = {Silverman, B. W.},\n\tjournal = {Journal of the Royal Statistical Society, Series C (Applied Statistics)},\n\tnumber = {1},\n\tyear = {1982},\n\tpages = {93--99},\n\ttitle = {Algorithm {AS} 176: Kernel density estimation using the fast {Fourier} transform},\n\tvolume = {31},\n}","@book{MASS:2002,\n\tauthor = {Venables, W. N. and Ripley, B. D.},\n\tyear = {2002},\n\tpublisher = {Springer},\n\ttitle = {Modern applied statistics with {S}},\n}","@article{Wand:1994,\n\tauthor = {Wand, M. P.},\n\tjournal = {Journal of Statistical Computation and Simulation},\n\tnumber = {4},\n\tyear = {1994},\n\tpages = {433--445},\n\ttitle = {Fast {Computation} of {Multivariate} {Kernel} {Estimators}},\n\tvolume = {3},\n}","@article{Wells:1986,\n\tauthor = {Wells, W. M.},\n\tjournal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n\tnumber = {2},\n\tyear = {1986},\n\tpages = {234--239},\n\ttitle = {Efficient synthesis of {Gaussian} filters by cascaded uniform filters},\n\tvolume = {8},\n}","@book{Wickham:2009,\n\tauthor = {Wickham, Hadley},\n\tyear = {2009},\n\tpublisher = {Springer},\n\ttitle = {ggplot2: Elegant {Graphics} for {Data} {Analysis}},\n}"],csl:[{"container-title":"IEEE Transactions on Visualization and Computer Graphics",author:[{given:"Michael",family:"Bostock"},{given:"Vadim",family:"Ogievetsky"},{given:"Jeffrey",family:"Heer"}],DOI:"10.1109/TVCG.2011.185",type:"article-journal",id:"Bostock:2011","citation-key":"Bostock:2011",issue:"12",issued:{"date-parts":[[2011]]},page:"2301-2309",publisher:"IEEE",title:"D3: Data-Driven Documents",volume:"17"},{author:[{given:"M.",family:"Bullmann"},{given:"T.",family:"Fetzer"},{given:"F.",family:"Ebner"},{given:"F.",family:"Deinzer"},{given:"M.",family:"Grzegorzek"}],"container-title":"Proc. International Conference on Information Fusion (FUSION)",DOI:"10.23919/ICIF.2018.8455686",type:"paper-conference",id:"Bullman:2018","citation-key":"Bullman:2018",issued:{"date-parts":[[2018]]},page:"1233-1240",title:"Fast Kernel Density Estimation Using Gaussian Filter Approximation"},{"container-title":"IEEE Transactions on Visualization and Computer Graphics",author:[{given:"Michael",family:"Correll"},{given:"Michael",family:"Gleicher"}],DOI:"10.1109/TVCG.2014.2346298",type:"article-journal",id:"Correll:2014","citation-key":"Correll:2014",issue:"12",issued:{"date-parts":[[2014]]},page:"2142-2151",publisher:"IEEE",title:"Error Bars Considered Harmful: Exploring Alternate Encodings for Mean and Error",volume:"20"},{"container-title":"IEEE Transactions on Pattern Analysis and Machine Intelligence",author:[{given:"R.",family:"Deriche"}],DOI:"10.1109/34.41386",type:"article-journal",id:"Deriche:1990","citation-key":"Deriche:1990",issue:"1",issued:{"date-parts":[[1990]]},page:"78-87",title:"Fast Algorithms for Low-Level Vision",volume:"12"},{author:[{given:"R.",family:"Deriche"}],type:"report",genre:"techreport",id:"Deriche:1993","citation-key":"Deriche:1993",issued:{"date-parts":[[1993]]},publisher:"INRIA",title:"Recursively implementing the Gaussian and its derivatives",URL:"http://hal.inria.fr/docs/00/07/47/78/PDF/RR-1893.svg"},{"container-title":"Image Processing On Line",author:[{given:"P.",family:"Getreuer"}],DOI:"10.5201/ipol.2013.87",type:"article-journal",id:"Getreuer:2013","citation-key":"Getreuer:2013",issued:{"date-parts":[[2013]]},page:"286-310",title:"A Survey of Gaussian Convolution Algorithms",volume:"3"},{author:[{given:"Alexander G",family:"Gray"},{given:"Andrew W",family:"Moore"}],"container-title":"Proc. 2003 SIAM International Conference on Data Mining",DOI:"10.1137/1.9781611972733.19",type:"paper-conference",id:"Gray:2003","citation-key":"Gray:2003",issued:{"date-parts":[[2003]]},page:"203-211",title:"Nonparametric density estimation: Toward computational tractability"},{author:[{given:"P.",family:"Gwosdek"},{given:"S.",family:"Grewenig"},{given:"A.",family:"Bruhn"},{given:"J.",family:"Weickert"}],"container-title":"Proc. International Conference on Scale Space and Variational Methods in Computer Vision",DOI:"10.1007/978-3-642-24785-9_38",type:"paper-conference",id:"Gwosdek:2011","citation-key":"Gwosdek:2011",issued:{"date-parts":[[2011]]},page:"447-458",title:"Theoretical foundations of Gaussian convolution by extended box filtering"},{"container-title":"The American Statistician",author:[{given:"Jerry L",family:"Hintze"},{given:"Ray D",family:"Nelson"}],DOI:"10.1080/00031305.1998.10480559",type:"article-journal",id:"Hintzel:1998","citation-key":"Hintzel:1998",issue:"2",issued:{"date-parts":[[1998]]},page:"181-184",publisher:"Taylor & Francis",title:"Violin Plots: A Box Plot-Density Trace Synergism",volume:"52"},{author:[{given:"Allison Marie",family:"Horst"},{given:"Alison Presmanes",family:"Hill"},{given:"Kristen B",family:"Gorman"}],DOI:"10.5281/zenodo.3960218",type:"report",id:"Horst:2020","citation-key":"Horst:2020",issued:{"date-parts":[[2020]]},note:"R package version 0.1.0",title:"palmerpenguins: Palmer Archipelago (Antarctica) penguin data",URL:"https://allisonhorst.github.io/palmerpenguins/"},{"container-title":"Journal of Statistical Computation and Simulation",author:[{given:"M. C.",family:"Jones"},{given:"H. W.",family:"Lotwick"}],DOI:"10.1080/00949658308810650",type:"article-journal",id:"Jones:1983","citation-key":"Jones:1983",issue:"2",issued:{"date-parts":[[1983]]},page:"133-149",title:"On the errors involved in computing the empirical characteristic function",volume:"17"},{"container-title":"IEEE Transactions on Visualization and Computer Graphics",author:[{given:"Gordon",family:"Kindlmann"},{given:"Carlos",family:"Scheidegger"}],DOI:"10.1109/TVCG.2014.2346325",type:"article-journal",id:"Kindlmann:2014","citation-key":"Kindlmann:2014",issue:"12",issued:{"date-parts":[[2014]]},page:"2181-2190",title:"An Algebraic Process for Visualization Design",volume:"20"},{"container-title":"SIGGRAPH Computer Graphics",author:[{given:"William E.",family:"Lorensen"},{given:"Harvey E.",family:"Cline"}],DOI:"10.1145/37402.37422",type:"article-journal",id:"Lorensen:1987:MCA","citation-key":"Lorensen:1987:MCA",issue:"4",issued:{"date-parts":[[1987,8]]},page:"163-169",title:"Marching Cubes: A High Resolution 3D Surface Construction Algorithm",volume:"21"},{"container-title":"The Annals of Mathematical Statistics",author:[{given:"Emanuel",family:"Parzen"}],DOI:"10.1214/aoms/1177704472",type:"article-journal",id:"Parzen:1962","citation-key":"Parzen:1962",issue:"3",issued:{"date-parts":[[1962]]},page:"1065 - 1076",publisher:"Institute of Mathematical Statistics",title:"On Estimation of a Probability Density Function and Mode",volume:"33"},{"container-title":"Journal of Machine Learning Research",author:[{given:"F.",family:"Pedregosa"},{given:"G.",family:"Varoquaux"},{given:"A.",family:"Gramfort"},{given:"V.",family:"Michel"},{given:"B.",family:"Thirion"},{given:"O.",family:"Grisel"},{given:"M.",family:"Blondel"},{given:"P.",family:"Prettenhofer"},{given:"R.",family:"Weiss"},{given:"V.",family:"Dubourg"},{given:"J.",family:"Vanderplas"},{given:"A.",family:"Passos"},{given:"D.",family:"Cournapeau"},{given:"M.",family:"Brucher"},{given:"M.",family:"Perrot"},{given:"E.",family:"Duchesnay"}],DOI:"10.5555/1953048.2078195",type:"article-journal",id:"ScikitLearn","citation-key":"ScikitLearn",issued:{"date-parts":[[2011]]},page:"2825-2830",title:"Scikit-learn: Machine Learning in Python",volume:"12"},{author:[{given:"Ernesto",family:"Ramos"},{given:"David",family:"Donoho"}],type:"document",id:"CarsData","citation-key":"CarsData",issued:{"date-parts":[[1983]]},publisher:"http://stat-computing.org/dataexpo/1983.html",title:"ASA Data Exposition Dataset",URL:"http://stat-computing.org/dataexpo/1983.html"},{"container-title":"The Annals of Mathematical Statistics",author:[{given:"Murray",family:"Rosenblatt"}],DOI:"10.1214/aoms/1177728190",type:"article-journal",id:"Rosenblatt:1956","citation-key":"Rosenblatt:1956",issue:"3",issued:{"date-parts":[[1956]]},page:"832-837",publisher:"Institute of Mathematical Statistics",title:"Remarks on Some Nonparametric Estimates of a Density Function",volume:"27"},{"container-title":"IEEE Transactions on Visualization and Computer Graphics",author:[{given:"Arvind",family:"Satyanarayan"},{given:"Ryan",family:"Russell"},{given:"Jane",family:"Hoffswell"},{given:"Jeffrey",family:"Heer"}],DOI:"10.1109/TVCG.2015.2467091",type:"article-journal",id:"Satyanarayan:2015","citation-key":"Satyanarayan:2015",issue:"1",issued:{"date-parts":[[2015]]},page:"659-668",publisher:"IEEE",title:"Reactive Vega: A streaming dataflow architecture for declarative interactive visualization",volume:"22"},{"container-title":"IEEE Transactions on Visualization and Computer Graphics",author:[{given:"Arvind",family:"Satyanarayan"},{given:"Dominik",family:"Moritz"},{given:"Kanit",family:"Wongsuphasawat"},{given:"Jeffrey",family:"Heer"}],DOI:"10.1109/TVCG.2016.2599030",type:"article-journal",id:"Satyanarayan:2016","citation-key":"Satyanarayan:2016",issue:"1",issued:{"date-parts":[[2016]]},page:"341-350",publisher:"IEEE",title:"Vega-Lite: A grammar of interactive graphics",volume:"23"},{"container-title":"Communications in Statistics - Theory and Methods",author:[{given:"D. W.",family:"Scott"},{given:"S. J.",family:"Sheather"}],DOI:"10.1080/03610928508828980",type:"article-journal",id:"Scott:1985","citation-key":"Scott:1985",issue:"6",issued:{"date-parts":[[1985]]},page:"1353-1359",title:"Kernel density estimation with binned data",volume:"14"},{author:[{given:"David W",family:"Scott"}],DOI:"10.1002/9780470316849",type:"book",id:"Scott:1992","citation-key":"Scott:1992",issued:{"date-parts":[[1992]]},publisher:"John Wiley & Sons",title:"Multivariate Density Estimation: Theory, Practice, and Visualization"},{"container-title":"Journal of the Royal Statistical Society, Series B (Methodological)",author:[{given:"S. J.",family:"Sheather"},{given:"M. C.",family:"Jones"}],DOI:"10.1111/j.2517-6161.1991.tb01857.x",type:"article-journal",id:"Sheather:1991","citation-key":"Sheather:1991",issue:"3",issued:{"date-parts":[[1991]]},page:"683-690",title:"A reliable data-based bandwidth selection method for kernel density estimation",volume:"53"},{"container-title":"Journal of the Royal Statistical Society, Series C (Applied Statistics)",author:[{given:"B. W.",family:"Silverman"}],DOI:"10.2307/2347084",type:"article-journal",id:"Silverman:1982","citation-key":"Silverman:1982",issue:"1",issued:{"date-parts":[[1982]]},page:"93-99",title:"Algorithm AS 176: Kernel density estimation using the fast Fourier transform",volume:"31"},{author:[{given:"W. N.",family:"Venables"},{given:"B. D.",family:"Ripley"}],DOI:"10.1007/978-0-387-21706-2",type:"book",id:"MASS:2002","citation-key":"MASS:2002",issued:{"date-parts":[[2002]]},publisher:"Springer",title:"Modern applied statistics with S"},{"container-title":"Journal of Statistical Computation and Simulation",author:[{given:"M. P.",family:"Wand"}],DOI:"10.2307/1390904",type:"article-journal",id:"Wand:1994","citation-key":"Wand:1994",issue:"4",issued:{"date-parts":[[1994]]},page:"433-445",title:"Fast Computation of Multivariate Kernel Estimators",volume:"3"},{"container-title":"IEEE Transactions on Pattern Analysis and Machine Intelligence",author:[{given:"W. M.",family:"Wells"}],DOI:"10.1109/TPAMI.1986.4767776",type:"article-journal",id:"Wells:1986","citation-key":"Wells:1986",issue:"2",issued:{"date-parts":[[1986]]},page:"234-239",title:"Efficient synthesis of Gaussian filters by cascaded uniform filters",volume:"8"},{author:[{given:"Hadley",family:"Wickham"}],DOI:"10.1007/978-0-387-98141-3",type:"book",id:"Wickham:2009","citation-key":"Wickham:2009",issued:{"date-parts":[[2009]]},publisher:"Springer",title:"ggplot2: Elegant Graphics for Data Analysis"}],data:[{id:"Bostock:2011",doi:"10.1109/TVCG.2011.185",s2id:"4f9630d72ae64e50b2cc110e7b10834e965e86fe",year:2011,author:[{given:"Michael",family:"Bostock"},{given:"Vadim",family:"Ogievetsky"},{given:"Jeffrey",family:"Heer"}],title:"D3: Data-Driven Documents",venue:"IEEE Transactions on Visualization and Computer Graphics",url:"https://www.semanticscholar.org/paper/4f9630d72ae64e50b2cc110e7b10834e965e86fe",abstract:"Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.",tldr:"This work shows how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components."},{id:"Bullman:2018",doi:"10.23919/ICIF.2018.8455686",s2id:"fdec11d4cf92e9ab353dc9374fe62287b76b0ba2",year:2018,author:[{given:"M.",family:"Bullmann"},{given:"T.",family:"Fetzer"},{given:"F.",family:"Ebner"},{given:"F.",family:"Deinzer"},{given:"M.",family:"Grzegorzek"}],title:"Fast Kernel Density Estimation Using Gaussian Filter Approximation",venue:"Proc. International Conference on Information Fusion (FUSION)",url:"https://www.semanticscholar.org/paper/fdec11d4cf92e9ab353dc9374fe62287b76b0ba2",abstract:"It is common practice to use a sample-based representation to solve problems having a probabilistic interpretation. In many real world scenarios one is then interested in finding a best estimate of the underlying problem, e.g. the position of a robot. This is often done by means of simple parametric point estimators, providing the sample statistics. However, in complex scenarios this frequently results in a poor representation, due to multimodal densities and limited sample sizes. Recovering the probability density function using a kernel density estimation yields a promising approach to solve the state estimation problem i. e. finding the “real” most probable state, but comes with high computational costs. Especially in time critical and time sequential scenarios, this turns out to be impractical. Therefore, this work uses techniques from digital signal processing in the context of estimation theory, to allow rapid computations of kernel density estimates. The gains in computational efficiency are realized by substituting the Gaussian filter with an approximate filter based on the box filter. Our approach outperforms other state of the art solutions, due to a fully linear complexity and a negligible overhead, even for small sample sets. Finally, our findings are evaluated and tested within a real world sensor fusion system.",tldr:"This work uses techniques from digital signal processing in the context of estimation theory, to allow rapid computations of kernel density estimates, and outperforms other state of the art solutions, due to a fully linear complexity and a negligible overhead, even for small sample sets."},{id:"Correll:2014",doi:"10.1109/TVCG.2014.2346298",s2id:"074ec716e8c481514f0c15e2714306b444dda0a1",year:2014,author:[{given:"Michael",family:"Correll"},{given:"Michael",family:"Gleicher"}],title:"Error Bars Considered Harmful: Exploring Alternate Encodings for Mean and Error",venue:"IEEE Transactions on Visualization and Computer Graphics",url:"https://www.semanticscholar.org/paper/074ec716e8c481514f0c15e2714306b444dda0a1",abstract:"When making an inference or comparison with uncertain, noisy, or incomplete data, measurement error and confidence intervals can be as important for judgment as the actual mean values of different groups. These often misunderstood statistical quantities are frequently represented by bar charts with error bars. This paper investigates drawbacks with this standard encoding, and considers a set of alternatives designed to more effectively communicate the implications of mean and error data to a general audience, drawing from lessons learned from the use of visual statistics in the information visualization community. We present a series of crowd-sourced experiments that confirm that the encoding of mean and error significantly changes how viewers make decisions about uncertain data. Careful consideration of design tradeoffs in the visual presentation of data results in human reasoning that is more consistently aligned with statistical inferences. We suggest the use of gradient plots (which use transparency to encode uncertainty) and violin plots (which use width) as better alternatives for inferential tasks than bar charts with error bars.",tldr:"It is confirmed that the encoding of mean and error significantly changes how viewers make decisions about uncertain data, and the use of gradient plots and violin plots are suggested as better alternatives for inferential tasks than bar charts with error bars."},{id:"Deriche:1990",doi:"10.1109/34.41386",year:1990,author:[{given:"R.",family:"Deriche"}],title:"Fast Algorithms for Low-Level Vision",venue:"IEEE Transactions on Pattern Analysis and Machine Intelligence"},{id:"Deriche:1993",year:1993,author:[{given:"R.",family:"Deriche"}],title:"Recursively implementing the Gaussian and its derivatives",url:"http://hal.inria.fr/docs/00/07/47/78/PDF/RR-1893.svg"},{id:"Getreuer:2013",doi:"10.5201/ipol.2013.87",s2id:"f99649f6002ad57110bd5d3db93fa335924edc24",year:2013,author:[{given:"P.",family:"Getreuer"}],title:"A Survey of Gaussian Convolution Algorithms",venue:"Image Processing On Line",url:"https://www.semanticscholar.org/paper/f99649f6002ad57110bd5d3db93fa335924edc24",abstract:"Gaussian convolution is a common operation and building block for algorithms in signal and image processing. Consequently, its ecient computation is important, and many fast approximations have been proposed. In this survey, we discuss approximate Gaussian convolution based on nite impulse response lters, DFT and DCT based convolution, box lters, and several recursive lters. Since boundary handling is sometimes overlooked in the original works, we pay particular attention to develop it here. We perform numerical experiments to compare the speed and quality of the algorithms.",tldr:"This survey discusses approximate Gaussian convolution based on nite impulse response lters, DFT and DCT based convolution, box lter, and several recursive lters and pays particular attention to boundary handling."},{id:"Gray:2003",doi:"10.1137/1.9781611972733.19",s2id:"7550b1c4abfd8fb046847f20cac360217057c47a",year:2003,author:[{given:"Alexander G",family:"Gray"},{given:"Andrew W",family:"Moore"}],title:"Nonparametric density estimation: Toward computational tractability",venue:"Proc. 2003 SIAM International Conference on Data Mining",url:"https://www.semanticscholar.org/paper/7550b1c4abfd8fb046847f20cac360217057c47a",abstract:"Density estimation is a core operation of virtually all probabilistic learning methods (as opposed to discriminative methods). Approaches to density estimation can be divided into two principal classes, parametric methods, such as Bayesian networks, and nonparametric methods such as kernel density estimation and smoothing splines. While neither choice should be universally preferred for all situations, a well-known benefit of nonparametric methods is their ability to achieve estimation optimality for ANY input distribution as more data are observed, a property that no model with a parametric assumption can have, and one of great importance in exploratory data analysis and mining where the underlying distribution is decidedly unknown. To date, however, despite a wealth of advanced underlying statistical theory, the use of nonparametric methods has been limited by their computational intractibility for all but the smallest datasets. In this paper, we present an algorithm for kernel density estimation, the chief nonparametric approach, which is dramatically faster than previous algorithmic approaches in terms of both dataset size and dimensionality. Furthermore, the algorithm provides arbitrarily tight accuracy guarantees, provides anytime convergence, works for all common kernel choices, and requires no parameter tuning. The algorithm is an instance of a new principle of algorithm design: multi-recursion, or higher-order",tldr:"This paper presents an algorithm for kernel density estimation, the chief nonparametric approach, which is dramatically faster than previous algorithmic approaches in terms of both dataset size and dimensionality and is an instance of a new principle of algorithm design: multi-recursion, or higher-order algorithm design."},{id:"Gwosdek:2011",doi:"10.1007/978-3-642-24785-9_38",s2id:"9be62834011856487dbd5368d276b78ba7c652d9",year:2011,author:[{given:"P.",family:"Gwosdek"},{given:"S.",family:"Grewenig"},{given:"A.",family:"Bruhn"},{given:"J.",family:"Weickert"}],title:"Theoretical foundations of Gaussian convolution by extended box filtering",venue:"Proc. International Conference on Scale Space and Variational Methods in Computer Vision",url:"https://www.semanticscholar.org/paper/9be62834011856487dbd5368d276b78ba7c652d9",tldr:null},{id:"Hintzel:1998",doi:"10.1080/00031305.1998.10480559",s2id:"c7ae5fd1d068fae58a0f7d2a5b572638db74c7fc",year:1998,author:[{given:"Jerry L",family:"Hintze"},{given:"Ray D",family:"Nelson"}],title:"Violin Plots: A Box Plot-Density Trace Synergism",venue:"The American Statistician",url:"https://www.semanticscholar.org/paper/c7ae5fd1d068fae58a0f7d2a5b572638db74c7fc",abstract:"Abstract Many modifications build on Tukey's original box plot. A proposed further adaptation, the violin plot, pools the best statistical features of alternative graphical representations of batches of data. It adds the information available from local density estimates to the basic summary statistics inherent in box plots. This marriage of summary statistics and density shape into a single plot provides a useful tool for data analysis and exploration.",tldr:"A proposed further adaptation, the violin plot, pools the best statistical features of alternative graphical representations of batches of data and adds the information available from local density estimates to the basic summary statistics inherent in box plots."},{id:"Horst:2020",doi:"10.5281/zenodo.3960218",s2id:"d7fdefbfa895658a360efc3458721e95e6dcf861",year:2020,author:[{given:"Allison Marie",family:"Horst"},{given:"Alison Presmanes",family:"Hill"},{given:"Kristen B",family:"Gorman"}],title:"palmerpenguins: Palmer Archipelago (Antarctica) penguin data",url:"https://allisonhorst.github.io/palmerpenguins/"},{id:"Jones:1983",doi:"10.1080/00949658308810650",s2id:"22cd4524838f5e06b809374b6bca24ba947b1607",year:1983,author:[{given:"M. C.",family:"Jones"},{given:"H. W.",family:"Lotwick"}],title:"On the errors involved in computing the empirical characteristic function",venue:"Journal of Statistical Computation and Simulation",url:"https://www.semanticscholar.org/paper/22cd4524838f5e06b809374b6bca24ba947b1607",abstract:"This paper considers discretisation errors involved in using the Fast Fourier Transform to compute the empirical characteristic function efficiently. A simple improvement to the usual histogram discretisation scheme is shown to reduce the mean square error considerably, as the grid size tends to zero. Simulation results show that the improvement is just as good in practical cases. The theoretical results are applied to the efficient calculation of kernel density estimates, described in Silverman (1982).",tldr:"A simple improvement to the usual histogram discretisation scheme is shown to reduce the mean square error considerably, as the grid size tends to zero."},{id:"Kindlmann:2014",doi:"10.1109/TVCG.2014.2346325",s2id:"847976a5526bbdf2f9995121e1d71de81edae776",year:2014,author:[{given:"Gordon",family:"Kindlmann"},{given:"Carlos",family:"Scheidegger"}],title:"An Algebraic Process for Visualization Design",venue:"IEEE Transactions on Visualization and Computer Graphics",url:"https://www.semanticscholar.org/paper/847976a5526bbdf2f9995121e1d71de81edae776",abstract:"We present a model of visualization design based on algebraic considerations of the visualization process. The model helps characterize visual encodings, guide their design, evaluate their effectiveness, and highlight their shortcomings. The model has three components: the underlying mathematical structure of the data or object being visualized, the concrete representation of the data in a computer, and (to the extent possible) a mathematical description of how humans perceive the visualization. Because we believe the value of our model lies in its practical application, we propose three general principles for good visualization design. We work through a collection of examples where our model helps explain the known properties of existing visualizations methods, both good and not-so-good, as well as suggesting some novel methods. We describe how to use the model alongside experimental user studies, since it can help frame experiment outcomes in an actionable manner. Exploring the implications and applications of our model and its design principles should provide many directions for future visualization research.",tldr:"A model of visualization design based on algebraic considerations of the visualization process, which helps characterize visual encodings, guide their design, evaluate their effectiveness, and highlight their shortcomings is presented."},{id:"Lorensen:1987:MCA",doi:"10.1145/37402.37422",year:1987,author:[{given:"William E.",family:"Lorensen"},{given:"Harvey E.",family:"Cline"}],title:"Marching Cubes: A High Resolution 3D Surface Construction Algorithm",venue:"SIGGRAPH Computer Graphics"},{id:"Parzen:1962",doi:"10.1214/aoms/1177704472",s2id:"de28c165623adabcdba0fdb18b65eba685aaf31d",year:1962,author:[{given:"Emanuel",family:"Parzen"}],title:"On Estimation of a Probability Density Function and Mode",venue:"The Annals of Mathematical Statistics",url:"https://www.semanticscholar.org/paper/de28c165623adabcdba0fdb18b65eba685aaf31d",abstract:"Abstract : Given a sequence of independent identically distributed random variables with a common probability density function, the problem of the estimation of a probability density function and of determining the mode of a probability function are discussed. Only estimates which are consistent and asymptotically normal are constructed. (Author)"},{id:"ScikitLearn",doi:"10.5555/1953048.2078195",s2id:"168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74",year:2011,author:[{given:"F.",family:"Pedregosa"},{given:"G.",family:"Varoquaux"},{given:"A.",family:"Gramfort"},{given:"V.",family:"Michel"},{given:"B.",family:"Thirion"},{given:"O.",family:"Grisel"},{given:"M.",family:"Blondel"},{given:"P.",family:"Prettenhofer"},{given:"R.",family:"Weiss"},{given:"V.",family:"Dubourg"},{given:"J.",family:"Vanderplas"},{given:"A.",family:"Passos"},{given:"D.",family:"Cournapeau"},{given:"M.",family:"Brucher"},{given:"M.",family:"Perrot"},{given:"E.",family:"Duchesnay"}],title:"Scikit-learn: Machine Learning in Python",venue:"Journal of Machine Learning Research",url:"https://www.semanticscholar.org/paper/168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74",abstract:"Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.",tldr:"Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems, focusing on bringing machine learning to non-specialists using a general-purpose high-level language."},{id:"CarsData",year:1983,author:[{given:"Ernesto",family:"Ramos"},{given:"David",family:"Donoho"}],title:"ASA Data Exposition Dataset",url:"http://stat-computing.org/dataexpo/1983.html"},{id:"Rosenblatt:1956",doi:"10.1214/aoms/1177728190",s2id:"2c455f0da2bd86a9b9ea432d1485049073d7c63d",year:1956,author:[{given:"Murray",family:"Rosenblatt"}],title:"Remarks on Some Nonparametric Estimates of a Density Function",venue:"The Annals of Mathematical Statistics",url:"https://www.semanticscholar.org/paper/2c455f0da2bd86a9b9ea432d1485049073d7c63d",abstract:"1. Summary. This note discusses some aspects of the estimation of the density function of a univariate probability distribution. All estimates of the density function satisfying relatively mild conditions are shown to be biased. The asymp­ totic mean square error of a particular class of estimates is evaluated."},{id:"Satyanarayan:2015",doi:"10.1109/TVCG.2015.2467091",s2id:"bab31ef6c37d54f0e1aa4666f0ccd4243354eb8f",year:2016,author:[{given:"Arvind",family:"Satyanarayan"},{given:"Ryan",family:"Russell"},{given:"Jane",family:"Hoffswell"},{given:"Jeffrey",family:"Heer"}],title:"Reactive Vega: A streaming dataflow architecture for declarative interactive visualization",venue:"IEEE Transactions on Visualization and Computer Graphics",url:"https://www.semanticscholar.org/paper/bab31ef6c37d54f0e1aa4666f0ccd4243354eb8f",abstract:"We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.",tldr:"Reactive Vega is presented, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization and the results of benchmark studies indicate superior interactive performance to both D3 and the original, non-reactive Vega system."},{id:"Satyanarayan:2016",doi:"10.1109/TVCG.2016.2599030",s2id:"f3b851991e3490384100a2743aa800606990daeb",year:2018,author:[{given:"Arvind",family:"Satyanarayan"},{given:"Dominik",family:"Moritz"},{given:"Kanit",family:"Wongsuphasawat"},{given:"Jeffrey",family:"Heer"}],title:"Vega-Lite: A grammar of interactive graphics",venue:"IEEE Transactions on Visualization and Computer Graphics",url:"https://www.semanticscholar.org/paper/f3b851991e3490384100a2743aa800606990daeb",abstract:"We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.",tldr:"Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction, that enables rapid specification of interactive data visualizations."},{id:"Scott:1985",doi:"10.1080/03610928508828980",s2id:"6bc7aa121a15bae1ca300e745b39a7392a510cc0",year:1985,author:[{given:"D. W.",family:"Scott"},{given:"S. J.",family:"Sheather"}],title:"Kernel density estimation with binned data",venue:"Communications in Statistics - Theory and Methods",url:"https://www.semanticscholar.org/paper/6bc7aa121a15bae1ca300e745b39a7392a510cc0",abstract:"Continuous data are often measured or used in binned or rounded form. In this paper we follow up on Hall's work analyzing the effect of using equally-spaced binned data in a kernel density estimator. It is shown that a surprisingly large amount of binning does not adversely affect the integrated mean squared error of a kernel estimate.",tldr:"It is shown that a surprisingly large amount of binning does not adversely affect the integrated mean squared error of a kernel estimate."},{id:"Scott:1992",doi:"10.1002/9780470316849",s2id:"6908b1db05f73a6d5d7fe70b8c577d8bf6df3c91",year:1992,author:[{given:"David W",family:"Scott"}],title:"Multivariate Density Estimation: Theory, Practice, and Visualization",venue:"Wiley Series in Probability and Statistics",url:"https://www.semanticscholar.org/paper/6908b1db05f73a6d5d7fe70b8c577d8bf6df3c91"},{id:"Sheather:1991",doi:"10.1111/j.2517-6161.1991.tb01857.x",s2id:"738f063d62eb02e41872679ea76e5c5a1553ff92",year:1991,author:[{given:"S. J.",family:"Sheather"},{given:"M. C.",family:"Jones"}],title:"A reliable data-based bandwidth selection method for kernel density estimation",venue:"Journal of the Royal Statistical Society, Series B (Methodological)",url:"https://www.semanticscholar.org/paper/738f063d62eb02e41872679ea76e5c5a1553ff92",abstract:"We present a new method for data-based selection of the bandwidth in kernel density estimation which has excellent properties. It improves on a recent procedure of Park and Marron (which itself is a good method) in various ways. First, the new method has superior theoretical performance; second, it also has a computational advantage; third, the new method has reliably good performance for smooth densities in simulations, performance that is second to none in the existing literature. These methods are based on choosing the bandwidth to (approximately) minimize good quality estimates of the mean integrated squared error. The key to the success of the current procedure is the reintroduction of a non- stochastic term which was previously omitted together with use of the bandwidth to reduce bias in estimation without inflating variance.",tldr:"The key to the success of the current procedure is the reintroduction of a non- stochastic term which was previously omitted together with use of the bandwidth to reduce bias in estimation without inflating variance."},{id:"Silverman:1982",doi:"10.2307/2347084",s2id:"ac387b2a1837a5aa294021900b664c4feeeb9cf9",year:1982,author:[{given:"B. W.",family:"Silverman"}],title:"Algorithm AS 176: Kernel density estimation using the fast Fourier transform",venue:"Journal of the Royal Statistical Society, Series C (Applied Statistics)",url:"https://www.semanticscholar.org/paper/ac387b2a1837a5aa294021900b664c4feeeb9cf9"},{id:"MASS:2002",doi:"10.1007/978-0-387-21706-2",s2id:"e31606c0cdb2b2cf1a8c749dd71402053b8f2b12",year:2010,author:[{given:"W. N.",family:"Venables"},{given:"B. D.",family:"Ripley"}],title:"Modern applied statistics with S",url:"https://www.semanticscholar.org/paper/e31606c0cdb2b2cf1a8c749dd71402053b8f2b12",tldr:"A guide to using S environments to perform statistical analyses providing both an introduction to the use of S and a course in modern statistical methods."},{id:"Wand:1994",doi:"10.2307/1390904",year:1994,author:[{given:"M. P.",family:"Wand"}],title:"Fast Computation of Multivariate Kernel Estimators",venue:"Journal of Statistical Computation and Simulation"},{id:"Wells:1986",doi:"10.1109/TPAMI.1986.4767776",s2id:"305b55e2fef5679878313933c1bf4ee0251ce53c",year:1986,author:[{given:"W. M.",family:"Wells"}],title:"Efficient synthesis of Gaussian filters by cascaded uniform filters",venue:"IEEE Transactions on Pattern Analysis and Machine Intelligence",url:"https://www.semanticscholar.org/paper/305b55e2fef5679878313933c1bf4ee0251ce53c",abstract:"Gaussian filtering is an important tool in image processing and computer vision. In this paper we discuss the background of Gaussian filtering and look at some methods for implementing it. Consideration of the central limit theorem suggests using a cascade of ``simple'' filters as a means of computing Gaussian filters. Among ``simple'' filters, uniform-coefficient finite-impulse-response digital filters are especially economical to implement. The idea of cascaded uniform filters has been around for a while [13], [16]. We show that this method is economical to implement, has good filtering characteristics, and is appropriate for hardware implementation. We point out an equivalence to one of Burt's methods [1], [3] under certain circumstances. As an extension, we describe an approach to implementing a Gaussian Pyramid which requires approximately two addition operations per pixel, per level, per dimension. We examine tradeoffs in choosing an algorithm for Gaussian filtering, and finally discuss an implementation.",tldr:"This paper describes an approach to implementing a Gaussian Pyramid which requires approximately two addition operations per pixel, per level, per dimension, and examines tradeoffs in choosing an algorithm for Gaussian filtering."},{id:"Wickham:2009",doi:"10.1007/978-0-387-98141-3",year:2009,author:[{given:"Hadley",family:"Wickham"}],title:"ggplot2: Elegant Graphics for Data Analysis"}]}},window.customElements.define("cite-ref",class extends ne{static get properties(){return{key:{type:String},mode:{type:String},index:{type:Number}}}constructor(){super(),this.mode="citation"}initialChildNodes(e){this.__prefix=e[0],this.__suffix=e[1]}citeData(){return this.data||(this.data=this.articleData()?.citations?.data[this.index-1])}render(){const{key:e,index:t,mode:i,data:n=this.citeData()}=this,a="cite-ref"+(n?"":" unresolved"),s=null==n?t??"??":"inline-author"===i?function(e,t,i=2){const{author:n,title:a}=e;if(!n||!n.length)return`${a} [${t}]`;let s=n[0].family;2===n.length?s+=` & ${n[1].family}`:n.length>i&&(s+=" et al.");return`${s} [${t}]`}(n,t):t;return this.renderWithTooltip(a,s,function(e,t){return t?G`<div class="cite-info">
      ${function(e){const{url:t,title:i,year:n,author:a}=e,s=n?G`\u2022 <span class="cite-year">${n}</a>`:"",o=i||oe(a).join(", ")||"Unknown Title";return t?G`<div class="cite-title">
      <a href=${t} target="_blank" rel="noopener noreferrer">${o}</a>
      ${s}
    </div>`:G`<div class="cite-title">${o}${s}</div>`}(t)}
      ${function(e,t=4){const{author:i,title:n}=e;if(!n)return null;const a=oe(i),s=a.length-t;if(s>1){const e=a.slice(0,t).join(", "),i=", "+a.slice(t).join(", "),n=G`<span class="cite-author-button" @click=${re}>+${s}&nbsp;authors</span>`,o=G`<span class="cite-author-expand"> ${n}</span>`,r=G` <span class="cite-author-button" @click=${le}>less</span>`,l=G`<span class="cite-author-hidden">${i}${r}</span>`;return G`<div class="cite-author">${e}${o}${l}</div>`}return a.length?G`<div class="cite-author">${a.join(", ")}</div>`:null}(t)}
      ${function(e){const{venue:t}=e;return t?G`<div class="cite-venue">${t}</div>`:null}(t)}
      ${function(e,t=300){const{abstract:i,tldr:n}=e,a=n||i;if(!a)return null;const s=a!==n&&a.length>t?a.slice(0,a.slice(0,t).lastIndexOf(" "))+"…":a;return G`<div class="cite-detail">${s}</div>`}(t)}
    </div>`:G`<div class="cite-info">
      <strong>Unresolved citation</strong><br>"${e}"
    </div>`}(e,n))}}),window.customElements.define("cross-ref",class extends ne{static get properties(){return{type:{type:String},xref:{type:String},index:{type:Number},short:{type:Boolean}}}show(){this.renderTooltipContent(),super.show()}goto(e){e.preventDefault();const t=`#${this.xref}`;history.replaceState(null,null,t),document.querySelector(t).scrollIntoView({behavior:"smooth",block:"nearest"})}renderTooltipContent(){if(null==this.index)return;const e=this.querySelector(".cross-ref-tooltip");e.replaceChildren(),de(e,document.getElementById(this.xref)),e.firstElementChild.className=this.type===he.FIGURE?"figure":this.type===he.TABLE?"table":""}renderUnresolvedReference(e){const t=G`<div class="cross-ref-tooltip">
      Unresolved ${this.type} reference: ${this.xref}
    </div>`;return this.renderWithTooltip(`${e} unresolved`,"?",t)}renderResolvedReference(e){if(this.type===he.SECTION)return this.removeEventListener("keydown",this.keyDown),this.removeEventListener("mousedown",this.mouseDown),G`<a class=${e} href="#${this.xref}" @click=${this.goto}>${this.index}</a>`;{const t=G`<div class="cross-ref-tooltip"></div>`;return this.renderWithTooltip(e,this.index,t)}}renderWithTooltip(e,t,i){const n=G`<div class="tooltip">${i}</div>`;return G`<span class=${e} @dblclick=${this.goto} tabindex=0>${n}${t}</span>`}render(){const{type:e,index:t,short:i}=this,n=`cross-ref ${e}${i?"":" full"}`;return null!=t?this.renderResolvedReference(n):this.renderUnresolvedReference(n)}}),window.customElements.define("inline-note",class extends ie{constructor(){super(),this.number=++me}render(){const e=this.number;return G`<span class="inline-note" @click=${e=>e.target.parentElement.classList.toggle("open")}>
      <sup class="inline-note-number">${e}</sup>
      <span class="note margin" data-number="${e}">${this.__children}</span>
    </span>`}}),window.customElements.define("tex-equation",class extends We{static get properties(){return{type:{type:String},nonumber:{type:Boolean}}}constructor(){super(),this.mode="display",this.type="align",this.nonumber=!1}prepareMath(){const e=this.type+(this.nonumber?"*":"");return`\\begin{${e}}\n${this.code}\n\\end{${e}}`}}),window.customElements.define("tex-math",We);
