<section id="header">
  <header>
    <h1 role="banner">Composable Live Programming with Engraft</h1>
    <div class="author"><span class="author-name">Anonymous Author</span></div>
  </header>
</section>

<section id="abstract">
  <h1 nonumber="true">Abstract</h1>
  <p>Live, interactive tools can support a diversity of domain-specific programming tasks, from visualization authoring to data wrangling. Real-world programming, however, requires performing multiple tasks in concert, calling for the use of multiple tools alongside conventional code. Programmers lack environments capable of composing live tools to support these situations. To enable live composability, we contribute Engraft, an API for the Web platform that allows live tools to be embedded within larger live-programming environments like computational notebooks. Engraft enables several new forms of composition: not only embedding live tools inside live environments, but also embedding live environments within each other and embedding live environments in the outside world, including conventional codebases. We demonstrate Engraft with examples from diverse domains, including web-application development and physics education. By providing composability, Engraft can help cultivate a cycle of use and innovation in live programming.</p>
</section>

<section id="1">
  <h1 id="introduction" data-counter="1">Introduction</h1><p>People use a vast range of rich, specialized computer interfaces in daily life. We use spreadsheets to track accounts, graphics editors to create images, and timeline views for video editing. These interfaces are crafted around their domains, offering representations that afford direct manipulation and meaningful feedback.</p><p>Turning our gaze to programming, this richness disappears. Conventionally, programming takes place in a uniform world of textual code.
Parsing text, processing images, building a visualization, and chaining steps of a process are all distinct tasks, but a programmer’s screen looks the same no matter which they are working on. <q>Domain-specific</q> languages can offer separate dialects for these separate situations, but even with DSLs, programming still takes on a textual form, deprived of the direct manipulation and live feedback that characterize everyday computer use.</p><p>Alternatives to textual code have been explored since the advent of interactive computing. Some of the earliest user interfaces developed were visual programming languages, using formalisms like flow charts to define programs <span class="cite-list"><cite-ref key="Ellis1969THEGP" index="9"></cite-ref>, <cite-ref key="doi:10.7249/RM6001" index="10"></cite-ref></span>. In this paper, we build on work in <em>live programming</em> <span class="cite-list"><cite-ref key="doi:10.1016/S1045-926X(05)80012-6" index="43"></cite-ref></span>: <q>programming tools which provide immediate feedback on the dynamic behavior of a program even while programming</q> <span class="cite-list"><cite-ref key="doi:10.22152/programming-journal.org/2019/3/1" index="35"></cite-ref></span>.
Live programming aims to provide the immediate feedback that we expect from rich computer applications. Live programming might be most helpful via a rich variety of domain-specific tools, with particular tools crafted to help programmers accomplish particular tasks. For example:</p><ul><li>Gneiss <span class="cite-list"><cite-ref key="doi:10.1184/R1/6714389.V1" index="4"></cite-ref></span> is a tool for making interactive, data-driven web applications through direct manipulation.</li><li>Lyra <span class="cite-list"><cite-ref key="doi:10.1111/cgf.12391" index="37"></cite-ref></span>, Data Illustrator <span class="cite-list"><cite-ref key="doi:10.1145/3173574.3173697" index="22"></cite-ref></span>, and Charticulator <span class="cite-list"><cite-ref key="doi:10.1109/TVCG.2018.2865158" index="36"></cite-ref></span> are visualization authoring systems that let authors create expressive data visualizations without using traditional code.</li><li>Wrangler <span class="cite-list"><cite-ref key="doi:10.1145/1978942.1979444" index="17"></cite-ref></span> is a programming-by-demonstration interface for data wrangling. With it, users can define complex scripts to clean up and reshape tabular data by directly manipulating a table, rather than writing lines of code.</li></ul><p>These tools use novel techniques to make programming tasks concrete, visible, and approachable. However, while particular tools may find their niches, the role of interactive tools in programming <em>at large</em> remains marginal. Programmers may go their entire careers without leaving the world of static text. Furthermore, the potential of live tools to extend programming power from trained software engineers to end-users in diverse disciplines remains unrealized. What fundamental limitations do live-programming systems have today which, if addressed, might bring them into broad use?</p><p><strong>We contend that a main factor limiting real use of live programming tools is their present lack of <em>composability</em>.</strong> Conventional programming derives its power in large part from composability. This composability is so fundamental to programming that we take it for granted. We assume that <em>of course</em> we can combine multiple Python libraries when we write our scripts, and nest our <code>if</code> statements and <code>for</code> loops however we like. The ability to freely combine building blocks is what makes programming a medium with infinite expressive potential.</p><p>This composability does not exist in the world of rich user interfaces, including live-programming tools. As an example, suppose a digital artist wants to make a website that displays summaries of random Wikipedia articles.<inline-note>This use-case is inspired by <cite-ref key="everest" mode="inline-author" index="32"></cite-ref>, a live-tweeted coding adventure.</inline-note> This project involves multiple steps:</p><ol><li>Call the Wikipedia API to get raw data about articles.</li><li>Process a JSON response to extract out relevant information.</li><li>Format this information into an attractive web page.</li><li>Host the above process on a publicly available site.</li></ol><p>This workflow is heterogeneous. We can imagine separate live-programming tools for each of these steps, like a tool which displays a JSON structure and lets a user pick the information they want (for step 2), and a tool which lets a user build a data-backed web page through direct manipulation (for step 3). Could the artist use such tools together to accomplish their larger goal?
Right now, they can not. Ad-hoc approaches are possible, including tools that generate code or hard-wired tool assemblies for specific workflows, but none of these can replicate the free-form composability of conventional code without losing liveness and immediacy.</p><p>We envision general-purpose programming systems combining three essential elements. Many systems combine two of these elements, but few research systems—and none in common use—include all three:</p><ul><li><strong>Liveness:</strong> Feedback about the program’s dynamic behavior deeply permeates the programming experience.</li><li><strong>Domain-specific richness:</strong> Programmers use interactive representations designed for the domains they work with.</li><li><strong>Composability:</strong> Tools can be freely combined to support diverse workflows and accomplish larger goals.</li></ul><p>We present <em>Engraft</em>,<inline-note>Grafting is <q>a horticultural technique whereby tissues of plants are joined so as to continue their growth together</q> <span class="cite-list"><cite-ref key="wikipedia-grafting" index="47"></cite-ref></span>. This provides an apt analogy for the way Engraft allows trees of heterogeneous live tools to work together.</inline-note> a system for live composition of live, domain-specific tools and environments. Engraft takes the form of an API on the Web platform. An Engraft-compatible tool follows a standard interface for embedding, allowing it to be embedded together with other tools within live environments like notebooks. In this way, disparate task-specific tools can be joined together to solve real problems, while maintaining liveness among them.</p><p>A number of key design decisions shape the Engraft API.
Engraft tools are given <em>freedom of implementation</em>. A tool must implement a common interface, but its internal implementation is otherwise unconstrained.
Engraft tools <em>can be embedded anywhere in the Web platform</em>, including embeddings inside <em>other tools</em>, as well as in diverse applications and development contexts.
Engraft tools communicate with their hosts using <em>streams of pure values</em>. A tool is given values by its host and it provides values in return.
Engraft tools expose <em>computational and UI behaviors, with computational behavior primary</em>. An Engraft tool can run without rendering any UI, but not visa versa.
Finally, Engraft tools <em>are not required to generate or edit underlying textual code</em>. Engraft explores a vision of live programming untethered from a textual-code source of truth.</p><p>By following these decisions, Engraft enables <strong>three forms of composition</strong>, all of which are underexplored and two of which are novel:</p><div class="table-three-forms"><div class="table-three-forms-wrapper"><table><thead></thead><tbody><tr><td class="center"><img width="500" src="assets/tool legos - tools on env.svg.png"></img></td><td><strong>Live tools inside live environments:</strong> The goal already described: joining task-specific tools together in a shared live environment.</td></tr><tr><td class="center"><img width="500" src="assets/tool legos - env on env.svg.png"></img></td><td><strong>Live environments inside live environments:</strong> Environments can embed in other live environments, with nested scopes at multiple levels in the programming process.</td></tr><tr><td class="center"><img width="500" src="assets/tool legos - tool on world.svg.png"></img></td><td><strong>Live tools inside the outside world:</strong> Engraft tools (including environments) can be embedded into applications or codebases.</td></tr></tbody></table></div></div><h2 id="summary-of-contributions" data-counter="1.1">Summary of Contributions</h2><ul><li>We identify <em>composability</em> as an essential element missing from the current live-programming ecosystem.</li><li>We articulate three forms of composition that are necessary for live programming to match conventional programming in expressiveness and practical utility.</li><li>We present a model for an API with which heterogeneous live tools can be composed together via the three forms of composition we articulated.</li><li>We present our prototype of this API, called Engraft, together with an assortment of example tools that showcase interaction styles that might be used in tools in the future.</li><li>We show, through examples, how our prototype makes a variety of programming activities visible and interactive.</li></ul>
</section>

<section id="2">
<h1 id="related-work" data-counter="2">Related Work</h1><p>Engraft combines three essential elements: <em>liveness</em>, <em>domain-specific richness</em>, and <em>composability</em>. Each of these elements have long histories in the literature, though it is rare for all three to be combined at once (<cross-ref type="fig" xref="venn" index="1"></cross-ref>).
We first look at pairwise combinations of these elements, then discuss the special triple intersection consisting of projects most similar to Engraft.</p><figure id="venn" class="figure" data-counter="1"><img width="500" src="assets/venn-2.png"></img><figcaption data-counter="1">Pairwise and three-way intersections between liveness, domain-specific richness, and composability.</figcaption></figure><h2 id="liveness-domain-specific-richness" data-counter="2.1">Liveness + Domain-specific richness</h2><p>Engraft is inspired by domain-specific programming tools like Gneiss <span class="cite-list"><cite-ref key="doi:10.1184/R1/6714389.V1" index="4"></cite-ref></span>, Lyra <span class="cite-list"><cite-ref key="doi:10.1111/cgf.12391" index="37"></cite-ref></span>, and Wrangler <span class="cite-list"><cite-ref key="doi:10.1145/1978942.1979444" index="17"></cite-ref></span>. These tools replace complex, opaque programming processes with direct interactions. To achieve this, they leverage novel programming paradigms (such as Gneiss’s extensions of the spreadsheet model) and interaction techniques (such as Wrangler’s use of <q>programming by demonstration</q>). We see enormous potential in tools like these.</p><p>However, these tools are fundamentally isolated. The challenge of combining them, or integrating them into conventional programming systems, undermines the benefits of their liveness, and arguably limits their use. Lacking such composability, developers of novel interactive programming tools have taken a variety of ad-hoc approaches to integrate them into larger workflows.</p><p>One approach is simply <q>copy-paste</q>. For example, <a href="https://regex101.com/">regex101</a>, <a href="https://www.debuggex.com/">Debuggex</a>, and <a href="https://regexr.com/">RegExr</a> offer live debuggers, visualizers, and documentation to help programmers write regular expressions. These tools are not integrated with developer tools like IDEs. One simply copies regular expressions in and out as needed.
Though quite a bit more complex than a regular-expression helper, Wrangler <span class="cite-list"><cite-ref key="doi:10.1145/1978942.1979444" index="17"></cite-ref></span> similarly <q>integrates</q> with larger programming tasks via <q>copy-paste</q> of generated code.
Although this works, consider what is lost.</p><p>There is a loss of <em>liveness</em>. In a copy-paste system, the user must provide sample input by hand. This tedious extra step is a place where mistakes can be propagated if the user’s assumptions about what the input data looks like do not match reality.
There is also a loss of <em>persistence</em>. With one of these online tools, a programmer may curate a set of test inputs, but this ensemble is not persisted when the regular expression is copy-pasted back to code.
Finally, there is a loss of <em>collocation</em>. Using an online tool requires leaving the application code and entering a new space. With this comes a potential for disorientation and distraction.</p><p>Academic researchers developing novel interactive programming tools have generally not focused attention on how they might be integrated into larger programming workflows, preferring to focus on the tools themselves.
Furthermore, even if tool-makers go beyond the call of duty and build tight integrations into larger environments, these integrations will be <em>ad-hoc</em>. They must be built from scratch, as was done to integrate Voyager <span class="cite-list"><cite-ref key="doi:10.1145/3025453.3025768" index="48"></cite-ref></span> into JupyterLab. Generally, integrations must be built separately for each development environment.
In contrast, Engraft provides a single API that tools and hosts can use for live, fully persistent, collocated embedding.</p><h2 id="composability-liveness" data-counter="2.2">Composability + Liveness</h2><p>Next, we consider systems combining composability and liveness,<inline-note>Some systems are live only in that they display the output of a program, and try to update this display in response to changes in the program. Examples include <q>live reloading</q> and <q>hot reloading</q> systems popular for application development. These are at the coarser end of a scale measuring the <em>granularity</em> of liveness. At the other end of the scale are systems that exhibit fine-grained liveness: making visible the dynamic behavior of smaller programming constructs like intermediate values and control flow.</inline-note> albeit without domain-specific richness. Most live programming editors fall into this space. We place these into three categories:</p><p><strong>Liveness within textual code.</strong> One common recipe is to augment textual-code editors with in-context displays showing run-time behavior. Rauch et al.’s <q>Babylonian-style Programming</q> <span class="cite-list"><cite-ref key="doi:10.22152/programming-journal.org/2019/3/9" index="34"></cite-ref></span> surveys the state of the art in this category as of 2012. They evaluate eight existing editors <span class="cite-list"><cite-ref key="doi:10.1145/1052883.1052894" index="6"></cite-ref>, <cite-ref key="light-table" index="13"></cite-ref>, <cite-ref key="doi:10.1145/2814189.2817268" index="15"></cite-ref>, <cite-ref key="seymour" index="18"></cite-ref>, <cite-ref key="live-literals" index="42"></cite-ref>, <cite-ref key="inventing-on-principle" index="45"></cite-ref>, <cite-ref key="learnable-programming" index="46"></cite-ref></span>, before adding their own to the list. Notable entrants to this category since 2012 include Swift Playgrounds in Xcode <span class="cite-list"><cite-ref key="swift-playgrounds" index="2"></cite-ref></span> and Projection Boxes <span class="cite-list"><cite-ref key="doi:10.1145/3313831.3376494" index="21"></cite-ref></span>. These editors imbue conventional textual code with powerful new forms of visibility. As they restrict their attention to this conventional textual code, they do not provide opportunities for rich task-specific representations and interactions.</p><p><strong>Liveness between textual code cells.</strong> Rather than threading live feedback into traditional codebases, other editors provide special interfaces where code is broken up into <q>cells</q>. These editors can then provide visibility into values flowing between cells. We call such editors <q>live environments</q>, as they provide liveness to environments where pieces of code are composed. The paradigmatic live environment is the spreadsheet. More recent live environments include Observable <span class="cite-list"><cite-ref key="observable" index="27"></cite-ref></span> and Natto <span class="cite-list"><cite-ref key="natto" index="40"></cite-ref></span>, which both augment JavaScript programming in-the-small with a live structure in-the-large: Observable via a computational notebook and Natto via nodes and wires on a canvas. While environments like these play an important role in building programs with Engraft, they do not, by themselves, enable natural domain-specific interactivity. Specifically: (1) Cells can render UI, but this UI cannot persistently modify program state.<inline-note>Observable and Natto have both implemented particular, ad-hoc tools that can persist state: Observable’s Data Table Cell <span class="cite-list"><cite-ref key="observable-data-table-cell" index="28"></cite-ref></span> and Natto’s Template Panes. These extensions are built into their respective platforms and can access capabilities that are not available to user-authored tools.</inline-note> (2) They do not support hierarchical nesting of tools. (3) They are both monolithic web applications which cannot themselves be embedded into other live environments or outside applications.<inline-note>Observable notebooks and Natto canvases can be invoked via JavaScript module export, but someone using this export cannot see their own inputs flowing through the notebook/canvas, nor do they have the ability to modify the notebook/canvas’s behavior in context.</inline-note></p><p><strong>Liveness with structured editors.</strong> Finally, we have <em>structured</em>, or <em>projectional</em>, editors which are not based on textual code or cells thereof, but which instead allow interactions directly with structured representations of code. Many structured-editor projects involve live feedback, including Enso <span class="cite-list"><cite-ref key="enso" index="11"></cite-ref></span>, Lamdu <span class="cite-list"><cite-ref key="lamdu" index="23"></cite-ref></span>, PANE <span class="cite-list"><cite-ref key="pane" index="14"></cite-ref></span>, and Subtext <span class="cite-list"><cite-ref key="doi:10.1145/1094811.1094851" index="7"></cite-ref></span>. To our knowledge, no live structured editor projects have added custom domain-specific components to their structures, though it would seem to be a natural direction.</p><h2 id="composability-domain-specific-richness" data-counter="2.3">Composability + Domain-specific richness</h2><p>The final pairing integrates domain-specific representations and interactions into general-purpose programming environments, albeit static ones. A number of projects have explored this possibility.
<cite-ref key="doi:10.1145/3428290" mode="inline-author" index="1"></cite-ref> describes a visual macro system for Racket which lets users define interactively editable visual syntaxes embedded inside of arbitrary Racket code.
Graphite <span class="cite-list"><cite-ref key="doi:10.1109/VLHCC.2011.6070422" index="29"></cite-ref></span> extends a Java IDE with pop-up <q>palettes</q> to bidirectionally edit literals in code.
MPS (Meta Programming System) <span class="cite-list"><cite-ref key="mps" index="16"></cite-ref></span> is a workbench for developing projectional domain-specific languages. MPS languages typically look mostly like conventional code, but they can embed custom interfaces like tables and state-machine diagrams.</p><p>These approaches differ from Engraft along many axes, but by far the most salient is their lack of liveness. In all the above cases, visual representations embedded in code represent static syntax, and do not show information about dynamic program behavior. All of the tools in Engraft benefit from liveness, and some, like <span class="toolname">Extractor</span> and <span class="toolname">Formatter</span>, derive their entire power from allowing the user to act directly on data in the system. These sort of tools are not possible in a system without liveness.</p><h2 id="all-three" data-counter="2.4">Combining All Three</h2><p>Engraft joins two recent projects that combine liveness, domain-specific richness, and composability: mage <span class="cite-list"><cite-ref key="doi:10.1145/3379337.3415842" index="19"></cite-ref></span> (<q>an API for allowing smooth transitions between GUI and code work in notebooks</q>) and Hazel’s livelits <span class="cite-list"><cite-ref key="doi:10.1145/3453483.3454059" index="31"></cite-ref></span> (<q>user-defined GUIs embedded persistently into code</q>).
These projects share both motivations and common design elements with Engraft. However, Engraft goes beyond them by enabling new forms of composition.</p><p>While mage and livelits support joining tools together in a shared live environment, Engraft further supports embedding environments within environments, and embedding live tools within the outside world.
Because its API is tied to its Jupyter host, mage tools cannot be embedded within each other, but must follow the flat structure of a Jupyter Notebook.</p><p>Unlike mage tools, livelits are nestable within each other and other Hazel <span class="cite-list"><cite-ref key="doi:10.1145/3290327" index="30"></cite-ref></span> constructs, but a smaller variety of tools are possible than with mage or Engraft.
Live environments like notebooks can not serve as livelits, as livelits’ typing discipline is not expressive enough to represent these dynamic environments.<inline-note>The Hazel environment itself can be embedded in livelits, but this still means that developers do not have the benefit of experimenting with alternative live environments.</inline-note>
Livelits, as the name <q>live literals</q> suggests, have so far been restricted to widgets like sliders and color pickers.
Engraft supports a broader range of tools, from nestable environments like <span class="toolname">Notebook</span> to programming-by-demonstration tools like <span class="toolname">Extractor</span> and <span class="toolname">Formatter</span>.</p><p>Engraft also differs from livelits in our implementation strategy. While livelits are built in Hazel, a self-contained research platform, Engraft is built in the Web platform, where it can grow through contact with actual use.</p>
</section>

<section id="3.0">
<h1 id="live-composability-with-engraft" data-counter="3">Live Composability with Engraft</h1><p>As we previewed in the introduction, Engraft enables three forms of live composition: <strong>live tools inside live environments</strong>, <strong>live environments inside live environments</strong>, and <strong>live tools inside the outside world</strong>. Our initial work on Engraft was driven by the first of these. The architecture that we designed in response to this goal proved to be more versatile than we expected, enabling the last two as an emergent byproduct. In retrospect, we believe all three of these forms will be important to make programming with live tools a viable alternative to static code.</p><p>This section describes the end-user experience of building programs with Engraft, making use of these three forms of composition. Later, in <cross-ref type="sec" xref="design-decisions" index="4"></cross-ref> and <cross-ref type="sec" xref="implementation" index="5"></cross-ref>, we discuss the design and implementation of the underlying Engraft API.</p>
</section>

<section id="3.1a">
<h2 id="live-tools-inside-live-environments" data-counter="3.1">Live tools inside live environments</h2>
</section>

<section id="3.1b">
<p>Earlier, we presented an example of a digital artist who wants to make a website that displays summaries of random Wikipedia articles. Let’s examine how this artist might accomplish their goal by composing live tools together in a live environment with Engraft.</p><p>They start by loading the Graft Garden website. This is a web application which provides a convenient starting point for using Engraft tools. Graft Garden will also host the output of these tools as a separate web page, as we will see later.</p><p>Once the artist tells Graft Garden to make a new project, they are presented with a blank page (<cross-ref type="fig" xref="new_patch" index="2"></cross-ref>), containing a single small code-editor box, called a <em>slot</em>. This slot is the starting point for everything they will do.</p><figure id="new_patch" class="figure" data-counter="2"><img src="assets/2022-09-09-20-07-48.png"></img><figcaption data-counter="2">A new <q>patch</q> (project) on Graft Garden.</figcaption></figure><p>The artist knows that their project will involve combining together multiple steps. So they would like to work in a <em>live environment</em> that allows multiple computational steps to be combined together in fluid and flexible ways. Example environments include computational notebooks (like Observable), free-form canvases of nodes and wires (like Natto), and spreadsheets (like Excel).
Engraft is not built around any one of these environments in particular. As versions of all of these have been implemented as Engraft tools, the artist can take their pick of whichever suits their needs.</p><p>In this case, the artist picks a computational notebook. They do this by beginning to type <code>/notebook</code> in the slot, and selecting <q class="single">notebook</q> from the autocomplete menu that pops up. Once they do this, the slot is replaced with the notebook interface (<cross-ref type="fig" xref="type_notebook" index="3"></cross-ref>).</p><figure id="type_notebook" class="figure" data-counter="3"><img width="45%" src="assets/2022-09-09-20-08-22.png"></img>
<img width="45%" src="assets/2022-09-09-20-08-35.png"></img><figcaption data-counter="3">The artist begins to type <code>/notebook</code> into the slot, and selects the autocomplete suggestion. A notebook is inserted into the slot.</figcaption></figure><p>This is a reactive notebook in which a user can type code snippets into cells. The notebook will evaluate these snippets and show their resulting values alongside the cells (<cross-ref type="fig" xref="example_notebook" index="4"></cross-ref>). Cells receive default names (like in a spreadsheet), but can be renamed. Cells can refer to one another, and the notebook ensures that a cell is re-evaluated when one of its references changes.</p><figure id="example_notebook" class="figure" data-counter="4"><img width="300" src="assets/2022-09-09-20-10-21.png"></img><figcaption data-counter="4">Example usage of a notebook. The second cell (B) refers to the first (A).</figcaption></figure><p>Let’s return to the artist. The first thing they need to do is get hold of data from the Wikipedia API. Rather than write networking code directly, they type <code>/request</code> into the first cell, and select <q class="single">request</q> from the autocomplete menu that pops up. This inserts a <span class="toolname">Request</span> tool into the cell. The notebook’s cells are slots, just like the root slot the artist used to invoke the notebook.</p><p>The <span class="toolname">Request</span> tool has two slots: one to provide a URL and one to provide an object of query parameters (<cross-ref type="fig" xref="request_tool" index="5"></cross-ref>). As the artist skims the Wikipedia API documentation, they experiment with different query parameters. The tool resends the query with every change, so the artist can see the effects of their changes live.</p><figure id="request_tool" class="figure" position="h" data-counter="5"><img width="500" src="assets/2022-09-09-20-17-23.png"></img><figcaption data-counter="5">A <span class="toolname">Request</span> tool inserted into the notebook. The artist has provided contents for its <q>url</q> and <q>params</q> slots. The request’s JSON response is shown to the right. Long string values are automatically placed in scrolling sub-windows.</figcaption></figure><p>Just like a snippet of code typed into a computational notebook, the <span class="toolname">Request</span> tool produces <em>output</em>, which is returned to the notebook that hosts it. The notebook can then display this output live, and make it available to other cells by reference.</p><p>Examining the output, and playing with query parameters, the artist eventually finds a configuration they like. It delivers five random articles, complete with titles and HTML-summary <q>extracts</q>.</p><p>While the artist can see the data they want in the API response, the task of extracting it out of the complicated JSON structure is a bit intimidating. Fortunately, they know a second tool, called the <span class="toolname">Extractor</span> tool<inline-note><span class="toolname">Extractor</span> is similar to an interaction found in Gneiss <span class="cite-list"><cite-ref key="doi:10.1184/R1/6714389.V1" index="4"></cite-ref></span>.</inline-note> (<cross-ref type="fig" xref="extractor_tool" index="6"></cross-ref>). This tool accepts JSON data as input and presents an interface that allows the user to select data values by clicking on those values directly. The tool generalizes from these clicks, providing an output structure with the values the user wants. The result is equivalent to writing code that loops over arrays and objects with chains of property accesses.</p><figure id="extractor_tool" class="figure" position="h" data-counter="6"><img width="500" src="assets/2022-09-09-20-18-42.png"></img><figcaption data-counter="6">An <span class="toolname">Extractor</span> tool inserted into the notebook below the <span class="toolname">Request</span> tool. It refers to the previous cell as input. The artist has selected various data fields by clicking on them. The tool’s output is shown to the right.</figcaption></figure>
</section>

<section id="3.1c">
<p>This tool is more interesting, in its liveness, than the <span class="toolname">Request</span> tool. The <span class="toolname">Request</span> tool offered a convenient form interface for specifying a request, but that interface was structurally similar to working with code. In contrast, the <span class="toolname">Extractor</span> tool’s interface relies on live input data to support programming-by-demonstration.</p><p>Now that the artist has extracted the data they care about, they want to reshape it into an attractive interface. For this they use a <span class="toolname">Formatter</span> tool<inline-note><span class="toolname">Formatter</span> is similar to a (second) interaction found in Gneiss <span class="cite-list"><cite-ref key="doi:10.1184/R1/6714389.V1" index="4"></cite-ref></span>, and is also inspired by Yoshiki Schmitz’s work <span class="cite-list"><cite-ref key="yoshiki" index="38"></cite-ref></span>.</inline-note> (<cross-ref type="fig" xref="formatter_tool" index="7"></cross-ref>). Given a JavaScript data structure, <span class="toolname">Formatter</span> automatically suggests a way to format the data into HTML output. It also provides direct-manipulation handles the user can use to choose different options for this formatting. Like <span class="toolname">Extractor</span>, <span class="toolname">Formatter</span> uses live data to power a programming-by-demonstration interface. The artist hands <span class="toolname">Formatter</span> the output of <span class="toolname">Extractor</span>, and does a bit of clean-up.</p><figure id="formatter_tool" class="figure" position="h" data-counter="7"><img width="500" src="assets/2022-09-09-20-19-26.png"></img><figcaption data-counter="7">A <span class="toolname">Formatter</span> tool inserted into the notebook below the <span class="toolname">Extractor</span> tool. It refers to the previous cell as input. The artist has used its interface (including an inspector on the left) to specify how the extracted data should be formatted. The tool output is shown to the right.</figcaption></figure><p>The artist has now built a live computational notebook, consisting of three live tools:</p><ol><li>a <span class="toolname">Request</span> tool, to get data from the Wikipedia API,</li><li>an <span class="toolname">Extractor</span> tool, to pluck out the data they need in a clean format, and</li><li>a <span class="toolname">Formatter</span> tool, to shape the data into an HTML document with the appearance they desire.</li></ol><p>The last step is to <q>deploy</q> this living program to a website, where a visitor will receive their own random set of articles. Conveniently, Graft Garden, the web application that has hosted their work so far, has already done this. The output of the last cell in the notebook (the <span class="toolname">Formatter</span>, in this case) is returned back to Graft Garden. Graft Garden provides a shareable link that displays this final return value without visible tool UI (<cross-ref type="fig" xref="randompedia" index="8"></cross-ref>). Note that the Wikipedia articles shown here are different than above, as the artist’s program runs anew every time this page is loaded.</p><figure id="randompedia" class="figure" position="h" data-counter="8"><img src="assets/2022-09-09-20-21-21.png"></img><figcaption data-counter="8">The artist’s final creation: a dynamic website invisibly powered by their Engraft program. It is available at a separate URL.</figcaption></figure><p>Our artist has not had to type any code to create this dynamic web page, aside from experimenting with API query parameters. A <q>results not typical</q> disclaimer applies here: In most cases, more JavaScript coding will be required to accomplish real-world programming goals with Engraft. This fits with our vision, as Engraft is built to gradually extend conventional programming workflows. There should be nothing stopping a user from using traditional textual code whenever it is useful or necessary to do so. But when using Engraft, a new possibility opens up: replacing certain steps with interactive, direct-manipulation tools.</p><p>In the story above, the artist chose to compose their tools inside of a <span class="toolname">Notebook</span>. As we mentioned earlier, this is not the only live environment an Engraft user may choose to use. For different tasks, different environments may be preferred.</p><p>Suppose a user wants to construct an arrow graphic to represent a vector of x- and y-values, perhaps as part of an interactive explanatory diagram. <cross-ref type="fig" xref="notebook_vs_canvas" index="9"></cross-ref> shows how they might do this in a <span class="toolname">Notebook</span>. It then shows the same logical structure expressed in a new environment (loosely modeled on Natto <span class="cite-list"><cite-ref key="natto-hn" index="39"></cite-ref></span><inline-note>A more ambitious adaptation of Natto, which could also be implemented with Engraft, would connect cells with wires rather than references.</inline-note>), called a <span class="toolname">NotebookCanvas</span>. Cells on a <span class="toolname">NotebookCanvas</span> work the same way as on a <span class="toolname">Notebook</span>, but they can be freely dragged around a canvas and resized however the user likes.</p><figure id="notebook_vs_canvas" class="figure" data-counter="9"><img width="30%" src="assets/2022-09-10-16-54-40.png"></img>
<img width="65%" src="assets/2022-09-10-16-58-15.png"></img><figcaption data-counter="9">(a) A <span class="toolname">Notebook</span> in which a user builds an arrow graphic for a vector. (b) A <span class="toolname">NotebookCanvas</span> consisting of the same cells, but arranged spatially.</figcaption></figure><p>The user might choose to use <span class="toolname">NotebookCanvas</span> over <span class="toolname">Notebook</span> for a number of reasons: higher visual density, space to organize nonlinear data-flows, and a looseness that avoids some <q>negative effects of prematurely or unnecessarily imposing a structure</q> <span class="cite-list"><cite-ref key="doi:10.1023/A:1008716330212" index="41"></cite-ref></span>. The user has this choice because Engraft decouples tools from environments, making it possible to choose the right environment for the job without losing access to the right tools.</p>
</section>

<section id="3.2">
<h2 id="live-environments-inside-live-environments" data-counter="3.2">Live environments inside live environments</h2><p>Live environments are powerful building blocks for live programming. The above example uses a <span class="toolname">Notebook</span> to link together three live tools. However we have found that one environment, by itself, is often not enough, because a single environment is <q>flat</q>.</p><p>To explain what we mean by <em>flat</em>, suppose an Observable user has an array of complex data elements. They would like to process each element of this array to obtain a new version of the array, a <q>map</q> operation. They are free, in Observable, to write a cell that performs this map operation:</p><pre><code>newArray = oldArray.map((element) =&gt; {
    return step3(step2(step1(element)));
});</code></pre><p>Here, the per-item processing function is complex, consisting of multiple steps (function calls). A selling point of a computational notebook is that it can split separate steps into separate cells, providing visibility into intermediate values. Here, Observable’s interface is not available <em>inside</em> this map operation, because the entire map operation needs to be inside a single cell. The benefits of liveness and visibility that Observable offers are lost in this deep structure. Observable is <em>flat</em>, and programming, in general, is not.</p><p>In contrast, the Engraft architecture suggests that environments could themselves implement the API of an Engraft tool, becoming tools themselves. This means that live environments can be embedded inside of other live environments, allowing these environments to reflect a nested structure in the computation being performed.</p><p>For instance, we have built a tool called <span class="toolname">Map</span>, designed to support a user mapping through an array. <span class="toolname">Map</span> takes an input array and provides a slot for a <q>per-item tool</q>. <span class="toolname">Map</span> shows the per-item tool being run on a single element of the array, so that the user has concrete data to inform their experience of live-programming the per-item tool. The user can use <span class="toolname">Map</span>’s interface to select which element of the array they would like to use as their example, so they can test that their per-item tool performs well across variations. To compute its final output, <span class="toolname">Map</span> also runs a copy of the per-item tool on each element of the input array, though most of these executions are invisible. (This is a good example of why it is important that tools can run without their interfaces being rendered.)
<cross-ref type="fig" xref="map_tool" index="10"></cross-ref> shows a notebook embedded inside of <span class="toolname">Map</span>, so that multiple stages in the per-item tool can be examined live as they are programmed.</p><figure id="map_tool" class="figure" data-counter="10"><img width="400" src="assets/2022-09-10-15-25-48.png"></img><figcaption data-counter="10">A toy example, showing <span class="toolname">Notebook</span> inside of <span class="toolname">Map</span> inside of <span class="toolname">Notebook</span>. <span class="toolname">Map</span> has been given the array <code>[0,1,2,3,4]</code> as input. Its inner notebook squares an item of an array and then adds 10, in two separate cells. The user has selected index 2 in the <span class="toolname">Map</span> tool as the example they would like to display in the inner notebook.</figcaption></figure><p>To see <span class="toolname">Map</span> used in a real-world context, let’s look at an <q>image quilt</q> generator made with Engraft (<cross-ref type="fig" xref="image_quilt" index="11"></cross-ref>). Starting with a user-supplied query, like <q>abstract</q> or <q>cat</q>, this web application displays a dense array of annotated artworks.</p><figure id="image_quilt" class="figure" data-counter="11"><img width="400" src="assets/2022-09-10-15-30-17.png"></img><figcaption data-counter="11">The image quilt application, displayed in Graft Garden’s <q>view</q> mode. The images shown are a result of the user typing <q>abstract</q> into the search box.</figcaption></figure><p>The Engraft program behind this application starts by querying the Art Institute of Chicago API for matching works of art. This returns an array of objects representing works of art. To make the quilt, we need to turn each element of this array into a composite of image and text. We can do this with <span class="toolname">Map</span> (<cross-ref type="fig" xref="image_quilt_program" index="12"></cross-ref>).</p><figure id="image_quilt_program" class="figure" data-counter="12"><img width="600" src="assets/2022-08-26-21-05-32.png"></img><figcaption data-counter="12">An excerpt of the program used to generate the image quilt. A <span class="toolname">Map</span> tool takes in an array of data returned by the Art Institute of Chicago API. A <span class="toolname">Notebook</span> embedded inside the <span class="toolname">Map</span> processes each element of this array. In three cells, it 1. constructs an image URL, 2. loads this URL into an image element, to check that it is constructed correctly, and 3. builds a composite, layering text on top of the image element with appropriate styling.</figcaption></figure><p>By splitting the per-item process into multiple steps in the <span class="toolname">Notebook</span>, we receive immediate feedback about each step. Is the URL of the image being generated correctly? How does the composite look with its current styling? (One can certainly imagine this composition step being replaced someday with a direct-manipulation tool!) Once the array of HTML elements is returned by <span class="toolname">Map</span>, it can finally be composed into the quilt.</p><p>Programming is full of nested abstractions, so mapping an array is only one example of where it can be valuable to nest environments. As a very different example, consider programming a physics simulation. We are inspired here by the Bootstrap curriculum, which uses programming to teach algebra, physics, and computation to students in grades 5-12 <span class="cite-list"><cite-ref key="bootstrap" index="3"></cite-ref></span>. We adopt a functional structure for our simulations similar to Bootstrap’s <q>reactor</q> <span class="cite-list"><cite-ref key="doi:10.22152/programming-journal.org/2019/3/11" index="33"></cite-ref></span>, where a simulation is defined by:</p><ul><li>a <em>state</em> value, initialized to a certain value,</li><li>a way to <em>view</em> the state, and</li><li>a way to <em>update</em> the state on each time step.</li></ul><p>A tool called <span class="toolname">Simulation</span> lets a user define each of these pieces in slots. It can be useful to insert a live environment into one of these slots – say, to break down the <q>update</q> into steps. Here, a <span class="toolname">Notebook</span> in the <q>update</q> slot of a <span class="toolname">Simulation</span> describes a bouncing ball behavior (<cross-ref type="fig" xref="simulation" index="13"></cross-ref>).</p><figure id="simulation" class="figure" data-counter="13"><img width="450" src="assets/2022-08-26-23-35-28.png"></img><figcaption data-counter="13">A <span class="toolname">Simulation</span> tool, loaded with code that describes how a ball bounces around a rectangular region. The user of the tool has provided 1. init: a slot to initialize the ball’s state, 2. view: a slot describing how the state should be rendered, and 3. update: a slot (<span class="toolname">Notebook</span>, here) describing how the state should be updated on each tick of time. The user has scrubbed the step slider to step 8, at which point the ball is bouncing off the rectangle’s right-hand side.</figcaption></figure><p>By dragging the <q>step</q> slider, the user can see the <q>view</q> and <q>update</q> in the context of that particular step. Here, for instance, we see that the <q>x bounce</q> cell in the notebook has evaluated to <code>true</code>, so its x velocity will be inverted in the next step, as it bounces off the right-hand side of the box. Scrubbing through the time steps with the slider, the user can check that the pieces of their computation do what they expect, even as conditions change.</p><p><span class="toolname">Simulation</span> could have been implemented as a top-level application, rather than a tool. But implementing it as a tool provides even more benefits. In the example above, <span class="toolname">Simulation</span> is in fact embedded in a larger <span class="notebook">Notebook</span> (not shown). This larger notebook provides the shared variables <q>width</q> and <q>height</q> that the <span class="toolname">Simulation</span>’s different slots can refer to. The <span class="toolname">Simulation</span> tool also provides output of its own back to the <span class="notebook">Notebook</span>: a trace of all the states the simulation passes through. This trace can be used, live, in other cells to analyze the output of the simulation. Here, we feed it into a tool that embeds Voyager 2 <span class="cite-list"><cite-ref key="doi:10.1145/3025453.3025768" index="48"></cite-ref></span>, a system for visual data exploration. Using Voyager 2’s interface, the user plots the x position over time (<cross-ref type="fig" xref="simulation_voyager" index="14"></cross-ref>). The bounce after time-step 8 is visible in this plot in a new way.</p><figure id="simulation_voyager" class="figure" data-counter="14"><img width="500" src="assets/2022-08-27-09-35-14.png"></img><figcaption data-counter="14">A <span class="toolname">Voyager</span> tool in the same <span class="toolname">Notebook</span> as the <span class="toolname">Simulation</span>. It has been provided with the <span class="toolname">Simulation</span>’s output as its input, and the user has dragged fields onto the encoding shelves to plot <q>x</q> against <q>i</q>.</figcaption></figure><p>There is nothing special about the example situations described above. Nested structures are pervasive in programming. To provide the benefits of liveness &amp; domain-specific richness across these nested structures, live environments must be similarly composable.</p>
</section>

<section id="3.3">
<h2 id="live-tools-inside-the-outside-world" data-counter="3.3">Live tools inside the outside world</h2><p>Given an Engraft slot, a programmer has access to the entire ecosystem of interoperable Engraft tools. But the question remains of how they get to that slot, and how the program in the slot gets things done in the larger world. Here, we discuss how the Engraft architecture makes it possible to embed live tools and environments where work is done in the real world. We focus on two categories of embeddings: codebases and applications.</p><h3 id="codebases" data-counter="3.3.1">Codebases</h3><p>So far, we have presented Engraft in the context of Graft Garden, a simple web application that hosts Engraft tools and lets users create custom web applications. While Graft Garden is easy to access and use, it naturally has a limited range of usefulness. We do not expect developers of complex web applications to abandon their preferred frameworks, throw out their codebases, and switch to Graft Garden (or any other imagined Engraft host, for that matter). However, we still believe that programmers working in codebases could benefit from the judicious use of live tools and environments, if this didn’t require switching entirely into a new, all-encompassing platform.</p><p>Fortunately, we have found that the structure of the Engraft ecosystem offers opportunities for integration with present programming practices. With these integrations, programmers can take advantage of what Engraft has to offer in an unobtrusive and gradual fashion.</p><p>As an example of this, we prototyped embedding of Engraft tools into conventional web-application programming workflows. Specifically, we implemented a React <q>hook</q> called <code>useLiveTool</code> which allows a live tool to be embedded into a React codebase. At development time, this hook presents the Engraft user interface running alongside a live version of the web application being developed (<cross-ref type="fig" xref="synonymizer" index="15"></cross-ref>). Data is fed, live, from the web application being developed into the Engraft user interface. The results are fed, live, back to the web application. When the developer is done working with the tool, they can disable it from being displayed. In production, the <q>computational behavior</q> of the tool is used without any visual presentation.</p><figure id="synonymizer" class="figure" data-counter="15"><img src="assets/2022-09-10-17-47-16.png"></img><figcaption data-counter="15">A conventional web application, Synonymizer, developed with <code>useLiveTool</code>. Because <code>useLiveTool</code> is called with <code>hide:false</code>, the live tool is displayed in the browser, to the right of the running application. Several live tools, including <span class="toolname">Notebook</span> and <span class="toolname">Extractor</span>, are used in this side pane to transform an API response passed from the conventional code into the tool into a clean set of words that can be displayed on screen. The running app shows the live output from the tool.</figcaption></figure><pre><code>const synonyms = useLiveTool(
    { response },
    { defaultValue: [], hide: false}
);</code></pre><p>This is only one example of how Engraft could be embedded into existing development contexts. Different situations will call for different embeddings. For instance, someone writing a command-line program may want to write a particular function with Engraft. Because the command-line program runs imperatively, with side effects, it can not use <code>useLiveTool</code>’s fully-reactive approach where the program re-runs as the user edits the function in Engraft. However, a <q>programming with examples</q> approach <span class="cite-list"><cite-ref key="doi:10.1145/22627.22349" index="26"></cite-ref></span> could be employed, where the user gathers a number of input values for their function before iterating on their function’s implementation, testing it on examples as they go.</p><p>The design and implementation of these various embeddings will be nontrivial, as they must bridge gaps between a variety of programming paradigms and Engraft’s own reactive infrastructure. We discuss some of these challenges briefly in <cross-ref type="sec" xref="technical-limitations" index="6.2"></cross-ref>. However, Engraft’s loosely-coupled functional architecture puts it in a good position to take on these challenges.</p><h3 id="applications" data-counter="3.3.2">Applications</h3><p>Codebases aside, we are also interested in ways interactive end-user applications can host Engraft tools. Graft Garden provides one example, but any application with access to the Web platform could provide an Engraft slot as an access point to the Engraft ecosystem.</p><p>For instance, Cuttle <span class="cite-list"><cite-ref key="cuttle" index="5"></cite-ref></span>, a vector editor for digital fabrication, currently has the ability to implement components and modifiers with bits of JavaScript code. If Cuttle’s code box were replaced with an Engraft slot, the world of Engraft programming tools would be available, in-place, to Cuttle users. (<cross-ref type="fig" xref="cuttle" index="16"></cross-ref>)</p><figure id="cuttle" class="figure" data-counter="16"><img src="assets/2022-09-10-14-51-56.png"></img><figcaption data-counter="16">A mockup of an imagined embedding of Engraft into Cuttle. The Engraft program defines a modifier in Cuttle which transforms an input heart shape into an array of rotated hearts.</figcaption></figure><p>One can imagine applications farther from the world of programming, using Engraft to provide open-ended extensions of their own interfaces. An animation application’s easing-function editor and color picker could be implemented as Engraft slots prepared with default tools. Experienced users could then choose to remove these defaults and replace them with their own tools. In this way, Engraft could enable end-user customization, blurring the lines between application user and developer.</p>
</section>

<section id="4">
<h1 id="design-decisions" data-counter="4">Engraft Design Decisions</h1><p>The Engraft prototype was developed in accordance with five high-level design decisions.</p><p>To support open-ended experimentation in tools, <strong>Engraft is defined as an open API, not a toolkit.</strong>
Engraft tools can be implemented in any way, within the bounds of the Engraft API and the Web platform, adopting their own styling, interaction techniques, and implementation frameworks. A toolkit approach would prematurely lock in constraints on tools’ designs. An API approach also makes it possible to adapt existing tools to Engraft with minimal changes. As a test of this, we wrapped Voyager 2 <span class="cite-list"><cite-ref key="doi:10.1145/3025453.3025768" index="48"></cite-ref></span>, a system for visual data exploration, as an Engraft tool. <cross-ref type="sec" xref="live-environments-inside-live-environments" index="3.2"></cross-ref> shows how this opens up new use-cases for Voyager.</p><p>To connect with existing programming activity, and to enable new forms of composition, <strong>Engraft is built on the Web platform.</strong>
A large part of the computing world now exists on the Web platform. Engraft can be composed together with this existing activity, as we described in <cross-ref type="sec" xref="live-tools-inside-the-outside-world" index="3.3"></cross-ref>. In this way, Engraft tools can perform their own specialized roles in a larger ecosystem. This supports gradual adoption of Engraft, creating a feedback loop of development and use. Engraft’s use of the Web platform is also the basis for Engraft tools’ recursive composability: Engraft tools can host one another because they are both implemented on the Web platform and hosted by the web platform. Systems like mage <span class="cite-list"><cite-ref key="doi:10.1145/3379337.3415842" index="19"></cite-ref></span>, which do not support open-ended embedding of tools on the Web, lack this.</p><p>To support visibility and open-ended composability, <strong>the Engraft API is based on streams of pure values.</strong>
A tool’s host provides it with a set of variables bound to JavaScript values. The tool can, at any point, provide output (a JavaScript value or error) through a host-provided callback. We chose to base communication on a functional, value-oriented paradigm due to the success this paradigm has had in diverse contexts ranging from React to spreadsheets.</p><p>To support both live editing and serious computational use, <strong>Engraft makes tool-running primary and tool-rendering secondary.</strong>
The Engraft API lets a tool run, taking in input from its host and returning output, without rendering any UI. As part of running, the tool offers its host an optional UI. In many situations, the host will use the option of <em>not</em> displaying a tool’s UI, such as when a codebase embeds a live tool in production or when a tool like <span class="toolname">Map</span> only renders an example instance of its body. By allowing tools to run invisibly, Engraft supports these serious computational uses. This relationship between running and displaying is not true the other way around: an Engraft tool’s UI <em>cannot</em> be displayed without running it. Requiring that tool developers create versions of their tools which can run in static environments would be a distraction from Engraft’s goal of supporting pervasively live programming.</p><p>To encourage innovative interactive tools, <strong>Engraft tools are not required to generate or edit underlying textual code.</strong>
In Engraft, a tool’s underlying state is not code, but a serializable JavaScript object we call its <em>program</em>. This program can take any form, and can be interpreted in any way at runtime by the tool’s implementation. This stands in contrast to a common approach taken by live-programming systems, in which a live tool ultimately generates source code which defines its computational behavior, and is often expected to re-parse this code after it has been manually edited. While it is true in a technical sense that any serializable JavaScript object could be represented as textual code and visa versa, the two formats have different grains. In platforms based on tools generating textual code, tool designers are encouraged to make tools based on pre-existing code patterns. With Engraft, we want tool designers to start with a task, and freely determine their design without regard to textual-code idioms.</p>
</section>

<section id="5">
<h1 id="implementation" data-counter="5">Engraft Implementation Details</h1><p>We now present implementation details of the Engraft prototype. We begin with a slightly idealized description of the Engraft API, before explaining a few deviations from this ideal, then go on to discuss the Engraft tool ecosystem.</p><h2 id="the-engraft-api" data-counter="5.1">The Engraft API</h2><p>An Engraft tool is implemented as a JavaScript class that abides by an interface that Engraft specifies. A host uses this interface to create and manage an instance of this tool it wants to embed. Since all tools abide by the same interface, a host that uses this interface can embed any tool.</p><p>A tool class’s interface is centered around a particular bundle of <q>properties</q> that contains all the information a host provides to an embedded tool. When a host creates a tool instance, it provides it with a set of properties (1, below). The host can later call an <q>update</q> method on a tool instance to provide a new set of properties (2, below). Finally, the host can call a <q>destroy</q> method when the tool is no longer needed (3, below).</p><pre><code>const toolInstance = new MyTool(properties);  // 1
toolInstance.update(newProperties);           // 2
toolInstance.destroy();                       // 3</code></pre><p>The real content of the Engraft API lies in the fields of the properties object. They are as follows:</p><ul><li><code>program</code>: The tool’s program, a serializable JavaScript object that defines its behavior.</li><li><code>updateProgram</code>: A callback the tool uses to request a change to its program.</li><li><code>reportOutput</code>: A callback the tool uses to report its output – a value or error.</li><li><code>reportView</code>: A callback the tool uses to report its view (UI).</li><li><code>varBindings</code>: Bindings of variable ids &amp; names to actual values, which the tool can immediately access.</li></ul><p>A tool with access to the above five values has everything it needs to operate. It can read in its program specification, grab bindings from the environment (if needed), perform computations, and report back output and a view. A reported view can display any information gathered during the tool’s execution, including intermediate values and final output. This view can also contain interactive controls which, when acted upon by the user, will trigger <code>updateProgram</code> to modify the tool’s program.</p><p>This design was inspired by the component model of React <span class="cite-list"><cite-ref key="react" index="24"></cite-ref></span>, a library for building user interfaces. React components offer a similar interface, in which a bundle of <q>props</q> is provided by an owner when a component is created, and then updated whenever the owner re-renders. React offers a set of tools for efficiently managing recomputation when a component’s props change, including <q>hooks</q> and higher-order components for memoization.</p><p>React’s model fit Engraft’s needs well enough that we chose to implement our prototype system directly using React. This means that an Engraft tool is defined as a React component, rather than as the class we described above. Our use of React here is quite idiosyncratic. React components usually return trees of HTML elements, but in Engraft, it is essential that view behavior remain optional, and secondary to computational behavior. So Engraft tool components never directly return any HTML elements. When React <q>renders</q> a tool, it will construct an abstract tree that stores and maintains the state of the tool, together with the state of any subtools it may contain. These tools can then use callbacks provided as props to report output values and UI views back up the tree.</p><p>In our use of React, the first four <q>properties</q> above are provided directly to tools as React <q>props</q>. The last property, <code>varBindings</code> is provided indirectly, using React’s <q>context</q> feature. By wrapping a React component in context, the entire subtree under this context gets access to this information. Since most tools pass down the bindings they receive from their parent unchanged to their children, context provides a better developer experience here than props.</p><p>In addition to providing a React component (in lieu of the class we first described), a tool also provides a function called <code>programFactory</code> which is used to initialize a program for a new instance of the tool. To support the common pattern of a tool having a <q>main input</q> which an environment may want to pre-populate, <code>programFactory</code> optionally accepts a string <code>defaultInputCode</code>. This allows ergonomic interactions, such as new cells in a notebook automatically taking in the previous cell as input.</p><p>For more details, the supplemental material includes example code for several small tools. React has served as a helpful infrastructure for Engraft; nevertheless, it may be worth reconsidering in future work, as it is a heavyweight, unorthodox dependency.</p><h2 id="slots-and-subtools" data-counter="5.2">Slots and Subtools</h2><p>Throughout this paper, we have shown Engraft programmers using <q>slots</q> to compose nested programs. The <span class="toolname">Slot</span> tool is the glue that holds together Engraft programs. It is a built-in tool that appears at first as a code editor. Arbitrary JavaScript can be entered into this code editor, where it is compiled, evaluated, and returned as output. References to Engraft variables can be inserted into this editor using an an auto-complete window. If a tool’s name is selected via auto-complete, the slot will be replaced with the tool, entering <q>subtool mode</q> (<cross-ref type="fig" xref="adder_slots" index="17"></cross-ref>).</p><figure id="adder_slots" class="figure" data-counter="17"><img width="20.5%" src="assets/2022-09-08-16-48-21.png"></img>
<img width="29.5%" src="assets/2022-09-08-16-50-09.png"></img>
<img width="40%" src="assets/2022-09-08-16-50-46.png"></img><figcaption data-counter="17">A simple <span class="toolname">Adder</span> tool. Its <q>y</q> slot is provided with (a) a code snippet, (b) a reference to a variable provided by the <span class="toolname">Adder</span>’s host, (c) a nested <span class="toolname">Notebook</span>.</figcaption></figure><p>When <span class="toolname">Slot</span> renders a subtool, it provides it with a <q>tool frame</q> to identify it. On hover, the title bar of this frame also reveals a few buttons (<cross-ref type="fig" xref="tool_frame" index="18"></cross-ref>):</p><ul><li>: Copy the tool’s program to the clipboard, so it can be pasted into a different location.</li><li>: Display a pop-up debugger window with information on the tool’s program and environment.</li><li>: Remove the subtool, bring the slot back into code mode.</li></ul><figure id="tool_frame" class="figure" data-counter="18"><img width="250" src="assets/2022-09-08-16-53-15.png"></img><figcaption data-counter="18">The appearance of an <span class="toolname">Adder</span> tool’s <q>tool frame</q> when its title bar is hovered, revealing three circular buttons.</figcaption></figure><p>We anticipate this frame will support additional general-purpose interactions in the future, such as <q>maximizing</q> a tool for focused work or <q>pinning</q> it to a sidebar.</p><p>Through the use of slots, a <q>tree of tools</q> is formed during the use of Engraft. <cross-ref type="fig" xref="tree_of_tools" index="19"></cross-ref> shows an example arrangement of tools together with a diagram of the resulting tree. Note, however, that there is no explicit reference to a tree of tools anywhere in the Engraft API or implementation. Rather, this tree emerges from the fact that a tool, like any other software system, is free to act as a host that embeds tools.</p><figure id="tree_of_tools" class="figure" data-counter="19"><img width="40%" src="assets/2022-09-08-16-46-22.png"></img>
<img width="50%" src="assets/2022-09-08-16-47-13.png"></img><figcaption data-counter="19">(a) An arrangement of an <span class="toolname">Adder</span> nested in an <span class="toolname">Adder</span> nested in a <span class="toolname">Notebook</span>. (b) The tree of tools resulting from this arrangement. Note the <span class="toolname">Slot</span> tools, which provide the code-editors shown as leaves of the tree, as well as invisible intermediates between tools and their subtools.</figcaption></figure><p>Although it is not built into the Engraft API (which could theoretically be used without it), <span class="toolname">Slot</span> plays an essential role in the Engraft user experience. While the Engraft API provides the computational structures needed for open-ended composition, <span class="toolname">Slot</span> provides users with an interface that makes that composition accessible in practice.</p><h2 id="where-do-tools-come-from" data-counter="5.3">Where do tools come from?</h2><p>We showed earlier how a tool can be implemented as a JavaScript module. This technical description raises a few questions:</p><p>How does a prospective tool user access one of these modules? In our current prototype, we side-step this question – all tools are bundled together with the Engraft system. For actual use, it will be important for tool creators to be able to post tools publicly and for tool users to be able to access them easily. One convenient approach would be to leverage existing package managers like NPM.</p><p>Does every tool need to be coded from scratch, by a developer intimately familiar with Engraft’s low-level API? Right now, yes. But we see a range of possibilities that would support more accessible tool creation. For instance:</p><ul><li>A user could build a composite of Engraft tools (e.g., a color picker built in a computational notebook) and then select parts of this composite to expose in a custom tool interface.</li><li>A user could take an existing web-based tool, and then describe how it could be embedded into an <code>iframe</code> and driven to make it participate in the Engraft API.</li></ul><p>At the same time, our preferred design is to build these higher level meta-tools on top of the minimal Engraft API, which we expect is general enough to support them.</p><h2 id="tools-built-so-far" data-counter="5.4">Tools built so far</h2><p>To date, we have implemented a few dozen primitive tools with Engraft. The examples in <cross-ref type="sec" xref="live-composability-with-engraft" index="3"></cross-ref> highlight some of these: <span class="toolname">Notebook</span>, <span class="toolname">Request</span>, <span class="toolname">Extractor</span>, <span class="toolname">Formatter</span>, <span class="toolname">NotebookCanvas</span>, <span class="toolname">Map</span>, <span class="toolname">Simulation</span>, and <span class="toolname">Voyager</span>. These examples also include <span class="toolname">Slider</span>, <span class="toolname">Color</span>, and <span class="toolname">Text</span> tools. Appendix <cross-ref type="sec" xref="tool-menagerie" short="true" index="A"></cross-ref> includes pictures and brief descriptions of eight more tools.
These tools are all <q>sketches</q>, intended to test the Engraft API’s design and to demonstrate its combinatorial possibilities. We expect that, with continued use, we will see both more polished and more radically divergent tools enter the Engraft ecosystem.</p>
</section>

<section id="6">
<h1 id="discussion" data-counter="6">Discussion</h1><p>Our starting point in this paper is a simple observation: In spite of enormous efforts from industry and academia spanning decades, live-programming tools are not a mainstream part of programming practice. To our knowledge, this fact has not found much discussion in the literature.<inline-note>Tanimoto’s 2013 reflections on live systems <span class="cite-list"><cite-ref key="Tanimoto:2013:PEL" index="44"></cite-ref></span> includes a section on <q>Criticisms of Liveness</q>, though he quickly dismisses them in favor of a generally optimistic view. Lau’s short piece <span class="cite-list"><cite-ref key="DBLP:journals/aim/Lau09" index="20"></cite-ref></span> on why programming-by-demonstration systems (a related category) sometimes fail is insightful, but it focuses on AI-specific aspects and does not apply to live-programming systems in general.</inline-note> We believe that, given the enormous potential live programming might offer, this gap should be confronted head-on.</p><p>This paper proposes <em>composability</em> as an essential element which must be combined with <em>liveness</em> and <em>domain-specific richness</em> to make alternatives to textual code effective in practice. We have presented Engraft: a prototype API which combines these three elements, enabling new forms of composition.</p><p>While we expect the lack of adoption of live tools is due to many factors, and there is no silver bullet that will make live tools truly usable, we believe that the approach Engraft makes concrete is compelling and worth further exploration.</p><h2 id="risks" data-counter="6.1">Risks</h2><p>There are numerous ways Engraft may fail to work in practice.</p><p><strong>Engraft is heterogeneous.</strong> We are excited by the prospect of Engraft fostering a vibrant, diverse, anarchic ecosystem of tools and environments. But our embrace of heterogeneous implementations carries liabilities. It might be challenging for users to learn new tools. It might be uncomfortable to work in a space that ties together discordant interfaces. Interoperability between tools might be a problem, since data exchange formats are not enforced.</p><p><strong>Engraft is untyped.</strong> Engraft is built off the Web platform, and embraces JavaScript’s highly dynamic, untyped style. This stands in contrast to the closely aligned livelits project <span class="cite-list"><cite-ref key="doi:10.1145/3453483.3454059" index="31"></cite-ref></span>, discussed earlier, which specifically builds on Hazel’s strong type discipline. Engraft may fail to scale to more complex work, if it turns out the benefits of static types are essential for managing this complexity. (We suspect that, in many cases, pervasive liveness forms an alternative to static types, but this is a speculative hypothesis.)</p><p><strong>Engraft is non-textual.</strong> Engraft is, ultimately, a structured editor, as an Engraft program is not manipulated entirely as text. This is a fraught path. Plain-text interactions are familiar and well-polished by decades of computing. Structured editors can easily fail to match their fluidity and ergonomics, resulting in frustration from users. Textual code is also assumed by many important workflows, such as version control, and it is not immediately clear how these can be extended to non-textual programs. Recent work has sought to address some of these issues (such as <cite-ref key="restructuring-structured-editing" mode="inline-author" index="25"></cite-ref>’s work on token-level editing and <cite-ref key="image-based" mode="inline-author" index="8"></cite-ref>’s work on version control), but this is still an active area of research.</p><p><strong>Engraft tools are mostly isolated from one another.</strong> An Engraft <q>tool</q> is analogous to a function or other bit of syntax in a functional programming language. It can access bindings provided by its host, return a value back to the host, and that’s it. This design follows a traditional functional-programming discipline, which brings many advantages, but which also constrains the space of what a tool can be. An illustrative example comes from Gneiss <span class="cite-list"><cite-ref key="doi:10.1184/R1/6714389.V1" index="4"></cite-ref></span>. Gneiss combines three separate tools: an API query tool, a spreadsheet, and an interface builder. We wondered how Gneiss could be <q>unbundled</q> with Engraft, so that the tools that make it up could be used in new contexts and different tools could be brought into Gneiss’s context. We found that, while it is possible to construct a workflow similar to Gneiss in Engraft today, the experience does not perfectly replicate Gneiss. Gneiss uses interactions that tightly tie its different tools together, like dragging a JSON field from the API query tool directly to the spreadsheet. It also uses flows of data which are, from a functional-programming perspective, quite messy, such as cyclic data flow between the spreadsheet and the interface builder. These are not presently possible with Engraft. It remains to be seen whether a programming environment like Engraft, based on isolated functional tools, is adequate to produce a holistically rich programming experience, or what would need to be added to the Engraft model to make it so.</p><h2 id="technical-limitations" data-counter="6.2">Technical Limitations</h2><p>Aside from those large unknowns, we already anticipate some ways Engraft will need to be developed to support realistic use.</p><p>Engraft’s <strong>use of the Web platform</strong> is a source of much of its potential, but it also brings along tricky issues. Security is naturally a concern. Web-based programming platforms (like Observable and Natto) have had to put much effort into sandboxing, and we can expect Engraft’s flexibly-nested structures would make this all the more difficult. Another source of challenges is layout and styling. Engraft tools push the boundaries of UI frameworks, since tools act as heterogeneous composable application interfaces. CSS and the rest of the Web platform were not designed to support anything like this. They have worked well for prototyping so far, but careful work is required to find approaches that ensure the system stays robust, even as diverse tools are added.</p><p>Engraft’s current <strong>reactivity model</strong> is limited. Currently, communication between tools and hosts is a free-for-all. A host can deliver new values to a tool whenever it likes, and the tool can reply with output whenever <em>it</em> likes. But there are situations where a greater degree of control is desirable. Certain hosts may want to run a tool synchronously, or run it asynchronously but in such a way that it can know for sure when the tool’s output is <q>up to date</q> with its inputs. Neither of these is possible right now. Changes to the reactivity model could also aid performance, as right now <q>glitches</q> can cause unnecessary computations on out-of-date inputs.</p><p>Engraft’s <strong>embedding into conventional codebases</strong> is incomplete, and there are details in the workflow that need working out. Many uses of live tools from conventional code will need forms of reactivity that are not currently supported, as described in the last paragraph. There are also questions around how the <q>program</q> of a live tool should be persisted. Currently, our prototype of <code>useLiveTool</code> simulates persistence by storing a tool’s program in the user’s web browser local storage. But for any real use, it will be important for this program to be stored as part of the web application’s codebase, where it can be delivered with the application for production use, checked into source control, etc. This means live tools will need to write back to the codebase during development. Careful engineering and design work is required here, as live tools are competing against refined and entrenched textual workflows.</p><h2 id="future-work" data-counter="6.3">Future Work</h2><p>While Engraft has been prototyped well enough to allow experimental use, it has not reached a stage where research would benefit from broad promulgation and use in practice. This is especially true because Engraft takes the form of an API standard. If tools and hosts were built around one version of this API and then future discoveries suggested moving to a new version, effort would be wasted, incompatibilities would proliferate, and confidence would be undermined. Or, perhaps worse, dependencies on one version of Engraft’s design might discourage iteration and exploration of Engraft itself, prematurely locking in an underdeveloped design.</p><p>Given this, there are several appealing ways to continue developing and testing Engraft.
One is to dive into a particular domain where end-user programming feels like a bottleneck, partnering closely with practitioners to test and iterate on the design of Engraft as it applies to their work. Once Engraft’s design can be validated through successful application in multiple domains (say, both creative coding and data science), it may be ready to grow more openly.</p><p>Another is to establish Engraft as an enabling platform for researchers developing experimental live tools. Suppose a researcher has an idea for a novel live tool. Without Engraft, they are in a tough spot. As effective as their tool may be for its task, evaluating the tool requires building enough complementary infrastructure that their novel tool can be demonstrated in an end-to-end workflow. This may involve a significant amount of work which is unrelated to the novel interactions they are exploring. If the researcher implements their tool on top of Engraft, however, they can test it in the context of all the tools, environments, and real-world embeddings that already exist in the Engraft ecosystem. We hope that, in this way, Engraft can lower the barrier to entry for live-tool research and accelerate innovation in this field.</p>
</section>

<section id="appendix">
<h1 id="tool-menagerie" data-counter="A">Tool Menagerie</h1><figure class="figure" position="!htb" data-counter="20"><img width="225" src="assets/2022-09-12-23-51-47.png"></img>
<figcaption data-counter="20"><q><span class="toolname">Import</span></q> allows modules to be dynamically imported from NPM.</figcaption></figure><figure class="figure" position="!htb" data-counter="21"><img width="501" src="assets/2022-09-13-00-09-07.png"></img><figcaption data-counter="21"><q><span class="toolname">File</span></q> lets the user upload a file into the browser by dragging and dropping it onto the tool. The file is then persistently saved in the Engraft program as a <code>data</code> URI string.</figcaption></figure><figure class="figure" position="!htb" data-counter="22"><img width="559" src="assets/2022-09-13-00-27-24.png"></img><figcaption data-counter="22"><q><span class="toolname">State</span></q> stores a piece of ephemeral state. It returns the current value of this state together with a setter. This can be used to implement stateful UIs.</figcaption></figure><figure class="figure" position="!htb" data-counter="23"><img width="485" src="assets/2022-09-13-00-17-44.png"></img><figcaption data-counter="23"><q><span class="toolname">Chalk</span></q> is a code editor that displays live values and errors inline.</figcaption></figure><figure class="figure" position="!htb" data-counter="24"><img width="400" src="assets/2022-09-13-00-34-17.png"></img><figcaption data-counter="24"><q><span class="toolname">Synthesizer</span></q> is a simple example-based program synthesizer, following the example of <span class="cite-list"><cite-ref key="doi:10.1145/3379337.3415869" index="12"></cite-ref></span>.</figcaption></figure><figure class="figure" position="!htb" data-counter="25"><img width="450" src="assets/2022-09-12-23-45-52.png"></img><figcaption data-counter="25"><q><span class="toolname">Chain</span></q> is a minimalist live environment inspired by the data-first design of spreadsheets.</figcaption></figure><figure class="figure" position="!htb" data-counter="26"><img width="600" src="assets/2022-09-13-00-53-46.png"></img><figcaption data-counter="26"><q><span class="toolname">Function</span></q> can be used to define a function, using examples for live feedback. <q><span class="toolname">Call</span></q> can then be used to call the function.</figcaption></figure>
</section>

<section id="references">
<h1 nonumber="true">References</h1><ol class="references"><li id="ref-0">Andersen, L., Ballantyne, M., &amp; Felleisen, M. (2020). Adding interactive visual syntax to textual code. Proceedings of the ACM on Programming Languages, 4(OOPSLA), 1–28. <a href="https://doi.org/10.1145/3428290">https://doi.org/10.1145/3428290</a></li><li id="ref-1">Apple Inc. (2014). WWDC 2014. <a href="https://www.youtube.com/watch?v=w87fOAG8fjk">https://www.youtube.com/watch?v=w87fOAG8fjk</a></li><li id="ref-2">Bootstrap. (2022). Bootstrap. <a href="https://bootstrapworld.org/index.shtml">https://bootstrapworld.org/index.shtml</a></li><li id="ref-3">Chang, K. S.-P. (2016). A Spreadsheet Model for Using Web Services and Creating Data-Driven Applications. Carnegie Mellon University. <a href="https://doi.org/10.1184/R1/6714389.V1">https://doi.org/10.1184/R1/6714389.V1</a></li><li id="ref-4">Cuttle Labs Inc. (2022). Cuttle - Design tool for digital cutting machines. <a href="https://cuttle.xyz/">https://cuttle.xyz/</a></li><li id="ref-5">Edwards, J. (2004). Example centric programming. ACM SIGPLAN Notices, 39(12), 84–91. <a href="https://doi.org/10.1145/1052883.1052894">https://doi.org/10.1145/1052883.1052894</a></li><li id="ref-6">Edwards, J. (2005, October 12). Subtext. Proceedings of the 20th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications. OOPSLA05: ACM SIGPLAN Object Oriented Programming Systems and Applications Conference. <a href="https://doi.org/10.1145/1094811.1094851">https://doi.org/10.1145/1094811.1094851</a></li><li id="ref-7">Edwards, J., &amp; Petricek, T. (2021). Typed Image-based Programming with Structure Editing. arXiv. <a href="https://arxiv.org/abs/2110.08993">https://arxiv.org/abs/2110.08993</a></li><li id="ref-8">Ellis, T. O., Heafner, J. F., &amp; Sibley, W. L. (1969). THE GRAIL PROJECT: AN EXPERIMENT IN MAN-MACHINE COMMUNICATIONS. <a href="https://www.rand.org/pubs/research_memoranda/RM5999.html">https://www.rand.org/pubs/research_memoranda/RM5999.html</a></li><li id="ref-9">Ellis, T., Heafner, J., &amp; Sibley, W. (1969). The GRAIL Language and Operations. RAND Corporation. <a href="https://doi.org/10.7249/rm6001">https://doi.org/10.7249/rm6001</a></li><li id="ref-10">Enso. (2022). Enso. <a href="https://enso.org/">https://enso.org/</a></li><li id="ref-11">Ferdowsifard, K., Ordookhanians, A., Peleg, H., Lerner, S., &amp; Polikarpova, N. (2020, October 20). Small-Step Live Programming by Example. Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology. UIST ’20: The 33rd Annual ACM Symposium on User Interface Software and Technology. <a href="https://doi.org/10.1145/3379337.3415869">https://doi.org/10.1145/3379337.3415869</a></li><li id="ref-12">Granger, C. (2022). Light Table. <a href="http://lighttable.com/">http://lighttable.com/</a></li><li id="ref-13">Horowitz, J. (2018). PANE: Programming with Visible Data. <a href="http://joshuahhh.com/projects/pane/">http://joshuahhh.com/projects/pane/</a></li><li id="ref-14">Imai, T., Masuhara, H., &amp; Aotani, T. (2015, October 25). Shiranui: a live programming with support for unit testing. Companion Proceedings of the 2015 ACM SIGPLAN International Conference on Systems, Programming, Languages and Applications: Software for Humanity. SPLASH ’15: Conference on Systems, Programming, Languages, and Applications: Software for Humanity. <a href="https://doi.org/10.1145/2814189.2817268">https://doi.org/10.1145/2814189.2817268</a></li><li id="ref-15">JetBrains s.r.o. (2022). MPS: The Domain-Specific Language Creator by JetBrains. <a href="https://www.jetbrains.com/mps/">https://www.jetbrains.com/mps/</a></li><li id="ref-16">Kandel, S., Paepcke, A., Hellerstein, J., &amp; Heer, J. (2011, May 7). Wrangler. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI ’11: CHI Conference on Human Factors in Computing Systems. <a href="https://doi.org/10.1145/1978942.1979444">https://doi.org/10.1145/1978942.1979444</a></li><li id="ref-17">Kasibatla, S., &amp; Warth, A. (2017). Seymour: Live Programming for the Classroom. <a href="https://harc.github.io/seymour-live2017/">https://harc.github.io/seymour-live2017/</a></li><li id="ref-18">Kery, M. B., Ren, D., Hohman, F., Moritz, D., Wongsuphasawat, K., &amp; Patel, K. (2020, October 20). mage: Fluid Moves Between Code and Graphical Work in Computational Notebooks. Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology. UIST ’20: The 33rd Annual ACM Symposium on User Interface Software and Technology. <a href="https://doi.org/10.1145/3379337.3415842">https://doi.org/10.1145/3379337.3415842</a></li><li id="ref-19">Lau, T. (2009). Why Programming-By-Demonstration Systems Fail: Lessons Learned for Usable AI. AI Mag., 30(4), 65–67. <a href="https://doi.org/10.1609/aimag.v30i4.2262">https://doi.org/10.1609/aimag.v30i4.2262</a></li><li id="ref-20">Lerner, S. (2020, April 21). Projection Boxes: On-the-fly Reconfigurable Visualization for Live Programming. Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. CHI ’20: CHI Conference on Human Factors in Computing Systems. <a href="https://doi.org/10.1145/3313831.3376494">https://doi.org/10.1145/3313831.3376494</a></li><li id="ref-21">Liu, Z., Thompson, J., Wilson, A., Dontcheva, M., Delorey, J., Grigg, S., Kerr, B., &amp; Stasko, J. (2018, April 19). Data Illustrator. Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. CHI ’18: CHI Conference on Human Factors in Computing Systems. <a href="https://doi.org/10.1145/3173574.3173697">https://doi.org/10.1145/3173574.3173697</a></li><li id="ref-22">Lotem, E., &amp; Chuchem, Y. (2022). Lamdu. <a href="https://www.lamdu.org/">https://www.lamdu.org/</a></li><li id="ref-23">Meta Platforms, Inc. (2022). React – A JavaScript library for building user interfaces. <a href="https://reactjs.org/">https://reactjs.org/</a></li><li id="ref-24">Moon, D., &amp; Omar, C. (2021). Restructuring Structure Editing. <a href="https://tylr.fun/essay/">https://tylr.fun/essay/</a></li><li id="ref-25">Myers, B. A. (1986). Visual programming, programming by example, and program visualization: a taxonomy. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems  - CHI ’86. the SIGCHI conference. <a href="https://doi.org/10.1145/22627.22349">https://doi.org/10.1145/22627.22349</a></li><li id="ref-26">Observable Inc. (2022). Observable - Explore, analyze, and explain data. As a team. <a href="https://observablehq.com/">https://observablehq.com/</a></li><li id="ref-27">Observable Inc. (2022). Quickly Explore &amp; Analyze Your Data With Data Table Cell / Observable / Observable. <a href="https://observablehq.com/@observablehq/introducing-data-table-cell">https://observablehq.com/@observablehq/introducing-data-table-cell</a></li><li id="ref-28">Omar, C., YoungSeok Yoon, LaToza, T. D., &amp; Myers, B. A. (2011, September). Active code completion. 2011 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). 2011 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC 2011). <a href="https://doi.org/10.1109/vlhcc.2011.6070422">https://doi.org/10.1109/vlhcc.2011.6070422</a></li><li id="ref-29">Omar, C., Voysey, I., Chugh, R., &amp; Hammer, M. A. (2019). Live functional programming with typed holes. Proceedings of the ACM on Programming Languages, 3(POPL), 1–32. <a href="https://doi.org/10.1145/3290327">https://doi.org/10.1145/3290327</a></li><li id="ref-30">Omar, C., Moon, D., Blinn, A., Voysey, I., Collins, N., &amp; Chugh, R. (2021, June 18). Filling typed holes with live GUIs. Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation. PLDI ’21: 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation. <a href="https://doi.org/10.1145/3453483.3454059">https://doi.org/10.1145/3453483.3454059</a></li><li id="ref-31">Pipkin, E. (2021). been having some  motivation troubles  recently (god who hasn’t) so i’m gonna pick a tiny personal project off my ideas list and see if i can get it working by morning. tonight - a lil bash script that emails me the summaries of 5 random wikipedia articles each morning. <a href="https://twitter.com/everestpipkin/status/1349274983651012609">https://twitter.com/everestpipkin/status/1349274983651012609</a></li><li id="ref-32">Politz, J., Lerner, B., Porncharoenwase, S., &amp; Krishnamurthi, S. (2019). Event Loops as First-Class Values: A Case Study in Pedagogic Language Design. The Art, Science, and Engineering of Programming, 3(3). <a href="https://doi.org/10.22152/programming-journal.org/2019/3/11">https://doi.org/10.22152/programming-journal.org/2019/3/11</a></li><li id="ref-33">Rauch, D., Rein, P., Ramson, S., Lincke, J., &amp; Hirschfeld, R. (2019). Babylonian-style Programming: Design and Implementation of an Integration of Live Examples into General-purpose Source Code. The Art, Science, and Engineering of Programming, 3(3). <a href="https://doi.org/10.22152/programming-journal.org/2019/3/9">https://doi.org/10.22152/programming-journal.org/2019/3/9</a></li><li id="ref-34">Rein, P., Ramson, S., Lincke, J., Hirschfeld, R., &amp; Pape, T. (2018). Exploratory and Live, Programming and Coding. The Art, Science, and Engineering of Programming, 3(1). <a href="https://doi.org/10.22152/programming-journal.org/2019/3/1">https://doi.org/10.22152/programming-journal.org/2019/3/1</a></li><li id="ref-35">Ren, D., Lee, B., &amp; Brehmer, M. (2019). Charticulator: Interactive Construction of Bespoke Chart Layouts. IEEE Transactions on Visualization and Computer Graphics, 25(1), 789–799. <a href="https://doi.org/10.1109/tvcg.2018.2865158">https://doi.org/10.1109/tvcg.2018.2865158</a></li><li id="ref-36">Satyanarayan, A., &amp; Heer, J. (2014). Lyra: An Interactive Visualization Design Environment. Computer Graphics Forum, 33(3), 351–360. <a href="https://doi.org/10.1111/cgf.12391">https://doi.org/10.1111/cgf.12391</a></li><li id="ref-37">Schmitz, Y. (2019). I’ve been jamming on this concept for making data-driven designs... <a href="https://twitter.com/yoshikischmitz/status/1176642448077967362">https://twitter.com/yoshikischmitz/status/1176642448077967362</a></li><li id="ref-38">Shen, P. (2021). Show HN: Natto – a canvas for writing and manipulating JavaScript. <a href="https://news.ycombinator.com/item?id=26478548">https://news.ycombinator.com/item?id=26478548</a></li><li id="ref-39">Shen, P. (2022). welcome! – natto. <a href="https://natto.dev/">https://natto.dev/</a></li><li id="ref-40">Shipman, F. M., &amp; Marshall, C. C. (1999). Formality Considered Harmful: Experiences, Emerging Themes, and Directions on the Use of Formal Representations in Interactive Systems. Computer Supported Cooperative Work (CSCW), 8(4), 333–352. <a href="https://doi.org/10.1023/a:1008716330212">https://doi.org/10.1023/a:1008716330212</a></li><li id="ref-41">van der Storm, T., &amp; Hermans, F. (2016). Live Literals. <a href="https://homepages.cwi.nl/~storm/livelit/livelit.html">https://homepages.cwi.nl/~storm/livelit/livelit.html</a></li><li id="ref-42">Tanimoto, S. L. (1990). VIVA: A visual language for image processing. Journal of Visual Languages &amp; Computing, 1(2), 127–139. <a href="https://doi.org/10.1016/s1045-926x(05)80012-6">https://doi.org/10.1016/s1045-926x(05)80012-6</a></li><li id="ref-43">Tanimoto, S. L. (2013). A Perspective on the Evolution of Live Programming. Proceedings of the 1st International Workshop on Live Programming, 31–34. <a href="https://doi.org/10.1109/LIVE.2013.6617346">https://doi.org/10.1109/LIVE.2013.6617346</a></li><li id="ref-44">Victor, B. (2012). Inventing on Principle. <a href="https://vimeo.com/36579366">https://vimeo.com/36579366</a></li><li id="ref-45">Victor, B. (2012). Learnable Programming. <a href="http://worrydream.com/LearnableProgramming/">http://worrydream.com/LearnableProgramming/</a></li><li id="ref-46">Wikipedia contributors. (2022). Grafting — Wikipedia, The Free Encyclopedia. <a href="https://en.wikipedia.org/w/index.php?title=Grafting&amp;oldid=1095365064">https://en.wikipedia.org/w/index.php?title=Grafting&amp;oldid=1095365064</a></li><li id="ref-47">Wongsuphasawat, K., Qu, Z., Moritz, D., Chang, R., Ouk, F., Anand, A., Mackinlay, J., Howe, B., &amp; Heer, J. (2017, May 2). Voyager 2. Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. CHI ’17: CHI Conference on Human Factors in Computing Systems. <a href="https://doi.org/10.1145/3025453.3025768">https://doi.org/10.1145/3025453.3025768</a></li></ol></article>
</section>