<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0"/>
    <meta charset="utf-8" />
    <title>Living Papers: A Language Toolkit for Augmented Scholarly Communication</title>
    <meta property="og:title" content="Living Papers: A Language Toolkit for Augmented Scholarly Communication" />
    <meta property="og:type" content="article" />
    <meta property="og:description" content="Living Papers: A Language Toolkit for Augmented Scholarly Communication" />
    <meta property="description" content="Living Papers: A Language Toolkit for Augmented Scholarly Communication" />
    <style>
/* Styles common to every theme */
article {
	--section-prefix: "§";
	--equation-prefix: "Equation ";
	--figure-prefix: "Figure ";
	--table-prefix: "Table ";
	--double-quote-start: "“";
	--double-quote-end: "”";
	--single-quote-start: "‘";
	--single-quote-end: "’";
	--highlight-color: #ff0;
	--tiny-size: 0.5em;
	--script-size: 0.7em;
	--smaller-size: 0.8em;
	--small-size: 0.9em;
	--large-size: 1.2em;
	--larger-size: 1.4em;
	--huge-size: 1.8em;
	--inline-math-size: 1em;
	--ref-color: steelblue;
	--ref-color-light: #c8dae9;
	--ref-color-hover: #90b4d2;
	--ref-color-error: maroon;
	--ref-weight: 500;
	--ref-decoration: none;
}

a {
	color: var(--ref-color);
	font-weight: var(--ref-weight);
	text-decoration: var(--ref-decoration);
}

a:hover {
	color: var(--ref-color-hover);
}

sub,
sup {
	line-height: 0;
}

q {
	quotes: var(--double-quote-start) var(--double-quote-end);
}

q.single {
	quotes: var(--single-quote-start) var(--single-quote-end);
}

blockquote {
	margin-left: 2em;
}

.action {
	cursor: pointer;
	text-decoration: underline dashed 1px #444;
}

.tooltip {
	display: none;
	background-color: white;
	z-index: 1;
	position: absolute;
	filter: drop-shadow(3px 3px 3px rgba(0,0,0,0.2));
	border: 1px solid #ccc;
	padding: 0.5em;
	cursor: auto;
	text-indent: initial;
	text-align: initial;
}

header h1 {
	font-size: var(--huge-size);
}

header .author-org {
	font-style: italic;
}

header .author-org::before {
	content: " · "
}

h1 {
	font-size: 1.4rem;
}

h2 {
	font-size: 1.2rem;
}

h3 {
	font-size: 1.1rem;
}

h4,
h5,
h6 {
	font-size: 1rem;
}

h1[data-counter]::before,
h2[data-counter]::before,
h3[data-counter]::before {
	content: attr(data-counter) " ";
}

figure.teaser > figcaption[data-counter]::before,
figure.figure > figcaption[data-counter]::before {
	content: var(--figure-prefix) attr(data-counter) ". ";
}

figure.table > figcaption[data-counter]::before {
	content: var(--table-prefix) attr(data-counter) ". ";
}

table {
	border-spacing: 0;
	border-collapse: collapse;
	margin: 0;
	margin-bottom: 2px;
}

thead tr {
	border-bottom: 1px solid #ccc;
}

thead th,
tbody td {
	font-size: var(--small-size);
	padding: 1px 0.33em;
	text-align: left;
	font-variant-numeric: tabular-nums;
}

tbody tr {
	border-bottom: 1px solid #eee;
}

ol.references {
	padding-inline-start: 2em;
}

ol.references li {
	font-size: var(--small-size);
	margin-bottom: 6px;
}

/* Only handles layout, e.g. no color styles */
:root {
	--max-article-width: 85ex;
	--article-padding: 32px;
	--margin-width: 400px;
	--gap-width: 100px;
	--article-width: min(var(--max-article-width), calc(100vw - var(--article-padding) * 2 - var(--gap-width) - var(--margin-width)));
	--article-margin-left: max(0px, calc(((100vw - var(--article-width) - var(--gap-width) - var(--margin-width)) / 2)));
}

html {
	box-sizing: border-box;
}

*,
*:before,
*:after {
	box-sizing: inherit;
	margin: 0;
	padding: 0;
}

article {
	width: var(--article-width);
	margin-left: var(--article-margin-left);
	padding: var(--article-padding);
}

h1,
h2 {
	margin: 0;
	padding: 3px;
}

h1,
h2,
h3 {
	margin: 0;
	padding: 0;
}

h1 {
	padding-top: 0.5em;
}

.title {
	font-size: 24pt;
	font-weight: bold;
}

p,
pre,
ul,
ol,
table {
	margin: 0;
}

ul,
ol {
	padding-left: 1.5em;
}

section > p {
	margin-bottom: 16px;
}

section > p:last-child {
	margin-bottom: 0;
}

aside,
.margin {
	position: relative;
	float: right;
	clear: right;
	width: var(--margin-width);
	margin-right: calc(-1 * var(--gap-width) - var(--margin-width));
	margin-bottom: 1em;
	vertical-align: unset;
}

aside {
	margin-left: 0;
	margin-top: 0;
}

aside > :first-child {
	margin-top: 0;
}

aside > :last-child {
	margin-bottom: 0;
}

.inlinenote-number {
	line-height: 1;
	padding: 1px;
}

.float-left {
	float: left;
	margin-right: 1em;
}

.float-right {
	float: right;
	margin-left: 1em;
}

.sticky {
	position: sticky;
	top: 0;
	z-index: 10;
}

.page {
	text-align: justify;
	width: calc(90vw - 2 * var(--article-padding) - 2 * var(--article-margin-left));
}

pre,
figure {
	max-width: calc(100vw - 2 * var(--article-padding) - 2 * var(--article-margin-left));
	overflow-x: auto;
}

.full {
	max-width: 100vw;
}

.full-image {
	width: 100%;
	object-fit: cover;
	vertical-align: middle;
}

.full figcaption {
	background: #eee;
	padding: 16px 0;
}

.centered {
	text-align: center;
}

.justify {
	text-align: justify;
}

figure {
	margin: 0;
	padding: 5px 0;
}

figure img,
figure svg,
figure canvas,
aside img,
aside svg,
aside canvas {
	object-fit: contain;
	max-width: 100%;
	height: auto;
}

header {
	padding-bottom: 1em;
}

footer {
	padding: 2em 0;
}

@media (max-width: 1100px) {
	:root {
		--article-padding: 16px;
	}

	article {
		width: min(var(--max-article-width), calc(100% - var(--article-padding) * 2));
	}

	pre,
	figure {
		max-width: calc(100vw - var(--article-padding) * 2);
	}

	.page {
		width: min(var(--max-article-width), 100%);
	}

	aside,
	.margin {
		float: none;
		margin: 0;
		width: auto;
	}

	.inline-note-number {
		cursor: pointer;
		padding: 1px 4px;
	}

	.inline-note:not(.open) .note,
	.inline-note .note::before {
		display: none;
	}
}

@media print {
	.sticky {
		position: relative;
	}
}

.error-block {
  display: block;
  border: solid 1px red;
  padding: 1em;
  max-width: 800px;
  font-size: 0.9em;
}

.cite-ref {
  color: var(--ref-color);
  font-weight: var(--ref-weight);
  text-decoration: var(--ref-decoration);
  cursor: pointer;
}

.cite-ref:hover {
  color: var(--ref-color-hover);
}

.cite-ref.unresolved,
.cite-ref.unresolved:hover {
  color: var(--ref-color-error);
}

.cite-ref .tooltip {
  width: 400px;
  font-weight: normal;
  color: black;
}

.cite-ref.unresolved .tooltip {
  text-align: center;
  padding: 4px;
  width: auto;
}

.cite-author, .cite-venue {
  margin-top: 0.25em;
}

.cite-author-button {
  padding: 4px;
  background-color: #eee;
  border-radius: 6px;
  font-size: 0.9em;
  cursor: pointer;
}

.cite-author-hidden {
  display: none;
}

.cite-year, .cite-author, .cite-venue {
  color: #666;
}

.cite-title a {
  font-weight: bold;
}

.cite-venue {
  font-style: italic;
}

.cite-detail {
  border-top: 1px solid #ccc;
  padding-top: 0.5em;
  margin-top: 0.5em;
}

.cross-ref {
  color: var(--ref-color);
  font-weight: var(--ref-weight);
  text-decoration: var(--ref-decoration);
  cursor: pointer;
}

.cross-ref:hover {
  color: var(--ref-color-hover);
}

.cross-ref.unresolved,
.cross-ref.unresolved:hover {
  color: var(--ref-color-error);
}

.cross-ref.sec.full::before {
  content: var(--section-prefix);
}

.cross-ref.fig.full::before {
  content: var(--figure-prefix);
}

.cross-ref.tbl.full::before {
  content: var(--table-prefix);
}

.cross-ref.eqn.full::before {
  content: var(--equation-prefix);
}

.cross-ref-tooltip {
  color: black;
}

.cross-ref-tooltip figure {
  width: 400px;
  padding-bottom: 0;
}

.cross-ref-tooltip figcaption {
  background-color: white;
  padding-bottom: 0;
}

.note {
	font-style: italic;
}

.inline-note .note::before {
	content: attr(data-number);
	position: absolute;
	right: var(--margin-width);
	padding-left: 1ex;
	padding-right: 1ex;
}

.draggable-text {
  text-decoration: underline dashed #888;
  cursor: ew-resize;
}

:not(.katex-display) > .katex {
  font-size: var(--inline-math-size) !important;
}

.katex * {
  pointer-events: none;
}

.katex .enclosing, .katex .enclosing *, .katex .maug-parent {
  pointer-events: initial;
}

.katex .maug {
	display: inline-block;
	cursor: pointer;
}

.katex .maug:hover {
	background: rgba(103, 176, 202, 0.22);
}

.katex .maug-tooltip {
  z-index: 99;
  position: absolute;
  border-bottom: 2px solid #000;
  background: #fff;
  border-radius: 2px;
  padding: 1px 5px;
  filter: drop-shadow(1px 1px 2px rgba(0, 0, 0, .2));
  font-size: 0.85em;
  pointer-events: none !important;
}

.katex .maug-tooltip svg {
  display: inline-block;
  position: absolute;
}

.katex .maug-tooltip * {
  pointer-events: none !important;
}

.toggle-text {
  text-decoration: underline dashed #888;
  cursor: pointer;
}

.quadtree {
  background-color: white;
  text-align: center;
}
article {
	--inline-math-size: 1.14em;
}

body {
	font: 16px/1.5 -apple-system, system-ui, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
	background: #fff;
	color: #000;
}

pre,
:not(pre) > code {
	font-family: monospace;
	font-size: 15px;
}

h1,
h2,
h3,
h4,
h5,
h6 {
	font-weight: 600;
	line-height: 1.25em;
	margin: 24px 0 16px;
}

h1,
h2 {
	border-bottom: 1px solid rgba(0, 0, 0, 0.1);
	padding-bottom: 6px;
	width: fit-content;
}

article p,
article > ul,
article > ol,
article > table,
article > pre,
article > code-block > pre,
.katex-display {
	margin: 12px 0;
}

td,
th {
	border-bottom: 1px solid rgba(0, 0, 0, 0.2);
	transition: 0.1s ease-out;
}

th,
tr:hover td {
	background: rgba(0, 0, 0, 0.1);
}

figure > figcaption {
	font-weight: 600;
	font-size: var(--small-size);
	line-height: 1.4em;
	padding-bottom: 1ex;
}

.sticky {
	background: rgba(255, 255, 255, 0.8);
	backdrop-filter: blur(4px);
}

aside,
.note {
	font-style: inherit;
	font-size: var(--small-size);
}

.note {
	background: #fff;
	transition: 0.1s ease-out;
}

.inline-note:hover .inline-note-number,
.inline-note:hover .note {
	background: var(--ref-color-light);
}

.inline-note .note::before {
	font-size: var(--smaller-size);
}

.normal {
  font-weight: 400;
}

.demi {
  font-weight: 600;
}

.bold,
.strong {
  font-weight: 700;
}

.mono,
.code {
  font-family: monospace;
}

.em,
.emph,
.italic {
  font-style: italic;
}

.highlight {
  background-color: var(--highlight-color);
}

.strike {
  text-decoration: line-through;
}

.underline {
  text-decoration: underline;
}

.smallcaps {
  font-variant: small-caps;
}

.lowercase {
  text-transform: lowercase;
}

.uppercase {
  text-transform: uppercase;
}

.capitalize {
  text-transform: capitalize;
}

.left {
  text-align: left;
}

.right {
  text-align: right;
}

.center {
  text-align: center;
}

.justify {
  text-align: justify;
}

.tiny {
  font-size: var(--tiny-size);
}

.scriptsize {
  font-size: var(--script-size);
}

.smaller,
.footnotesize {
  font-size: var(--smaller-size);
}

.small {
  font-size: var(--small-size);
}

.large {
  font-size: var(--large-size);
}

.larger {
  font-size: var(--larger-size);
}

.huge {
  font-size: var(--huge-size);
}

.hide {
  display: none;
}

aside {
  margin-top: 10px;
}

h1 {
  margin-top: 2em;
}

h2 {
  margin-top: 2em;
}

.interactive {
  background-color: white;
  padding: 1em;
  filter: drop-shadow(2px 2px 4px rgba(0, 0, 0, .2));
}

.math-input {
  display: inline-block;
  width: 220px;
}

.math-input input {
  font-family: monospace !important;
  font-size: 0.9em !important;
  border: 1px dashed #ccc;
  padding: 3px;
  border-radius: 4px;
  outline: none;
}

figure.page {
  margin-bottom: 1em;
}

.references {
  overflow-wrap: break-word;
}

    </style>
  </head>
  <body>
    <article><header><h1 role="banner">Living Papers: A Language Toolkit for Augmented Scholarly Communication</h1><div class="author"><span class="author-name">Jeffrey Heer</span><span class="author-org">University of Washington</span></div><div class="author"><span class="author-name">Matthew Conlen</span><span class="author-org">University of Washington</span></div><div class="author"><span class="author-name">Vishal Devireddy</span><span class="author-org">University of Washington</span></div><div class="author"><span class="author-name">Tu Nguyen</span><span class="author-org">University of Washington</span></div><div class="author"><span class="author-name">Joshua Horowitz</span><span class="author-org">University of Washington</span></div></header><h1 nonumber="true">Abstract</h1><p>Computing technology has deeply shaped how academic articles are written and produced, yet article formats and affordances have changed little over centuries.
The status quo consists of digital files optimized for printed paper—ill-suited to interactive reading aids, accessibility, dynamic figures, or easy information extraction and reuse.
Guided by formative discussions with scholarly communication researchers and publishing tool developers, we present Living Papers, a language toolkit for producing augmented academic articles that span print, interactive, and computational media.
Living Papers articles may include formatted text, references, executable code, and interactive components.
Articles are parsed into a standardized document format from which a variety of outputs are generated, including static PDFs, dynamic web pages, and extraction APIs for paper content and metadata.
We describe Living Papers’ architecture, document model, and reactive runtime, and detail key aspects such as citation processing and conversion of interactive components to static content.
We demonstrate the use and extension of Living Papers through examples spanning traditional research papers, explorable explanations, information extraction, and reading aids such as enhanced citations, cross-references, and equations.
Living Papers is available as an extensible, open source platform intended to support both article authors and researchers of augmented reading and writing experiences.</p><h1 id="introduction" data-counter="1">Introduction</h1><aside class="html:only" style="max-width: 360px;"><blockquote><p><img class="interactive" width="300" alt="Scanned page from a journal." src="assets/philosophical-transactions.png"></img></p></blockquote><p>A page from <em>Philosophical Transactions of the Royal Society</em> (1665), one of the first scientific journals.</p></aside><p>For centuries, the format of academic articles has adhered to conventions compatible with the movable type printing press: a <q>user interface</q> consisting of textual, mathematical, and graphical content organized into sections, figures, and linkages such as footnotes, bibliographic citations, and cross-references.
In recent decades, computational technologies such as word processing, digital typesetting, and the Internet have had a tremendous impact on how research articles are written, produced, archived, and accessed, yet had relatively little impact on the structure of articles themselves.
Physical paper has multiple virtues as a format—it is tangible and archival, with no batteries required.
But academic articles are now often read on a screen <span class="cite-list">[<cite-ref key="ritchie2022big" index="52"></cite-ref>]</span>, using a proprietary format optimized for print (PDF) that suffers from accessibility concerns <span class="cite-list">[<cite-ref key="doi:10.1145/2851581.2892588" index="6"></cite-ref>]</span> and complicates computational extraction and analysis <span class="cite-list">[<cite-ref key="doi:10.48550/arXiv.2301.10140" index="31"></cite-ref>]</span>.</p><p>In contrast, visions of alternative publishing formats have been a staple of Human-Computer Interaction since the inception of the field, from initial hypertext designs <span class="cite-list">[<cite-ref key="doi:10.1145/800197.806036" index="42"></cite-ref>]</span>, to the World Wide Web <span class="cite-list">[<cite-ref key="doi:10.1145/179606.179671" index="5"></cite-ref>]</span>, to interactive documents now published regularly by data-driven journalists <span class="cite-list">[<cite-ref key="doi:10.1145/3242587.3242600" index="9"></cite-ref>]</span>.
Despite exciting innovations in augmented reading aids <span class="cite-list">[<cite-ref key="doi:10.1145/3290605.3300295" index="14"></cite-ref>, <cite-ref key="doi:10.1145/3411764.3445648" index="22"></cite-ref>, <cite-ref key="doi:10.1145/3491102.3501932" index="23"></cite-ref>, <cite-ref key="doi:10.1145/3490099.3511162" index="51"></cite-ref>]</span> and experiments with online-first research venues <span class="cite-list">[<cite-ref key="doi:10.23915/distill.00031" index="59"></cite-ref>, <cite-ref key="visxai" index="66"></cite-ref>]</span>, academic publishing remains resistant to change.</p><p>Meanwhile, both corporations <span class="cite-list">[<cite-ref key="gscholar" index="18"></cite-ref>]</span> and non-profits <span class="cite-list">[<cite-ref key="doi:10.18653/v1/N18-3011" index="2"></cite-ref>]</span> have indexed large swathes of the literature, often applying vision and NLP methods for not-always-accurate extraction of paper content and metadata <span class="cite-list">[<cite-ref key="doi:10.1162/tacl_a_00466" index="57"></cite-ref>]</span>.
These efforts enable large-scale search and scientometric analysis <span class="cite-list">[<cite-ref key="doi:10.1126/science.aao0185" index="17"></cite-ref>]</span>;
however, robust and flexible tools for content extraction and reuse remain out of reach for many researchers.</p><p>We seek to bridge present and future publishing through novel authoring tools.
We contribute Living Papers, a framework for writing enhanced articles that encompass multiple output types:
<em>interactive web pages</em> to enable augmented reading experiences, accessibility, and self-publishing;
<em>static PDFs</em> to align incentives and participate in existing publishing workflows;
and <em>application programming interfaces (APIs)</em> to enable easy extraction and reuse of both article content and executable code.
In sum, Living Papers is a <q>language toolkit</q> consisting of a standardized document model and a set of extensible parsers, transforms, and output generators.</p><aside class="interactive margin html:only"><p>This web-based article includes interactive content!
Here is a trivial, but fun, explorable:</p><cell-view data-cell="2"></cell-view><cell-view data-cell="3"></cell-view><cell-view data-cell="8"></cell-view></aside><p>To support dynamic reading aids and explorable explanations <span class="cite-list">[<cite-ref key="expexp" index="62"></cite-ref>]</span>, Living Papers produces web-based articles with a reactive runtime and extensible component system.
We use Markdown <span class="cite-list">[<cite-ref key="markdown" index="20"></cite-ref>]</span> as a default input format, with syntax extensions for custom components.
Articles may include executable code in languages such as JavaScript, R, and Python to generate static or interactive content.
To support <q>backwards compatibility</q> with current publishing practices, the Living Papers compiler automatically converts interactive and web-based material to static content, and generates LaTeX <span class="cite-list">[<cite-ref key="latex" index="36"></cite-ref>]</span> projects or compiled PDFs using extensible journal and conference templates.
To assist not only people but also computers to more easily interpret papers, Living Papers can compile article content into accessible data structures, APIs, and software modules.</p><p>We present our design objectives for Living Papers, honed in conversations with publishing tool developers and researchers of both augmented reading aids and information extraction from academic articles.
We seek to balance tensions among dynamic content, accessible authoring, participation in existing publishing workflows, and research into novel techniques.
We evaluate the system by demonstration, sharing articles by ourselves and others that span formal research papers (including this one!), explorable explanations, and enhanced content extraction and reuse.
These examples highlight augmentations such as enhanced previews for citations and cross-referenced material, equations with interactive term definitions, and articles with dynamic content such as explorable multiverse analyses <span class="cite-list">[<cite-ref key="doi:10.1145/3290605.3300295" index="14"></cite-ref>]</span>.
Living Papers is available as open source software, and intended to support both article authors and researchers exploring augmented forms of scholarly communication.</p><div class="interactive html:only"><p>Other resources:</p><ul><li><a href="index.pdf">LaTeX PDF version of this paper</a></li><li><a href="../">Supplemental material: articles and extraction APIs</a></li></ul></div><h1 id="rel" data-counter="2">Related Work</h1><p>Living Papers connects prior research on augmented reading, article authoring tools, and information extraction from academic papers.</p><h2 id="rel-reading" data-counter="2.1">Augmented Reading</h2><p>Augmented reading interfaces have long been a topic of HCI research.
In addition to the development of hypertext <span class="cite-list">[<cite-ref key="doi:10.1145/800197.806036" index="42"></cite-ref>]</span> and HTML <span class="cite-list">[<cite-ref key="doi:10.1145/179606.179671" index="5"></cite-ref>]</span>, earlier works include <cite-ref key="doi:10.1145/142750.142751" mode="inline-author" index="25"></cite-ref>’s Edit Wear and Read Wear—a document viewer showing traces of social reading and writing activity—and Xerox PARC projects including Fluid Documents <span class="cite-list">[<cite-ref key="doi:10.1145/332040.332440" index="67"></cite-ref>]</span> and eXperiments in the Future of Reading (XFR) <span class="cite-list">[<cite-ref key="doi:10.1145/369825.369829" index="21"></cite-ref>]</span>.</p><aside class="html:only"><p><img alt="A visual overview of 16 kinds of math augmentation in four categories: visual notation (geometry and data), style (color, brightness, and space), annotation (border, background, extent, strikethrough, pointer, connector, and labels), and interactivity (editable, scrubbable, external controls, and linked selection)." src="assets/maugs.png"></img>
An overview of math augmentations by <cite-ref key="doi:10.1145/3491102.3501932" mode="inline-author" index="23"></cite-ref>.</p></aside><p>More recent research focuses specifically on scholarly communication.
A common aim is to provide contextual information about references, technical terms, and mathematical symbols where they are used, without having to break one’s flow by jumping to another part of the document.
ScholarPhi <span class="cite-list">[<cite-ref key="doi:10.1145/3411764.3445648" index="22"></cite-ref>]</span> annotates papers with definitions of terms and symbols.
Other projects study math augmentations to improve the readability of formulas <span class="cite-list">[<cite-ref key="doi:10.1145/3491102.3501932" index="23"></cite-ref>]</span>,
perform rich linking of text and tables <span class="cite-list">[<cite-ref key="doi:10.1109/TVCG.2018.2865119" index="4"></cite-ref>, <cite-ref key="doi:10.1145/3242587.3242617" index="30"></cite-ref>]</span>,
provide context by surfacing citation text from later papers <span class="cite-list">[<cite-ref key="doi:10.1145/3490099.3511162" index="51"></cite-ref>]</span>,
support skimming via automatic highlights <span class="cite-list">[<cite-ref key="doi:10.48550/arXiv.2205.04561" index="16"></cite-ref>]</span>,
and produce plain language summaries for broader audiences <span class="cite-list">[<cite-ref key="doi:10.48550/arXiv.2203.00130" index="3"></cite-ref>]</span>.
Some of these techniques are now available in the online Semantic Reader application <span class="cite-list">[<cite-ref key="semreader" index="1"></cite-ref>]</span>.
<cite-ref key="doi:10.1145/3290605.3300295" mode="inline-author" index="14"></cite-ref> prototype <q>multiverse</q> analyses of varied data analysis choices by interacting with the paper itself.
Living Papers provides a platform for the development and deployment of such techniques.</p><p>Elsewhere, interactive articles with dynamic figures, annotations, and embedded simulations have gained prominence, particularly in data-driven journalism <span class="cite-list">[<cite-ref key="doi:10.1145/3242587.3242600" index="9"></cite-ref>]</span>.
Distill.pub <span class="cite-list">[<cite-ref key="doi:10.23915/distill.00031" index="59"></cite-ref>]</span>, a journal for explaining machine learning, and the IEEE VISxAI workshop <span class="cite-list">[<cite-ref key="visxai" index="66"></cite-ref>]</span>, provide academic venues for online-first, interactive web content.
However, Distill is now on indefinite hiatus <span class="cite-list">[<cite-ref key="doi:10.23915/distill.00031" index="59"></cite-ref>]</span>, in part due to the editing and mentoring costs of high-quality interactive articles.
Living Papers seeks to make it easier to write and self-publish such articles, but also align incentives by simultaneously producing static outputs for submission to traditional research venues.</p><h2 id="rel-authoring" data-counter="2.2">Authoring Tools</h2><p>Academic articles are typically written using word processors or digital typesetting tools, notably TeX <span class="cite-list">[<cite-ref key="tex" index="34"></cite-ref>]</span> and LaTeX <span class="cite-list">[<cite-ref key="latex" index="36"></cite-ref>]</span>.
TeX’s mathematical notation has become a <em>de facto</em> standard for writing formulae, also applicable on the Web via packages such as KaTeX <span class="cite-list">[<cite-ref key="katex" index="15"></cite-ref>]</span>.
Collaborative authoring is supported via web applications, including Overleaf <span class="cite-list">[<cite-ref key="overleaf" index="47"></cite-ref>]</span>.
Typst <span class="cite-list">[<cite-ref key="typst" index="61"></cite-ref>]</span> is a more recent alternative to TeX with its own markup language and integrated scripting language, runnable online via WebAssembly.
For formatted text, Markdown <span class="cite-list">[<cite-ref key="markdown" index="20"></cite-ref>]</span> is a popular alternative to both HTML and LaTeX.</p><p>Pandoc <span class="cite-list">[<cite-ref key="pandoc" index="39"></cite-ref>]</span> is a document converter with many-to-many (though sometimes lossy) transformations among formats.
Pandoc parses input documents into an internal abstract syntax tree (AST) representation, from which it then produces converted outputs.
Living Papers follows a similar approach, and even uses Pandoc to parse input Markdown files, but differs by providing built-in reading augmentations, an integrated reactive runtime, an extensible component system, and API outputs for information extraction.</p><p>Authoring tools may include executable code to enable interactivity or to support computational generation of content such as figures, tables, and statistical models.
Knuth’s Literate Programming <span class="cite-list">[<cite-ref key="doi:10.1093/comjnl/27.2.97" index="35"></cite-ref>]</span> popularized the interleaving of code and narrative within a single document and has had a strong influence on computational notebooks and related formats <span class="cite-list">[<cite-ref key="doi:10.1145/3173574.3173606" index="53"></cite-ref>]</span>.
Computational notebooks including Jupyter <span class="cite-list">[<cite-ref key="jupyter" index="33"></cite-ref>]</span> and Observable <span class="cite-list">[<cite-ref key="observable" index="46"></cite-ref>]</span> structure a document into <q>cells</q> that may contain text (with Markdown syntax) or runnable code.
CurveNote <span class="cite-list">[<cite-ref key="curvenote" index="13"></cite-ref>]</span> builds on Jupyter notebooks to produce online articles, while JupyterBook <span class="cite-list">[<cite-ref key="jupyterbook" index="28"></cite-ref>]</span> uses a Markdown-based format (MyST <span class="cite-list">[<cite-ref key="myst" index="41"></cite-ref>]</span>) with references to external notebook content.</p><p>RMarkdown <span class="cite-list">[<cite-ref key="rmarkdown" index="50"></cite-ref>]</span> and its successor Quarto <span class="cite-list">[<cite-ref key="quarto" index="49"></cite-ref>]</span> interleave executable code blocks into Markdown syntax. Code is extracted, evaluated, and results are stitched back into the document. Code is typically evaluated at compile time (e.g., running an R script), though Quarto also supports <q>live</q> JavaScript in the browser.
Living Papers similarly supports interleaved text and code, and can execute code either at compile time or within an integrated reactive runtime and component system.
Both Living Papers and Quarto independently chose to incorporate the JavaScript dialect of Observable notebooks <span class="cite-list">[<cite-ref key="observable" index="46"></cite-ref>]</span> for interactive content.
Quarto does not provide a component library and relies primarily on Pandoc for its implementation (Living Papers uses Pandoc only for parsing).</p><p>Manubot <span class="cite-list">[<cite-ref key="doi:10.1371/journal.pcbi.1007128" index="26"></cite-ref>]</span> provides a toolchain for scholarly publishing that takes Markdown files as input, supports automatic resolution of Digital Object Identifiers (DOIs), and generates static Web and PDF output using Pandoc and GitHub actions.
Living Papers similarly supports retrieval of bibliographic metadata given DOIs or other paper identifiers.
Nota <span class="cite-list">[<cite-ref key="nota" index="12"></cite-ref>]</span> is a tool for writing web documents with augmented reading aids and interactive figures implemented within the React <span class="cite-list">[<cite-ref key="react" index="40"></cite-ref>]</span> framework.
Nota uses a variant of Markdown syntax extended with constructs for defining terms and inline scripting.</p><p>Idyll <span class="cite-list">[<cite-ref key="doi:10.1145/3242587.3242600" index="9"></cite-ref>]</span> is a language for interactive articles, including explorable explanations <span class="cite-list">[<cite-ref key="expexp" index="62"></cite-ref>]</span>.
Idyll uses Markdown syntax, extended to include arbitrary components, and produces web applications implemented using React.
Living Papers similarly supports an extensible component model, though using W3C-standard custom HTML elements rather than React.
Living Papers uses a modified version of Idyll’s abstract syntax tree (AST) format, and provides an extended tool chain to support academic articles, including citation processing, multiple output formats, and conversion of interactive content to static output.
In addition, Living Papers uses Observable’s reactive runtime for linked interactive content.
In contrast to Idyll, Living Papers authors can write code directly in their articles and import content from existing Observable notebooks, enabling custom interactives with much less software engineering.
Fidyll <span class="cite-list">[<cite-ref key="doi:10.48550/arXiv.2205.09858" index="11"></cite-ref>]</span> provides a higher-level syntax for Idyll focused squarely on narrative visualization, and also targets slideshow, video, and PDF output.</p><p>Living Papers and the projects above share significant overlaps.
Markdown syntax is prevalent across projects and multiple tools use identifiers such as DOIs to automatically resolve bibliographic data.
Living Papers differs from the other projects by combining both support for academic papers (including <q>built-in</q> reading augmentations) and an integrated reactive runtime and component system.
To the best of our knowledge, Living Papers is also unique in generating APIs for context extraction and reuse.</p><p>Meanwhile, other tools for interactive documents use graphical interfaces rather than textual markup and code.
Idyll Studio <span class="cite-list">[<cite-ref key="doi:10.1145/3472749.3474731" index="10"></cite-ref>]</span> provides a WYSIWYG editor for Idyll articles (though not custom components).
Webstrates <span class="cite-list">[<cite-ref key="doi:10.1145/2807442.2807446" index="32"></cite-ref>]</span> support collaborative editing to a shared, network-accessible document model.
VisFlow <span class="cite-list">[<cite-ref key="doi:10.1145/3411764.3445354" index="58"></cite-ref>]</span> uses text-chart links to support dynamic layouts for narrative visualization.
Scalar <span class="cite-list">[<cite-ref key="scalar" index="60"></cite-ref>]</span> is a web-first tool that provides authoring interfaces and content reuse, primarily serving the digital humanities community.
Here we focus on the language toolkit provided by Living Papers, upon which future graphical and collaborative editors might build.</p><h2 id="rel-extraction" data-counter="2.3">Information Extraction &amp; Reuse</h2><p>Other projects focus on analyzing and extracting content from papers, sometimes available only in PDF form.
Augmented reading techniques (<cross-ref type="sec" xref="rel-reading" index="2.1"></cross-ref>) and literature review tools <span class="cite-list">[<cite-ref key="doi:10.48550/arXiv.2205.02007" index="27"></cite-ref>]</span> depend upon accurate identification or synthesis of term definitions <span class="cite-list">[<cite-ref key="doi:10.48550/arXiv.2010.05129" index="29"></cite-ref>]</span>, citation sentences <span class="cite-list">[<cite-ref key="doi:10.1145/3490099.3511162" index="51"></cite-ref>]</span>, summary text <span class="cite-list">[<cite-ref key="doi:10.48550/arXiv.2203.00130" index="3"></cite-ref>]</span>, and more.
Extraction tools include GROBID <span class="cite-list">[<cite-ref key="doi:10.1007/978-3-642-04346-8_62" index="37"></cite-ref>]</span> and the infrastructure behind the open Semantic Scholar graph <span class="cite-list">[<cite-ref key="doi:10.18653/v1/N18-3011" index="2"></cite-ref>]</span>.
Extraction tools can <q>unlock</q> content to convert PDF documents to more screen reader accessible HTML <span class="cite-list">[<cite-ref key="doi:10.1145/3441852.3476545" index="63"></cite-ref>]</span> or interpret bitmap images of charts <span class="cite-list">[<cite-ref key="doi:10.1145/2047196.2047247" index="56"></cite-ref>]</span>.
However, automatic extraction from PDFs is a difficult, error-prone task <span class="cite-list">[<cite-ref key="doi:10.1162/tacl_a_00466" index="57"></cite-ref>]</span>.</p><p>Living Papers instead supports extraction and reuse directly from published results.
In addition to articles intended for people to read, Living Papers produces outputs for computational use.
Living Papers generates a structured AST format in JavaScript Object Notation (JSON) and an application programming interface (API) that provides convenient access to paper metadata (title, authors, etc.) and content (section text, figures, captions, references, <em>in situ</em> citations).
Moreover, the interactive content of a Living Papers article compiles to a separate, importable JavaScript module, enabling reuse of computational content in other articles or web pages.</p><h1 id="goals" data-counter="3">Design Goals &amp; Process</h1><p>Living Papers seeks to balance sometimes competing goals, such as supporting both interactive web articles and standard print workflows.
Through our iterative development we have discussed our goals and progress with multiple stakeholder groups.
Over the period of a year we spoke with augmented reading and accessibility researchers from the CHI, UIST, VIS, and ASSETS communities; information extraction and knowledge base researchers (many associated with the Semantic Scholar team <span class="cite-list">[<cite-ref key="doi:10.18653/v1/N18-3011" index="2"></cite-ref>]</span>); and publishing tool developers, including contributors to Quarto <span class="cite-list">[<cite-ref key="quarto" index="49"></cite-ref>]</span>, Distill.pub <span class="cite-list">[<cite-ref key="doi:10.23915/distill.00031" index="59"></cite-ref>]</span>, Nota <span class="cite-list">[<cite-ref key="nota" index="12"></cite-ref>]</span>, Jupyter <span class="cite-list">[<cite-ref key="jupyter" index="33"></cite-ref>]</span>, Observable <span class="cite-list">[<cite-ref key="observable" index="46"></cite-ref>]</span>, and the New York Times.
We use Living Papers to write our own research articles and observed its use by graduate students in a Fall 2022 course on the Future of Scholarly Communication.
Through this process we arrived at the following design considerations.</p><p><em><strong>Augmented</strong> reading experiences.</em>
We seek to aid contextual understanding of references, formulas, and other content without <q>bouncing</q> between paper sections (<cross-ref type="sec" xref="rel-reading" index="2.1"></cross-ref>).
By default, output web articles include contextual previews for both citations and cross-references.
We also demonstrate extensions for augmented equations, term definitions, and alternative reading interfaces.</p><p><em><strong>Computational</strong> media.</em>
We seek to recast scholarly publications from static articles to computational artifacts more amenable to both people and machines.
Authors should be able to incorporate reproducible results such as models and data visualizations, which can then be reused as-is in other media.
Living Papers supports interaction via a reactive runtime that integrates executable code blocks and an extensible component library that includes augmented citations, cross-references, equations, and interactive text.
While tools like Semantic Scholar rely on accurate information extraction to provide reading aids, Living Papers side-steps this issue via language design and enables downstream extraction by producing APIs to query paper content and reuse reactive web content.</p><p><em><strong>Approachable</strong> writing and content generation.</em>
We sought a familiar yet sufficiently expressive markup language, leading us to use Markdown as our default input format.
We follow Pandoc’s <span class="cite-list">[<cite-ref key="pandoc" index="39"></cite-ref>]</span> Markdown syntax, which is familiar to users of RMarkdown <span class="cite-list">[<cite-ref key="rmarkdown" index="50"></cite-ref>]</span> and includes constructs for tables, math blocks, and citations.
In addition, syntax highlighting (e.g., in VSCode) is already supported.
We want to simplify inclusion of computer-generated models and figures, for example using executable code blocks.
In addition, Living Papers’ citation processor performs automatic lookup of bibliographic metadata from DOIs and other identifiers (e.g., PubMed and Semantic Scholar ids) to help ease reference management, while still supporting standard citation formats such as BibTeX.</p><p><em><strong>Compatible</strong> with existing publishing norms.</em>
We hypothesize that the print-focused needs of current publication workflows is a major impediment to the adoption of augmented formats.
Distill.pub editors, for instance, emphasized the issue of aligning to existing incentives.
Living Papers supports both interactive web-based content and traditional print-based media.
Authors should be able to write their content once and generate both augmented web pages and submission-worthy PDFs.
To accommodate these needs, Living Papers automatically converts interactive material to static text or images for print output, while also supporting output-specific blocks when authors wish to specialize content for different media.</p><p><em><strong>Accessible</strong> and <strong>archivable</strong> content and interactions.</em>
Accessibility researchers expressed a strong preference for HTML over PDF, as HTML output with semantic tags better supports screen readers than standard PDF output.
Living Papers’ default web page template uses a responsive layout that adjusts for desktop or mobile viewing.
By publishing to the Web, Living Papers is also applicable to more informal genres such as blog posts.
Meanwhile, static output enables printing to paper for both reading and archival purposes.</p><p><em><strong>Collaborative</strong> authoring and review.</em>
Much academic work is collaborative in nature.
Living Papers uses plain text formats that operate well with revision control and diff’ing tools such as Git, supporting awareness and integration of collaborators’ work.
We also support anchored annotations <span class="cite-list">[<cite-ref key="doi:10.1016/S1389-1286(00)00043-8" index="48"></cite-ref>]</span> to a Living Papers AST, providing infrastructure for collaborative commentary or annotations of terms or named entities of interest.
Though beyond the scope of this paper, we plan to build on these features to support collaborative authoring and reviewing interfaces in future work.</p><p><em><strong>Extensible</strong> platform for research.</em>
While Living Papers is intended to be useful as-is, our collective understanding of the design space of augmented reading aids and effective use of interactivity is still developing.
For example, augmented reading researchers desired an extensible research platform for better dissemination and testing of techniques.
To support continued research and evaluation, Living Papers provides an open architecture with flexible parsing, transforms, and output formats.
Living Papers can support exploration of new input markup languages, AST transforms, reading aids, custom interactive components, output types, and more.</p><p>In terms of <em>non-goals</em>, web application frameworks, static site generators, and narrative visualization tools (e.g., for rich <q>scrollytelling</q> <span class="cite-list">[<cite-ref key="doi:10.1145/3242587.3242600" index="9"></cite-ref>]</span>) overlap with Living Papers.
We do not attempt to cover this space, but instead focus squarely on academic articles.
We prioritize familiarity and practicality (including use of Markdown, the Observable runtime, BibTeX, and leaky abstractions over LaTeX) over formal elegance—<q>evolution, not revolution.</q>
This focus was honed by discussions with notebook and publishing tool creators, and by the accretive history of the Web versus other document systems, all the way back to Nelson and the <q>curse of Xanadu</q> <span class="cite-list">[<cite-ref key="xanadu" index="65"></cite-ref>]</span>.
Living Papers intentionally embraces a <q>polyglot</q> syntax.</p><h1 id="examples" data-counter="4">Example Articles</h1><p>Before detailing Living Papers’ technical building blocks, we present a set of example articles that span—and blur the distinction between—traditional research papers and explorable explanations.
All article sources and outputs are included as supplemental material.
Beyond the examples presented here, both ourselves and others have used Living Papers to write research papers for course projects and for venues such as IEEE VIS, ACM CHI, and UIST—including this paper.</p><h2 id="example-kde" data-counter="4.1">Fast &amp; Accurate Kernel Density Estimation</h2><figure id="kde" class="figure page" position="t" data-counter="1"><img width="98%" alt="Screenshots of a research paper titled  in PDF and HTML formats. The HTML output shows tooltips for citation information and figure references." src="assets/fast-kde.png"></img><figcaption data-counter="1">Living Papers version of an IEEE VIS 2021 paper, with PDF (<em>left</em>) and HTML (<em>center</em>) output generated from the same source document. Web output includes reading aids for citations (<em>top right</em>) and cross-references (<em>bottom right</em>).</figcaption></figure><p><cross-ref type="fig" xref="kde" index="1"></cross-ref> shows an IEEE VIS 2021 paper on kernel density estimation <span class="cite-list">[<cite-ref key="doi:10.1109/VIS49827.2021.9623323" index="24"></cite-ref>]</span>.
The original LaTeX manuscript includes text, equations, and figures created with the Vega visualization grammar <span class="cite-list">[<cite-ref key="doi:10.1109/TVCG.2015.2467091" index="54"></cite-ref>]</span>, which were manually converted from SVG to PDF format.
The Living Papers version is written in a more <em>approachable</em> Markdown syntax, produces <em>compatible</em>, <em>archivable</em> PDF output, and converts source SVG images to PDF output for inclusion in LaTeX.
Living Papers uses extended Markdown syntax to define a <code>figure</code> component:</p><pre><code>::: figure {#id .class property=value}
![alt text](image.svg)
| Caption text
:::</code></pre><p>References in BibTeX format can be included in-document, in a separate file, or retrieved using an inline identifier (e.g., using DOIs, <code>@doi:10.1109/VIS49827.2021.9623323</code>).
Living Papers’ more <em>accessible</em> <code>html</code> output includes <em>augmented</em> reading aids that provide previews for citations and cross-references (<cross-ref type="fig" xref="kde" index="1"></cross-ref>, <em>right</em>).</p><p>Living Papers also helps manage figure layout across media types.
The Web-based version includes margin figures (indicated by a <code>.margin</code> class on figure components), which, for the <code>latex</code> output, are instead placed within a two-column layout.
LaTeX is notoriously finicky with figure layout: to ensure desired placement, authors may need to move figure source definitions far from the content they reference.
Living Papers provides a <code>\place{id}</code> directive that indicates where to place a referenced figure or table within the output <code>latex</code> source.
This allows <code>html</code> output to place the figure where it is defined in the original Living Papers source, while repositioning the figure as desired within generated LaTeX.
To adjust layout and prevent undesirable gaps or overflows, the <code>latex</code> output module also accepts a <code>vspace</code> option that systematically inserts vertical offset instructions for figures, captions, or other named node types.
We have found these extensions valuable for expediting article production, including for this current paper.</p><h2 id="example-lucas" data-counter="4.2">An Iterative Image Registration Technique</h2><figure id="maugs" class="figure page" data-counter="2"><img alt="Screenshot of a Living Papers article with semantically colored equations. A colored variable has a tooltip with the description  There is a related line graph in the sidebar." src="assets/lucas-kanade.png"></img>
<figcaption data-counter="2">Colored terms with nested, interactive definitions (<em>left</em>) aid equation understanding in Lucas &amp; Kanade’s classic optical flow estimation paper <span class="cite-list">[<cite-ref key="LucasKanade81" index="38"></cite-ref>]</span>. A <q>sticky</q> margin figure (<em>right</em>) stays fixed while scrolling the current section, maintaining context.</figcaption></figure><p><cross-ref type="fig" xref="maugs" index="2"></cross-ref> recreates Lucas &amp; Kanade’s paper on optical flow estimation <span class="cite-list">[<cite-ref key="LucasKanade81" index="38"></cite-ref>]</span>.
The Living Papers version provides math augmentations <span class="cite-list">[<cite-ref key="doi:10.1145/3491102.3501932" index="23"></cite-ref>]</span> to help readers make sense of the paper’s formulas, demonstrating Living Papers’ <em>extensibility</em>.
Equations include colored terms; in-situ definitions are revealed on mouse click.
A custom AST transform first parses <code>definitions</code> components in the document source:</p><aside class="interactive html:only"><p>Equations augmented with term definitions:</p><tex-math maug="\begin{split}
  @F&#39;(x) &amp;\approx \frac{@F(x + @h) - @F(x)}{@h} \\
  &amp;= \frac{@G(x) - @F(x)}{@h}
\end{split}">\begin{split}
  F&#39;(x) &amp;\approx \frac{F(x + h) - F(x)}{h} \\
  &amp;= \frac{G(x) - F(x)}{h}
\end{split}</tex-math></aside><pre><code>~~~ definitions
@F :blue: First stereo image
@x :red: Position vector in an image
~~~</code></pre><p>Mathematical notation can reference defined terms within <code>$</code>-delimited inline math (e.g., <code>$@F(@x)$</code> <span class="html:only">for <tex-math mode="inline" code="F(x)" maug="@F(@x)"></tex-math></span>) and equation components (<code>~~~ equation</code>).
Augmented formulas are then rendered using Web components that inject color annotations into KaTeX <span class="cite-list">[<cite-ref key="katex" index="15"></cite-ref>]</span> source and bind event listeners to the rendered terms.
<em>Compatible</em> <code>latex</code> output shows normal, unaugmented math.</p><p>The article includes <em>augmented</em> <q>sticky</q> figures that persist to maintain context while reading.
For <code>html</code> output, adding the attribute <code>sticky-until=&quot;#sec4_2&quot;</code> to a figure component causes that figure to stay on-screen until the section with id <code>sec4_2</code> is reached.
The <code>latex</code> output ignores these web-specific annotations.</p><h2 id="example-multiverse" data-counter="4.3">Explorable Multiverse Analysis</h2><figure id="multiverse" class="figure" position="t" data-counter="3"><img alt="Screenshot of a webpage containing a point plot with error bars. There is a scrubbable input embedded in the plot’s text description." src="assets/multiverse-drag.png"></img>
<figcaption data-counter="3">Interactive text enables explorable multiverse analysis of data analysis choices <span class="cite-list">[<cite-ref key="doi:10.1145/3290605.3300295" index="14"></cite-ref>]</span>. Dragging or clicking the text cycles through statistical procedures and resulting plots.</figcaption></figure><aside class="interactive html:only"><p>Multiverse analysis of experimental results:</p><p><img data-attr="1" alt="Point plot with error bars."></img></p><ul><li>Transform: <toggle-text data-bind="logTransform">
<span>Log-transformed data</span>
<span>Untransformed data</span></toggle-text></li><li>Procedure: <toggle-text data-bind="bootstrap">
<span>BCa bootstrap</span>
<span>Parametric (t-distribution)</span></toggle-text></li><li>Confidence level: <option-text options="[50,68,80,90,95,99,99.9]" suffix="%" span="20" data-bind="confidenceLevel"></option-text></li></ul></aside><p>Living Papers articles can include interactive <em>computational</em> content.
Here we recreate <cite-ref key="doi:10.1145/3290605.3300295" mode="inline-author" index="14"></cite-ref>’s explorable multiverse analyses for assessing the sensitivity of different statistical analysis decisions.
Readers can explore a range of data analysis choices by interacting with built-in components for draggable and toggleable text (<cross-ref type="fig" xref="multiverse" index="3"></cross-ref>).
For example, the following inline component syntax adds draggable text for a choice of confidence interval levels:</p><pre><code>[:option-text:]{
  options=[50,68,80,90,95,99,99.9]
  suffix=&quot;%&quot;
  bind=confidenceLevel
}</code></pre><p>The reactive runtime binds the component value to the runtime’s <code>confidenceLevel</code> variable, causing all dependent components to update.
The inline JavaScript code <code>`js confidenceLevel`</code>, for example, dynamically displays the current value as output text.
Other bound components similarly update via two-way bindings.</p><p>The article uses pre-computed images for all confidence level and analysis procedure combinations (e.g., bootstrapped vs. parametric intervals).
The image syntax <code>![alt text](`figA`)</code> binds code output—here, the variable <code>figA</code>—to the image source URL.
Alternatively, result images could be generated during article compilation by using the <code>knitr</code> transform to evaluate R code blocks (<cross-ref type="sec" xref="transforms-optin" index="7.2"></cross-ref>).</p><p>This article also compiles to <em>compatible</em> LaTeX.
An output-specific AST transform (<cross-ref type="sec" xref="transforms-output" index="7.3"></cross-ref>) evaluates the reactive runtime in a headless web browser, generates static content, and rewrites the article AST by replacing all dynamic elements.
The resulting PDF is a coherent article describing just the default set of analysis choices.</p><h2 id="example-barnes-hut" data-counter="4.4">The Barnes-Hut Approximation</h2><figure id="barnes-hut" class="figure page" data-counter="4"><img alt="Screenshot of an explanation of the average running time theta of the Barnes-Hut algorithm. There is a line graph, interactive text, and a quadtree visualization." src="assets/barnes-hut.png"></img>
<figcaption data-counter="4">An explorable explanation of the Barnes-Hut approximation for N-body forces. Linked text and chart elements update the <tex-math mode="inline" code="\Theta"></tex-math> variable in the Living Papers reactive runtime, driving highlighting and simulation parameters.</figcaption></figure><aside class="interactive barnes-hut html:only"><p>Explore n-body force estimation:</p><p><barnes-hut data-attr="2" width="350" height="350" layout="false" estimate="true"></barnes-hut></p><cell-view data-bind="theta" data-cell="15"></cell-view></aside><p><cross-ref type="fig" xref="barnes-hut" index="4"></cross-ref> shows an explorable explanation of the Barnes-Hut approximation for N-body forces, originally written using Idyll <span class="cite-list">[<cite-ref key="doi:10.1145/3242587.3242600" index="9"></cite-ref>]</span>, which demonstrates <em>augmented</em> reading, <em>computational</em> media, and <em>extensibility</em>.
A custom simulation component—showcasing force-directed layout and interactive visualizations of quadtree structures and force calculations—is included as a margin figure that persists throughout the article.
The simulation and linked plots update in response to interactions with the article, including input from <em>action links</em> (e.g., <code>[Θ = 0.5](`theta=0.5`)</code>) and bound sliders (created with the Observable standard library’s <code>Inputs.range</code> method):</p><pre><code>~~~ js {bind=theta}
Inputs.range([0, 2], { step: 0.1, label: &#39;Theta&#39; })
~~~</code></pre><p>Similar to the Idyll version, the force simulation and Vega-based plots are implemented as custom components.
Converting the original React components to W3C custom HTML elements was straightforward, involving changes only to <q>wrapper</q> code.
However, the Idyll version also involves custom components for sliders and action links (implemented in separate JavaScript files) and integration logic that requires knowledge of Idyll internals.
Living Papers supports these features, including reuse of common Observable components, directly within the primary article source.</p><p>The article compiles to LaTeX, but, if done naïvely, can produce an illegible article due to the lack of interaction.
Using <em>output-specific</em> blocks, Living Papers authors can designate content that should be included only for target output types.
Here, we can annotate the persistent interactive simulation as <code>html:only</code>.
We can then use <code>latex:only</code> blocks to include <em>compatible</em> simulation snapshots with desired keyframe parameters in the static output.</p><figure id="zoomable" class="figure margin" data-counter="5"><img alt="Zoomed out and zoomed in views of a paper reading interface." src="assets/engraft.png"></img>
<figcaption data-counter="5">A zoomable paper reading interface created by post-processing Living Papers <code>html</code> output.</figcaption></figure><h2 id="example-zoomable" data-counter="4.5">Zoomable Paper Reader</h2><p><cross-ref type="fig" xref="zoomable" index="5"></cross-ref> shows an <em>augmented</em> reading interface created by a student, demonstrating <em>extensible</em> output.
JavaScript code post-processes Living Papers <code>html</code> output into a zoomable, column-oriented layout.
The initial view provides an overview of the full paper.
A reader can freely pan and zoom the canvas.
For a linear reading experience, the reader can click a region of the article (Fig. <cross-ref type="fig" xref="zoomable" short="true" index="5"></cross-ref> <em>top-left</em>) and zoom in to a tracked, scrollable navigation mode (Fig. <cross-ref type="fig" xref="zoomable" short="true" index="5"></cross-ref> <em>bottom-center</em>).
When the reader reaches the end of a column, they can continue scrolling to trigger automatic panning along a <q>track</q> to the top of the next column.
The content in each column is standard Living Papers output, with the same reading aids and reactive content options previously discussed.
We are now refactoring this layout and navigation code into a reusable <code>html</code> output template.</p><h1 id="living-papers-architecture" data-counter="5">Living Papers Architecture</h1><figure id="overview" class="figure page" data-counter="6"><img alt="Pipeline diagram of the Living Papers compilation process, showing input source text, parsed abstract syntax tree, and output PDF, web page, and API code." src="assets/overview.png"></img>
<figcaption data-counter="6">Overview of Living Papers compilation. Input files (e.g., using extended Markdown syntax) are parsed to produce an Abstract Syntax Tree (AST) that is further updated by AST transforms for citations, executable code, and more. Modules for <code>web</code>, <code>latex</code>, and <code>api</code> output apply output-specific AST transforms and then generate output files.</figcaption></figure><figure id="pipeline" class="figure page" data-counter="7"><img alt="A detailed pipeline diagram showing all computational steps. The input markdown is preprocessed into transformed markdown, parsed into a Pandoc AST, converted into an initial Living Papers AST, transformed into a canonical Living Papers AST, and then transformed into output-specific ASTs and outputs." src="assets/pipeline.png"></img>
<figcaption data-counter="7">Pipeline to parse a Markdown file (<cross-ref type="sec" xref="parse" index="6"></cross-ref>), perform AST transforms (<cross-ref type="sec" xref="transforms" index="7"></cross-ref>), and generate HTML, LaTeX, and API outputs (<cross-ref type="sec" xref="output" index="8"></cross-ref>).</figcaption></figure><p>Living Papers uses the compilation pipeline illustrated in Figures <cross-ref type="fig" xref="overview" short="true" index="6"></cross-ref> &amp; <cross-ref type="fig" xref="pipeline" short="true" index="7"></cross-ref>.
Input files are <em>parsed</em> into an abstract syntax tree (AST).
AST <em>transforms</em> then analyze and update the AST, including citation processing and analysis of executable code, to form a <em>canonical AST</em> that represents the article in standalone fashion.
One or more <em>output modules</em> take the canonical AST as input, apply <em>output-specific transforms</em>, and then generate output files.
Living Papers is implemented in JavaScript and provides a command line utility (<code>lpub</code>) for article compilation.
Here we describe the core abstractions of the document model, reactive runtime, and extensibility mechanisms.
Later sections further detail the compilation steps of parsing (<cross-ref type="sec" xref="parse" index="6"></cross-ref>), AST transformation (<cross-ref type="sec" xref="transforms" index="7"></cross-ref>), and output generation (<cross-ref type="sec" xref="output" index="8"></cross-ref>).</p><h2 id="document-model" data-counter="5.1">Document Model</h2><p>Living Papers uses an AST format adapted from Idyll <span class="cite-list">[<cite-ref key="doi:10.1145/3242587.3242600" index="9"></cite-ref>]</span>, analagous to the Document Object Model (DOM) used by web browsers.
An AST is representable in JSON format, facilitating both processing and serialization.
At the top-level, an AST consists of three properties: <em>metadata</em>, <em>data</em>, and the <em>article</em> tree.
Article <em>metadata</em> includes information such as title, authors, and keywords, as well as processing options for outputs, transforms, and components.
Article <em>data</em>, such as resolved citations or term definitions, can be accessed by downstream components and generated APIs.
Extensions can add their own data properties as needed.
Living Papers includes a stand-alone library for AST creation, modification, and traversal.</p><p>The document tree is rooted at the AST <em>article</em> property.
A document node may contain a <em>type</em>, <em>name</em>, <em>properties</em>, and either a <em>value</em> or <em>children</em>.
Currently, we only use the types <em>textnode</em> and <em>component</em>.
A text node contains verbatim text as a string <em>value</em>.
Component nodes include a <em>name</em> (e.g., <code>p</code> for paragraph or <code>em</code> for emphasis) and may include <em>children</em> as an array of child AST nodes.
<cross-ref type="fig" xref="overview" index="6"></cross-ref> (<em>middle</em>) illustrates this AST structure.
All Living Papers start with a root node with the component name <code>article</code>.</p><p>Node properties consist of key-value pairs where the <em>values</em> take one of three types.
<em>Value</em>-typed properties simply contain a static value.
<em>Expression</em>-typed properties contain a reactive JavaScript expression, which can be used to dynamically set component properties.
<em>Event</em>-typed properties contain JavaScript event handler code.
Unlike expression properties, event handlers can update variable assignments in the reactive runtime (<cross-ref type="sec" xref="runtime" index="5.2"></cross-ref>).
The special <code>class</code> property may contain one or more named classes used to style content.
Living Papers includes a standard set of classes for layout and sizing shared by <code>html</code> and <code>latex</code> output.</p><p>Our design prioritizes Web output, while maintaining flexibility for other outputs.
Basic AST component nodes adhere to matching HTML elements.
Living Papers’ <code>p</code>, <code>link</code>, and <code>image</code> nodes map to <code>p</code>, <code>a</code>, and <code>img</code> HTML tags, with properties that align to corresponding HTML attributes.
Similarly, formatting (<code>em</code>, <code>strong</code>, <code>blockquote</code>, …) and list (<code>ul</code>, <code>ol</code>, <code>li</code>) nodes mirror their HTML equivalents.</p><p>Other nodes are specific to Living Papers.
The <code>cite-list</code> and <code>cite-ref</code> nodes represent citations.
A <code>cross-ref</code> node represents a reference to a section, <code>figure</code>, <code>table</code>, or <code>equation</code> elsewhere in the article.
The <code>code</code> and <code>codeblock</code> components represent source code, often with syntax highlighting.
Meanwhile, <code>math</code> and <code>equation</code> nodes represent expressions in TeX math notation.</p><aside class="interactive html:only"><p>Typeset math for <cell-view class="math-input" data-bind="texcode" inline="true" data-cell="17"></cell-view></p><tex-math data-attr="3"></tex-math></aside><p>Component nodes for executable code, math formulas, or other specialized syntax may include content in a <code>code</code> property or child text node.
For example, a <code>math</code> node with the formula for the golden ratio <tex-math mode="inline" code="\phi"></tex-math> could contain a single child text node with the string <code>\phi=\frac{1+\sqrt{5}}{2}</code>.
Downstream transforms or output modules then process this content as needed.
With <code>html</code> output, each of these is ultimately displayed using a custom HTML element.</p><h2 id="runtime" data-counter="5.2">Reactive Runtime</h2><p>To support interaction, Living Papers includes a <em>reactive runtime</em> in which changes to variables or code outputs automatically propagate to dependent elements.
Though the runtime is browser-based, it is tied to features of Living Papers’ core document model, including <em>expression</em>- and <em>event</em>-typed properties.</p><p>Unlike Idyll, which uses its own basic reactive variable store within a React <span class="cite-list">[<cite-ref key="react" index="40"></cite-ref>]</span> context, Living Papers uses the same reactive runtime as Observable notebooks <span class="cite-list">[<cite-ref key="obsruntime" index="45"></cite-ref>]</span>.
In addition to providing a robust and performant reactive engine, we chose this approach to leverage Observable’s standard library (with built-in access to libraries including D3 <span class="cite-list">[<cite-ref key="doi:10.1109/TVCG.2011.185" index="7"></cite-ref>]</span> and Vega-Lite <span class="cite-list">[<cite-ref key="doi:10.1109/TVCG.2016.2599030" index="55"></cite-ref>]</span>) and import content from existing Observable notebooks.
Authors can create content such as dynamic figures within an external notebook and then reuse that work, importing it directly in a Living Papers article.</p><p>After initial parsing, an AST transform identifies executable code blocks using Observable’s JavaScript dialect and converts them to <code>cell-view</code> component nodes.
Multiple named cells (reactive units) can be defined within one code block by using a single-line <code>---</code> delimiter. Only the last cell in a block is mapped to visible output.</p><p>Other components can also participate.
<em>Expression</em>-valued properties map to reactive variables in the runtime, updating their corresponding components upon change.
<em>Event</em>-valued properties are evaluated upon component input events (such as click), and can assign new values to named reactive variables, triggering article updates.
Both custom components and JavaScript-defined elements (e.g., Observable Inputs <span class="cite-list">[<cite-ref key="obsinputs" index="44"></cite-ref>]</span>) can serve as input widgets, so long as the resulting Web element exposes a gettable and settable <em>value</em> property.
Living Papers AST nodes also support a <code>bind</code> property that instructs the runtime to instantiate a two-way binding between a named reactive variable and the input component <em>value</em>.</p><aside class="interactive html:only"><p>A slider-bound variable and interpolated math:</p><cell-view data-bind="v" data-cell="19"></cell-view><p><tex-math data-attr="4" mode="inline"></tex-math></p></aside><p>Depending on the input format, Living Papers provides syntactic sugar for runtime integration.
In Living Papers Markdown, the span <code>$$x^2 = ${v}^2 = ${v*v}$$</code> specifies a dynamic equation: JavaScript string interpolation is performed for the templated code <code>${v}</code> and <code>${v*v}</code>, the resulting TeX formula is then typeset.
We use a double <code>$$</code> delimiter here to enable these internal template variables.
Instead of a normal hyperlink, the link syntax <code>[click me](`v+=1`)</code> specifies an <em>action link</em>
with an <em>event</em>-typed <code>onclick</code> property invoked upon click.
Similarly, the image syntax <code>![alt text](`image_src`)</code> creates an <em>expression</em>-valued <code>src</code> property that dynamically sets the source URL to the <code>image_src</code> variable.</p><h2 id="extensibility" data-counter="5.3">Extensibility</h2><p>The Living Papers compiler marshals a number of extensible modules.
Articles may specify AST <em>transforms</em> to apply.
Web output may include <em>components</em> implemented as custom HTML elements.
Both <code>html</code> and <code>latex</code> output are generated using <em>templates</em>.</p><p>The compiler maintains a <em>context</em> object across parsing, transforms, and output generation to provide access to needed resources and services.
The context provides access to the source file paths, directories, and external options (to complement or override options provided as article metadata) as well as caching, logging, and a resolution method for extension lookup.</p><p>Living Papers supports third-party extensions using a resolution scheme to lookup external transforms, components, templates, parsers, or output modules.
If an extension is specified as a file path, it is looked up directly, typically within the same article project.
Otherwise, the extension specification is treated as an npm (Node Package Manager) package name and looked up using Node.js’ built-in resolution algorithm.
Third-party packages can include a special <code>living-papers</code> entry in their <code>package.json</code> file, providing a manifest for any extensions (transforms, components, etc.) provided; these are then added to the compiler’s internal registry.</p><h1 id="parse" data-counter="6">Input Parsing</h1><figure id="md-components" class="figure margin" data-counter="8"><pre style="margin-bottom: 1em;"><code>::: figure {#overview .page position=&quot;t&quot;}
![alt text](image.png)
| Figure caption text.
:::

~~~ equation {#kde}
f(x) = \frac{1}{n\sigma} \sum_{i=1}^{n}
  K{\Big (}\frac{x - x_i}{\sigma}{\Big )}
~~~

[:range-text:]{min=1 max=10 bind=var}</code></pre><figcaption data-counter="8">Living Papers Markdown syntax for block and inline component elements. Fenced blocks (<code>:::</code>) contain Markdown content to be parsed. Verbatim blocks (<code>~~~</code>) pass child content as-is. Inline elements may include parsed child content in the span after the <code>:component-name:</code>.</figcaption></figure><p>Parsing is the first phase of article compilation.
The Living Papers architecture supports arbitrary parsers dispatched by file extension or a specified input type, including the <q>non-parser</q> of reading in an existing canonical AST JSON file.
That said, our current implementation focuses on an extended Markdown format.</p><p>Given its familiarity and support for citations, references, tables, and more, we use Pandoc’s Markdown variant.
The parser module calls the Pandoc binary to parse inputs and produce a Pandoc AST in JSON format, then transforms the Pandoc AST to a Living Papers AST.
Prior to invoking Pandoc, a pre-processor is used to handle our customized component syntax, including block and inline components (<cross-ref type="fig" xref="md-components" index="8"></cross-ref>), and to properly escape backtick-quoted code in component attributes, action links, and images.
The pre-processor emits Pandoc-compatible Markdown.<inline-note>We adopted Pandoc to expedite development. However, the parser does not track input token positions, which are valuable for linking input and output. Pandoc and the pre-processor may later be replaced by a JavaScript implementation. That said, parsing Pandoc ASTs provides an avenue for conversion from other formats (see <cross-ref type="sec" xref="discussion" index="9"></cross-ref>).</inline-note></p><p>The parser performs additional interpretation tasks when mapping the Pandoc AST to a Living Papers AST.
Notably, it classifies different references by type.
While <code>@Knuth:84</code> cites a reference by id (e.g., in BibTeX), <code>@doi:10.1093/comjnl/27.2.97</code> instead cites the work by its DOI.
Meanwhile, references such as <code>@fig:overview</code> or <code>@eqn:kde</code> are cross-references to article content.
The parser distinguishes among these based on the prefix.</p><p>Though the Markdown parser is not internally extensible at present, Living Papers can also accept entirely new parsers.
In any case, novel components are supported via AST transforms.
For example, a transform can extract and process code blocks with custom component names (e.g., the math term definitions in <cross-ref type="sec" xref="example-lucas" index="4.2"></cross-ref>).
As such transforms of verbatim content are applied downstream of the initial parse, they can be reused with any future parsers as long as those parsers produce compatible ASTs.</p><h1 id="transforms" data-counter="7">AST Transforms</h1><p>After an initial parse, the compiler applies AST transforms to map the parser output to a canonical AST representation of the article.
Different output modules may also apply subsequent AST transforms.
An AST transform is created by calling a constructor method that passes in options, resulting in a function that takes an AST and context (<cross-ref type="sec" xref="extensibility" index="5.3"></cross-ref>) as input and returns a modified AST as output.</p><h2 id="transforms-postparse" data-counter="7.1">Post-Parse Transforms</h2><p>The first transform applied after parsing handles <em>inclusion</em> of additional content.
Depending on the specified options, additional source files are loaded, either parsed or left verbatim, and then added to the AST.
As in many other document processors, this allows article content to be spread over multiple files.</p><p>The next transform performs <em>runtime code extraction</em>, identifying executable code (e.g., <code>`js value.toFixed(2)`</code>) and mapping it to <code>cell-view</code> components for inclusion in the reactive runtime.
Subsequent parsing and generation of runtime code occurs later during <code>html</code> output generation (<cross-ref type="sec" xref="output-web" index="8.1"></cross-ref>).</p><p>The <em>citations</em> transform provides citation processing.
Any external bibliography (BibTeX) files referenced in the article metadata are first loaded and parsed.
Next, the transform finds <code>bibliography</code> component nodes in the AST and parses their verbatim content.
Bibliographic data is parsed using the citation.js library <span class="cite-list">[<cite-ref key="citejs" index="64"></cite-ref>]</span>, with CSL-JSON <span class="cite-list">[<cite-ref key="csl" index="8"></cite-ref>]</span> as our canonical format.
The transform then traverses the AST to visit all <code>cite-ref</code> nodes.
If a citation refers to a work by an internal id, the transform attempts to look up that id among the parsed entries.
If the citation instead uses an external id such as a DOI, the transform attempts to retrieve a CSL-JSON entry from the Web.
For DOI lookup we use the REST API of <a href="https://doi.org">doi.org</a>.
Given a resolved external id, the transform also queries the Semantic Scholar API <span class="cite-list">[<cite-ref key="doi:10.18653/v1/N18-3011" index="2"></cite-ref>]</span> for additional information, including abstracts and summary (<q>tldr</q>) snippets.
Network request results are cached across iterative compilations for improved performance.</p><p>The <em>citations</em> transform produces multiple results.
Bibliographic entries for all cited works are included in a formatted bibliography at the end of the article.
All <code>cite-ref</code> nodes are updated to include an integer index into the sorted bibliography and a resolved id.<inline-note>If a DOI and internal id refer to the same article, they are resolved to a single id.</inline-note>
To support in-context reading aids and information extraction, bibliographic data (CSL-JSON, BibTeX, and Semantic Scholar data) are added to the article AST’s top-level <code>data</code> property under the <code>citations</code> key.
Citation lookup failures are also recognized, resulting in informative error messages.</p><h2 id="transforms-optin" data-counter="7.2">Opt-In Transforms</h2><p>Opt-in AST transforms specified in an article’s metadata run after the standard transforms.
Either custom third-party transforms or the following built-in transforms may be invoked.</p><figure id="knitr" class="figure margin" data-counter="9"><img alt="Two scatter plots with regression lines generated by ggplot." src="assets/knitr.png"></img>
<figcaption data-counter="9">The <em>knitr</em> transform evaluates R code blocks at compile time and rewrites the AST. Fitted parameters bind to the runtime for inclusion in formula text.</figcaption></figure><p>The <em>knitr</em> transform extracts executable code written in the R programming language, synthesizes and evaluates an R script, and weaves the results back into the Living Papers AST.
The transform writes extracted R code to blocks in an external Markdown file, invokes the knitr program (also used by RMarkdown and Quarto) to evaluate the code, and parses the resulting output Markdown to extract generated content.
Adding a <code>bind</code> property to an R code block causes JSON-serialized output to be bound to a named variable in the reactive runtime.
As in <cross-ref type="fig" xref="knitr" index="9"></cross-ref>, one can fit a statistical model in R and pass the fitted parameters and other data for processing by JavaScript.
In the future, we hope to provide analagous functionality for compile-time evaluation of Python code blocks.</p><figure id="pyodide" class="figure interactive margin" data-counter="10">
<div class="html:only"><cell-view data-cell="23"></cell-view><cell-view data-cell="24"></cell-view></div><figcaption data-counter="10">Using the <em>pyodide</em> transform: a dynamic Python Matplotlib chart is parameterized by a JavaScript slider.</figcaption></figure><p>The <em>pyodide</em> transform extracts Python code to run directly within the reactive runtime.
We use Pyodide, a WebAssembly port of Python and libraries including Pandas, Matplotlib, and Scikit-Learn.
Pyodide evaluates Python code in the browser, including an object model with direct JavaScript bindings.
The transform leverages Pyodide to create Python cells that run just like standard Observable JavaScript cells.
<cross-ref type="fig" xref="pyodide" index="10"></cross-ref> shows a Python Matplotlib figure interactively driven by an Observable Inputs slider.
However, Pyodide and associated libraries take a few seconds to initialize, delaying page loading time.
Languages such as R might be similarly integrated if they are compiled to WebAssembly.</p><h2 id="transforms-output" data-counter="7.3">Output-Specific Transforms</h2><p>Ouput modules apply transforms to prepare an AST for a specific output type.
For example, <code>html</code> output applies multiple transforms to aid layout, section numbering, and other aspects (<cross-ref type="sec" xref="output-web" index="8.1"></cross-ref>).
Here we focus on a particularly important transform shared by multiple output types: conversion of interactive and web-specific content to static assets such as text and images.</p><p>The <em>convert</em> transform first analyzes an input AST to form a <em>conversion plan</em>, consisting of nodes and properties that need to be converted to produce static output.
For example, SVG images are supported in the browser but not by LaTeX; we want to convert those to PDF format prior to <code>latex</code> output generation.
Other content is generated or parameterized by the reactive runtime (e.g., <em>expression</em>-typed properties).
We must instantiate a runtime, evaluate the content, then extract and convert it.</p><p>To perform conversion we use Puppeteer <span class="cite-list">[<cite-ref key="puppeteer" index="19"></cite-ref>]</span>, an instrumented, headless browser commonly used for automated web page testing.
In order to associate AST nodes with resulting HTML DOM elements, the transform first annotates the AST nodes we wish to convert with a unique id attribute.
This attribute passes through the <code>html</code> output module to the resulting web page, enabling dynamic lookup via CSS selectors.
The transform then loads the compiled article in Puppeteer, extracts the rendered content, and rewrites the corresponding AST nodes.
For expression-typed AST node properties and text content, generated values are simply transferred as-is.
For all other content, the transform takes an image screenshot in either PNG, JPG, or PDF format.</p><p>Puppeteer provides a convenient API for extracting bitmap images of an identified DOM element.
However, for PDF output, only full page printing is supported.
To work around this limitation, the transform dynamically injects a new stylesheet into the Puppeteer page that hides all content but the desired target element.
It also applies absolute positioning to override any local layout directives.
The transform then retrieves the element’s bounding box and <q>prints</q> a PDF page whose dimensions exactly match that of the target element.
The result is a vector graphics PDF that can be directly included in <code>latex</code> output.</p><h1 id="output" data-counter="8">Output Generation</h1><p>Given a canonical AST, Living Papers invokes output generation modules to produce both human- and machine-readable articles.</p><h2 id="output-web" data-counter="8.1">Web Output</h2><figure class="figure margin" data-counter="11"><div class="center"><p><img alt="A Living Papers article viewed at a mobile form factor. A popup with citation information is shown." src="assets/mobile-view.png"></img></p></div><figcaption data-counter="11">A web-based article viewed at a mobile form factor. The default theme provides a responsive layout.</figcaption></figure><p>To generate interactive web pages, the <code>html</code> output module first applies a sequence of output-specific AST transforms.
These transforms prepare syntax-highlighted code listings;
handle sections designated by the <code>abstract</code>, <code>acknowledgements</code>, and <code>appendix</code> component nodes;
generate a header section with article title and authors;
insert section and figure numbers;
resolve cross-references;
and process nodes with a <code>sticky-until</code> attribute, which causes content to persist on screen until an indicated section is reached.</p><p>Given a web-specific AST, the module first compiles code for the reactive runtime.
Code from all <code>cell-view</code> nodes and <em>expression</em>- and <em>event</em>-typed properties is compiled to standard JavaScript functions for inclusion in the Living Papers runtime.
While <code>cell-view</code> components and expression properties map to standard reactive variables, event handlers must be dealt with separately.
As the Observable runtime does not allow a cell to be redefined internally, event handlers must modify the runtime by re-defining variables externally.
The code generator inserts a proxy object to collect all variable assignments made by a handler; these assignments are then applied to the runtime in batch when the handler completes.</p><p>Next, the module marshals all components that map to custom HTML elements.
Living Papers includes components for citations (<code>cite-ref</code>), cross-references (<code>cross-ref</code>), reactive runtime output (<code>cell-view</code>), syntax-highlighted code (<code>code-block</code>), and math blocks (<code>math</code>, <code>equation</code>).
KaTeX <span class="cite-list">[<cite-ref key="katex" index="15"></cite-ref>]</span> is used to process and typeset TeX notation in the browser.
To aid reading, citation and cross-reference components provide tooltips with contextual information: title, authors, venue, and summary for citations, and a live content snapshot and caption for cross-references.
The component library includes other interactive elements; for example <code>range-text</code> to select from a range of values by dragging and <code>toggle-text</code> to cycle through values upon click or touch.
These input components can be bound to reactive variables (<cross-ref type="sec" xref="runtime" index="5.2"></cross-ref>) to drive dynamic content.
External custom components are also supported (<cross-ref type="sec" xref="extensibility" index="5.3"></cross-ref>).</p><p>The <code>html</code> output module then generates entry code to register any custom components used, instantiate the runtime, load generated runtime code, and assign the top-level AST <em>data</em> property to the root <code>article</code> element for subsequent lookup.
All generated code and component definitions are run through a bundler that packages and optionally minifies the code for use.
If an article does not contain interactive content or custom components, this process is skipped and no output JavaScript is generated.</p><p>Finally, the module generates output HTML and CSS by walking the AST and mapping nodes to corresponding HTML elements or text nodes.
Output-specific nodes or properties (e.g., those flagged for <code>latex</code> output) are ignored.
To generate CSS, both base CSS definitions shared by all articles and the CSS for a named theme are loaded.
Alternative themes can be used via Living Papers’ extension mechanisms.
The default layout uses multiple columns with a main column for primary content and a right margin column for footnotes and marginalia (tagged with the <code>.margin</code> class).
Media queries collapse all content to a single-column layout for accessible mobile reading.
An article’s <em>metadata</em> may include a <code>styles</code> property, indicating a custom CSS file to also include.
The collected CSS files are then bundled and optionally minified.
Depending on the article <em>metadata</em> settings, the resulting HTML, CSS, and JavaScript are either written as separate files to an output directory, or as a <code>selfContained</code> HTML file that includes CSS and JavaScript inline.</p><p>Living Papers also provides a <code>static</code> output module, which generates HTML without any interactive elements.
Interactive content is first converted to static assets by an output-specific transform (<cross-ref type="sec" xref="transforms-output" index="7.3"></cross-ref>), after which the same generation process above is performed.
This option can be used to generate static, no-motion content for both accessibility and archival purposes.</p><h2 id="print-output" data-counter="8.2">Print Output</h2><p>Print output is generated by the <code>latex</code> output module.
The module can produce a full LaTeX project, consisting of a directory with generated source files and assets.
By default, the module generates a LaTeX project in a temporary directory and invokes the external <code>pdflatex</code> command to produce a PDF.</p><p>The <em>convert</em> transform first maps interactive or Web content to LaTeX-compatible assets, as described in <cross-ref type="sec" xref="transforms-output" index="7.3"></cross-ref>.
The output module then walks the AST to generate output LaTeX content.
Standard text is processed to map to LaTeX special characters and escape sequences as needed, while nodes containing <q>raw</q> TeX content are written verbatim.
The module segments generated content into named variables (e.g., preamble, abstract, body, acknowledgements, appendix) and passes these to a selected template.
Living Papers provides an extensible set of LaTeX templates for various publishing venues, including built-in templates for ACM and IEEE journals and conferences.
Living Papers includes additional directives to aid TeX-specific layout concerns, described earlier in <cross-ref type="sec" xref="example-kde" index="4.1"></cross-ref>.</p><h2 id="computational-output" data-counter="8.3">Computational Output</h2><p>Living Papers also supports outputs intended for computational consumption.
The <code>ast</code> output module simply writes the canonical AST in JSON format.
The AST can then be loaded and analyzed to extract article content, data, and metadata.</p><p>The <code>api</code> output module generates an API for more convenient access.
The generated API includes methods for accessing metadata (title, authors, etc.), querying article content (abstract, section text, captions, citations), and exporting figure content (including generated images).
The generated API can be easily imported as a standard ECMAScript module, including directly from a URL.
The <code>api</code> output module first runs an output-specific transform to generate static PNG images for all figures, tables, and equations.
Next it annotates the AST with these images in the form of base64-encoded data URLs.
It then generates a JavaScript module that loads the AST and provides methods to query and access the content.
We envision these modules being used for information extraction (e.g., for construction of academic knowledge bases) and to enable new applications (e.g., content for research lab websites, course syllabi, or curated libraries).</p><p>Like computational notebooks, Living Papers articles can contain executable code (e.g., models and dynamic figures) that people may wish to reuse in other articles or web pages.
The <code>runtime</code> output module generates a standalone JavaScript module that contains the compiled runtime code of an article and is compatible with Observable notebooks.
With this functionality, a Living Papers article can directly import (or <em>transclude</em> <span class="cite-list">[<cite-ref key="Nelson:81" index="43"></cite-ref>]</span>) the computational content of other papers.
Examples of runtime transclusion and the extraction API are included as supplemental material.</p><h1 id="discussion" data-counter="9">Discussion &amp; Future Work</h1><p>We presented Living Papers, a framework to bridge academic publishing of printed papers, interactive web pages, and machine-readable APIs and assets.
Living Papers provides an extensible infrastructure for parsing, transformation, and generation of scholarly articles, coupled with a reactive runtime and component system supporting augmented reading aids and interactive texts.
To the best of our knowledge, Living Papers is unique in its combination of reading augmentations, language-level interaction support, asset conversion, and output API generation for academic articles.</p><p>While we have not conducted a formal summative evaluation of Living Papers, our development process has been informed through consultation and collaboration with multiple stakeholders, spanning academic researchers and publishing tool developers.
Over the past six months we have used Living Papers to write five submitted research articles in our own lab, and have observed student use in a graduate scholarly communication course.
While we don’t expect all users to react as positively, one external paper collaborator told us unprompted that <q>Living Papers is a bliss.</q>
We have particularly appreciated the directness of Markdown syntax, the ease of generating Web output with reading aids <q>baked in,</q> and the ability to directly incorporate code to generate content such as models, figures, and tables.
As showcased by our examples (<cross-ref type="sec" xref="examples" index="4"></cross-ref>), we have been able to readily incorporate varied levels of interactivity, ranging from standalone interactive graphics to richly linked explorable explanations.
Going forward we hope to more deeply evaluate Living Papers and systematically study authoring experiences.</p><p>While rich interactivity can be attention-grabbing, finding an appropriate balance—in terms of both author effort and reader benefits—remains an open research question.
Beyond citations, cross-references, and term definitions, what should be in the <q>standard library</q> of reading augmentations that authors can apply with little-to-no effort?
And under what conditions do richer, explorable explanations significantly improve reader comprehension?
We hope Living Papers will be used by ourselves and others to further develop and study the space of reading augmentations.</p><p>With respect to accessibility, we see Living Papers as a promising work in progress.
The current offering includes HTML output with semantic tags, alt-text images, responsive design to common viewing form factors, and the ability to convert computational output to static content (including static HTML, not just PDF).
The latter may be helpful for people with motion sensitivity.
Generated paper APIs could enable additional accessibility aids.
That said, our design goals (<cross-ref type="sec" xref="goals" index="3"></cross-ref>) can be in tension, particularly balancing accessibility with rich interactive output.
There is no guarantee that authors’ interactive content will be accessible.
For example, generating more accessible and screen-reader navigable visualizations is an active area of research <span class="cite-list">[<cite-ref key="doi:10.1111/cgf.14519" index="68"></cite-ref>]</span>.
We see deeper engagement with accessibility stakeholders, the curation of accessible <q>standard library</q> components, and subsequent studies as vital future work.</p><p>Another area for future work is graphical and collaborative environments for article writing and reviewing.
WYSIWYG editors (c.f., <span class="cite-list">[<cite-ref key="doi:10.1145/3472749.3474731" index="10"></cite-ref>, <cite-ref key="doi:10.1145/2807442.2807446" index="32"></cite-ref>]</span>) provide an alternative to markup languages, and might operate directly on Living Papers AST structures.
Interfaces for annotation and commenting would aid both collaborative writing and paper reviewing.
Living Papers already includes infrastructure for selecting and excerpting AST segments that future interfaces might build upon.
Another next step is to support multi-chapter books or multi-page websites in addition to single articles.
We are interested in using Living Papers for end-to-end management of a workshop or conference, including study of peer (or post-publication) review and the generation of online proceedings.</p><p>Meanwhile, we seek to leverage the computational output of Living Papers.
We envision laboratory web sites, curated reading lists, or novel literature search tools populated with content extracted from Living Papers APIs.
However, this vision rests on either the network effects of wide-spread adoption or the ability to more effectively parse existing content to a shared machine-readable representation.
We believe Living Papers can contribute to conversations about what such a shared document model can and should include, particularly with respect to interactive content.</p><p>One avenue may be to convert existing documents to the Living Papers format.
Though parsing PDFs is difficult, existing tools that target HTML output (such as SciA11y <span class="cite-list">[<cite-ref key="doi:10.1145/3441852.3476545" index="63"></cite-ref>]</span>) might also target Living Papers.
Meanwhile, other structured document formats can (sometimes lossily) be transformed.
As Living Papers can parse Pandoc ASTs, with additional engineering we might leverage Pandoc to convert from LaTeX, MS Word, and other formats.</p><p>One potential concern is the large <q>syntactic surface</q> of Living Papers.
To make full use of the system, paper authors must learn Living Papers Markdown, Observable JavaScript (for interactive content), BibTeX (for references), bits of TeX/LaTeX (for math equations, or when custom output-specific directives are needed), and so on.
Developers of new transforms and components require further knowledge, such as standard JavaScript, HTML, and CSS.
These complications are a direct consequence of Living Papers’ evolutionary approach and its embrace of the Web and <q>literate programming</q> design patterns.
While arguably complex, both <q>interleaved</q> syntax and these constituent languages are already in widespread use.
We hope to build on this familiarity and infrastructure, while making many aspects <q>opt-in</q> rather than required.</p><p>Still, adoption is difficult and hard to predict.
Even if Living Papers falls short of a widely-used framework, it can be deployed for real-world publications and websites, and also help influence the trajectory and feature set of other tools.
For individual users, Living Papers provides natural escape hatches: one can produce a LaTeX project or interactive web page and, if desired, jettison Living Papers and move forward with the generated outputs.</p><p>More broadly, Living Papers can serve as a non-proprietary and extensible research system for experimentation—but one that also connects with existing publishing workflows, hopefully better aligning with author incentives.
It offers a path for developers of novel reading or authoring techniques to integrate into an existing system for wider deployment in the wild.
Living Papers is available as open source software at <a href="https://github.com/uwdata/living-papers/">github.com/uwdata/living-papers</a>.</p><h1 nonumber="true">References</h1><ol class="references"><li id="ref-0">Allen Institute for Artificial Intelligence, Semantic Scholar Team. (2023). Semantic Reader. <a href="https://www.semanticscholar.org/product/semantic-reader">https://www.semanticscholar.org/product/semantic-reader</a></li><li id="ref-1">Ammar, W., Groeneveld, D., Bhagavatula, C., Beltagy, I., Crawford, M., Downey, D., Dunkelberger, J., Elgohary, A., Feldman, S., Ha, V., Kinney, R., Kohlmeier, S., Lo, K., Murray, T., Ooi, H.-H., Peters, M., Power, J., Skjonsberg, S., Wang, L., … oren. (2018). Construction of the Literature Graph in Semantic Scholar. Proceedings of the 2018 Conference of the North American Chapter of
          the Association for Computational Linguistics: Human Language
          Technologies, Volume 3 (Industry Papers). Proceedings of the 2018 Conference of the North American Chapter of
          the Association for Computational Linguistics: Human Language
          Technologies, Volume 3 (Industry Papers). <a href="https://doi.org/10.18653/v1/n18-3011">https://doi.org/10.18653/v1/n18-3011</a></li><li id="ref-2">August, T., Wang, L. L., Bragg, J., Hearst, M. A., Head, A., &amp; Lo, K. (2022). Paper Plain: Making Medical Research Papers Approachable to Healthcare Consumers with Natural Language Processing (Version 1). arXiv. <a href="https://doi.org/10.48550/ARXIV.2203.00130">https://doi.org/10.48550/ARXIV.2203.00130</a></li><li id="ref-3">Badam, S. K., Liu, Z., &amp; Elmqvist, N. (2019). Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading. IEEE Transactions on Visualization and Computer Graphics, 25(1), 661–671. <a href="https://doi.org/10.1109/tvcg.2018.2865119">https://doi.org/10.1109/tvcg.2018.2865119</a></li><li id="ref-4">Berners-Lee, T., Cailliau, R., Luotonen, A., Nielsen, H. F., &amp; Secret, A. (1994). The World-Wide Web. Communications of the ACM, 37(8), 76–82. <a href="https://doi.org/10.1145/179606.179671">https://doi.org/10.1145/179606.179671</a></li><li id="ref-5">Bigham, J. P., Brady, E. L., Gleason, C., Guo, A., &amp; Shamma, D. A. (2016, May 7). An Uninteresting Tour Through Why Our Research Papers Aren’t Accessible. Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems. CHI’16: CHI Conference on Human Factors in Computing Systems. <a href="https://doi.org/10.1145/2851581.2892588">https://doi.org/10.1145/2851581.2892588</a></li><li id="ref-6">Bostock, M., Ogievetsky, V., &amp; Heer, J. (2011). D³ Data-Driven Documents. IEEE Transactions on Visualization and Computer Graphics, 17(12), 2301–2309. <a href="https://doi.org/10.1109/tvcg.2011.185">https://doi.org/10.1109/tvcg.2011.185</a></li><li id="ref-7">Citation Style Language. (2023). <a href="https://citationstyles.org/">https://citationstyles.org/</a></li><li id="ref-8">Conlen, M., &amp; Heer, J. (2018, October 11). Idyll. Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology. UIST ’18: The 31st Annual ACM Symposium on User Interface Software and Technology. <a href="https://doi.org/10.1145/3242587.3242600">https://doi.org/10.1145/3242587.3242600</a></li><li id="ref-9">Conlen, M., Vo, M., Tan, A., &amp; Heer, J. (2021, October 10). Idyll Studio: A Structured Editor for Authoring Interactive &amp; Data-Driven Articles. The 34th Annual ACM Symposium on User Interface Software and Technology. UIST ’21: The 34th Annual ACM Symposium on User Interface Software and Technology. <a href="https://doi.org/10.1145/3472749.3474731">https://doi.org/10.1145/3472749.3474731</a></li><li id="ref-10">Conlen, M., &amp; Heer, J. (2022). Fidyll: A Compiler for Cross-Format Data Stories &amp; Explorable Explanations (Version 1). arXiv. <a href="https://doi.org/10.48550/ARXIV.2205.09858">https://doi.org/10.48550/ARXIV.2205.09858</a></li><li id="ref-11">Crichton, W. (2023). A New Medium for Communicating Research on Programming Languages. <a href="https://willcrichton.net/nota/">https://willcrichton.net/nota/</a></li><li id="ref-12">Curvenote. (2023). <a href="https://curvenote.com/">https://curvenote.com/</a></li><li id="ref-13">Dragicevic, P., Jansen, Y., Sarma, A., Kay, M., &amp; Chevalier, F. (2019, May 2). Increasing the Transparency of Research Papers with Explorable Multiverse Analyses. Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. CHI ’19: CHI Conference on Human Factors in Computing Systems. <a href="https://doi.org/10.1145/3290605.3300295">https://doi.org/10.1145/3290605.3300295</a></li><li id="ref-14">Eisenberg, E., &amp; Alpert, S. (2023). KaTeX: The fastest math typesetting library for the web. <a href="https://katex.org">https://katex.org</a></li><li id="ref-15">Fok, R., Kambhamettu, H., Soldaini, L., Bragg, J., Lo, K., Head, A., Hearst, M. A., &amp; Weld, D. S. (2022). Scim: Intelligent Skimming Support for Scientific Papers. arXiv. <a href="https://doi.org/10.48550/ARXIV.2205.04561">https://doi.org/10.48550/ARXIV.2205.04561</a></li><li id="ref-16">Fortunato, S., Bergstrom, C. T., Börner, K., Evans, J. A., Helbing, D., Milojević, S., Petersen, A. M., Radicchi, F., Sinatra, R., Uzzi, B., Vespignani, A., Waltman, L., Wang, D., &amp; Barabási, A.-L. (2018). Science of science. Science, 359(6379). <a href="https://doi.org/10.1126/science.aao0185">https://doi.org/10.1126/science.aao0185</a></li><li id="ref-17">Google Scholar. (2023). <a href="https://scholar.google.com/">https://scholar.google.com/</a></li><li id="ref-18">Google, Inc. (2023). Puppeteer. <a href="https://pptr.dev/">https://pptr.dev/</a></li><li id="ref-19">Gruber, J. (2004). Markdown. <a href="https://daringfireball.net/projects/markdown/">https://daringfireball.net/projects/markdown/</a></li><li id="ref-20">Harrison, S., Minneman, S., Back, M., Balsamo, A., Chow, M., Gold, R., Gorbet, M., &amp; Mac Donald, D. (2001). Design: the what of XFR. Interactions, 8(3), 21–30. <a href="https://doi.org/10.1145/369825.369829">https://doi.org/10.1145/369825.369829</a></li><li id="ref-21">Head, A., Lo, K., Kang, D., Fok, R., Skjonsberg, S., Weld, D. S., &amp; Hearst, M. A. (2021, May 6). Augmenting Scientific Papers with Just-in-Time, Position-Sensitive Definitions of Terms and Symbols. Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. CHI ’21: CHI Conference on Human Factors in Computing Systems. <a href="https://doi.org/10.1145/3411764.3445648">https://doi.org/10.1145/3411764.3445648</a></li><li id="ref-22">Head, A., Xie, A., &amp; Hearst, M. A. (2022, April 29). Math Augmentation: How Authors Enhance the Readability of Formulas using Novel Visual Design Practices. CHI Conference on Human Factors in Computing Systems. CHI ’22: CHI Conference on Human Factors in Computing Systems. <a href="https://doi.org/10.1145/3491102.3501932">https://doi.org/10.1145/3491102.3501932</a></li><li id="ref-23">Heer, J. (2021, October). Fast &amp; Accurate Gaussian Kernel Density Estimation. 2021 IEEE Visualization Conference (VIS). 2021 IEEE Visualization Conference (VIS). <a href="https://doi.org/10.1109/vis49827.2021.9623323">https://doi.org/10.1109/vis49827.2021.9623323</a></li><li id="ref-24">Hill, W. C., Hollan, J. D., Wroblewski, D., &amp; McCandless, T. (1992). Edit wear and read wear. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems  - CHI ’92. the SIGCHI conference. <a href="https://doi.org/10.1145/142750.142751">https://doi.org/10.1145/142750.142751</a></li><li id="ref-25">Himmelstein, D. S., Rubinetti, V., Slochower, D. R., Hu, D., Malladi, V. S., Greene, C. S., &amp; Gitter, A. (2019). Open collaborative writing with Manubot. PLOS Computational Biology, 15(6), e1007128. <a href="https://doi.org/10.1371/journal.pcbi.1007128">https://doi.org/10.1371/journal.pcbi.1007128</a></li><li id="ref-26">Hope, T., Downey, D., Etzioni, O., Weld, D. S., &amp; Horvitz, E. (2022). A Computational Inflection for Scientific Discovery (Version 2). arXiv. <a href="https://doi.org/10.48550/ARXIV.2205.02007">https://doi.org/10.48550/ARXIV.2205.02007</a></li><li id="ref-27">Jupyter Book. (2023). <a href="https://jupyterbook.org/">https://jupyterbook.org/</a></li><li id="ref-28">Kang, D., Head, A., Sidhu, R., Lo, K., Weld, D. S., &amp; Hearst, M. A. (2020). Document-Level Definition Detection in Scholarly Documents: Existing Models, Error Analyses, and Future Directions (Version 1). arXiv. <a href="https://doi.org/10.48550/ARXIV.2010.05129">https://doi.org/10.48550/ARXIV.2010.05129</a></li><li id="ref-29">Kim, D. H., Hoque, E., Kim, J., &amp; Agrawala, M. (2018, October 11). Facilitating Document Reading by Linking Text and Tables. Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology. UIST ’18: The 31st Annual ACM Symposium on User Interface Software and Technology. <a href="https://doi.org/10.1145/3242587.3242617">https://doi.org/10.1145/3242587.3242617</a></li><li id="ref-30">Kinney, R., Anastasiades, C., Authur, R., Beltagy, I., Bragg, J., Buraczynski, A., Cachola, I., Candra, S., Chandrasekhar, Y., Cohan, A., Crawford, M., Downey, D., Dunkelberger, J., Etzioni, O., Evans, R., Feldman, S., Gorney, J., Graham, D., Hu, F., … Weld, D. S. (2023). The Semantic Scholar Open Data Platform (Version 1). arXiv. <a href="https://doi.org/10.48550/ARXIV.2301.10140">https://doi.org/10.48550/ARXIV.2301.10140</a></li><li id="ref-31">Klokmose, C. N., Eagan, J. R., Baader, S., Mackay, W., &amp; Beaudouin-Lafon, M. (2015, November 5). Webstrates. Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology. UIST ’15: The 28th Annual ACM Symposium on User Interface Software and Technology. <a href="https://doi.org/10.1145/2807442.2807446">https://doi.org/10.1145/2807442.2807446</a></li><li id="ref-32">Kluyver, T., Ragan-Kelley, B., Pérez, F., Granger, B. E., Bussonnier, M., Frederic, J., Kelley, K., Hamrick, J. B., Grout, J., Corlay, S., &amp; others. (2016). Jupyter Notebooks-a publishing format for reproducible computational workflows. (Vol. 2016).</li><li id="ref-33">Knuth, D. E. (1979). TEX and METAFONT: New directions in typesetting. American Mathematical Society.</li><li id="ref-34">Knuth, D. E. (1984). Literate Programming. The Computer Journal, 27(2), 97–111. <a href="https://doi.org/10.1093/comjnl/27.2.97">https://doi.org/10.1093/comjnl/27.2.97</a></li><li id="ref-35">Lamport, L. (1985). LaTeX: A Document Preparation System. Addison-Wesley Professional.</li><li id="ref-36">Lopez, P. (2009). GROBID: Combining Automatic Bibliographic Data Recognition and Term Extraction for Scholarship Publications. In Research and Advanced Technology for Digital Libraries (pp. 473–474). Springer Berlin Heidelberg. <a href="https://doi.org/10.1007/978-3-642-04346-8_62">https://doi.org/10.1007/978-3-642-04346-8_62</a></li><li id="ref-37">Lucas, B. D., &amp; Kanade, T. (1981). An Iterative Image Registration Technique with an Application to Stereo Vision. International Joint Conference on Artificial Intelligence.</li><li id="ref-38">MacFarlane, J. (2023). Pandoc: A Universal Document Converter. <a href="https://pandoc.org/">https://pandoc.org/</a></li><li id="ref-39">Meta Open Source. (2023). React. <a href="https://react.dev/">https://react.dev/</a></li><li id="ref-40">MyST Markdown. (2023). <a href="https://myst-tools.org/">https://myst-tools.org/</a></li><li id="ref-41">Nelson, T. H. (1965). Complex information processing. Proceedings of the 1965 20th National Conference On   -. the 1965 20th national conference. <a href="https://doi.org/10.1145/800197.806036">https://doi.org/10.1145/800197.806036</a></li><li id="ref-42">Nelson, T. H. (1981). Literary Machines. Mindful Press.</li><li id="ref-43">Observable Inputs. (2023). <a href="https://github.com/observablehq/inputs">https://github.com/observablehq/inputs</a></li><li id="ref-44">Observable Runtime. (2023). <a href="https://github.com/observablehq/runtime">https://github.com/observablehq/runtime</a></li><li id="ref-45">Observable. (2023). <a href="https://observablehq.com/">https://observablehq.com/</a></li><li id="ref-46">Overleaf. (2023). Online LaTeX Editor. <a href="https://www.overleaf.com/">https://www.overleaf.com/</a></li><li id="ref-47">Phelps, T. A., &amp; Wilensky, R. (2000). Robust intra-document locations. Computer Networks, 33(1–6), 105–118. <a href="https://doi.org/10.1016/s1389-1286(00)00043-8">https://doi.org/10.1016/s1389-1286(00)00043-8</a></li><li id="ref-48">Quarto. (2023). <a href="https://quarto.org/">https://quarto.org/</a></li><li id="ref-49">RMarkdown. (2023). <a href="https://rmarkdown.rstudio.com/">https://rmarkdown.rstudio.com/</a></li><li id="ref-50">Rachatasumrit, N., Bragg, J., Zhang, A. X., &amp; Weld, D. S. (2022, March 22). CiteRead: Integrating Localized Citation Contexts into Scientific Paper Reading. 27th International Conference on Intelligent User Interfaces. IUI ’22: 27th International Conference on Intelligent User Interfaces. <a href="https://doi.org/10.1145/3490099.3511162">https://doi.org/10.1145/3490099.3511162</a></li><li id="ref-51">Ritchie, S. (2022). The Big Idea: Should we get rid of the scientific paper? The Guardian, 11. <a href="https://www.theguardian.com/books/2022/apr/11/the-big-idea-should-we-get-rid-of-the-scientific-paper">https://www.theguardian.com/books/2022/apr/11/the-big-idea-should-we-get-rid-of-the-scientific-paper</a></li><li id="ref-52">Rule, A., Tabard, A., &amp; Hollan, J. D. (2018, April 19). Exploration and Explanation in Computational Notebooks. Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. CHI ’18: CHI Conference on Human Factors in Computing Systems. <a href="https://doi.org/10.1145/3173574.3173606">https://doi.org/10.1145/3173574.3173606</a></li><li id="ref-53">Satyanarayan, A., Russell, R., Hoffswell, J., &amp; Heer, J. (2016). Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization. IEEE Transactions on Visualization and Computer Graphics, 22(1), 659–668. <a href="https://doi.org/10.1109/tvcg.2015.2467091">https://doi.org/10.1109/tvcg.2015.2467091</a></li><li id="ref-54">Satyanarayan, A., Moritz, D., Wongsuphasawat, K., &amp; Heer, J. (2017). Vega-Lite: A Grammar of Interactive Graphics. IEEE Transactions on Visualization and Computer Graphics, 23(1), 341–350. <a href="https://doi.org/10.1109/tvcg.2016.2599030">https://doi.org/10.1109/tvcg.2016.2599030</a></li><li id="ref-55">Savva, M., Kong, N., Chhajta, A., Fei-Fei, L., Agrawala, M., &amp; Heer, J. (2011, October 16). ReVision. Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology. UIST ’11: The 24th Annual ACM Symposium on User Interface Software and Technology. <a href="https://doi.org/10.1145/2047196.2047247">https://doi.org/10.1145/2047196.2047247</a></li><li id="ref-56">Shen, Z., Lo, K., Wang, L. L., Kuehl, B., Weld, D. S., &amp; Downey, D. (2022). VILA: Improving Structured Content Extraction from Scientific PDFs Using Visual Layout Groups. Transactions of the Association for Computational Linguistics, 10, 376–392. <a href="https://doi.org/10.1162/tacl_a_00466">https://doi.org/10.1162/tacl_a_00466</a></li><li id="ref-57">Sultanum, N., Chevalier, F., Bylinskii, Z., &amp; Liu, Z. (2021, May 6). Leveraging Text-Chart Links to Support Authoring of Data-Driven Articles with VizFlow. Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. CHI ’21: CHI Conference on Human Factors in Computing Systems. <a href="https://doi.org/10.1145/3411764.3445354">https://doi.org/10.1145/3411764.3445354</a></li><li id="ref-58">Team, E. (2021). Distill Hiatus. Distill, 6(7). <a href="https://doi.org/10.23915/distill.00031">https://doi.org/10.23915/distill.00031</a></li><li id="ref-59">The Alliance for Networking Visual Culture. (2023). Scalar. <a href="https://scalar.me/anvc/scalar/">https://scalar.me/anvc/scalar/</a></li><li id="ref-60">Typst. (2023). Typst: Compose papers faster. <a href="https://typst.app/">https://typst.app/</a></li><li id="ref-61">Victor, B. (2011). Explorable Explanations. <a href="http://worrydream.com/ExplorableExplanations/">http://worrydream.com/ExplorableExplanations/</a></li><li id="ref-62">Wang, L. L., Cachola, I., Bragg, J., Cheng, E. Y.-Y., Haupt, C., Latzke, M., Kuehl, B., van Zuylen, M. N., Wagner, L., &amp; Weld, D. (2021, October 17). SciA11y: Converting Scientific Papers to Accessible HTML. The 23rd International ACM SIGACCESS Conference on Computers and Accessibility. ASSETS ’21: The 23rd International ACM SIGACCESS Conference on Computers and Accessibility. <a href="https://doi.org/10.1145/3441852.3476545">https://doi.org/10.1145/3441852.3476545</a></li><li id="ref-63">Willighagen, L. (2023). Citation.js. <a href="https://citation.js.org/">https://citation.js.org/</a></li><li id="ref-64">Wolf, G. (1995, June). The Curse of Xanadu. Wired. <a href="https://www.wired.com/1995/06/xanadu/">https://www.wired.com/1995/06/xanadu/</a></li><li id="ref-65">Workshop on Visualization for AI Explainability. (2022). <a href="http://visxai.io/">http://visxai.io/</a></li><li id="ref-66">Zellweger, P. T., Regli, S. H., Mackinlay, J. D., &amp; Chang, B.-W. (2000, April). The impact of fluid documents on reading and browsing. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI00: Human Factors in Computing Systems. <a href="https://doi.org/10.1145/332040.332440">https://doi.org/10.1145/332040.332440</a></li><li id="ref-67">Zong, J., Lee, C., Lundgard, A., Jang, J., Hajas, D., &amp; Satyanarayan, A. (2022). Rich Screen Reader Experiences for Accessible Data Visualization. Computer Graphics Forum, 41(3), 15–27. <a href="https://doi.org/10.1111/cgf.14519">https://doi.org/10.1111/cgf.14519</a></li></ol></article>
    <script type="module">
import define1 from 'https://api.observablehq.com/@jheer/scrubber.js?v=3';

/**
 * @license
 * Copyright 2019 Google LLC
 * SPDX-License-Identifier: BSD-3-Clause
 */
const t$1=window,e$2=t$1.ShadowRoot&&(void 0===t$1.ShadyCSS||t$1.ShadyCSS.nativeShadow)&&"adoptedStyleSheets"in Document.prototype&&"replace"in CSSStyleSheet.prototype,s$3=Symbol(),n$3=new WeakMap;let o$3 = class o{constructor(t,e,n){if(this._$cssResult$=!0,n!==s$3)throw Error("CSSResult is not constructable. Use `unsafeCSS` or `css` instead.");this.cssText=t,this.t=e;}get styleSheet(){let t=this.o;const s=this.t;if(e$2&&void 0===t){const e=void 0!==s&&1===s.length;e&&(t=n$3.get(s)),void 0===t&&((this.o=t=new CSSStyleSheet).replaceSync(this.cssText),e&&n$3.set(s,t));}return t}toString(){return this.cssText}};const r$2=t=>new o$3("string"==typeof t?t:t+"",void 0,s$3),S$1=(s,n)=>{e$2?s.adoptedStyleSheets=n.map((t=>t instanceof CSSStyleSheet?t:t.styleSheet)):n.forEach((e=>{const n=document.createElement("style"),o=t$1.litNonce;void 0!==o&&n.setAttribute("nonce",o),n.textContent=e.cssText,s.appendChild(n);}));},c$1=e$2?t=>t:t=>t instanceof CSSStyleSheet?(t=>{let e="";for(const s of t.cssRules)e+=s.cssText;return r$2(e)})(t):t;

/**
 * @license
 * Copyright 2017 Google LLC
 * SPDX-License-Identifier: BSD-3-Clause
 */var s$2;const e$1=window,r$1=e$1.trustedTypes,h$1=r$1?r$1.emptyScript:"",o$2=e$1.reactiveElementPolyfillSupport,n$2={toAttribute(t,i){switch(i){case Boolean:t=t?h$1:null;break;case Object:case Array:t=null==t?t:JSON.stringify(t);}return t},fromAttribute(t,i){let s=t;switch(i){case Boolean:s=null!==t;break;case Number:s=null===t?null:Number(t);break;case Object:case Array:try{s=JSON.parse(t);}catch(t){s=null;}}return s}},a$1=(t,i)=>i!==t&&(i==i||t==t),l$2={attribute:!0,type:String,converter:n$2,reflect:!1,hasChanged:a$1};let d$1 = class d extends HTMLElement{constructor(){super(),this._$Ei=new Map,this.isUpdatePending=!1,this.hasUpdated=!1,this._$El=null,this.u();}static addInitializer(t){var i;this.finalize(),(null!==(i=this.h)&&void 0!==i?i:this.h=[]).push(t);}static get observedAttributes(){this.finalize();const t=[];return this.elementProperties.forEach(((i,s)=>{const e=this._$Ep(s,i);void 0!==e&&(this._$Ev.set(e,s),t.push(e));})),t}static createProperty(t,i=l$2){if(i.state&&(i.attribute=!1),this.finalize(),this.elementProperties.set(t,i),!i.noAccessor&&!this.prototype.hasOwnProperty(t)){const s="symbol"==typeof t?Symbol():"__"+t,e=this.getPropertyDescriptor(t,s,i);void 0!==e&&Object.defineProperty(this.prototype,t,e);}}static getPropertyDescriptor(t,i,s){return {get(){return this[i]},set(e){const r=this[t];this[i]=e,this.requestUpdate(t,r,s);},configurable:!0,enumerable:!0}}static getPropertyOptions(t){return this.elementProperties.get(t)||l$2}static finalize(){if(this.hasOwnProperty("finalized"))return !1;this.finalized=!0;const t=Object.getPrototypeOf(this);if(t.finalize(),void 0!==t.h&&(this.h=[...t.h]),this.elementProperties=new Map(t.elementProperties),this._$Ev=new Map,this.hasOwnProperty("properties")){const t=this.properties,i=[...Object.getOwnPropertyNames(t),...Object.getOwnPropertySymbols(t)];for(const s of i)this.createProperty(s,t[s]);}return this.elementStyles=this.finalizeStyles(this.styles),!0}static finalizeStyles(i){const s=[];if(Array.isArray(i)){const e=new Set(i.flat(1/0).reverse());for(const i of e)s.unshift(c$1(i));}else void 0!==i&&s.push(c$1(i));return s}static _$Ep(t,i){const s=i.attribute;return !1===s?void 0:"string"==typeof s?s:"string"==typeof t?t.toLowerCase():void 0}u(){var t;this._$E_=new Promise((t=>this.enableUpdating=t)),this._$AL=new Map,this._$Eg(),this.requestUpdate(),null===(t=this.constructor.h)||void 0===t||t.forEach((t=>t(this)));}addController(t){var i,s;(null!==(i=this._$ES)&&void 0!==i?i:this._$ES=[]).push(t),void 0!==this.renderRoot&&this.isConnected&&(null===(s=t.hostConnected)||void 0===s||s.call(t));}removeController(t){var i;null===(i=this._$ES)||void 0===i||i.splice(this._$ES.indexOf(t)>>>0,1);}_$Eg(){this.constructor.elementProperties.forEach(((t,i)=>{this.hasOwnProperty(i)&&(this._$Ei.set(i,this[i]),delete this[i]);}));}createRenderRoot(){var t;const s=null!==(t=this.shadowRoot)&&void 0!==t?t:this.attachShadow(this.constructor.shadowRootOptions);return S$1(s,this.constructor.elementStyles),s}connectedCallback(){var t;void 0===this.renderRoot&&(this.renderRoot=this.createRenderRoot()),this.enableUpdating(!0),null===(t=this._$ES)||void 0===t||t.forEach((t=>{var i;return null===(i=t.hostConnected)||void 0===i?void 0:i.call(t)}));}enableUpdating(t){}disconnectedCallback(){var t;null===(t=this._$ES)||void 0===t||t.forEach((t=>{var i;return null===(i=t.hostDisconnected)||void 0===i?void 0:i.call(t)}));}attributeChangedCallback(t,i,s){this._$AK(t,s);}_$EO(t,i,s=l$2){var e;const r=this.constructor._$Ep(t,s);if(void 0!==r&&!0===s.reflect){const h=(void 0!==(null===(e=s.converter)||void 0===e?void 0:e.toAttribute)?s.converter:n$2).toAttribute(i,s.type);this._$El=t,null==h?this.removeAttribute(r):this.setAttribute(r,h),this._$El=null;}}_$AK(t,i){var s;const e=this.constructor,r=e._$Ev.get(t);if(void 0!==r&&this._$El!==r){const t=e.getPropertyOptions(r),h="function"==typeof t.converter?{fromAttribute:t.converter}:void 0!==(null===(s=t.converter)||void 0===s?void 0:s.fromAttribute)?t.converter:n$2;this._$El=r,this[r]=h.fromAttribute(i,t.type),this._$El=null;}}requestUpdate(t,i,s){let e=!0;void 0!==t&&(((s=s||this.constructor.getPropertyOptions(t)).hasChanged||a$1)(this[t],i)?(this._$AL.has(t)||this._$AL.set(t,i),!0===s.reflect&&this._$El!==t&&(void 0===this._$EC&&(this._$EC=new Map),this._$EC.set(t,s))):e=!1),!this.isUpdatePending&&e&&(this._$E_=this._$Ej());}async _$Ej(){this.isUpdatePending=!0;try{await this._$E_;}catch(t){Promise.reject(t);}const t=this.scheduleUpdate();return null!=t&&await t,!this.isUpdatePending}scheduleUpdate(){return this.performUpdate()}performUpdate(){var t;if(!this.isUpdatePending)return;this.hasUpdated,this._$Ei&&(this._$Ei.forEach(((t,i)=>this[i]=t)),this._$Ei=void 0);let i=!1;const s=this._$AL;try{i=this.shouldUpdate(s),i?(this.willUpdate(s),null===(t=this._$ES)||void 0===t||t.forEach((t=>{var i;return null===(i=t.hostUpdate)||void 0===i?void 0:i.call(t)})),this.update(s)):this._$Ek();}catch(t){throw i=!1,this._$Ek(),t}i&&this._$AE(s);}willUpdate(t){}_$AE(t){var i;null===(i=this._$ES)||void 0===i||i.forEach((t=>{var i;return null===(i=t.hostUpdated)||void 0===i?void 0:i.call(t)})),this.hasUpdated||(this.hasUpdated=!0,this.firstUpdated(t)),this.updated(t);}_$Ek(){this._$AL=new Map,this.isUpdatePending=!1;}get updateComplete(){return this.getUpdateComplete()}getUpdateComplete(){return this._$E_}shouldUpdate(t){return !0}update(t){void 0!==this._$EC&&(this._$EC.forEach(((t,i)=>this._$EO(i,this[i],t))),this._$EC=void 0),this._$Ek();}updated(t){}firstUpdated(t){}};d$1.finalized=!0,d$1.elementProperties=new Map,d$1.elementStyles=[],d$1.shadowRootOptions={mode:"open"},null==o$2||o$2({ReactiveElement:d$1}),(null!==(s$2=e$1.reactiveElementVersions)&&void 0!==s$2?s$2:e$1.reactiveElementVersions=[]).push("1.6.1");

/**
 * @license
 * Copyright 2017 Google LLC
 * SPDX-License-Identifier: BSD-3-Clause
 */
var t;const i=window,s$1=i.trustedTypes,e=s$1?s$1.createPolicy("lit-html",{createHTML:t=>t}):void 0,o$1="$lit$",n$1=`lit$${(Math.random()+"").slice(9)}$`,l$1="?"+n$1,h=`<${l$1}>`,r=document,d=()=>r.createComment(""),u=t=>null===t||"object"!=typeof t&&"function"!=typeof t,c=Array.isArray,v=t=>c(t)||"function"==typeof(null==t?void 0:t[Symbol.iterator]),a="[ \t\n\f\r]",f=/<(?:(!--|\/[^a-zA-Z])|(\/?[a-zA-Z][^>\s]*)|(\/?$))/g,_=/-->/g,m=/>/g,p=RegExp(`>|${a}(?:([^\\s"'>=/]+)(${a}*=${a}*(?:[^ \t\n\f\r"'\`<>=]|("|')|))|$)`,"g"),g=/'/g,$=/"/g,y=/^(?:script|style|textarea|title)$/i,w=t=>(i,...s)=>({_$litType$:t,strings:i,values:s}),x=w(1),T=Symbol.for("lit-noChange"),A=Symbol.for("lit-nothing"),E=new WeakMap,C=r.createTreeWalker(r,129,null,!1),P=(t,i)=>{const s=t.length-1,l=[];let r,d=2===i?"<svg>":"",u=f;for(let i=0;i<s;i++){const s=t[i];let e,c,v=-1,a=0;for(;a<s.length&&(u.lastIndex=a,c=u.exec(s),null!==c);)a=u.lastIndex,u===f?"!--"===c[1]?u=_:void 0!==c[1]?u=m:void 0!==c[2]?(y.test(c[2])&&(r=RegExp("</"+c[2],"g")),u=p):void 0!==c[3]&&(u=p):u===p?">"===c[0]?(u=null!=r?r:f,v=-1):void 0===c[1]?v=-2:(v=u.lastIndex-c[2].length,e=c[1],u=void 0===c[3]?p:'"'===c[3]?$:g):u===$||u===g?u=p:u===_||u===m?u=f:(u=p,r=void 0);const w=u===p&&t[i+1].startsWith("/>")?" ":"";d+=u===f?s+h:v>=0?(l.push(e),s.slice(0,v)+o$1+s.slice(v)+n$1+w):s+n$1+(-2===v?(l.push(void 0),i):w);}const c=d+(t[s]||"<?>")+(2===i?"</svg>":"");if(!Array.isArray(t)||!t.hasOwnProperty("raw"))throw Error("invalid template strings array");return [void 0!==e?e.createHTML(c):c,l]};class V{constructor({strings:t,_$litType$:i},e){let h;this.parts=[];let r=0,u=0;const c=t.length-1,v=this.parts,[a,f]=P(t,i);if(this.el=V.createElement(a,e),C.currentNode=this.el.content,2===i){const t=this.el.content,i=t.firstChild;i.remove(),t.append(...i.childNodes);}for(;null!==(h=C.nextNode())&&v.length<c;){if(1===h.nodeType){if(h.hasAttributes()){const t=[];for(const i of h.getAttributeNames())if(i.endsWith(o$1)||i.startsWith(n$1)){const s=f[u++];if(t.push(i),void 0!==s){const t=h.getAttribute(s.toLowerCase()+o$1).split(n$1),i=/([.?@])?(.*)/.exec(s);v.push({type:1,index:r,name:i[2],strings:t,ctor:"."===i[1]?k:"?"===i[1]?I:"@"===i[1]?L:R});}else v.push({type:6,index:r});}for(const i of t)h.removeAttribute(i);}if(y.test(h.tagName)){const t=h.textContent.split(n$1),i=t.length-1;if(i>0){h.textContent=s$1?s$1.emptyScript:"";for(let s=0;s<i;s++)h.append(t[s],d()),C.nextNode(),v.push({type:2,index:++r});h.append(t[i],d());}}}else if(8===h.nodeType)if(h.data===l$1)v.push({type:2,index:r});else {let t=-1;for(;-1!==(t=h.data.indexOf(n$1,t+1));)v.push({type:7,index:r}),t+=n$1.length-1;}r++;}}static createElement(t,i){const s=r.createElement("template");return s.innerHTML=t,s}}function N(t,i,s=t,e){var o,n,l,h;if(i===T)return i;let r=void 0!==e?null===(o=s._$Co)||void 0===o?void 0:o[e]:s._$Cl;const d=u(i)?void 0:i._$litDirective$;return (null==r?void 0:r.constructor)!==d&&(null===(n=null==r?void 0:r._$AO)||void 0===n||n.call(r,!1),void 0===d?r=void 0:(r=new d(t),r._$AT(t,s,e)),void 0!==e?(null!==(l=(h=s)._$Co)&&void 0!==l?l:h._$Co=[])[e]=r:s._$Cl=r),void 0!==r&&(i=N(t,r._$AS(t,i.values),r,e)),i}class S{constructor(t,i){this.u=[],this._$AN=void 0,this._$AD=t,this._$AM=i;}get parentNode(){return this._$AM.parentNode}get _$AU(){return this._$AM._$AU}v(t){var i;const{el:{content:s},parts:e}=this._$AD,o=(null!==(i=null==t?void 0:t.creationScope)&&void 0!==i?i:r).importNode(s,!0);C.currentNode=o;let n=C.nextNode(),l=0,h=0,d=e[0];for(;void 0!==d;){if(l===d.index){let i;2===d.type?i=new M(n,n.nextSibling,this,t):1===d.type?i=new d.ctor(n,d.name,d.strings,this,t):6===d.type&&(i=new z(n,this,t)),this.u.push(i),d=e[++h];}l!==(null==d?void 0:d.index)&&(n=C.nextNode(),l++);}return o}p(t){let i=0;for(const s of this.u)void 0!==s&&(void 0!==s.strings?(s._$AI(t,s,i),i+=s.strings.length-2):s._$AI(t[i])),i++;}}class M{constructor(t,i,s,e){var o;this.type=2,this._$AH=A,this._$AN=void 0,this._$AA=t,this._$AB=i,this._$AM=s,this.options=e,this._$Cm=null===(o=null==e?void 0:e.isConnected)||void 0===o||o;}get _$AU(){var t,i;return null!==(i=null===(t=this._$AM)||void 0===t?void 0:t._$AU)&&void 0!==i?i:this._$Cm}get parentNode(){let t=this._$AA.parentNode;const i=this._$AM;return void 0!==i&&11===(null==t?void 0:t.nodeType)&&(t=i.parentNode),t}get startNode(){return this._$AA}get endNode(){return this._$AB}_$AI(t,i=this){t=N(this,t,i),u(t)?t===A||null==t||""===t?(this._$AH!==A&&this._$AR(),this._$AH=A):t!==this._$AH&&t!==T&&this.g(t):void 0!==t._$litType$?this.$(t):void 0!==t.nodeType?this.T(t):v(t)?this.k(t):this.g(t);}S(t){return this._$AA.parentNode.insertBefore(t,this._$AB)}T(t){this._$AH!==t&&(this._$AR(),this._$AH=this.S(t));}g(t){this._$AH!==A&&u(this._$AH)?this._$AA.nextSibling.data=t:this.T(r.createTextNode(t)),this._$AH=t;}$(t){var i;const{values:s,_$litType$:e}=t,o="number"==typeof e?this._$AC(t):(void 0===e.el&&(e.el=V.createElement(e.h,this.options)),e);if((null===(i=this._$AH)||void 0===i?void 0:i._$AD)===o)this._$AH.p(s);else {const t=new S(o,this),i=t.v(this.options);t.p(s),this.T(i),this._$AH=t;}}_$AC(t){let i=E.get(t.strings);return void 0===i&&E.set(t.strings,i=new V(t)),i}k(t){c(this._$AH)||(this._$AH=[],this._$AR());const i=this._$AH;let s,e=0;for(const o of t)e===i.length?i.push(s=new M(this.S(d()),this.S(d()),this,this.options)):s=i[e],s._$AI(o),e++;e<i.length&&(this._$AR(s&&s._$AB.nextSibling,e),i.length=e);}_$AR(t=this._$AA.nextSibling,i){var s;for(null===(s=this._$AP)||void 0===s||s.call(this,!1,!0,i);t&&t!==this._$AB;){const i=t.nextSibling;t.remove(),t=i;}}setConnected(t){var i;void 0===this._$AM&&(this._$Cm=t,null===(i=this._$AP)||void 0===i||i.call(this,t));}}class R{constructor(t,i,s,e,o){this.type=1,this._$AH=A,this._$AN=void 0,this.element=t,this.name=i,this._$AM=e,this.options=o,s.length>2||""!==s[0]||""!==s[1]?(this._$AH=Array(s.length-1).fill(new String),this.strings=s):this._$AH=A;}get tagName(){return this.element.tagName}get _$AU(){return this._$AM._$AU}_$AI(t,i=this,s,e){const o=this.strings;let n=!1;if(void 0===o)t=N(this,t,i,0),n=!u(t)||t!==this._$AH&&t!==T,n&&(this._$AH=t);else {const e=t;let l,h;for(t=o[0],l=0;l<o.length-1;l++)h=N(this,e[s+l],i,l),h===T&&(h=this._$AH[l]),n||(n=!u(h)||h!==this._$AH[l]),h===A?t=A:t!==A&&(t+=(null!=h?h:"")+o[l+1]),this._$AH[l]=h;}n&&!e&&this.j(t);}j(t){t===A?this.element.removeAttribute(this.name):this.element.setAttribute(this.name,null!=t?t:"");}}class k extends R{constructor(){super(...arguments),this.type=3;}j(t){this.element[this.name]=t===A?void 0:t;}}const H=s$1?s$1.emptyScript:"";class I extends R{constructor(){super(...arguments),this.type=4;}j(t){t&&t!==A?this.element.setAttribute(this.name,H):this.element.removeAttribute(this.name);}}class L extends R{constructor(t,i,s,e,o){super(t,i,s,e,o),this.type=5;}_$AI(t,i=this){var s;if((t=null!==(s=N(this,t,i,0))&&void 0!==s?s:A)===T)return;const e=this._$AH,o=t===A&&e!==A||t.capture!==e.capture||t.once!==e.once||t.passive!==e.passive,n=t!==A&&(e===A||o);o&&this.element.removeEventListener(this.name,this,e),n&&this.element.addEventListener(this.name,this,t),this._$AH=t;}handleEvent(t){var i,s;"function"==typeof this._$AH?this._$AH.call(null!==(s=null===(i=this.options)||void 0===i?void 0:i.host)&&void 0!==s?s:this.element,t):this._$AH.handleEvent(t);}}class z{constructor(t,i,s){this.element=t,this.type=6,this._$AN=void 0,this._$AM=i,this.options=s;}get _$AU(){return this._$AM._$AU}_$AI(t){N(this,t);}}const j=i.litHtmlPolyfillSupport;null==j||j(V,M),(null!==(t=i.litHtmlVersions)&&void 0!==t?t:i.litHtmlVersions=[]).push("2.7.0");const B=(t,i,s)=>{var e,o;const n=null!==(e=null==s?void 0:s.renderBefore)&&void 0!==e?e:i;let l=n._$litPart$;if(void 0===l){const t=null!==(o=null==s?void 0:s.renderBefore)&&void 0!==o?o:null;n._$litPart$=l=new M(i.insertBefore(d(),t),t,void 0,null!=s?s:{});}return l._$AI(t),l};

/**
 * @license
 * Copyright 2017 Google LLC
 * SPDX-License-Identifier: BSD-3-Clause
 */var l,o;class s extends d$1{constructor(){super(...arguments),this.renderOptions={host:this},this._$Do=void 0;}createRenderRoot(){var t,e;const i=super.createRenderRoot();return null!==(t=(e=this.renderOptions).renderBefore)&&void 0!==t||(e.renderBefore=i.firstChild),i}update(t){const i=this.render();this.hasUpdated||(this.renderOptions.isConnected=this.isConnected),super.update(t),this._$Do=B(i,this.renderRoot,this.renderOptions);}connectedCallback(){var t;super.connectedCallback(),null===(t=this._$Do)||void 0===t||t.setConnected(!0);}disconnectedCallback(){var t;super.disconnectedCallback(),null===(t=this._$Do)||void 0===t||t.setConnected(!1);}render(){return T}}s.finalized=!0,s._$litElement$=!0,null===(l=globalThis.litElementHydrateSupport)||void 0===l||l.call(globalThis,{LitElement:s});const n=globalThis.litElementPolyfillSupport;null==n||n({LitElement:s});(null!==(o=globalThis.litElementVersions)&&void 0!==o?o:globalThis.litElementVersions=[]).push("3.3.0");

const CELL_VIEW = 'cell-view';
const DATA_ATTR = 'data-attr';
const DATA_CELL = 'data-cell';
const DATA_BIND = 'data-bind';
const DATA_BIND_SET = 'data-bind-set';

async function binding(runtime, name) {
  return new Binding(runtime, name, await runtime.value(name));
}

function onNextTick(f) {
  typeof window !== 'undefined' && window.requestAnimationFrame
    ? window.requestAnimationFrame(f)
    : setTimeout(f, 0);
}

class Binding {
  constructor(runtime, name, value) {
    this.runtime = runtime;
    this.name = name;
    this.value = value;
    this.paused = false;
    this.ignore = null;
    this.queued = [];
    this.inputs = new Map;

    // observe changes to the variable within the runtime
    runtime.variable(null, x => x, [name], {
      fulfilled: value => this.paused ? this.dequeue() : this.update(value)
    });
  }

  /**
   * Add an input to the binding group.
   */
  add(input, {
    override = false,
    event = _eventof(input),
    valueof = _valueof
  } = {}) {
    if (override) {
      // set bound variable value to the input value
      this.update(valueof(input));
    } else {
      // set input value to the bound variable value
      valueof(input, this.value);
    }

    // register bindings
    const listener = () => this.queue(input, valueof(input));
    this.inputs.set(input, { input, event, listener, valueof });
    input.addEventListener(event, listener);
    return this;
  }

  /**
   * Add a changeable cell value to the binding group.
   */
  addCell(cell, options) {
    let prev;
    cell.addEventListener('change', async () => {
      const next = cell.value;
      if (next === prev) return;
      if (prev) this.delete(prev);
      this.add(prev = next, options);
    });
    return this;
  }

  /**
   * Delete an input from the binding group.
   */
  delete(input) {
    const { event, listener } = this.inputs.get(input);
    input.removeEventListener(event, listener);
    this.inputs.delete(input);
  }

  /**
   * Queue requested changes to the bound variable value.
   * Process events on next tick. This lets us to debounce
   * multiple events arriving on the same tick.
   */
  queue(input, value) {
    if (this.ignore !== input) {
      if (!this.paused && !this.queued.length) {
        onNextTick(() => this.dequeue());
      }
      this.queued.push(value);
    }
  }

  /**
   * Clear request queue, process only most recent entry.
   */
  dequeue() {
    this.paused = false;
    if (this.queued.length) {
      const queue = this.queued;
      this.queued = [];
      this.update(queue.pop());
    }
  }

  /**
   * Update the value of the binding group.
   */
  update(value) {
    if (this.value === value) return;
    this.value = value;
    this.paused = true;

    // update bound inputs as needed
    for (const { input, event, valueof } of this.inputs.values()) {
      if (valueof(input) !== value) {
        this.ignore = input;
        valueof(input, value);
        input.dispatchEvent(new Event(event));
        this.ignore = null;
      }
    }

    // update shared variable
    this.runtime.redefine(this.name, value);
  }
}

/**
 * Get/set the state value of an input element.
 */
function _valueof(input, value) {
  if (arguments.length > 1) {
    switch (input.type) {
      case 'date': return (input.valueAsDate = value);
      case 'checkbox': return (input.checked = value);
      default: return (input.value = value);
    }
  } else {
    switch (input.type) {
      case 'range':
      case 'number': return input.valueAsNumber;
      case 'date': return input.valueAsDate;
      case 'checkbox': return input.checked;
      default: return input.value;
    }
  }
}

/**
 * Get the update event type for an input element.
 */
function _eventof(input) {
  switch (input.type) {
    case 'button':
    case 'submit':
    case 'checkbox': return 'click';
    default: return 'input';
  }
}

const PENDING = 'pending';
const FULFILLED = 'fulfilled';
const REJECTED = 'rejected';

class Observer {
  constructor(callback) {
    this.status = PENDING;
    this.value = undefined;
    this.callback = callback;
  }

  promise() {
    switch (this.status) {
      case FULFILLED:
        return Promise.resolve(this.value);
      case REJECTED:
        return Promise.reject(this.value.error);
      case PENDING:
        return this._promise || (this._promise = new Promise((resolve, reject) => {
          this._resolve = resolve;
          this._reject = reject;
        }));
    }
  }

  update(status, value) {
    this.status = status;
    if (status !== PENDING) this.value = value;
    this.callback(this.status, this.value);
  }

  pending() {
    this.update(PENDING, undefined);
  }

  fulfilled(value) {
    this.update(FULFILLED, value);
    if (this._promise) {
      this._resolve(value);
      this._promise = this._resolve = this._reject = null;
    }
  }

  rejected(error, name) {
    this.update(REJECTED, { error, name });
    if (this._promise) {
      this._reject(error);
      this._promise = this._resolve = this._reject = null;
    }
  }
}

function hydrate(runtime, root, module, bind = {}) {
  const {
    cells = () => [],
    attrs = () => [],
    event = () => []
  } = module;

  const resolve = resolver$1(root);
  runtime.define(cells(), observeCells(root));
  runtime.define(attrs(), observeAttrs(resolve, bind.attrs));
  runtime.define(event(), observeEvent(resolve, bind.events, runtime));
  createBindings(root, runtime);
}

function resolver$1(root) {
  const map = new Map;
  root.querySelectorAll(`[${DATA_ATTR}]`).forEach(node => {
    map.set(node.getAttribute(DATA_ATTR), node);
  });
  return el => typeof el === 'object' ? el : map.get(el);
}

function observeCells(root) {
  const map = new Map;
  root.querySelectorAll(CELL_VIEW).forEach(node => {
    map.set(+node.getAttribute(DATA_CELL), node.observer);
  });
  return def => map.get(def.cell);
}

function observeAttrs(resolve, attrs) {
  return def => {
    const [target, name] = attrs[def.cell];
    const node = resolve(target);
    const observer = new Observer((status, value) => {
      if (status === FULFILLED) {
        node.setAttribute(name, value);
      } else if (status === REJECTED) {
        console.error(value.error);
      }
    });
    node.observers = node.observers || new Map;
    node.observers.set(name, observer);
    return observer;
  };
}

function observeEvent(resolve, event, runtime) {
  return def => {
    const { define: [id], cell } = def;
    const [source, name] = event[cell];
    const node = resolve(source);
    node.addEventListener(name, runtime.handler(id));
    return {
      rejected(err) {
        console.error(err);
      }
    };
  };
}

function createBindings(root, runtime) {
  const bind = new Map;

  // collect input elements with declared bindings
  const process = (attr, override) => {
    root.querySelectorAll(`[${attr}]`).forEach(el => {
      const name = el.getAttribute(attr);
      const input = { el, override };
      bind.has(name) ? bind.get(name).push(input) : bind.set(name, [input]);
    });
  };
  process(DATA_BIND, false);
  process(DATA_BIND_SET, true);

  // instantiate bindings
  const add = (binding, { el, override }) => {
    el.tagName.toLowerCase() === CELL_VIEW
      ? binding.addCell(el, { override })
      : binding.add(el, { override });
  };
  bind.forEach((list, name) => {
    binding(runtime, name).then(binding => {
      list.forEach(input => add(binding, input));
    });
  });
}

const {getPrototypeOf, getOwnPropertyDescriptors} = Object;
getPrototypeOf({});

var EOL = {},
    EOF = {},
    QUOTE = 34,
    NEWLINE = 10,
    RETURN = 13;

function objectConverter(columns) {
  return new Function("d", "return {" + columns.map(function(name, i) {
    return JSON.stringify(name) + ": d[" + i + "] || \"\"";
  }).join(",") + "}");
}

function customConverter(columns, f) {
  var object = objectConverter(columns);
  return function(row, i) {
    return f(object(row), i, columns);
  };
}

// Compute unique columns in order of discovery.
function inferColumns(rows) {
  var columnSet = Object.create(null),
      columns = [];

  rows.forEach(function(row) {
    for (var column in row) {
      if (!(column in columnSet)) {
        columns.push(columnSet[column] = column);
      }
    }
  });

  return columns;
}

function pad(value, width) {
  var s = value + "", length = s.length;
  return length < width ? new Array(width - length + 1).join(0) + s : s;
}

function formatYear(year) {
  return year < 0 ? "-" + pad(-year, 6)
    : year > 9999 ? "+" + pad(year, 6)
    : pad(year, 4);
}

function formatDate(date) {
  var hours = date.getUTCHours(),
      minutes = date.getUTCMinutes(),
      seconds = date.getUTCSeconds(),
      milliseconds = date.getUTCMilliseconds();
  return isNaN(date) ? "Invalid Date"
      : formatYear(date.getUTCFullYear()) + "-" + pad(date.getUTCMonth() + 1, 2) + "-" + pad(date.getUTCDate(), 2)
      + (milliseconds ? "T" + pad(hours, 2) + ":" + pad(minutes, 2) + ":" + pad(seconds, 2) + "." + pad(milliseconds, 3) + "Z"
      : seconds ? "T" + pad(hours, 2) + ":" + pad(minutes, 2) + ":" + pad(seconds, 2) + "Z"
      : minutes || hours ? "T" + pad(hours, 2) + ":" + pad(minutes, 2) + "Z"
      : "");
}

function dsv$1(delimiter) {
  var reFormat = new RegExp("[\"" + delimiter + "\n\r]"),
      DELIMITER = delimiter.charCodeAt(0);

  function parse(text, f) {
    var convert, columns, rows = parseRows(text, function(row, i) {
      if (convert) return convert(row, i - 1);
      columns = row, convert = f ? customConverter(row, f) : objectConverter(row);
    });
    rows.columns = columns || [];
    return rows;
  }

  function parseRows(text, f) {
    var rows = [], // output rows
        N = text.length,
        I = 0, // current character index
        n = 0, // current line number
        t, // current token
        eof = N <= 0, // current token followed by EOF?
        eol = false; // current token followed by EOL?

    // Strip the trailing newline.
    if (text.charCodeAt(N - 1) === NEWLINE) --N;
    if (text.charCodeAt(N - 1) === RETURN) --N;

    function token() {
      if (eof) return EOF;
      if (eol) return eol = false, EOL;

      // Unescape quotes.
      var i, j = I, c;
      if (text.charCodeAt(j) === QUOTE) {
        while (I++ < N && text.charCodeAt(I) !== QUOTE || text.charCodeAt(++I) === QUOTE);
        if ((i = I) >= N) eof = true;
        else if ((c = text.charCodeAt(I++)) === NEWLINE) eol = true;
        else if (c === RETURN) { eol = true; if (text.charCodeAt(I) === NEWLINE) ++I; }
        return text.slice(j + 1, i - 1).replace(/""/g, "\"");
      }

      // Find next delimiter or newline.
      while (I < N) {
        if ((c = text.charCodeAt(i = I++)) === NEWLINE) eol = true;
        else if (c === RETURN) { eol = true; if (text.charCodeAt(I) === NEWLINE) ++I; }
        else if (c !== DELIMITER) continue;
        return text.slice(j, i);
      }

      // Return last token before EOF.
      return eof = true, text.slice(j, N);
    }

    while ((t = token()) !== EOF) {
      var row = [];
      while (t !== EOL && t !== EOF) row.push(t), t = token();
      if (f && (row = f(row, n++)) == null) continue;
      rows.push(row);
    }

    return rows;
  }

  function preformatBody(rows, columns) {
    return rows.map(function(row) {
      return columns.map(function(column) {
        return formatValue(row[column]);
      }).join(delimiter);
    });
  }

  function format(rows, columns) {
    if (columns == null) columns = inferColumns(rows);
    return [columns.map(formatValue).join(delimiter)].concat(preformatBody(rows, columns)).join("\n");
  }

  function formatBody(rows, columns) {
    if (columns == null) columns = inferColumns(rows);
    return preformatBody(rows, columns).join("\n");
  }

  function formatRows(rows) {
    return rows.map(formatRow).join("\n");
  }

  function formatRow(row) {
    return row.map(formatValue).join(delimiter);
  }

  function formatValue(value) {
    return value == null ? ""
        : value instanceof Date ? formatDate(value)
        : reFormat.test(value += "") ? "\"" + value.replace(/"/g, "\"\"") + "\""
        : value;
  }

  return {
    parse: parse,
    parseRows: parseRows,
    format: format,
    formatBody: formatBody,
    formatRows: formatRows,
    formatRow: formatRow,
    formatValue: formatValue
  };
}

var csv = dsv$1(",");

var csvParse = csv.parse;
var csvParseRows = csv.parseRows;

var tsv = dsv$1("\t");

var tsvParse = tsv.parse;
var tsvParseRows = tsv.parseRows;

function autoType(object) {
  for (var key in object) {
    var value = object[key].trim(), number, m;
    if (!value) value = null;
    else if (value === "true") value = true;
    else if (value === "false") value = false;
    else if (value === "NaN") value = NaN;
    else if (!isNaN(number = +value)) value = number;
    else if (m = value.match(/^([-+]\d{2})?\d{4}(-\d{2}(-\d{2})?)?(T\d{2}:\d{2}(:\d{2}(\.\d{3})?)?(Z|[-+]\d{2}:\d{2})?)?$/)) {
      if (fixtz && !!m[4] && !m[7]) value = value.replace(/-/g, "/").replace(/T/, " ");
      value = new Date(value);
    }
    else continue;
    object[key] = value;
  }
  return object;
}

// https://github.com/d3/d3-dsv/issues/45
const fixtz = new Date("2019-01-01T00:00").getHours() || new Date("2019-07-01T00:00").getHours();

function dependency(name, version, main) {
  return {
    resolve(path = main) {
      return `${name}@${version}/${path}`;
    }
  };
}

const d3 = dependency("d3", "7.8.4", "dist/d3.min.js");
const inputs = dependency("@observablehq/inputs", "0.10.4", "dist/inputs.min.js");
const plot = dependency("@observablehq/plot", "0.6.5", "dist/plot.umd.min.js");
const graphviz = dependency("@observablehq/graphviz", "0.2.1", "dist/graphviz.min.js");
const highlight = dependency("@observablehq/highlight.js", "2.0.0", "highlight.min.js");
const katex = dependency("@observablehq/katex", "0.11.1", "dist/katex.min.js");
const lodash = dependency("lodash", "4.17.21", "lodash.min.js");
const htl = dependency("htl", "0.3.1", "dist/htl.min.js");
const jszip = dependency("jszip", "3.10.1", "dist/jszip.min.js");
const marked = dependency("marked", "0.3.12", "marked.min.js");
const sql = dependency("sql.js", "1.8.0", "dist/sql-wasm.js");
const vega = dependency("vega", "5.22.1", "build/vega.min.js");
const vegalite = dependency("vega-lite", "5.6.0", "build/vega-lite.min.js");
const vegaliteApi = dependency("vega-lite-api", "5.0.0", "build/vega-lite-api.min.js");
const arrow4 = dependency("apache-arrow", "4.0.1", "Arrow.es2015.min.js");
const arrow9 = dependency("apache-arrow", "9.0.0", "+esm");
const arrow11 = dependency("apache-arrow", "11.0.0", "+esm");
const arquero = dependency("arquero", "4.8.8", "dist/arquero.min.js");
const topojson = dependency("topojson-client", "3.1.0", "dist/topojson-client.min.js");
const exceljs = dependency("exceljs", "4.3.0", "dist/exceljs.min.js");
const mermaid$1 = dependency("mermaid", "9.2.2", "dist/mermaid.min.js");
const leaflet$1 = dependency("leaflet", "1.9.3", "dist/leaflet.js");
const duckdb = dependency("@duckdb/duckdb-wasm", "1.24.0", "+esm");

const metas = new Map;
const queue$1 = [];
const map$2 = queue$1.map;
const some = queue$1.some;
const hasOwnProperty = queue$1.hasOwnProperty;
const identifierRe = /^((?:@[^/@]+\/)?[^/@]+)(?:@([^/]+))?(?:\/(.*))?$/;
const versionRe = /^\d+\.\d+\.\d+(-[\w-.+]+)?$/;
const extensionRe = /(?:\.[^/]*|\/)$/;

class RequireError extends Error {
  constructor(message) {
    super(message);
  }
}

RequireError.prototype.name = RequireError.name;

function parseIdentifier(identifier) {
  const match = identifierRe.exec(identifier);
  return match && {
    name: match[1],
    version: match[2],
    path: match[3]
  };
}

function resolveFrom(origin = "https://cdn.jsdelivr.net/npm/", mains = ["unpkg", "jsdelivr", "browser", "main"]) {
  if (!/\/$/.test(origin)) throw new Error("origin lacks trailing slash");

  function main(meta) {
    for (const key of mains) {
      let value = meta[key];
      if (typeof value === "string") {
        if (value.startsWith("./")) value = value.slice(2);
        return extensionRe.test(value) ? value : `${value}.js`;
      }
    }
  }

  function resolveMeta(target) {
    const url = `${origin}${target.name}${target.version ? `@${target.version}` : ""}/package.json`;
    let meta = metas.get(url);
    if (!meta) metas.set(url, meta = fetch(url).then(response => {
      if (!response.ok) throw new RequireError("unable to load package.json");
      if (response.redirected && !metas.has(response.url)) metas.set(response.url, meta);
      return response.json();
    }));
    return meta;
  }

  return async function resolve(name, base) {
    if (name.startsWith(origin)) name = name.substring(origin.length);
    if (/^(\w+:)|\/\//i.test(name)) return name;
    if (/^[.]{0,2}\//i.test(name)) return new URL(name, base == null ? location : base).href;
    if (!name.length || /^[\s._]/.test(name) || /\s$/.test(name)) throw new RequireError("illegal name");
    const target = parseIdentifier(name);
    if (!target) return `${origin}${name}`;
    if (!target.version && base != null && base.startsWith(origin)) {
      const meta = await resolveMeta(parseIdentifier(base.substring(origin.length)));
      target.version = meta.dependencies && meta.dependencies[target.name] || meta.peerDependencies && meta.peerDependencies[target.name];
    }
    if (target.path && !extensionRe.test(target.path)) target.path += ".js";
    if (target.path && target.version && versionRe.test(target.version)) return `${origin}${target.name}@${target.version}/${target.path}`;
    const meta = await resolveMeta(target);
    return `${origin}${meta.name}@${meta.version}/${target.path || main(meta) || "index.js"}`;
  };
}

var require = requireFrom(resolveFrom());

function requireFrom(resolver) {
  const cache = new Map;
  const requireBase = requireRelative(null);

  function requireAbsolute(url) {
    if (typeof url !== "string") return url;
    let module = cache.get(url);
    if (!module) cache.set(url, module = new Promise((resolve, reject) => {
      const script = document.createElement("script");
      script.onload = () => {
        try { resolve(queue$1.pop()(requireRelative(url))); }
        catch (error) { reject(new RequireError("invalid module")); }
        script.remove();
      };
      script.onerror = () => {
        reject(new RequireError("unable to load module"));
        script.remove();
      };
      script.async = true;
      script.src = url;
      window.define = define;
      document.head.appendChild(script);
    }));
    return module;
  }

  function requireRelative(base) {
    return name => Promise.resolve(resolver(name, base)).then(requireAbsolute);
  }

  function requireAlias(aliases) {
    return requireFrom((name, base) => {
      if (name in aliases) {
        name = aliases[name], base = null;
        if (typeof name !== "string") return name;
      }
      return resolver(name, base);
    });
  }

  function require(name) {
    return arguments.length > 1
        ? Promise.all(map$2.call(arguments, requireBase)).then(merge)
        : requireBase(name);
  }

  require.alias = requireAlias;
  require.resolve = resolver;

  return require;
}

function merge(modules) {
  const o = {};
  for (const m of modules) {
    for (const k in m) {
      if (hasOwnProperty.call(m, k)) {
        if (m[k] == null) Object.defineProperty(o, k, {get: getter(m, k)});
        else o[k] = m[k];
      }
    }
  }
  return o;
}

function getter(object, name) {
  return () => object[name];
}

function isbuiltin(name) {
  name = name + "";
  return name === "exports" || name === "module";
}

function define(name, dependencies, factory) {
  const n = arguments.length;
  if (n < 2) factory = name, dependencies = [];
  else if (n < 3) factory = dependencies, dependencies = typeof name === "string" ? [] : name;
  queue$1.push(some.call(dependencies, isbuiltin) ? require => {
    const exports = {};
    const module = {exports};
    return Promise.all(map$2.call(dependencies, name => {
      name = name + "";
      return name === "exports" ? exports : name === "module" ? module : require(name);
    })).then(dependencies => {
      factory.apply(null, dependencies);
      return module.exports;
    });
  } : require => {
    return Promise.all(map$2.call(dependencies, require)).then(dependencies => {
      return typeof factory === "function" ? factory.apply(null, dependencies) : factory;
    });
  });
}

define.amd = {};

// TODO Allow this to be overridden using the Library’s resolver.
const cdn = "https://cdn.observableusercontent.com/npm/";

let requireDefault = require;

function setDefaultRequire(require) {
  requireDefault = require;
}

function requirer(resolver) {
  return resolver == null ? requireDefault : requireFrom(resolver);
}

async function SQLite(require) {
  const [init, dist] = await Promise.all([require(sql.resolve()), require.resolve(sql.resolve("dist/"))]);
  return init({locateFile: file => `${dist}${file}`});
}

class SQLiteDatabaseClient {
  constructor(db) {
    Object.defineProperties(this, {
      _db: {value: db}
    });
  }
  static async open(source) {
    const [SQL, buffer] = await Promise.all([SQLite(requireDefault), Promise.resolve(source).then(load)]);
    return new SQLiteDatabaseClient(new SQL.Database(buffer));
  }
  async query(query, params) {
    return await exec(this._db, query, params);
  }
  async queryRow(query, params) {
    return (await this.query(query, params))[0] || null;
  }
  async explain(query, params) {
    const rows = await this.query(`EXPLAIN QUERY PLAN ${query}`, params);
    return element$1("pre", {className: "observablehq--inspect"}, [
      text$2(rows.map(row => row.detail).join("\n"))
    ]);
  }
  async describeTables({schema} = {}) {
    return this.query(`SELECT NULLIF(schema, 'main') AS schema, name FROM pragma_table_list() WHERE type = 'table'${schema == null ? "" : ` AND schema = ?`} AND name NOT LIKE 'sqlite_%' ORDER BY schema, name`, schema == null ? [] : [schema]);
  }
  async describeColumns({schema, table} = {}) {
    if (table == null) throw new Error(`missing table`);
    const rows = await this.query(`SELECT name, type, "notnull" FROM pragma_table_info(?${schema == null ? "" : `, ?`}) ORDER BY cid`, schema == null ? [table] : [table, schema]);
    if (!rows.length) throw new Error(`table not found: ${table}`);
    return rows.map(({name, type, notnull}) => ({name, type: sqliteType(type), databaseType: type, nullable: !notnull}));
  }
  async describe(object) {
    const rows = await (object === undefined
      ? this.query(`SELECT name FROM sqlite_master WHERE type = 'table'`)
      : this.query(`SELECT * FROM pragma_table_info(?)`, [object]));
    if (!rows.length) throw new Error("Not found");
    const {columns} = rows;
    return element$1("table", {value: rows}, [
      element$1("thead", [element$1("tr", columns.map(c => element$1("th", [text$2(c)])))]),
      element$1("tbody", rows.map(r => element$1("tr", columns.map(c => element$1("td", [text$2(r[c])])))))
    ]);
  }
  async sql() {
    return this.query(...this.queryTag.apply(this, arguments));
  }
  queryTag(strings, ...params) {
    return [strings.join("?"), params];
  }
}

Object.defineProperty(SQLiteDatabaseClient.prototype, "dialect", {
  value: "sqlite"
});

// https://www.sqlite.org/datatype3.html
function sqliteType(type) {
  switch (type) {
    case "NULL":
      return "null";
    case "INT":
    case "INTEGER":
    case "TINYINT":
    case "SMALLINT":
    case "MEDIUMINT":
    case "BIGINT":
    case "UNSIGNED BIG INT":
    case "INT2":
    case "INT8":
      return "integer";
    case "TEXT":
    case "CLOB":
      return "string";
    case "REAL":
    case "DOUBLE":
    case "DOUBLE PRECISION":
    case "FLOAT":
    case "NUMERIC":
      return "number";
    case "BLOB":
      return "buffer";
    case "DATE":
    case "DATETIME":
      return "string"; // TODO convert strings to Date instances in sql.js
    default:
      return /^(?:(?:(?:VARYING|NATIVE) )?CHARACTER|(?:N|VAR|NVAR)CHAR)\(/.test(type) ? "string"
        : /^(?:DECIMAL|NUMERIC)\(/.test(type) ? "number"
        : "other";
  }
}

function load(source) {
  return typeof source === "string" ? fetch(source).then(load)
    : source instanceof Response || source instanceof Blob ? source.arrayBuffer().then(load)
    : source instanceof ArrayBuffer ? new Uint8Array(source)
    : source;
}

async function exec(db, query, params) {
  const [result] = await db.exec(query, params);
  if (!result) return [];
  const {columns, values} = result;
  const rows = values.map(row => Object.fromEntries(row.map((value, i) => [columns[i], value])));
  rows.columns = columns;
  return rows;
}

function element$1(name, props, children) {
  if (arguments.length === 2) children = props, props = undefined;
  const element = document.createElement(name);
  if (props !== undefined) for (const p in props) element[p] = props[p];
  if (children !== undefined) for (const c of children) element.appendChild(c);
  return element;
}

function text$2(value) {
  return document.createTextNode(value);
}

function ascending(a, b) {
  return a == null || b == null ? NaN : a < b ? -1 : a > b ? 1 : a >= b ? 0 : NaN;
}

function greatest(values, compare = ascending) {
  let max;
  let defined = false;
  if (compare.length === 1) {
    let maxValue;
    for (const element of values) {
      const value = compare(element);
      if (defined
          ? ascending(value, maxValue) > 0
          : ascending(value, value) === 0) {
        max = element;
        maxValue = value;
        defined = true;
      }
    }
  } else {
    for (const value of values) {
      if (defined
          ? compare(value, max) > 0
          : compare(value, value) === 0) {
        max = value;
        defined = true;
      }
    }
  }
  return max;
}

function reverse(values) {
  if (typeof values[Symbol.iterator] !== "function") throw new TypeError("values is not iterable");
  return Array.from(values).reverse();
}

function isArqueroTable(value) {
  // Arquero tables have a `toArrowBuffer` function
  return value && typeof value.toArrowBuffer === "function";
}

// Returns true if the vaue is an Apache Arrow table. This uses a “duck” test
// (instead of strict instanceof) because we want it to work with a range of
// Apache Arrow versions at least 7.0.0 or above.
// https://arrow.apache.org/docs/7.0/js/classes/Arrow_dom.Table.html
function isArrowTable(value) {
  return (
    value &&
    typeof value.getChild === "function" &&
    typeof value.toArray === "function" &&
    value.schema &&
    Array.isArray(value.schema.fields)
  );
}

function getArrowTableSchema(table) {
  return table.schema.fields.map(getArrowFieldSchema);
}

function getArrowFieldSchema(field) {
  return {
    name: field.name,
    type: getArrowType(field.type),
    nullable: field.nullable,
    databaseType: String(field.type)
  };
}

// https://github.com/apache/arrow/blob/89f9a0948961f6e94f1ef5e4f310b707d22a3c11/js/src/enum.ts#L140-L141
function getArrowType(type) {
  switch (type.typeId) {
    case 2: // Int
      return "integer";
    case 3: // Float
    case 7: // Decimal
      return "number";
    case 4: // Binary
    case 15: // FixedSizeBinary
      return "buffer";
    case 5: // Utf8
      return "string";
    case 6: // Bool
      return "boolean";
    case 8: // Date
    case 9: // Time
    case 10: // Timestamp
      return "date";
    case 12: // List
    case 16: // FixedSizeList
      return "array";
    case 13: // Struct
    case 14: // Union
      return "object";
    case 11: // Interval
    case 17: // Map
    default:
      return "other";
  }
}

async function loadArrow() {
  return await import(`${cdn}${arrow11.resolve()}`);
}

// Adapted from https://observablehq.com/@cmudig/duckdb-client
// Copyright 2021 CMU Data Interaction Group
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
//
// 1. Redistributions of source code must retain the above copyright notice,
//    this list of conditions and the following disclaimer.
//
// 2. Redistributions in binary form must reproduce the above copyright notice,
//    this list of conditions and the following disclaimer in the documentation
//    and/or other materials provided with the distribution.
//
// 3. Neither the name of the copyright holder nor the names of its contributors
//    may be used to endorse or promote products derived from this software
//    without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.

let promise;

class DuckDBClient {
  constructor(db) {
    Object.defineProperties(this, {
      _db: {value: db}
    });
  }

  async queryStream(query, params) {
    const connection = await this._db.connect();
    let reader, batch;
    try {
      if (params?.length > 0) {
        const statement = await connection.prepare(query);
        reader = await statement.send(...params);
      } else {
        reader = await connection.send(query);
      }
      batch = await reader.next();
      if (batch.done) throw new Error("missing first batch");
    } catch (error) {
      await connection.close();
      throw error;
    }
    return {
      schema: getArrowTableSchema(batch.value),
      async *readRows() {
        try {
          while (!batch.done) {
            yield batch.value.toArray();
            batch = await reader.next();
          }
        } finally {
          await connection.close();
        }
      }
    };
  }

  async query(query, params) {
    const result = await this.queryStream(query, params);
    const results = [];
    for await (const rows of result.readRows()) {
      for (const row of rows) {
        results.push(row);
      }
    }
    results.schema = result.schema;
    return results;
  }

  async queryRow(query, params) {
    const result = await this.queryStream(query, params);
    const reader = result.readRows();
    try {
      const {done, value} = await reader.next();
      return done || !value.length ? null : value[0];
    } finally {
      await reader.return();
    }
  }

  async sql(strings, ...args) {
    return await this.query(strings.join("?"), args);
  }

  queryTag(strings, ...params) {
    return [strings.join("?"), params];
  }

  escape(name) {
    return `"${name}"`;
  }

  async describeTables() {
    const tables = await this.query(`SHOW TABLES`);
    return tables.map(({name}) => ({name}));
  }

  async describeColumns({table} = {}) {
    const columns = await this.query(`DESCRIBE ${this.escape(table)}`);
    return columns.map(({column_name, column_type, null: nullable}) => ({
      name: column_name,
      type: getDuckDBType(column_type),
      nullable: nullable !== "NO",
      databaseType: column_type
    }));
  }

  static async of(sources = {}, config = {}) {
    const db = await createDuckDB();
    if (config.query?.castTimestampToDate === undefined) {
      config = {...config, query: {...config.query, castTimestampToDate: true}};
    }
    if (config.query?.castBigIntToDouble === undefined) {
      config = {...config, query: {...config.query, castBigIntToDouble: true}};
    }
    await db.open(config);
    await Promise.all(
      Object.entries(sources).map(async ([name, source]) => {
        if (source instanceof FileAttachment$1) { // bare file
          await insertFile(db, name, source);
        } else if (isArrowTable(source)) { // bare arrow table
          await insertArrowTable(db, name, source);
        } else if (Array.isArray(source)) { // bare array of objects
          await insertArray(db, name, source);
        } else if (isArqueroTable(source)) {
          await insertArqueroTable(db, name, source);
        } else if ("data" in source) { // data + options
          const {data, ...options} = source;
          if (isArrowTable(data)) {
            await insertArrowTable(db, name, data, options);
          } else {
            await insertArray(db, name, data, options);
          }
        } else if ("file" in source) { // file + options
          const {file, ...options} = source;
          await insertFile(db, name, file, options);
        } else {
          throw new Error(`invalid source: ${source}`);
        }
      })
    );
    return new DuckDBClient(db);
  }
}

Object.defineProperty(DuckDBClient.prototype, "dialect", {
  value: "duckdb"
});

async function insertFile(database, name, file, options) {
  const url = await file.url();
  if (url.startsWith("blob:")) {
    const buffer = await file.arrayBuffer();
    await database.registerFileBuffer(file.name, new Uint8Array(buffer));
  } else {
    await database.registerFileURL(file.name, url, 4); // duckdb.DuckDBDataProtocol.HTTP
  }
  const connection = await database.connect();
  try {
    switch (file.mimeType) {
      case "text/csv":
      case "text/tab-separated-values": {
        return await connection.insertCSVFromPath(file.name, {
          name,
          schema: "main",
          ...options
        }).catch(async (error) => {
          // If initial attempt to insert CSV resulted in a conversion
          // error, try again, this time treating all columns as strings.
          if (error.toString().includes("Could not convert")) {
            return await insertUntypedCSV(connection, file, name);
          }
          throw error;
        });
      }
      case "application/json":
        return await connection.insertJSONFromPath(file.name, {
          name,
          schema: "main",
          ...options
        });
      default:
        if (/\.arrow$/i.test(file.name)) {
          const buffer = new Uint8Array(await file.arrayBuffer());
          return await connection.insertArrowFromIPCStream(buffer, {
            name,
            schema: "main",
            ...options
          });
        }
        if (/\.parquet$/i.test(file.name)) {
          return await connection.query(
            `CREATE VIEW '${name}' AS SELECT * FROM parquet_scan('${file.name}')`
          );
        }
        throw new Error(`unknown file type: ${file.mimeType}`);
    }
  } finally {
    await connection.close();
  }
}

async function insertUntypedCSV(connection, file, name) {
  const statement = await connection.prepare(
    `CREATE TABLE '${name}' AS SELECT * FROM read_csv_auto(?, ALL_VARCHAR=TRUE)`
  );
  return await statement.send(file.name);
}

async function insertArrowTable(database, name, table, options) {
  const connection = await database.connect();
  try {
    await connection.insertArrowTable(table, {
      name,
      schema: "main",
      ...options
    });
  } finally {
    await connection.close();
  }
}

async function insertArqueroTable(database, name, source) {
  // TODO When we have stdlib versioning and can upgrade Arquero to version 5,
  // we can then call source.toArrow() directly, with insertArrowTable()
  const arrow = await loadArrow();
  const table = arrow.tableFromIPC(source.toArrowBuffer());
  return await insertArrowTable(database, name, table);
}

async function insertArray(database, name, array, options) {
  const arrow = await loadArrow();
  const table = arrow.tableFromJSON(array);
  return await insertArrowTable(database, name, table, options);
}

async function loadDuckDB() {
  const module = await import(`${cdn}${duckdb.resolve()}`);
  const bundle = await module.selectBundle({
    mvp: {
      mainModule: `${cdn}${duckdb.resolve("dist/duckdb-mvp.wasm")}`,
      mainWorker: `${cdn}${duckdb.resolve("dist/duckdb-browser-mvp.worker.js")}`
    },
    eh: {
      mainModule: `${cdn}${duckdb.resolve("dist/duckdb-eh.wasm")}`,
      mainWorker: `${cdn}${duckdb.resolve("dist/duckdb-browser-eh.worker.js")}`
    }
  });
  const logger = new module.ConsoleLogger();
  return {module, bundle, logger};
}

async function createDuckDB() {
  if (promise === undefined) promise = loadDuckDB();
  const {module, bundle, logger} = await promise;
  const worker = await module.createWorker(bundle.mainWorker);
  const db = new module.AsyncDuckDB(logger, worker);
  await db.instantiate(bundle.mainModule);
  return db;
}

// https://duckdb.org/docs/sql/data_types/overview
function getDuckDBType(type) {
  switch (type) {
    case "BIGINT":
    case "HUGEINT":
    case "UBIGINT":
      return "bigint";
    case "DOUBLE":
    case "REAL":
    case "FLOAT":
      return "number";
    case "INTEGER":
    case "SMALLINT":
    case "TINYINT":
    case "USMALLINT":
    case "UINTEGER":
    case "UTINYINT":
      return "integer";
    case "BOOLEAN":
      return "boolean";
    case "DATE":
    case "TIMESTAMP":
    case "TIMESTAMP WITH TIME ZONE":
      return "date";
    case "VARCHAR":
    case "UUID":
      return "string";
    // case "BLOB":
    // case "INTERVAL":
    // case "TIME":
    default:
      if (/^DECIMAL\(/.test(type)) return "integer";
      return "other";
  }
}

const nChecks = 20; // number of values to check in each array

// We support two levels of DatabaseClient. The simplest DatabaseClient
// implements only the client.sql tagged template literal. More advanced
// DatabaseClients implement client.query and client.queryStream, which support
// streaming and abort, and the client.queryTag tagged template literal is used
// to translate the contents of a SQL cell or Table cell into the appropriate
// arguments for calling client.query or client.queryStream. For table cells, we
// additionally require client.describeColumns. The client.describeTables method
// is optional.
function isDatabaseClient(value, mode) {
  return (
    value &&
    (typeof value.sql === "function" ||
      (typeof value.queryTag === "function" &&
        (typeof value.query === "function" ||
          typeof value.queryStream === "function"))) &&
    (mode !== "table" || typeof value.describeColumns === "function") &&
    value !== __query // don’t match our internal helper
  );
}

// Returns true if the value is a typed array (for a single-column table), or if
// it’s an array. In the latter case, the elements of the array must be
// consistently typed: either plain objects or primitives or dates.
function isDataArray(value) {
  return (
    (Array.isArray(value) &&
      (isQueryResultSetSchema(value.schema) ||
        isQueryResultSetColumns(value.columns) ||
        arrayContainsObjects(value) ||
        arrayContainsPrimitives(value) ||
        arrayContainsDates(value))) ||
    isTypedArray(value)
  );
}

// Given an array, checks that the given value is an array that does not contain
// any primitive values (at least for the first few values that we check), and
// that the first object contains enumerable keys (see computeSchema for how we
// infer the columns). We assume that the contents of the table are homogenous,
// but we don’t currently enforce this.
// https://observablehq.com/@observablehq/database-client-specification#§1
function arrayContainsObjects(value) {
  const n = Math.min(nChecks, value.length);
  for (let i = 0; i < n; ++i) {
    const v = value[i];
    if (v === null || typeof v !== "object") return false;
  }
  return n > 0 && objectHasEnumerableKeys(value[0]);
}

// Using a for-in loop here means that we can abort after finding at least one
// enumerable key (whereas Object.keys would require materializing the array of
// all keys, which would be considerably slower if the value has many keys!).
// This function assumes that value is an object; see arrayContainsObjects.
function objectHasEnumerableKeys(value) {
  for (const _ in value) return true;
  return false;
}

function isQueryResultSetSchema(schemas) {
  return (
    Array.isArray(schemas) &&
    schemas.every(isColumnSchema)
  );
}

function isQueryResultSetColumns(columns) {
  return (Array.isArray(columns) && columns.every((name) => typeof name === "string"));
}

function isColumnSchema(schema) {
  return schema && typeof schema.name === "string" && typeof schema.type === "string";
}

// Returns true if the value represents an array of primitives (i.e., a
// single-column table). This should only be passed values for which
// isDataArray returns true.
function arrayIsPrimitive(value) {
  return (
    isTypedArray(value) ||
    arrayContainsPrimitives(value) ||
    arrayContainsDates(value)
  );
}

// Given an array, checks that the first n elements are primitives (number,
// string, boolean, bigint) of a consistent type.
function arrayContainsPrimitives(value) {
  const n = Math.min(nChecks, value.length);
  if (!(n > 0)) return false;
  let type;
  let hasPrimitive = false; // ensure we encounter 1+ primitives
  for (let i = 0; i < n; ++i) {
    const v = value[i];
    if (v == null) continue; // ignore null and undefined
    const t = typeof v;
    if (type === undefined) {
      switch (t) {
        case "number":
        case "boolean":
        case "string":
        case "bigint":
          type = t;
          break;
        default:
          return false;
      }
    } else if (t !== type) {
      return false;
    }
    hasPrimitive = true;
  }
  return hasPrimitive;
}

// Given an array, checks that the first n elements are dates.
function arrayContainsDates(value) {
  const n = Math.min(nChecks, value.length);
  if (!(n > 0)) return false;
  let hasDate = false; // ensure we encounter 1+ dates
  for (let i = 0; i < n; ++i) {
    const v = value[i];
    if (v == null) continue; // ignore null and undefined
    if (!(v instanceof Date)) return false;
    hasDate = true;
  }
  return hasDate;
}

function isTypedArray(value) {
  return (
    value instanceof Int8Array ||
    value instanceof Int16Array ||
    value instanceof Int32Array ||
    value instanceof Uint8Array ||
    value instanceof Uint8ClampedArray ||
    value instanceof Uint16Array ||
    value instanceof Uint32Array ||
    value instanceof Float32Array ||
    value instanceof Float64Array
  );
}

// __query is used by table cells; __query.sql is used by SQL cells.
const __query = Object.assign(
  async (source, operations, invalidation, name) => {
    source = await loadTableDataSource(await source, name);
    if (isDatabaseClient(source)) return evaluateQuery(source, makeQueryTemplate(operations, source), invalidation);
    if (isDataArray(source)) return __table(source, operations);
    if (!source) throw new Error("missing data source");
    throw new Error("invalid data source");
  },
  {
    sql(source, invalidation, name) {
      return async function () {
        return evaluateQuery(await loadSqlDataSource(await source, name), arguments, invalidation);
      };
    }
  }
);

// We use a weak map to cache loaded data sources by key so that we don’t have
// to e.g. create separate SQLiteDatabaseClients every time we’re querying the
// same SQLite file attachment. Since this is a weak map, unused references will
// be garbage collected when they are no longer desired. Note: the name should
// be consistent, as it is not part of the cache key!
function sourceCache(loadSource) {
  const cache = new WeakMap();
  return (source, name) => {
    if (!source) throw new Error("data source not found");
    let promise = cache.get(source);
    if (!promise || (isDataArray(source) && source.length !== promise._numRows)) {
      // Warning: do not await here! We need to populate the cache synchronously.
      promise = loadSource(source, name);
      promise._numRows = source.length; // This will be undefined for DatabaseClients
      cache.set(source, promise);
    }
    return promise;
  };
}

const loadTableDataSource = sourceCache(async (source, name) => {
  if (source instanceof FileAttachment$1) {
    switch (source.mimeType) {
      case "text/csv": return source.csv();
      case "text/tab-separated-values": return source.tsv();
      case "application/json": return source.json();
      case "application/x-sqlite3": return source.sqlite();
    }
    if (/\.(arrow|parquet)$/i.test(source.name)) return loadDuckDBClient(source, name);
    throw new Error(`unsupported file type: ${source.mimeType}`);
  }
  if (isArrowTable(source) || isArqueroTable(source)) return loadDuckDBClient(source, name);
  if (isDataArray(source) && arrayIsPrimitive(source))
    return Array.from(source, (value) => ({value}));
  return source;
});

const loadSqlDataSource = sourceCache(async (source, name) => {
  if (source instanceof FileAttachment$1) {
    switch (source.mimeType) {
      case "text/csv":
      case "text/tab-separated-values":
      case "application/json": return loadDuckDBClient(source, name);
      case "application/x-sqlite3": return source.sqlite();
    }
    if (/\.(arrow|parquet)$/i.test(source.name)) return loadDuckDBClient(source, name);
    throw new Error(`unsupported file type: ${source.mimeType}`);
  }
  if (isDataArray(source)) return loadDuckDBClient(await asArrowTable(source, name), name);
  if (isArrowTable(source) || isArqueroTable(source)) return loadDuckDBClient(source, name);
  return source;
});

async function asArrowTable(array, name) {
  const arrow = await loadArrow();
  return arrayIsPrimitive(array)
    ? arrow.tableFromArrays({[name]: array})
    : arrow.tableFromJSON(array);
}

function loadDuckDBClient(
  source,
  name = source instanceof FileAttachment$1
    ? getFileSourceName(source)
    : "__table"
) {
  return DuckDBClient.of({[name]: source});
}

function getFileSourceName(file) {
  return file.name
    .replace(/@\d+(?=\.|$)/, "") // strip Observable file version number
    .replace(/\.\w+$/, ""); // strip file extension
}

async function evaluateQuery(source, args, invalidation) {
  if (!source) throw new Error("missing data source");

  // If this DatabaseClient supports abort and streaming, use that.
  if (typeof source.queryTag === "function") {
    const abortController = new AbortController();
    const options = {signal: abortController.signal};
    invalidation.then(() => abortController.abort("invalidated"));
    if (typeof source.queryStream === "function") {
      return accumulateQuery(
        source.queryStream(...source.queryTag.apply(source, args), options)
      );
    }
    if (typeof source.query === "function") {
      return source.query(...source.queryTag.apply(source, args), options);
    }
  }

  // Otherwise, fallback to the basic sql tagged template literal.
  if (typeof source.sql === "function") {
    return source.sql.apply(source, args);
  }

  // TODO: test if source is a file attachment, and support CSV etc.
  throw new Error("source does not implement query, queryStream, or sql");
}

// Generator function that yields accumulated query results client.queryStream
async function* accumulateQuery(queryRequest) {
  let then = performance.now();
  const queryResponse = await queryRequest;
  const values = [];
  values.done = false;
  values.error = null;
  values.schema = queryResponse.schema;
  try {
    for await (const rows of queryResponse.readRows()) {
      if (performance.now() - then > 150 && values.length > 0) {
        yield values;
        then = performance.now();
      }
      for (const value of rows) {
        values.push(value);
      }
    }
    values.done = true;
    yield values;
  } catch (error) {
    values.error = error;
    yield values;
  }
}

/**
 * Returns a SQL query in the form [[parts], ...params] where parts is an array
 * of sub-strings and params are the parameter values to be inserted between each
 * sub-string.
 */
function makeQueryTemplate(operations, source) {
  const escaper =
    typeof source.escape === "function" ? source.escape : (i) => i;
  const {select, from, filter, sort, slice} = operations;
  if (!from.table)
    throw new Error("missing from table");
  if (select.columns && select.columns.length === 0)
    throw new Error("at least one column must be selected");
  const names = new Map(operations.names?.map(({column, name}) => [column, name]));
  const columns = select.columns ? select.columns.map((column) =>  {
    const override = names.get(column);
    return override ? `${escaper(column)} AS ${escaper(override)}` : escaper(column);
  }).join(", ") : "*";
  const args = [
    [`SELECT ${columns} FROM ${formatTable(from.table, escaper)}`]
  ];
  for (let i = 0; i < filter.length; ++i) {
    appendSql(i ? `\nAND ` : `\nWHERE `, args);
    appendWhereEntry(filter[i], args, escaper);
  }
  for (let i = 0; i < sort.length; ++i) {
    appendSql(i ? `, ` : `\nORDER BY `, args);
    appendOrderBy(sort[i], args, escaper);
  }
  if (source.dialect === "mssql" || source.dialect === "oracle") {
    if (slice.to !== null || slice.from !== null) {
      if (!sort.length) {
        if (!select.columns)
          throw new Error(
              "at least one column must be explicitly specified. Received '*'."
          );
        appendSql(`\nORDER BY `, args);
        appendOrderBy(
          {column: select.columns[0], direction: "ASC"},
          args,
          escaper
        );
      }
      appendSql(`\nOFFSET ${slice.from || 0} ROWS`, args);
      appendSql(
        `\nFETCH NEXT ${
          slice.to !== null ? slice.to - (slice.from || 0) : 1e9
        } ROWS ONLY`,
        args
      );
    }
  } else {
    if (slice.to !== null || slice.from !== null) {
      appendSql(
        `\nLIMIT ${slice.to !== null ? slice.to - (slice.from || 0) : 1e9}`,
        args
      );
    }
    if (slice.from !== null) {
      appendSql(` OFFSET ${slice.from}`, args);
    }
  }
  return args;
}

function formatTable(table, escaper) {
  if (typeof table === "object") { // i.e., not a bare string specifier
    let from = "";
    if (table.database != null) from += escaper(table.database) + ".";
    if (table.schema != null) from += escaper(table.schema) + ".";
    from += escaper(table.table);
    return from;
  } else {
    return escaper(table);
  }
}

function appendSql(sql, args) {
  const strings = args[0];
  strings[strings.length - 1] += sql;
}

function appendOrderBy({column, direction}, args, escaper) {
  appendSql(`${escaper(column)} ${direction.toUpperCase()}`, args);
}

function appendWhereEntry({type, operands}, args, escaper) {
  if (operands.length < 1) throw new Error("Invalid operand length");

  // Unary operations
  // We treat `v` and `nv` as `NULL` and `NOT NULL` unary operations in SQL,
  // since the database already validates column types.
  if (operands.length === 1 || type === "v" || type === "nv") {
    appendOperand(operands[0], args, escaper);
    switch (type) {
      case "n":
      case "nv":
        appendSql(` IS NULL`, args);
        return;
      case "nn":
      case "v":
        appendSql(` IS NOT NULL`, args);
        return;
      default:
        throw new Error("Invalid filter operation");
    }
  }

  // Binary operations
  if (operands.length === 2) {
    if (["in", "nin"].includes(type)) ; else if (["c", "nc"].includes(type)) {
      // TODO: Case (in)sensitive?
      appendOperand(operands[0], args, escaper);
      switch (type) {
        case "c":
          appendSql(` LIKE `, args);
          break;
        case "nc":
          appendSql(` NOT LIKE `, args);
          break;
      }
      appendOperand(likeOperand(operands[1]), args, escaper);
      return;
    } else {
      appendOperand(operands[0], args, escaper);
      switch (type) {
        case "eq":
          appendSql(` = `, args);
          break;
        case "ne":
          appendSql(` <> `, args);
          break;
        case "gt":
          appendSql(` > `, args);
          break;
        case "lt":
          appendSql(` < `, args);
          break;
        case "gte":
          appendSql(` >= `, args);
          break;
        case "lte":
          appendSql(` <= `, args);
          break;
        default:
          throw new Error("Invalid filter operation");
      }
      appendOperand(operands[1], args, escaper);
      return;
    }
  }

  // List operations
  appendOperand(operands[0], args, escaper);
  switch (type) {
    case "in":
      appendSql(` IN (`, args);
      break;
    case "nin":
      appendSql(` NOT IN (`, args);
      break;
    default:
      throw new Error("Invalid filter operation");
  }
  appendListOperands(operands.slice(1), args);
  appendSql(")", args);
}

function appendOperand(o, args, escaper) {
  if (o.type === "column") {
    appendSql(escaper(o.value), args);
  } else {
    args.push(o.value);
    args[0].push("");
  }
}

// TODO: Support column operands here?
function appendListOperands(ops, args) {
  let first = true;
  for (const op of ops) {
    if (first) first = false;
    else appendSql(",", args);
    args.push(op.value);
    args[0].push("");
  }
}

function likeOperand(operand) {
  return {...operand, value: `%${operand.value}%`};
}

// Comparator function that moves null values (undefined, null, NaN) to the
// end of the array.
function defined(a, b) {
  return (a == null || !(a >= a)) - (b == null || !(b >= b));
}

// Comparator function that sorts values in ascending order, with null values at
// the end.
function ascendingDefined(a, b) {
  return defined(a, b) || (a < b ? -1 : a > b ? 1 : 0);
}

// Comparator function that sorts values in descending order, with null values
// at the end.
function descendingDefined(a, b) {
  return defined(a, b) || (a > b ? -1 : a < b ? 1 : 0);
}

// Functions for checking type validity
const isValidNumber = (value) => typeof value === "number" && !Number.isNaN(value);
const isValidInteger = (value) => Number.isInteger(value) && !Number.isNaN(value);
const isValidString = (value) => typeof value === "string";
const isValidBoolean = (value) => typeof value === "boolean";
const isValidBigint = (value) => typeof value === "bigint";
const isValidDate = (value) => value instanceof Date && !isNaN(value);
const isValidBuffer = (value) => value instanceof ArrayBuffer;
const isValidArray = (value) => Array.isArray(value);
const isValidObject = (value) => typeof value === "object" && value !== null;
const isValidOther = (value) => value != null;

// Function to get the correct validity checking function based on type
function getTypeValidator(colType) {
  switch (colType) {
    case "string":
      return isValidString;
    case "bigint":
      return isValidBigint;
    case "boolean":
      return isValidBoolean;
    case "number":
      return isValidNumber;
    case "integer":
      return isValidInteger;
    case "date":
      return isValidDate;
    case "buffer":
      return isValidBuffer;
    case "array":
      return isValidArray;
    case "object":
      return isValidObject;
    case "other":
    default:
      return isValidOther;
  }
}

// Accepts dates in the form of ISOString and LocaleDateString, with or without time
const DATE_TEST = /^(([-+]\d{2})?\d{4}(-\d{2}(-\d{2}))|(\d{1,2})\/(\d{1,2})\/(\d{2,4}))([T ]\d{2}:\d{2}(:\d{2}(\.\d{3})?)?(Z|[-+]\d{2}:\d{2})?)?$/;

function coerceToType(value, type) {
  switch (type) {
    case "string":
      return typeof value === "string" || value == null ? value : String(value);
    case "boolean":
      if (typeof value === "string") {
        const trimValue = value.trim().toLowerCase();
        return trimValue === "true"
          ? true
          : trimValue === "false"
          ? false
          : null;
      }
      return typeof value === "boolean" || value == null
        ? value
        : Boolean(value);
    case "bigint":
      return typeof value === "bigint" || value == null
        ? value
        : Number.isInteger(typeof value === "string" && !value.trim() ? NaN : +value)
        ? BigInt(value) // eslint-disable-line no-undef
        : undefined;
    case "integer": // not a target type for coercion, but can be inferred
    case "number": {
      return typeof value === "number"
        ? value
        : value == null || (typeof value === "string" && !value.trim())
        ? NaN
        : Number(value);
    }
    case "date": {
      if (value instanceof Date || value == null) return value;
      if (typeof value === "number") return new Date(value);
      const trimValue = String(value).trim();
      if (typeof value === "string" && !trimValue) return null;
      return new Date(DATE_TEST.test(trimValue) ? trimValue : NaN);
    }
    case "array":
    case "object":
    case "buffer":
    case "other":
      return value;
    default:
      throw new Error(`Unable to coerce to type: ${type}`);
  }
}

// This function applies table cell operations to an in-memory table (array of
// objects); it should be equivalent to the corresponding SQL query. TODO Use
// DuckDBClient for data arrays, too, and then we wouldn’t need our own __table
// function to do table operations on in-memory data?
function __table(source, operations) {
  const input = source;
  let {schema, columns} = source;
  let inferredSchema = false;
  if (!isQueryResultSetSchema(schema)) {
    schema = inferSchema(source, isQueryResultSetColumns(columns) ? columns : undefined);
    inferredSchema = true;
  }
  // Combine column types from schema with user-selected types in operations
  const types = new Map(schema.map(({name, type}) => [name, type]));
  if (operations.types) {
    for (const {name, type} of operations.types) {
      types.set(name, type);
      // update schema with user-selected type
      if (schema === input.schema) schema = schema.slice(); // copy on write
      const colIndex = schema.findIndex((col) => col.name === name);
      if (colIndex > -1) schema[colIndex] = {...schema[colIndex], type};
    }
    source = source.map(d => coerceRow(d, types, schema));
  } else if (inferredSchema) {
    // Coerce data according to new schema, unless that happened due to
    // operations.types, above.
    source = source.map(d => coerceRow(d, types, schema));
  }
  for (const {type, operands} of operations.filter) {
    const [{value: column}] = operands;
    const values = operands.slice(1).map(({value}) => value);
    switch (type) {
      // valid (matches the column type)
      case "v": {
        const [colType] = values;
        const isValid = getTypeValidator(colType);
        source = source.filter(d => isValid(d[column]));
        break;
      }
      // not valid (doesn't match the column type)
      case "nv": {
        const [colType] = values;
        const isValid = getTypeValidator(colType);
        source = source.filter(d => !isValid(d[column]));
        break;
      }
      case "eq": {
        const [value] = values;
        if (value instanceof Date) {
          const time = +value; // compare as primitive
          source = source.filter((d) => +d[column] === time);
        } else {
          source = source.filter((d) => d[column] === value);
        }
        break;
      }
      case "ne": {
        const [value] = values;
        source = source.filter((d) => d[column] !== value);
        break;
      }
      case "c": {
        const [value] = values;
        source = source.filter(
          (d) => typeof d[column] === "string" && d[column].includes(value)
        );
        break;
      }
      case "nc": {
        const [value] = values;
        source = source.filter(
          (d) => typeof d[column] === "string" && !d[column].includes(value)
        );
        break;
      }
      case "in": {
        const set = new Set(values); // TODO support dates?
        source = source.filter((d) => set.has(d[column]));
        break;
      }
      case "nin": {
        const set = new Set(values); // TODO support dates?
        source = source.filter((d) => !set.has(d[column]));
        break;
      }
      case "n": {
        source = source.filter((d) => d[column] == null);
        break;
      }
      case "nn": {
        source = source.filter((d) => d[column] != null);
        break;
      }
      case "lt": {
        const [value] = values;
        source = source.filter((d) => d[column] < value);
        break;
      }
      case "lte": {
        const [value] = values;
        source = source.filter((d) => d[column] <= value);
        break;
      }
      case "gt": {
        const [value] = values;
        source = source.filter((d) => d[column] > value);
        break;
      }
      case "gte": {
        const [value] = values;
        source = source.filter((d) => d[column] >= value);
        break;
      }
      default:
        throw new Error(`unknown filter type: ${type}`);
    }
  }
  for (const {column, direction} of reverse(operations.sort)) {
    const compare = direction === "desc" ? descendingDefined : ascendingDefined;
    if (source === input) source = source.slice(); // defensive copy
    source.sort((a, b) => compare(a[column], b[column]));
  }
  let {from, to} = operations.slice;
  from = from == null ? 0 : Math.max(0, from);
  to = to == null ? Infinity : Math.max(0, to);
  if (from > 0 || to < Infinity) {
    source = source.slice(Math.max(0, from), Math.max(0, to));
  }
  if (operations.select.columns) {
    if (schema) {
      const schemaByName = new Map(schema.map((s) => [s.name, s]));
      schema = operations.select.columns.map((c) => schemaByName.get(c));
    }
    if (columns) {
      columns = operations.select.columns;
    }
    source = source.map((d) =>
      Object.fromEntries(operations.select.columns.map((c) => [c, d[c]]))
    );
  }
  if (operations.names) {
    const overridesByName = new Map(operations.names.map((n) => [n.column, n]));
    if (schema) {
      schema = schema.map((s) => {
        const override = overridesByName.get(s.name);
        return ({...s, ...(override ? {name: override.name} : null)});
      });
    }
    if (columns) {
      columns = columns.map((c) => {
        const override = overridesByName.get(c);
        return override?.name ?? c;
      });
    }
    source = source.map((d) =>
      Object.fromEntries(Object.keys(d).map((k) => {
        const override = overridesByName.get(k);
        return [override?.name ?? k, d[k]];
      }))
    );
  }
  if (source !== input) {
    if (schema) source.schema = schema;
    if (columns) source.columns = columns;
  }
  return source;
}

function coerceRow(object, types, schema) {
  const coerced = {};
  for (const col of schema) {
    const type = types.get(col.name);
    const value = object[col.name];
    coerced[col.name] = type === "raw" ? value : coerceToType(value, type);
  }
  return coerced;
}

function createTypeCount() {
  return {
    boolean: 0,
    integer: 0,
    number: 0,
    date: 0,
    string: 0,
    array: 0,
    object: 0,
    bigint: 0,
    buffer: 0,
    defined: 0
  };
}

// Caution: the order below matters! 🌶️ The first one that passes the ≥90% test
// should be the one that we chose, and therefore these types should be listed
// from most specific to least specific.
const types = [
  "boolean",
  "integer",
  "number",
  "date",
  "bigint",
  "array",
  "object",
  "buffer"
  // Note: "other" and "string" are intentionally omitted; see below!
];

// We need to show *all* keys present in the array of Objects
function getAllKeys(rows) {
  const keys = new Set();
  for (const row of rows) {
    // avoid crash if row is null or undefined
    if (row) {
      // only enumerable properties
      for (const key in row) {
        // only own properties
        if (Object.prototype.hasOwnProperty.call(row, key)) {
          // unique properties, in the order they appear
          keys.add(key);
        }
      }
    }
  }
  return Array.from(keys);
}

function inferSchema(source, columns = getAllKeys(source)) {
  const schema = [];
  const sampleSize = 100;
  const sample = source.slice(0, sampleSize);
  for (const col of columns) {
    const colCount = createTypeCount();
    for (const d of sample) {
      let value = d[col];
      if (value == null) continue;
      const type = typeof value;
      if (type !== "string") {
        ++colCount.defined;
        if (Array.isArray(value)) ++colCount.array;
        else if (value instanceof Date) ++colCount.date;
        else if (value instanceof ArrayBuffer) ++colCount.buffer;
        else if (type === "number") {
          ++colCount.number;
          if (Number.isInteger(value)) ++colCount.integer;
        }
        // bigint, boolean, or object
        else if (type in colCount) ++colCount[type];
      } else {
        value = value.trim();
        if (!value) continue;
        ++colCount.defined;
        ++colCount.string;
        if (/^(true|false)$/i.test(value)) {
          ++colCount.boolean;
        } else if (value && !isNaN(value)) {
          ++colCount.number;
          if (Number.isInteger(+value)) ++colCount.integer;
        } else if (DATE_TEST.test(value)) ++colCount.date;
      }
    }
    // Chose the non-string, non-other type with the greatest count that is also
    // ≥90%; or if no such type meets that criterion, fallback to string if
    // ≥90%; and lastly fallback to other.
    const minCount = Math.max(1, colCount.defined * 0.9);
    const type =
      greatest(types, (type) =>
        colCount[type] >= minCount ? colCount[type] : NaN
      ) ?? (colCount.string >= minCount ? "string" : "other");
    schema.push({
      name: col,
      type: type,
      inferred: type
    });
  }
  return schema;
}

class Workbook {
  constructor(workbook) {
    Object.defineProperties(this, {
      _: {value: workbook},
      sheetNames: {
        value: workbook.worksheets.map((s) => s.name),
        enumerable: true
      }
    });
  }
  sheet(name, options) {
    const sname =
      typeof name === "number"
        ? this.sheetNames[name]
        : this.sheetNames.includes((name += ""))
        ? name
        : null;
    if (sname == null) throw new Error(`Sheet not found: ${name}`);
    const sheet = this._.getWorksheet(sname);
    return extract(sheet, options);
  }
}

function extract(sheet, {range, headers} = {}) {
  let [[c0, r0], [c1, r1]] = parseRange(range, sheet);
  const headerRow = headers ? sheet._rows[r0++] : null;
  let names = new Set(["#"]);
  for (let n = c0; n <= c1; n++) {
    const value = headerRow ? valueOf(headerRow.findCell(n + 1)) : null;
    let name = (value && value + "") || toColumn(n);
    while (names.has(name)) name += "_";
    names.add(name);
  }
  names = new Array(c0).concat(Array.from(names));

  const output = new Array(r1 - r0 + 1);
  for (let r = r0; r <= r1; r++) {
    const row = (output[r - r0] = Object.create(null, {"#": {value: r + 1}}));
    const _row = sheet.getRow(r + 1);
    if (_row.hasValues)
      for (let c = c0; c <= c1; c++) {
        const value = valueOf(_row.findCell(c + 1));
        if (value != null) row[names[c + 1]] = value;
      }
  }

  output.columns = names.filter(() => true); // Filter sparse columns
  return output;
}

function valueOf(cell) {
  if (!cell) return;
  const {value} = cell;
  if (value && typeof value === "object" && !(value instanceof Date)) {
    if (value.formula || value.sharedFormula) {
      return value.result && value.result.error ? NaN : value.result;
    }
    if (value.richText) {
      return richText(value);
    }
    if (value.text) {
      let {text} = value;
      if (text.richText) text = richText(text);
      return value.hyperlink && value.hyperlink !== text
        ? `${value.hyperlink} ${text}`
        : text;
    }
    return value;
  }
  return value;
}

function richText(value) {
  return value.richText.map((d) => d.text).join("");
}

function parseRange(specifier = ":", {columnCount, rowCount}) {
  specifier += "";
  if (!specifier.match(/^[A-Z]*\d*:[A-Z]*\d*$/))
    throw new Error("Malformed range specifier");
  const [[c0 = 0, r0 = 0], [c1 = columnCount - 1, r1 = rowCount - 1]] =
    specifier.split(":").map(fromCellReference);
  return [
    [c0, r0],
    [c1, r1]
  ];
}

// Returns the default column name for a zero-based column index.
// For example: 0 -> "A", 1 -> "B", 25 -> "Z", 26 -> "AA", 27 -> "AB".
function toColumn(c) {
  let sc = "";
  c++;
  do {
    sc = String.fromCharCode(64 + (c % 26 || 26)) + sc;
  } while ((c = Math.floor((c - 1) / 26)));
  return sc;
}

// Returns the zero-based indexes from a cell reference.
// For example: "A1" -> [0, 0], "B2" -> [1, 1], "AA10" -> [26, 9].
function fromCellReference(s) {
  const [, sc, sr] = s.match(/^([A-Z]*)(\d*)$/);
  let c = 0;
  if (sc)
    for (let i = 0; i < sc.length; i++)
      c += Math.pow(26, sc.length - i - 1) * (sc.charCodeAt(i) - 64);
  return [c ? c - 1 : undefined, sr ? +sr - 1 : undefined];
}

async function remote_fetch(file) {
  const response = await fetch(await file.url());
  if (!response.ok) throw new Error(`Unable to load file: ${file.name}`);
  return response;
}

function enforceSchema(source, schema) {
  const types = new Map(schema.map(({name, type}) => [name, type]));
  return Object.assign(source.map(d => coerceRow(d, types, schema)), {schema});
}

async function dsv(file, delimiter, {array = false, typed = false} = {}) {
  const text = await file.text();
  const parse = (delimiter === "\t"
    ? (array ? tsvParseRows : tsvParse)
    : (array ? csvParseRows : csvParse));
  if (typed === "auto" && !array) {
    const source = parse(text);
    return enforceSchema(source, inferSchema(source, source.columns));
  }
  return parse(text, typed && autoType);
}

class AbstractFile {
  constructor(name, mimeType) {
    Object.defineProperty(this, "name", {value: name, enumerable: true});
    if (mimeType !== undefined) Object.defineProperty(this, "mimeType", {value: mimeType + "", enumerable: true});
  }
  async blob() {
    return (await remote_fetch(this)).blob();
  }
  async arrayBuffer() {
    return (await remote_fetch(this)).arrayBuffer();
  }
  async text() {
    return (await remote_fetch(this)).text();
  }
  async json() {
    return (await remote_fetch(this)).json();
  }
  async stream() {
    return (await remote_fetch(this)).body;
  }
  async csv(options) {
    return dsv(this, ",", options);
  }
  async tsv(options) {
    return dsv(this, "\t", options);
  }
  async image(props) {
    const url = await this.url();
    return new Promise((resolve, reject) => {
      const i = new Image();
      if (new URL(url, document.baseURI).origin !== new URL(location).origin) {
        i.crossOrigin = "anonymous";
      }
      Object.assign(i, props);
      i.onload = () => resolve(i);
      i.onerror = () => reject(new Error(`Unable to load file: ${this.name}`));
      i.src = url;
    });
  }
  async arrow({version = 4} = {}) {
    switch (version) {
      case 4: {
        const [Arrow, response] = await Promise.all([requireDefault(arrow4.resolve()), remote_fetch(this)]);
        return Arrow.Table.from(response);
      }
      case 9: {
        const [Arrow, response] = await Promise.all([import(`${cdn}${arrow9.resolve()}`), remote_fetch(this)]);
        return Arrow.tableFromIPC(response);
      }
      case 11: {
        const [Arrow, response] = await Promise.all([import(`${cdn}${arrow11.resolve()}`), remote_fetch(this)]);
        return Arrow.tableFromIPC(response);
      }
      default: throw new Error(`unsupported arrow version: ${version}`);
    }
  }
  async sqlite() {
    return SQLiteDatabaseClient.open(remote_fetch(this));
  }
  async zip() {
    const [JSZip, buffer] = await Promise.all([requireDefault(jszip.resolve()), this.arrayBuffer()]);
    return new ZipArchive(await JSZip.loadAsync(buffer));
  }
  async xml(mimeType = "application/xml") {
    return (new DOMParser).parseFromString(await this.text(), mimeType);
  }
  async html() {
    return this.xml("text/html");
  }
  async xlsx() {
    const [ExcelJS, buffer] = await Promise.all([requireDefault(exceljs.resolve()), this.arrayBuffer()]);
    return new Workbook(await new ExcelJS.Workbook().xlsx.load(buffer));
  }
}

let FileAttachment$1 = class FileAttachment extends AbstractFile {
  constructor(url, name, mimeType) {
    super(name, mimeType);
    Object.defineProperty(this, "_url", {value: url});
  }
  async url() {
    return (await this._url) + "";
  }
};

function NoFileAttachments(name) {
  throw new Error(`File not found: ${name}`);
}

function FileAttachments(resolve) {
  return Object.assign(
    name => {
      const result = resolve(name += "");
      if (result == null) throw new Error(`File not found: ${name}`);
      if (typeof result === "object" && "url" in result) {
        const {url, mimeType} = result;
        return new FileAttachment$1(url, name, mimeType);
      }
      return new FileAttachment$1(result, name);
    },
    {prototype: FileAttachment$1.prototype} // instanceof
  );
}

class ZipArchive {
  constructor(archive) {
    Object.defineProperty(this, "_", {value: archive});
    this.filenames = Object.keys(archive.files).filter(name => !archive.files[name].dir);
  }
  file(path) {
    const object = this._.file(path += "");
    if (!object || object.dir) throw new Error(`file not found: ${path}`);
    return new ZipArchiveEntry(object);
  }
}

class ZipArchiveEntry extends AbstractFile {
  constructor(object) {
    super(object.name);
    Object.defineProperty(this, "_", {value: object});
    Object.defineProperty(this, "_url", {writable: true});
  }
  async url() {
    return this._url || (this._url = this.blob().then(URL.createObjectURL));
  }
  async blob() {
    return this._.async("blob");
  }
  async arrayBuffer() {
    return this._.async("arraybuffer");
  }
  async text() {
    return this._.async("text");
  }
  async json() {
    return JSON.parse(await this.text());
  }
}

function canvas(width, height) {
  var canvas = document.createElement("canvas");
  canvas.width = width;
  canvas.height = height;
  return canvas;
}

function context2d(width, height, dpi) {
  if (dpi == null) dpi = devicePixelRatio;
  var canvas = document.createElement("canvas");
  canvas.width = width * dpi;
  canvas.height = height * dpi;
  canvas.style.width = width + "px";
  var context = canvas.getContext("2d");
  context.scale(dpi, dpi);
  return context;
}

function download(value, name = "untitled", label = "Save") {
  const a = document.createElement("a");
  const b = a.appendChild(document.createElement("button"));
  b.textContent = label;
  a.download = name;

  async function reset() {
    await new Promise(requestAnimationFrame);
    URL.revokeObjectURL(a.href);
    a.removeAttribute("href");
    b.textContent = label;
    b.disabled = false;
  }

  a.onclick = async event => {
    b.disabled = true;
    if (a.href) return reset(); // Already saved.
    b.textContent = "Saving…";
    try {
      const object = await (typeof value === "function" ? value() : value);
      b.textContent = "Download";
      a.href = URL.createObjectURL(object); // eslint-disable-line require-atomic-updates
    } catch (ignore) {
      b.textContent = label;
    }
    if (event.eventPhase) return reset(); // Already downloaded.
    b.disabled = false;
  };

  return a;
}

var namespaces = {
  math: "http://www.w3.org/1998/Math/MathML",
  svg: "http://www.w3.org/2000/svg",
  xhtml: "http://www.w3.org/1999/xhtml",
  xlink: "http://www.w3.org/1999/xlink",
  xml: "http://www.w3.org/XML/1998/namespace",
  xmlns: "http://www.w3.org/2000/xmlns/"
};

function element(name, attributes) {
  var prefix = name += "", i = prefix.indexOf(":"), value;
  if (i >= 0 && (prefix = name.slice(0, i)) !== "xmlns") name = name.slice(i + 1);
  var element = namespaces.hasOwnProperty(prefix) // eslint-disable-line no-prototype-builtins
      ? document.createElementNS(namespaces[prefix], name)
      : document.createElement(name);
  if (attributes) for (var key in attributes) {
    prefix = key, i = prefix.indexOf(":"), value = attributes[key];
    if (i >= 0 && (prefix = key.slice(0, i)) !== "xmlns") key = key.slice(i + 1);
    if (namespaces.hasOwnProperty(prefix)) element.setAttributeNS(namespaces[prefix], key, value); // eslint-disable-line no-prototype-builtins
    else element.setAttribute(key, value);
  }
  return element;
}

function input$1(type) {
  var input = document.createElement("input");
  if (type != null) input.type = type;
  return input;
}

function range$1(min, max, step) {
  if (arguments.length === 1) max = min, min = null;
  var input = document.createElement("input");
  input.min = min = min == null ? 0 : +min;
  input.max = max = max == null ? 1 : +max;
  input.step = step == null ? "any" : step = +step;
  input.type = "range";
  return input;
}

function select(values) {
  var select = document.createElement("select");
  Array.prototype.forEach.call(values, function(value) {
    var option = document.createElement("option");
    option.value = option.textContent = value;
    select.appendChild(option);
  });
  return select;
}

function svg$1(width, height) {
  var svg = document.createElementNS("http://www.w3.org/2000/svg", "svg");
  svg.setAttribute("viewBox", [0, 0, width, height]);
  svg.setAttribute("width", width);
  svg.setAttribute("height", height);
  return svg;
}

function text$1(value) {
  return document.createTextNode(value);
}

var count = 0;

function uid(name) {
  return new Id("O-" + (name == null ? "" : name + "-") + ++count);
}

function Id(id) {
  this.id = id;
  this.href = new URL(`#${id}`, location) + "";
}

Id.prototype.toString = function() {
  return "url(" + this.href + ")";
};

var DOM = /*#__PURE__*/Object.freeze({
  __proto__: null,
  canvas: canvas,
  context2d: context2d,
  download: download,
  element: element,
  input: input$1,
  range: range$1,
  select: select,
  svg: svg$1,
  text: text$1,
  uid: uid
});

function buffer(file) {
  return new Promise(function(resolve, reject) {
    var reader = new FileReader;
    reader.onload = function() { resolve(reader.result); };
    reader.onerror = reject;
    reader.readAsArrayBuffer(file);
  });
}

function text(file) {
  return new Promise(function(resolve, reject) {
    var reader = new FileReader;
    reader.onload = function() { resolve(reader.result); };
    reader.onerror = reject;
    reader.readAsText(file);
  });
}

function url(file) {
  return new Promise(function(resolve, reject) {
    var reader = new FileReader;
    reader.onload = function() { resolve(reader.result); };
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
}

var Files = /*#__PURE__*/Object.freeze({
  __proto__: null,
  buffer: buffer,
  text: text,
  url: url
});

function that() {
  return this;
}

function disposable(value, dispose) {
  let done = false;
  if (typeof dispose !== "function") {
    throw new Error("dispose is not a function");
  }
  return {
    [Symbol.iterator]: that,
    next: () => done ? {done: true} : (done = true, {done: false, value}),
    return: () => (done = true, dispose(value), {done: true}),
    throw: () => ({done: done = true})
  };
}

function* filter(iterator, test) {
  var result, index = -1;
  while (!(result = iterator.next()).done) {
    if (test(result.value, ++index)) {
      yield result.value;
    }
  }
}

function observe(initialize) {
  let stale = false;
  let value;
  let resolve;
  const dispose = initialize(change);

  if (dispose != null && typeof dispose !== "function") {
    throw new Error(typeof dispose.then === "function"
        ? "async initializers are not supported"
        : "initializer returned something, but not a dispose function");
  }

  function change(x) {
    if (resolve) resolve(x), resolve = null;
    else stale = true;
    return value = x;
  }

  function next() {
    return {done: false, value: stale
        ? (stale = false, Promise.resolve(value))
        : new Promise(_ => (resolve = _))};
  }

  return {
    [Symbol.iterator]: that,
    throw: () => ({done: true}),
    return: () => (dispose != null && dispose(), {done: true}),
    next
  };
}

function input(input) {
  return observe(function(change) {
    var event = eventof(input), value = valueof(input);
    function inputted() { change(valueof(input)); }
    input.addEventListener(event, inputted);
    if (value !== undefined) change(value);
    return function() { input.removeEventListener(event, inputted); };
  });
}

function valueof(input) {
  switch (input.type) {
    case "range":
    case "number": return input.valueAsNumber;
    case "date": return input.valueAsDate;
    case "checkbox": return input.checked;
    case "file": return input.multiple ? input.files : input.files[0];
    case "select-multiple": return Array.from(input.selectedOptions, o => o.value);
    default: return input.value;
  }
}

function eventof(input) {
  switch (input.type) {
    case "button":
    case "submit":
    case "checkbox": return "click";
    case "file": return "change";
    default: return "input";
  }
}

function* map$1(iterator, transform) {
  var result, index = -1;
  while (!(result = iterator.next()).done) {
    yield transform(result.value, ++index);
  }
}

function queue(initialize) {
  let resolve;
  const queue = [];
  const dispose = initialize(push);

  if (dispose != null && typeof dispose !== "function") {
    throw new Error(typeof dispose.then === "function"
        ? "async initializers are not supported"
        : "initializer returned something, but not a dispose function");
  }

  function push(x) {
    queue.push(x);
    if (resolve) resolve(queue.shift()), resolve = null;
    return x;
  }

  function next() {
    return {done: false, value: queue.length
        ? Promise.resolve(queue.shift())
        : new Promise(_ => (resolve = _))};
  }

  return {
    [Symbol.iterator]: that,
    throw: () => ({done: true}),
    return: () => (dispose != null && dispose(), {done: true}),
    next
  };
}

function* range(start, stop, step) {
  start = +start;
  stop = +stop;
  step = (n = arguments.length) < 2 ? (stop = start, start = 0, 1) : n < 3 ? 1 : +step;
  var i = -1, n = Math.max(0, Math.ceil((stop - start) / step)) | 0;
  while (++i < n) {
    yield start + i * step;
  }
}

function valueAt(iterator, i) {
  if (!isFinite(i = +i) || i < 0 || i !== i | 0) return;
  var result, index = -1;
  while (!(result = iterator.next()).done) {
    if (++index === i) {
      return result.value;
    }
  }
}

function worker(source) {
  const url = URL.createObjectURL(new Blob([source], {type: "text/javascript"}));
  const worker = new Worker(url);
  return disposable(worker, () => {
    worker.terminate();
    URL.revokeObjectURL(url);
  });
}

var Generators = /*#__PURE__*/Object.freeze({
  __proto__: null,
  disposable: disposable,
  filter: filter,
  input: input,
  map: map$1,
  observe: observe,
  queue: queue,
  range: range,
  valueAt: valueAt,
  worker: worker
});

function template(render, wrapper) {
  return function(strings) {
    var string = strings[0],
        parts = [], part,
        root = null,
        node, nodes,
        walker,
        i, n, j, m, k = -1;

    // Concatenate the text using comments as placeholders.
    for (i = 1, n = arguments.length; i < n; ++i) {
      part = arguments[i];
      if (part instanceof Node) {
        parts[++k] = part;
        string += "<!--o:" + k + "-->";
      } else if (Array.isArray(part)) {
        for (j = 0, m = part.length; j < m; ++j) {
          node = part[j];
          if (node instanceof Node) {
            if (root === null) {
              parts[++k] = root = document.createDocumentFragment();
              string += "<!--o:" + k + "-->";
            }
            root.appendChild(node);
          } else {
            root = null;
            string += node;
          }
        }
        root = null;
      } else {
        string += part;
      }
      string += strings[i];
    }

    // Render the text.
    root = render(string);

    // Walk the rendered content to replace comment placeholders.
    if (++k > 0) {
      nodes = new Array(k);
      walker = document.createTreeWalker(root, NodeFilter.SHOW_COMMENT, null, false);
      while (walker.nextNode()) {
        node = walker.currentNode;
        if (/^o:/.test(node.nodeValue)) {
          nodes[+node.nodeValue.slice(2)] = node;
        }
      }
      for (i = 0; i < k; ++i) {
        if (node = nodes[i]) {
          node.parentNode.replaceChild(parts[i], node);
        }
      }
    }

    // Is the rendered content
    // … a parent of a single child? Detach and return the child.
    // … a document fragment? Replace the fragment with an element.
    // … some other node? Return it.
    return root.childNodes.length === 1 ? root.removeChild(root.firstChild)
        : root.nodeType === 11 ? ((node = wrapper()).appendChild(root), node)
        : root;
  };
}

const html = template(function(string) {
  var template = document.createElement("template");
  template.innerHTML = string.trim();
  return document.importNode(template.content, true);
}, function() {
  return document.createElement("span");
});

async function leaflet(require) {
  const L = await require(leaflet$1.resolve());
  if (!L._style) {
    const link = document.createElement("link");
    link.rel = "stylesheet";
    link.href = await require.resolve(leaflet$1.resolve("dist/leaflet.css"));
    L._style = document.head.appendChild(link);
  }
  return L;
}

function md(require) {
  return require(marked.resolve()).then(function(marked) {
    return template(
      function(string) {
        var root = document.createElement("div");
        root.innerHTML = marked(string, {langPrefix: ""}).trim();
        var code = root.querySelectorAll("pre code[class]");
        if (code.length > 0) {
          require(highlight.resolve()).then(function(hl) {
            code.forEach(function(block) {
              function done() {
                hl.highlightBlock(block);
                block.parentNode.classList.add("observablehq--md-pre");
              }
              if (hl.getLanguage(block.className)) {
                done();
              } else {
                require(highlight.resolve("async-languages/index.js"))
                  .then(index => {
                    if (index.has(block.className)) {
                      return require(highlight.resolve("async-languages/" + index.get(block.className))).then(language => {
                        hl.registerLanguage(block.className, language);
                      });
                    }
                  })
                  .then(done, done);
              }
            });
          });
        }
        return root;
      },
      function() {
        return document.createElement("div");
      }
    );
  });
}

async function mermaid(require) {
  const mer = await require(mermaid$1.resolve());
  mer.initialize({securityLevel: "loose", theme: "neutral"});
  return function mermaid() {
    const root = document.createElement("div");
    root.innerHTML = mer.render(uid().id, String.raw.apply(String, arguments));
    return root.removeChild(root.firstChild);
  };
}

function Mutable(value) {
  let change;
  Object.defineProperties(this, {
    generator: {value: observe(_ => void (change = _))},
    value: {get: () => value, set: x => change(value = x)} // eslint-disable-line no-setter-return
  });
  if (value !== undefined) change(value);
}

function* now() {
  while (true) {
    yield Date.now();
  }
}

function delay(duration, value) {
  return new Promise(function(resolve) {
    setTimeout(function() {
      resolve(value);
    }, duration);
  });
}

var timeouts = new Map;

function timeout(now, time) {
  var t = new Promise(function(resolve) {
    timeouts.delete(time);
    var delay = time - now;
    if (!(delay > 0)) throw new Error("invalid time");
    if (delay > 0x7fffffff) throw new Error("too long to wait");
    setTimeout(resolve, delay);
  });
  timeouts.set(time, t);
  return t;
}

function when(time, value) {
  var now;
  return (now = timeouts.get(time = +time)) ? now.then(() => value)
      : (now = Date.now()) >= time ? Promise.resolve(value)
      : timeout(now, time).then(() => value);
}

function tick(duration, value) {
  return when(Math.ceil((Date.now() + 1) / duration) * duration, value);
}

var Promises = /*#__PURE__*/Object.freeze({
  __proto__: null,
  delay: delay,
  tick: tick,
  when: when
});

function resolve$1(name, base) {
  if (/^(\w+:)|\/\//i.test(name)) return name;
  if (/^[.]{0,2}\//i.test(name)) return new URL(name, base == null ? location : base).href;
  if (!name.length || /^[\s._]/.test(name) || /\s$/.test(name)) throw new Error("illegal name");
  return "https://unpkg.com/" + name;
}

const svg = template(function(string) {
  var root = document.createElementNS("http://www.w3.org/2000/svg", "g");
  root.innerHTML = string.trim();
  return root;
}, function() {
  return document.createElementNS("http://www.w3.org/2000/svg", "g");
});

var raw = String.raw;

function style$1(href) {
  return new Promise(function(resolve, reject) {
    var link = document.createElement("link");
    link.rel = "stylesheet";
    link.href = href;
    link.onerror = reject;
    link.onload = resolve;
    document.head.appendChild(link);
  });
}

function tex(require) {
  return Promise.all([
    require(katex.resolve()),
    require.resolve(katex.resolve("dist/katex.min.css")).then(style$1)
  ]).then(function(values) {
    var katex = values[0], tex = renderer();

    function renderer(options) {
      return function() {
        var root = document.createElement("div");
        katex.render(raw.apply(String, arguments), root, options);
        return root.removeChild(root.firstChild);
      };
    }

    tex.options = renderer;
    tex.block = renderer({displayMode: true});
    return tex;
  });
}

async function vl(require) {
  const [v, vl, api] = await Promise.all([vega, vegalite, vegaliteApi].map(d => require(d.resolve())));
  return api.register(v, vl);
}

function width() {
  return observe(function(change) {
    var width = change(document.body.clientWidth);
    function resized() {
      var w = document.body.clientWidth;
      if (w !== width) change(width = w);
    }
    window.addEventListener("resize", resized);
    return function() {
      window.removeEventListener("resize", resized);
    };
  });
}

const Library = Object.assign(Object.defineProperties(function Library(resolver) {
  const require = requirer(resolver);
  Object.defineProperties(this, properties({
    FileAttachment: () => NoFileAttachments,
    Mutable: () => Mutable,
    now,
    width,

    // Tagged template literals
    dot: () => require(graphviz.resolve()),
    htl: () => require(htl.resolve()),
    html: () => html,
    md: () => md(require),
    svg: () => svg,
    tex: () => tex(require),

    // Recommended libraries
    // https://observablehq.com/@observablehq/recommended-libraries
    _: () => require(lodash.resolve()),
    aq: () => require.alias({"apache-arrow": arrow4.resolve()})(arquero.resolve()), // TODO upgrade to apache-arrow@9
    Arrow: () => require(arrow4.resolve()), // TODO upgrade to apache-arrow@9
    d3: () => require(d3.resolve()),
    DuckDBClient: () => DuckDBClient,
    Inputs: () => require(inputs.resolve()).then(Inputs => ({...Inputs, file: Inputs.fileOf(AbstractFile)})),
    L: () => leaflet(require),
    mermaid: () => mermaid(require),
    Plot: () => require(plot.resolve()),
    __query: () => __query,
    require: () => require,
    resolve: () => resolve$1, // deprecated; use async require.resolve instead
    SQLite: () => SQLite(require),
    SQLiteDatabaseClient: () => SQLiteDatabaseClient,
    topojson: () => require(topojson.resolve()),
    vl: () => vl(require),

    // Sample datasets
    // https://observablehq.com/@observablehq/datasets
    aapl: () => new FileAttachment$1("https://static.observableusercontent.com/files/3ccff97fd2d93da734e76829b2b066eafdaac6a1fafdec0faf6ebc443271cfc109d29e80dd217468fcb2aff1e6bffdc73f356cc48feb657f35378e6abbbb63b9").csv({typed: true}),
    alphabet: () => new FileAttachment$1("https://static.observableusercontent.com/files/75d52e6c3130b1cae83cda89305e17b50f33e7420ef205587a135e8562bcfd22e483cf4fa2fb5df6dff66f9c5d19740be1cfaf47406286e2eb6574b49ffc685d").csv({typed: true}),
    cars: () => new FileAttachment$1("https://static.observableusercontent.com/files/048ec3dfd528110c0665dfa363dd28bc516ffb7247231f3ab25005036717f5c4c232a5efc7bb74bc03037155cb72b1abe85a33d86eb9f1a336196030443be4f6").csv({typed: true}),
    citywages: () => new FileAttachment$1("https://static.observableusercontent.com/files/39837ec5121fcc163131dbc2fe8c1a2e0b3423a5d1e96b5ce371e2ac2e20a290d78b71a4fb08b9fa6a0107776e17fb78af313b8ea70f4cc6648fad68ddf06f7a").csv({typed: true}),
    diamonds: () => new FileAttachment$1("https://static.observableusercontent.com/files/87942b1f5d061a21fa4bb8f2162db44e3ef0f7391301f867ab5ba718b225a63091af20675f0bfe7f922db097b217b377135203a7eab34651e21a8d09f4e37252").csv({typed: true}),
    flare: () => new FileAttachment$1("https://static.observableusercontent.com/files/a6b0d94a7f5828fd133765a934f4c9746d2010e2f342d335923991f31b14120de96b5cb4f160d509d8dc627f0107d7f5b5070d2516f01e4c862b5b4867533000").csv({typed: true}),
    industries: () => new FileAttachment$1("https://static.observableusercontent.com/files/76f13741128340cc88798c0a0b7fa5a2df8370f57554000774ab8ee9ae785ffa2903010cad670d4939af3e9c17e5e18e7e05ed2b38b848ac2fc1a0066aa0005f").csv({typed: true}),
    miserables: () => new FileAttachment$1("https://static.observableusercontent.com/files/31d904f6e21d42d4963ece9c8cc4fbd75efcbdc404bf511bc79906f0a1be68b5a01e935f65123670ed04e35ca8cae3c2b943f82bf8db49c5a67c85cbb58db052").json(),
    olympians: () => new FileAttachment$1("https://static.observableusercontent.com/files/31ca24545a0603dce099d10ee89ee5ae72d29fa55e8fc7c9ffb5ded87ac83060d80f1d9e21f4ae8eb04c1e8940b7287d179fe8060d887fb1f055f430e210007c").csv({typed: true}),
    penguins: () => new FileAttachment$1("https://static.observableusercontent.com/files/715db1223e067f00500780077febc6cebbdd90c151d3d78317c802732252052ab0e367039872ab9c77d6ef99e5f55a0724b35ddc898a1c99cb14c31a379af80a").csv({typed: true}),
    weather: () => new FileAttachment$1("https://static.observableusercontent.com/files/693a46b22b33db0f042728700e0c73e836fa13d55446df89120682d55339c6db7cc9e574d3d73f24ecc9bc7eb9ac9a1e7e104a1ee52c00aab1e77eb102913c1f").csv({typed: true}),

    // Note: these are namespace objects, and thus exposed directly rather than
    // being wrapped in a function. This allows library.Generators to resolve,
    // rather than needing module.value.
    DOM,
    Files,
    Generators,
    Promises
  }));
}, {
  resolve: {
    get: () => requireDefault.resolve,
    enumerable: true,
    configurable: true
  },
  require: {
    get: () => requireDefault,
    set: setDefaultRequire,
    enumerable: true,
    configurable: true
  }
}), {
  resolveFrom,
  requireFrom
});

function properties(values) {
  return Object.fromEntries(Object.entries(values).map(property));
}

function property([key, value]) {
  return [key, ({value, writable: true, enumerable: true})];
}

class RuntimeError extends Error {
  constructor(message, input) {
    super(message);
    this.input = input;
  }
}

RuntimeError.prototype.name = "RuntimeError";

function generatorish(value) {
  return value
      && typeof value.next === "function"
      && typeof value.return === "function";
}

function constant(x) {
  return () => x;
}

function identity(x) {
  return x;
}

function rethrow(error) {
  return () => {
    throw error;
  };
}

const prototype = Array.prototype;
const map = prototype.map;

function noop() {}

const TYPE_NORMAL = 1; // a normal variable
const TYPE_IMPLICIT = 2; // created on reference
const TYPE_DUPLICATE = 3; // created on duplicate definition

const no_observer = Symbol("no-observer");

function Variable(type, module, observer) {
  if (!observer) observer = no_observer;
  Object.defineProperties(this, {
    _observer: {value: observer, writable: true},
    _definition: {value: variable_undefined, writable: true},
    _duplicate: {value: undefined, writable: true},
    _duplicates: {value: undefined, writable: true},
    _indegree: {value: NaN, writable: true}, // The number of computing inputs.
    _inputs: {value: [], writable: true},
    _invalidate: {value: noop, writable: true},
    _module: {value: module},
    _name: {value: null, writable: true},
    _outputs: {value: new Set, writable: true},
    _promise: {value: Promise.resolve(undefined), writable: true},
    _reachable: {value: observer !== no_observer, writable: true}, // Is this variable transitively visible?
    _rejector: {value: variable_rejector(this)},
    _type: {value: type},
    _value: {value: undefined, writable: true},
    _version: {value: 0, writable: true}
  });
}

Object.defineProperties(Variable.prototype, {
  _pending: {value: variable_pending, writable: true, configurable: true},
  _fulfilled: {value: variable_fulfilled, writable: true, configurable: true},
  _rejected: {value: variable_rejected, writable: true, configurable: true},
  define: {value: variable_define, writable: true, configurable: true},
  delete: {value: variable_delete, writable: true, configurable: true},
  import: {value: variable_import, writable: true, configurable: true}
});

function variable_attach(variable) {
  variable._module._runtime._dirty.add(variable);
  variable._outputs.add(this);
}

function variable_detach(variable) {
  variable._module._runtime._dirty.add(variable);
  variable._outputs.delete(this);
}

function variable_undefined() {
  throw variable_undefined;
}

function variable_stale() {
  throw variable_stale;
}

function variable_rejector(variable) {
  return (error) => {
    if (error === variable_stale) throw error;
    if (error === variable_undefined) throw new RuntimeError(`${variable._name} is not defined`, variable._name);
    if (error instanceof Error && error.message) throw new RuntimeError(error.message, variable._name);
    throw new RuntimeError(`${variable._name} could not be resolved`, variable._name);
  };
}

function variable_duplicate(name) {
  return () => {
    throw new RuntimeError(`${name} is defined more than once`);
  };
}

function variable_define(name, inputs, definition) {
  switch (arguments.length) {
    case 1: {
      definition = name, name = inputs = null;
      break;
    }
    case 2: {
      definition = inputs;
      if (typeof name === "string") inputs = null;
      else inputs = name, name = null;
      break;
    }
  }
  return variable_defineImpl.call(this,
    name == null ? null : String(name),
    inputs == null ? [] : map.call(inputs, this._module._resolve, this._module),
    typeof definition === "function" ? definition : constant(definition)
  );
}

function variable_defineImpl(name, inputs, definition) {
  const scope = this._module._scope, runtime = this._module._runtime;

  this._inputs.forEach(variable_detach, this);
  inputs.forEach(variable_attach, this);
  this._inputs = inputs;
  this._definition = definition;
  this._value = undefined;

  // Is this an active variable (that may require disposal)?
  if (definition === noop) runtime._variables.delete(this);
  else runtime._variables.add(this);

  // Did the variable’s name change? Time to patch references!
  if (name !== this._name || scope.get(name) !== this) {
    let error, found;

    if (this._name) { // Did this variable previously have a name?
      if (this._outputs.size) { // And did other variables reference this variable?
        scope.delete(this._name);
        found = this._module._resolve(this._name);
        found._outputs = this._outputs, this._outputs = new Set;
        found._outputs.forEach(function(output) { output._inputs[output._inputs.indexOf(this)] = found; }, this);
        found._outputs.forEach(runtime._updates.add, runtime._updates);
        runtime._dirty.add(found).add(this);
        scope.set(this._name, found);
      } else if ((found = scope.get(this._name)) === this) { // Do no other variables reference this variable?
        scope.delete(this._name); // It’s safe to delete!
      } else if (found._type === TYPE_DUPLICATE) { // Do other variables assign this name?
        found._duplicates.delete(this); // This variable no longer assigns this name.
        this._duplicate = undefined;
        if (found._duplicates.size === 1) { // Is there now only one variable assigning this name?
          found = found._duplicates.keys().next().value; // Any references are now fixed!
          error = scope.get(this._name);
          found._outputs = error._outputs, error._outputs = new Set;
          found._outputs.forEach(function(output) { output._inputs[output._inputs.indexOf(error)] = found; });
          found._definition = found._duplicate, found._duplicate = undefined;
          runtime._dirty.add(error).add(found);
          runtime._updates.add(found);
          scope.set(this._name, found);
        }
      } else {
        throw new Error;
      }
    }

    if (this._outputs.size) throw new Error;

    if (name) { // Does this variable have a new name?
      if (found = scope.get(name)) { // Do other variables reference or assign this name?
        if (found._type === TYPE_DUPLICATE) { // Do multiple other variables already define this name?
          this._definition = variable_duplicate(name), this._duplicate = definition;
          found._duplicates.add(this);
        } else if (found._type === TYPE_IMPLICIT) { // Are the variable references broken?
          this._outputs = found._outputs, found._outputs = new Set; // Now they’re fixed!
          this._outputs.forEach(function(output) { output._inputs[output._inputs.indexOf(found)] = this; }, this);
          runtime._dirty.add(found).add(this);
          scope.set(name, this);
        } else { // Does another variable define this name?
          found._duplicate = found._definition, this._duplicate = definition; // Now they’re duplicates.
          error = new Variable(TYPE_DUPLICATE, this._module);
          error._name = name;
          error._definition = this._definition = found._definition = variable_duplicate(name);
          error._outputs = found._outputs, found._outputs = new Set;
          error._outputs.forEach(function(output) { output._inputs[output._inputs.indexOf(found)] = error; });
          error._duplicates = new Set([this, found]);
          runtime._dirty.add(found).add(error);
          runtime._updates.add(found).add(error);
          scope.set(name, error);
        }
      } else {
        scope.set(name, this);
      }
    }

    this._name = name;
  }

  // If this redefined variable was previously evaluated, invalidate it. (If the
  // variable was never evaluated, then the invalidated value could never have
  // been exposed and we can avoid this extra work.)
  if (this._version > 0) ++this._version;

  runtime._updates.add(this);
  runtime._compute();
  return this;
}

function variable_import(remote, name, module) {
  if (arguments.length < 3) module = name, name = remote;
  return variable_defineImpl.call(this, String(name), [module._resolve(String(remote))], identity);
}

function variable_delete() {
  return variable_defineImpl.call(this, null, [], noop);
}

function variable_pending() {
  if (this._observer.pending) this._observer.pending();
}

function variable_fulfilled(value) {
  if (this._observer.fulfilled) this._observer.fulfilled(value, this._name);
}

function variable_rejected(error) {
  if (this._observer.rejected) this._observer.rejected(error, this._name);
}

const variable_variable = Symbol("variable");
const variable_invalidation = Symbol("invalidation");
const variable_visibility = Symbol("visibility");

function Module(runtime, builtins = []) {
  Object.defineProperties(this, {
    _runtime: {value: runtime},
    _scope: {value: new Map},
    _builtins: {value: new Map([
      ["@variable", variable_variable],
      ["invalidation", variable_invalidation],
      ["visibility", variable_visibility],
      ...builtins
    ])},
    _source: {value: null, writable: true}
  });
}

Object.defineProperties(Module.prototype, {
  _resolve: {value: module_resolve, writable: true, configurable: true},
  redefine: {value: module_redefine, writable: true, configurable: true},
  define: {value: module_define, writable: true, configurable: true},
  derive: {value: module_derive, writable: true, configurable: true},
  import: {value: module_import, writable: true, configurable: true},
  value: {value: module_value, writable: true, configurable: true},
  variable: {value: module_variable, writable: true, configurable: true},
  builtin: {value: module_builtin, writable: true, configurable: true}
});

function module_redefine(name) {
  const v = this._scope.get(name);
  if (!v) throw new RuntimeError(`${name} is not defined`);
  if (v._type === TYPE_DUPLICATE) throw new RuntimeError(`${name} is defined more than once`);
  return v.define.apply(v, arguments);
}

function module_define() {
  const v = new Variable(TYPE_NORMAL, this);
  return v.define.apply(v, arguments);
}

function module_import() {
  const v = new Variable(TYPE_NORMAL, this);
  return v.import.apply(v, arguments);
}

function module_variable(observer) {
  return new Variable(TYPE_NORMAL, this, observer);
}

async function module_value(name) {
  let v = this._scope.get(name);
  if (!v) throw new RuntimeError(`${name} is not defined`);
  if (v._observer === no_observer) {
    v = this.variable(true).define([name], identity);
    try {
      return await module_revalue(this._runtime, v);
    } finally {
      v.delete();
    }
  } else {
    return module_revalue(this._runtime, v);
  }
}

// If the variable is redefined before its value resolves, try again.
async function module_revalue(runtime, variable) {
  await runtime._compute();
  try {
    return await variable._promise;
  } catch (error) {
    if (error === variable_stale) return module_revalue(runtime, variable);
    throw error;
  }
}

function module_derive(injects, injectModule) {
  const map = new Map();
  const modules = new Set();
  const copies = [];

  // Given a module, derives an alias of that module with an initially-empty
  // definition. The variables will be copied later in a second pass below.
  function alias(source) {
    let target = map.get(source);
    if (target) return target;
    target = new Module(source._runtime, source._builtins);
    target._source = source;
    map.set(source, target);
    copies.push([target, source]);
    modules.add(source);
    return target;
  }

  // Inject the given variables as reverse imports into the derived module.
  const derive = alias(this);
  for (const inject of injects) {
    const {alias, name} = typeof inject === "object" ? inject : {name: inject};
    derive.import(name, alias == null ? name : alias, injectModule);
  }

  // Iterate over all the variables (currently) in this module. If any
  // represents an import-with (i.e., an import of a module with a _source), the
  // transitive import-with must be copied, too, as direct injections may affect
  // transitive injections. Note that an import-with can only be created with
  // module.derive and hence it’s not possible for an import-with to be added
  // later; therefore we only need to apply this check once, now.
  for (const module of modules) {
    for (const [name, variable] of module._scope) {
      if (variable._definition === identity) { // import
        if (module === this && derive._scope.has(name)) continue; // overridden by injection
        const importedModule = variable._inputs[0]._module;
        if (importedModule._source) alias(importedModule);
      }
    }
  }

  // Finally, with the modules resolved, copy the variable definitions.
  for (const [target, source] of copies) {
    for (const [name, sourceVariable] of source._scope) {
      const targetVariable = target._scope.get(name);
      if (targetVariable && targetVariable._type !== TYPE_IMPLICIT) continue; // preserve injection
      if (sourceVariable._definition === identity) { // import
        const sourceInput = sourceVariable._inputs[0];
        const sourceModule = sourceInput._module;
        target.import(sourceInput._name, name, map.get(sourceModule) || sourceModule);
      } else { // non-import
        target.define(name, sourceVariable._inputs.map(variable_name), sourceVariable._definition);
      }
    }
  }

  return derive;
}

function module_resolve(name) {
  let variable = this._scope.get(name), value;
  if (!variable) {
    variable = new Variable(TYPE_IMPLICIT, this);
    if (this._builtins.has(name)) {
      variable.define(name, constant(this._builtins.get(name)));
    } else if (this._runtime._builtin._scope.has(name)) {
      variable.import(name, this._runtime._builtin);
    } else {
      try {
        value = this._runtime._global(name);
      } catch (error) {
        return variable.define(name, rethrow(error));
      }
      if (value === undefined) {
        this._scope.set(variable._name = name, variable);
      } else {
        variable.define(name, constant(value));
      }
    }
  }
  return variable;
}

function module_builtin(name, value) {
  this._builtins.set(name, value);
}

function variable_name(variable) {
  return variable._name;
}

const frame = typeof requestAnimationFrame === "function" ? requestAnimationFrame
  : typeof setImmediate === "function" ? setImmediate
  : f => setTimeout(f, 0);

function Runtime(builtins = new Library, global = window_global) {
  const builtin = this.module();
  Object.defineProperties(this, {
    _dirty: {value: new Set},
    _updates: {value: new Set},
    _precomputes: {value: [], writable: true},
    _computing: {value: null, writable: true},
    _init: {value: null, writable: true},
    _modules: {value: new Map},
    _variables: {value: new Set},
    _disposed: {value: false, writable: true},
    _builtin: {value: builtin},
    _global: {value: global}
  });
  if (builtins) for (const name in builtins) {
    (new Variable(TYPE_IMPLICIT, builtin)).define(name, [], builtins[name]);
  }
}

Object.defineProperties(Runtime.prototype, {
  _precompute: {value: runtime_precompute, writable: true, configurable: true},
  _compute: {value: runtime_compute, writable: true, configurable: true},
  _computeSoon: {value: runtime_computeSoon, writable: true, configurable: true},
  _computeNow: {value: runtime_computeNow, writable: true, configurable: true},
  dispose: {value: runtime_dispose, writable: true, configurable: true},
  module: {value: runtime_module, writable: true, configurable: true},
  fileAttachments: {value: FileAttachments, writable: true, configurable: true}
});

function runtime_dispose() {
  this._computing = Promise.resolve();
  this._disposed = true;
  this._variables.forEach(v => {
    v._invalidate();
    v._version = NaN;
  });
}

function runtime_module(define, observer = noop) {
  let module;
  if (define === undefined) {
    if (module = this._init) {
      this._init = null;
      return module;
    }
    return new Module(this);
  }
  module = this._modules.get(define);
  if (module) return module;
  this._init = module = new Module(this);
  this._modules.set(define, module);
  try {
    define(this, observer);
  } finally {
    this._init = null;
  }
  return module;
}

function runtime_precompute(callback) {
  this._precomputes.push(callback);
  this._compute();
}

function runtime_compute() {
  return this._computing || (this._computing = this._computeSoon());
}

function runtime_computeSoon() {
  return new Promise(frame).then(() => this._disposed ? undefined : this._computeNow());
}

async function runtime_computeNow() {
  let queue = [],
      variables,
      variable,
      precomputes = this._precomputes;

  // If there are any paused generators, resume them before computing so they
  // can update (if synchronous) before computing downstream variables.
  if (precomputes.length) {
    this._precomputes = [];
    for (const callback of precomputes) callback();
    await runtime_defer(3);
  }

  // Compute the reachability of the transitive closure of dirty variables.
  // Any newly-reachable variable must also be recomputed.
  // Any no-longer-reachable variable must be terminated.
  variables = new Set(this._dirty);
  variables.forEach(function(variable) {
    variable._inputs.forEach(variables.add, variables);
    const reachable = variable_reachable(variable);
    if (reachable > variable._reachable) {
      this._updates.add(variable);
    } else if (reachable < variable._reachable) {
      variable._invalidate();
    }
    variable._reachable = reachable;
  }, this);

  // Compute the transitive closure of updating, reachable variables.
  variables = new Set(this._updates);
  variables.forEach(function(variable) {
    if (variable._reachable) {
      variable._indegree = 0;
      variable._outputs.forEach(variables.add, variables);
    } else {
      variable._indegree = NaN;
      variables.delete(variable);
    }
  });

  this._computing = null;
  this._updates.clear();
  this._dirty.clear();

  // Compute the indegree of updating variables.
  variables.forEach(function(variable) {
    variable._outputs.forEach(variable_increment);
  });

  do {
    // Identify the root variables (those with no updating inputs).
    variables.forEach(function(variable) {
      if (variable._indegree === 0) {
        queue.push(variable);
      }
    });

    // Compute the variables in topological order.
    while (variable = queue.pop()) {
      variable_compute(variable);
      variable._outputs.forEach(postqueue);
      variables.delete(variable);
    }

    // Any remaining variables are circular, or depend on them.
    variables.forEach(function(variable) {
      if (variable_circular(variable)) {
        variable_error(variable, new RuntimeError("circular definition"));
        variable._outputs.forEach(variable_decrement);
        variables.delete(variable);
      }
    });
  } while (variables.size);

  function postqueue(variable) {
    if (--variable._indegree === 0) {
      queue.push(variable);
    }
  }
}

// We want to give generators, if they’re defined synchronously, a chance to
// update before computing downstream variables. This creates a synchronous
// promise chain of the given depth that we’ll await before recomputing
// downstream variables.
function runtime_defer(depth = 0) {
  let p = Promise.resolve();
  for (let i = 0; i < depth; ++i) p = p.then(() => {});
  return p;
}

function variable_circular(variable) {
  const inputs = new Set(variable._inputs);
  for (const i of inputs) {
    if (i === variable) return true;
    i._inputs.forEach(inputs.add, inputs);
  }
  return false;
}

function variable_increment(variable) {
  ++variable._indegree;
}

function variable_decrement(variable) {
  --variable._indegree;
}

function variable_value(variable) {
  return variable._promise.catch(variable._rejector);
}

function variable_invalidator(variable) {
  return new Promise(function(resolve) {
    variable._invalidate = resolve;
  });
}

function variable_intersector(invalidation, variable) {
  let node = typeof IntersectionObserver === "function" && variable._observer && variable._observer._node;
  let visible = !node, resolve = noop, reject = noop, promise, observer;
  if (node) {
    observer = new IntersectionObserver(([entry]) => (visible = entry.isIntersecting) && (promise = null, resolve()));
    observer.observe(node);
    invalidation.then(() => (observer.disconnect(), observer = null, reject()));
  }
  return function(value) {
    if (visible) return Promise.resolve(value);
    if (!observer) return Promise.reject();
    if (!promise) promise = new Promise((y, n) => (resolve = y, reject = n));
    return promise.then(() => value);
  };
}

function variable_compute(variable) {
  variable._invalidate();
  variable._invalidate = noop;
  variable._pending();

  const value0 = variable._value;
  const version = ++variable._version;

  // Lazily-constructed invalidation variable; only constructed if referenced as an input.
  let invalidation = null;

  // If the variable doesn’t have any inputs, we can optimize slightly.
  const promise = variable._promise = (variable._inputs.length
      ? Promise.all(variable._inputs.map(variable_value)).then(define)
      : new Promise(resolve => resolve(variable._definition.call(value0))))
    .then(generate);

  // Compute the initial value of the variable.
  function define(inputs) {
    if (variable._version !== version) throw variable_stale;

    // Replace any reference to invalidation with the promise, lazily.
    for (let i = 0, n = inputs.length; i < n; ++i) {
      switch (inputs[i]) {
        case variable_invalidation: {
          inputs[i] = invalidation = variable_invalidator(variable);
          break;
        }
        case variable_visibility: {
          if (!invalidation) invalidation = variable_invalidator(variable);
          inputs[i] = variable_intersector(invalidation, variable);
          break;
        }
        case variable_variable: {
          inputs[i] = variable;
          break;
        }
      }
    }

    return variable._definition.apply(value0, inputs);
  }

  // If the value is a generator, then retrieve its first value, and dispose of
  // the generator if the variable is invalidated. Note that the cell may
  // already have been invalidated here, in which case we need to terminate the
  // generator immediately!
  function generate(value) {
    if (variable._version !== version) throw variable_stale;
    if (generatorish(value)) {
      (invalidation || variable_invalidator(variable)).then(variable_return(value));
      return variable_generate(variable, version, value);
    }
    return value;
  }

  promise.then((value) => {
    variable._value = value;
    variable._fulfilled(value);
  }, (error) => {
    if (error === variable_stale) return;
    variable._value = undefined;
    variable._rejected(error);
  });
}

function variable_generate(variable, version, generator) {
  const runtime = variable._module._runtime;
  let currentValue; // so that yield resolves to the yielded value

  // Retrieve the next value from the generator; if successful, invoke the
  // specified callback. The returned promise resolves to the yielded value, or
  // to undefined if the generator is done.
  function compute(onfulfilled) {
    return new Promise(resolve => resolve(generator.next(currentValue))).then(({done, value}) => {
      return done ? undefined : Promise.resolve(value).then(onfulfilled);
    });
  }

  // Retrieve the next value from the generator; if successful, fulfill the
  // variable, compute downstream variables, and schedule the next value to be
  // pulled from the generator at the start of the next animation frame. If not
  // successful, reject the variable, compute downstream variables, and return.
  function recompute() {
    const promise = compute((value) => {
      if (variable._version !== version) throw variable_stale;
      currentValue = value;
      postcompute(value, promise).then(() => runtime._precompute(recompute));
      variable._fulfilled(value);
      return value;
    });
    promise.catch((error) => {
      if (error === variable_stale || variable._version !== version) return;
      postcompute(undefined, promise);
      variable._rejected(error);
    });
  }

  // After the generator fulfills or rejects, set its current value, promise,
  // and schedule any downstream variables for update.
  function postcompute(value, promise) {
    variable._value = value;
    variable._promise = promise;
    variable._outputs.forEach(runtime._updates.add, runtime._updates);
    return runtime._compute();
  }

  // When retrieving the first value from the generator, the promise graph is
  // already established, so we only need to queue the next pull.
  return compute((value) => {
    if (variable._version !== version) throw variable_stale;
    currentValue = value;
    runtime._precompute(recompute);
    return value;
  });
}

function variable_error(variable, error) {
  variable._invalidate();
  variable._invalidate = noop;
  variable._pending();
  ++variable._version;
  variable._indegree = NaN;
  (variable._promise = Promise.reject(error)).catch(noop);
  variable._value = undefined;
  variable._rejected(error);
}

function variable_return(generator) {
  return function() {
    generator.return();
  };
}

function variable_reachable(variable) {
  if (variable._observer !== no_observer) return true; // Directly reachable.
  const outputs = new Set(variable._outputs);
  for (const output of outputs) {
    if (output._observer !== no_observer) return true;
    output._outputs.forEach(outputs.add, outputs);
  }
  return false;
}

function window_global(name) {
  return globalThis[name];
}

/**
 * Resolve a file attachment name.
 * @param {string} name the file name to resolve
 * @returns the resolved file URL or null if not found
 */
function resolve(name) {
  // for now simply use the name as the URL!
  return name;
}

const FileAttachment = Runtime.prototype.fileAttachments(resolve);

/**
 * Reactive runtime engine.
 */
class ObservableRuntime {
  /**
   * Create a new runtime instance.
   */
  constructor() {
    // Prepare a standard library instance
    const lib = Object.assign(new Library, {
      FileAttachment: () => FileAttachment
    });

    /**
     * Instantiate an Observable runtime instance.
     */
    this.runtime = new Runtime(lib);

    /**
     * The main module (variable namespace).
     */
    this.main = this.runtime.module();
  }

  /**
   * Redefine a variable in the runtime.
   * @param {string} name The name of the variable.
   * @param {function} defn A function that returns the variable value.
   * @param {any[]} [inputs] The inputs to the definition function.
   */
  redefine(name, defn, inputs = []) {
    this.main.redefine(name, inputs, defn);
  }

  /**
   * Define a new variable in the runtime.
   * @param {string} name The name of the variable.
   * @param {function} defn A function that returns the variable value.
   * @param {any[]} inputs The inputs to the definition function.
   * @param {*} [observer] An observer instance that receives updates
   *  as the variable status changes.
   */
  variable(name, defn, inputs = [], observer) {
    this.main.variable(observer).define(name, inputs, defn);
  }

  /**
   * Instatiate an external module (namespace) in the runtime.
   * If injection values are provided, a derived module will be
   * created with injected variables from the main modulde.
   * @param {function} define The module definition function.
   * @param {object} [inject] An array of {name, alias} objects
   *  indicating variables to inject from the main module.
   * @returns The new module.
   */
  module(define, inject) {
    const mod = this.runtime.module(define);
    return inject ? mod.derive(inject, this.main) : mod;
  }

  /**
   * Import variables from an external module into the main module.
   * @param {object} from The module to import from.
   * @param {string} name The source name of the variable to import.
   * @param {string} alias The alias (target name) for the imported variable.
   */
  import(from, name, alias = name) {
    this.main.import(name, alias, from);
  }

  /**
   * Request the value for a named variable in the runtime.
   * @param {string} name The variable name.
   * @returns {Promise} A Promise for the variable value.
   */
  value(name) {
    return this.main.value(name);
  }

  /**
   * Define a set of variables in the main module.
   * @param {object[]} defs An array of variable definition objects.
   * @param {function} observer A function to call to get an observer
   *  instance for a variable.
   */
  define(defs, observer) {
    const mods = new Map;
    defs.forEach(def => {
      if (def.module) {
        const [id, define, inject] = def.module;
        mods.set(id, this.module(define, inject));
      } else if (def.import) {
        const [id, name, alias] = def.import;
        this.import(mods.get(id), name, alias);
      } else if (def.define) {
        const [name, inputs, defn] = def.define;
        this.variable(name, defn, inputs, observer(def));
      }
    });
  }

  /**
   * Generate an event handler function for a named assignment handler in the
   * runtime. The event handler collects all assignments to a proxy object
   * and propagates the assignments to the runtime by redefining variables.
   * @param {string} id The handler id (variable name).
   * @returns {function} The generated event handler.
   */
  handler(id) {
    return async (e) => {
      // prevent default event response
      e.preventDefault();

      // retrieve handler and variables from runtime
      const [handler, vars] = await this.value(id);
      const values = await Promise.all(vars.map(name => this.value(name)));

      // populate proxy object with variable values
      const proxy = Object.create(null);
      values.forEach((value, i) => proxy[vars[i]] = value);

      // invoke event handler
      await handler(proxy)(e);

      // propagate proxied assignments back to the runtime
      values.forEach((value, i) => {
        const name = vars[i];
        if (value !== proxy[name]) {
          this.redefine(name, proxy[name]);
        }
      });
    }
  }
}

function removeChildren(node, index = 0) {
  const nodes = node.childNodes;
  let i = nodes.length;
  while (i > index) node.removeChild(nodes[--i]);
}

/**
 * Abstract base class for Living Papers custom elements.
 */
class ArticleElement extends s {
  createRenderRoot() {
    // do not use a shadow dom
    return this;
  }

  connectedCallback() {
    if (!this.__initchildnodes) {
      // detach initial child nodes upon first connection to the DOM
      this.__initchildnodes = true;
      this.initialChildNodes(
        Array.from(this.childNodes, node => (node.__element = this, node))
      );
      removeChildren(this);
    }
    super.connectedCallback();
  }

  initialChildNodes(nodes) {
    // store initial child nodes for subsequent access
    this.__children = nodes;
  }

  articleData() {
    let el = this;
    for (; el.tagName !== 'ARTICLE'; el = el.parentNode || el.__element);
    return el?.__data;
  }
}

class CellView extends ArticleElement {
  static get properties() {
    return {
      value: {state: true},
      status: {type: String, state: true}
    };
  }

  constructor() {
    super();
    this.status = PENDING;
    this.observer = new Observer((status, value) => {
      this.status = status;
      if (status !== PENDING) {
        this.value = value;
        this.dispatchEvent(new Event('change'));
      }
    });
  }

  render() {
    switch (this.status) {
      case PENDING:
      case FULFILLED:
        return this.value;
      case REJECTED:
        return error(this.value.error);
      default:
        return error(`Unrecognized status: ${this.status}.`);
    }
  }
}

function error(message) {
  return x`<span class="error-block">${message}</span>`;
}

class Tooltip extends ArticleElement {

  constructor() {
    super();
    this.visible = false;
    this.addEventListener('keydown', this.keyDown);
    this.addEventListener('mousedown', this.mouseDown);
  }

  mouseDownClose = (event) => {
    if (this.contains(event.target)) return;
    this.hide();
  }

  keyDownClose = (event) => {
    if (!isCloseKey(event.key)) return;
    this.hide();
  }

  keyDown(event) {
    if (!isOpenKey(event.key) || this.visible) return;
    this.show();
  }

  mouseDown() {
    if (this.visible) return;
    this.show();
  }

  hide() {
    this.querySelector('.tooltip').style.display = 'none';
    this.visible = false;

    // clean up event listeners
    document.removeEventListener('keydown', this.keyDownClose);
    document.removeEventListener('mousedown', this.mouseDownClose);
  }

  show() {
    const bbox = this.getBoundingClientRect();
    const ttip = this.querySelector('.tooltip');
    ttip.style.display = 'inline-block';
    this.visible = true;
    transformTooltip(bbox, ttip);

    // add the close tooltip events
    document.addEventListener('keydown', this.keyDownClose);
    document.addEventListener('mousedown', this.mouseDownClose);
  }

  renderWithTooltip(classes, body, tooltip) {
    const tip = x`<div class="tooltip">${tooltip}</div>`;
    return x`<span class=${classes} tabindex=0>${tip}${body}</span>`;
  }
}

const isOpenKey = (key, openKey = 'Enter') => key === openKey;

const isCloseKey = (key, closeKey = 'Escape') => key === closeKey;

function transformTooltip(spanBBox, ttip) {
  // set translate to zero to undo any prior settings
  ttip.style.transform = `translate(0, 0)`;
  const tipBBox = ttip.getBoundingClientRect();
  const tipWidth = tipBBox.width;
  const tipX = tipBBox.left;
  const spanX = spanBBox.left;
  const maxWidth = document.body.clientWidth - 16;

  // case 1: tooltip is wider than document, shift to the leftmost point
  // case 2: tooltip extends out of view, shift back until it fits
  // otherwise, shift to match left-most edge of span
  const dx = tipWidth > maxWidth ? -tipX
    : spanX + tipWidth > maxWidth ? maxWidth - (tipX + tipWidth)
    : spanX - tipX;

  // offset tooltip to 2 pixels below bottom of span
  const dy = spanBBox.bottom - tipBBox.top + 2;

  ttip.style.transform = `translate(${dx}px, ${dy}px)`;
}

class CiteRef extends Tooltip {

  static get properties() {
    return {
      key: {type: String},
      mode: {type: String},
      index: {type: Number}
    };
  }

  constructor() {
    super();
    this.mode = 'citation';
  }

  initialChildNodes(nodes) {
    this.__prefix = nodes[0];
    this.__suffix = nodes[1];
  }

  citeData() {
    return this.data || (
      this.data = this.articleData()?.citations?.data[this.index - 1]
    );
  }

  render() {
    const { key, index, mode, data = this.citeData() } = this;

    const classes = `cite-ref${data ? '' : ' unresolved'}`;
    const content = data == null ? (index ?? '??')
      : mode === 'inline-author' ? inlineContent(data, index)
      : index;
    return this.renderWithTooltip(classes, content, renderCiteInfo(key, data));
  }
}

function renderCiteInfo(key, data) {
  if (data) {
    return x`<div class="cite-info">
      ${renderCiteTitle(data)}
      ${renderCiteAuthor(data)}
      ${renderCiteVenue(data)}
      ${renderCiteDetail(data)}
    </div>`;
  } else {
    return x`<div class="cite-info">
      <strong>Unresolved citation</strong><br>"${key}"
    </div>`;
  }
}

function renderCiteTitle(data) {
  const { url, title, year, author } = data;
  const date = year ? x`\u2022 <span class="cite-year">${year}</a>` : '';
  const text = title || authorNames(author).join(', ') || 'Unknown Title';
  if (url) {
    return x`<div class="cite-title">
      <a href=${url} target="_blank" rel="noopener noreferrer">${text}</a>
      ${date}
    </div>`;
  } else {
    return x`<div class="cite-title">${text}${date}</div>`;
  }
}

function authorNames(authorList) {
  return (authorList || []).map(({ given, family }) => {
    return given
      ? `${given.includes('.') ? given : given[0] + '.'} ${family}`
      : family;
  });
}

function renderCiteAuthor(data, maxAuthors = 4) {
  const { author, title } = data;
  if (!title) return null; // authors will be listed under title instead
  const authors = authorNames(author);
  const diff = authors.length - maxAuthors;
  if (diff > 1) { // ensure > 1, prevents case of +1 author only
    const authorsShow = authors.slice(0, maxAuthors).join(', ');
    const authorsHide = ', ' + authors.slice(maxAuthors).join(', ');
    const hiddenCount = x`<span class="cite-author-button" @click=${more}>+${diff}&nbsp;authors</span>`;
    const expand = x`<span class="cite-author-expand"> ${hiddenCount}</span>`;
    const collapse = x` <span class="cite-author-button" @click=${less}>less</span>`;
    const hidden = x`<span class="cite-author-hidden">${authorsHide}${collapse}</span>`;
    return x`<div class="cite-author">${authorsShow}${expand}${hidden}</div>`
  } else {
    return authors.length
      ? x`<div class="cite-author">${authors.join(', ')}</div>`
      : null;
  }
}

function more() {
  this.querySelector('.cite-author-expand').style.display = 'none';
  this.querySelector('.cite-author-hidden').style.display = 'inline';
}

function less() {
  this.querySelector('.cite-author-expand').style.display = 'inline';
  this.querySelector('.cite-author-hidden').style.display = 'none';
}

function renderCiteVenue(data) {
  const { venue } = data;
  return venue
    ? x`<div class="cite-venue">${venue}</div>`
    : null;
}

function renderCiteDetail(data, limit = 300) {
  const { abstract, tldr } = data;
  const detail = tldr || abstract;
  if (!detail) return null;
  const desc = detail !== tldr && detail.length > limit
    ? detail.slice(0, detail.slice(0, limit).lastIndexOf(' ')) + '…'
    : detail;

  // TODO: make shortened text expandable?
  return x`<div class="cite-detail">${desc}</div>`;
}

// Returns inline authors, or abbrev. if there are more than etal authors
function inlineContent(data, index, etal = 2) {
  const { author, title } = data;

  if (!author || !author.length) {
    return `${title} [${index}]`;
  }

  let authors = author[0].family;
  if (author.length === 2) {
    authors += ` & ${author[1].family}`;
  } else if (author.length > etal) {
    authors += ' et al.';
  }
  return `${authors} [${index}]`;
}

class CrossRef extends Tooltip {
  static get properties() {
    return {
      type: {type: String},
      xref: {type: String},
      index: {type: Number},
      short: {type: Boolean},
    };
  }

  show() {
    this.renderTooltipContent();
    super.show();
  }

  goto(event) {
    // prevent jump to referenced element
    event.preventDefault();

    // add id to hash component of current URL
    // do not change the page undo history
    const id =`#${this.xref}`;
    history.replaceState(null, null, id);

    // smoothly scroll to referenced component
    document.querySelector(id)
      .scrollIntoView({ behavior: 'smooth', block: 'nearest' });
  }

  renderTooltipContent() {
    if (this.index == null) return;

    const tooltip = this.querySelector('.cross-ref-tooltip');
    // remove previous tooltip content
    tooltip.replaceChildren();
    cloneReference(tooltip, document.getElementById(this.xref));

    // clear all additional styling classes on figures and tables
    tooltip.firstElementChild.className = (this.type === referenceTypes.FIGURE)
      ? 'figure'
      : (this.type === referenceTypes.TABLE) ? 'table' : '';
  }

  renderUnresolvedReference(cls) {
    const tooltipContent = x`<div class="cross-ref-tooltip">
      Unresolved ${this.type} reference: ${this.xref}
    </div>`;

    return this.renderWithTooltip(`${cls} unresolved`, '?', tooltipContent);
  }

  renderResolvedReference(cls) {
    // render a default reference if it is a section reference
    if (this.type === referenceTypes.SECTION) {
      // remove default tooltip listeners for section references
      this.removeEventListener('keydown', this.keyDown);
      this.removeEventListener('mousedown', this.mouseDown);
      return x`<a class=${cls} href="#${this.xref}" @click=${this.goto}>${this.index}</a>`;
    } else {
      const tooltipContent = x`<div class="cross-ref-tooltip"></div>`;
      return this.renderWithTooltip(cls, this.index, tooltipContent);
    }
  }

  renderWithTooltip(classes, body, tooltip) {
    const tip = x`<div class="tooltip">${tooltip}</div>`;
    return x`<span class=${classes} @dblclick=${this.goto} tabindex=0>${tip}${body}</span>`;
  }

  render() {
    const { type, index, short } = this;
    const resolved = index != null;
    const cls = `cross-ref ${type}${!short ? ' full' : ''}`;

    return resolved
      ? this.renderResolvedReference(cls)
      : this.renderUnresolvedReference(cls);
  }
}

const EQN_NUM_CLASSNAME = 'tag';

function cloneReference(parent, node) {
  // don't clone the equation number
  if (node.className === EQN_NUM_CLASSNAME) return;

  // clone the node with attributes
  const clone = node.cloneNode();

  // remove duplicate ids and attach to the parent
  if (clone.id) clone.removeAttribute('id');
  parent.append(clone);

  // check if we should clone the children
  if (hasUnclonableChildren(node)) return;

  for (const child of node.childNodes) {
    cloneReference(clone, child);
  }
}

const referenceTypes = {
  SECTION: 'sec',
  FIGURE: 'fig',
  TABLE: 'tbl',
  EQUATION: 'eqn',
};

const nodes = new Set([
  'CITE-REF',
  'CODE-BLOCK',
  'CROSS-REF',
  'INLINE-NOTE',
  'RANGE-TEXT',
  'TEX-MATH',
]);

const hasUnclonableChildren = (node) => {
  return nodes.has(node.tagName);
};

let numNotes = 0; // incrementing counter of notes

class InlineNote extends ArticleElement {
  constructor() {
    super();
    this.number = ++numNotes;
  }

  render() {
    const num = this.number;
    return x`<span class="inline-note" @click=${(evt) => evt.target.parentElement.classList.toggle('open')}>
      <sup class="inline-note-number">${num}</sup>
      <span class="note margin" data-number="${num}">${this.__children}</span>
    </span>`;
  }
}

class DraggableText extends ArticleElement {
  constructor() {
    super();
    this.span = 1;
    this.title = 'Draggable text';
    this.prefix = '';
    this.suffix = '';
    this.addEventListener('click', e => e.stopPropagation());
    this.addEventListener('mousedown', e => this.onMouseDown(e));
  }

  onMouseDown(e) {
    e.stopImmediatePropagation();
    const mx = e.x;
    const i0 = this.currentIndex();

    const cursor = this.ownerDocument.body.style.cursor;
    this.ownerDocument.body.style.cursor = 'ew-resize';

    const select = this.style.MozUserSelect;
    this.style.MozUserSelect = 'none';

    const move = e => {
      e.preventDefault();
      e.stopImmediatePropagation();
      const index = this.updatedIndex(mx, e.x, i0);
      if (index !== this.currentIndex()) {
        this.setValue(index);
        this.dispatchEvent(new CustomEvent('input'));
        this.requestUpdate();
      }
    };

    const up = e => {
      e.preventDefault();
      e.stopImmediatePropagation();
      this.ownerDocument.body.style.cursor = cursor;
      this.style.MozUserSelect = select;
      window.removeEventListener('mousemove', move);
      window.removeEventListener('mouseup', up);
    };

    window.addEventListener('mousemove', move);
    window.addEventListener('mouseup', up);
  }

  render() {
    return x`<span class="draggable-text" title=${this.title}>${this.prefix}${this.content()}${this.suffix}</span>`;
  }
}

class OptionText extends DraggableText {
  static get properties() {
    return {
      value: {attribute: false},
      options: {type: Array},
      span: {type: Number},
      title: {type: String},
      prefix: {type: String},
      suffix: {type: String}
    };
  }

  constructor() {
    super();
    this.value = undefined;
    this.index = 0;
    this.options = [];
  }

  currentIndex() {
    return this.index;
  }

  updatedIndex(x1, x2, i0) {
    const { span, options } = this;
    const di = Math.round((x2 - x1) / span);
    return Math.max(Math.min(i0 + di, options.length - 1), 0);
  }

  getIndex(value) {
    return Math.max(0, this.options.indexOf(value));
  }

  getValue(index) {
    const { options } = this;
    return options[index];
  }

  setValue(index) {
    this.index = index;
    this.value = this.getValue(index);
  }

  content() {
    this.index = this.getIndex(this.value);
    return this.value ?? this.options[this.index];
  }
}

const SCHEMA = 'dependencies';
const DEPS = Symbol('dependencies');
const LOAD = Symbol('load');
const TRUE = Promise.resolve(true);

const cache = new Map();

function resolver(name, version) {
  return path => `https://cdn.jsdelivr.net/npm/${name}@${version}/${path}`;
}

function style(href, doc = globalThis.document) {
  return new Promise(function(resolve, reject) {
    const link = doc.createElement('link');
    link.rel = 'stylesheet';
    link.href = href;
    link.onerror = reject;
    link.onload = resolve;
    doc.head.appendChild(link);
  });
}

function getDependencyBase(object) {
  let ctor = typeof HTMLElement !== 'undefined' && object instanceof HTMLElement
    ? object.constructor
    : object;
  while (ctor && !Object.hasOwn(ctor, SCHEMA)) {
    ctor = Object.getPrototypeOf(ctor);
    if (ctor && ctor.name === 'HTMLElement') return null;
  }
  return ctor;
}

function hasDependencies(object) {
  const base = getDependencyBase(object);
  return !base || (base[DEPS]?.[LOAD] === TRUE);
}

function getDependency(object, name) {
  return getDependencyBase(object)?.[DEPS]?.[name];
}

function setDependencies(object, loaded) {
  const base = getDependencyBase(object);
  if (base) {
    const deps = base[DEPS] || (base[DEPS] = {});
    for (const name in loaded) {
      deps[name] = loaded[name];
    }
    deps[LOAD] = TRUE;
  }
}

function loadDependencies(object) {
  const base = getDependencyBase(object);
  if (!base) return TRUE;

  // get dependency map, exit if load already began
  const deps = base[DEPS] || (base[DEPS] = {});
  if (deps[LOAD]) return deps[LOAD];

  // load dependent modules and css
  const load = { main: [], css: [] };
  const schema = base[SCHEMA];
  schema.forEach(({ name, version, main, css }) => {
    const resolve = resolver(name, version);
    const mainURI = resolve(main);
    const cssURI = resolve(css);

    const promise = cache.get(mainURI) || require(mainURI);
    cache.set(mainURI, promise);
    load.main.push(promise);

    if (css && !cache.has(cssURI)) {
      cache.set(cssURI, true);
      load.css.push(style(cssURI, object.ownerDocument));
    }
  });

  // once loaded, inject dependencies
  return deps[LOAD] = Promise.all(load.main.concat(load.css))
    .then(exports => {
      const map = schema.reduce((d, s, i) => (d[s.name] = exports[i], d), {});
      setDependencies(base, map);
    });
}

/**
 * Abstract base class for Living Papers custom elements
 * with dependencies loaded from a CDN upon page load.
 * Implementations must define a static `dependencies` getter
 * that returns a list of dependency definitions.
 */
class DependentElement extends ArticleElement {
  getDependency(name) {
    // proxy calls to the getDependency helper
    return getDependency(this, name);
  }

  shouldUpdate() {
    // check if dependencies are loaded and available
    // if not, load and request update once ready
    return hasDependencies(this) ? true
      : (loadDependencies(this).then(() => { this.requestUpdate(); }), false);
  }
}

class TexMath extends DependentElement {
  static get dependencies() {
    return [
      {
        name: 'katex',
        version: '0.15.3',
        module: 'dist/katex.mjs',
        main: 'dist/katex.min.js',
        css: 'dist/katex.min.css'
      }
    ]
  }

  static get properties() {
    return {
      mode: { type: String },
      code: { type: String },
      maug: { type: String },
      leqno: { type: Boolean },
      fleqn: { type: Boolean, converter: v => v !== 'false' },
      minRuleThickness: { type: Number }
    };
  }

  constructor() {
    super();
    this.mode = 'display';
    this.leqno = false;
    this.fleqn = false;
  }

  initialChildNodes(nodes) {
    // attempt to extract code from first child
    if (!this.hasAttribute('code') && nodes.length) {
      this.code = nodes[0].textContent;
    }
  }

  addAugmentations() {
    let code = this.maug || this.code;
    for (let i = 0; i < this.definitions.length; i++) {
      const { replace, symbol } = this.definitions[i];
      code = code.replaceAll(replace, `\\htmlClass{maug maug-${i}}{${symbol}}`);
    }
    return code;
  }

  prepareMath() {
    if (!this.definitions) {
      this.definitions = this.articleData()?.definitions || [];
    }
    return this.addAugmentations();
  }

  render() {
    const katex = this.getDependency('katex');
    if (!katex || !this.code) return;

    // See https://katex.org/docs/options.html
    const displayMode = this.mode === 'display';
    const options = {
      throwOnError: false,
      displayMode,
      leqno: this.leqno,
      fleqn: this.fleqn,
      minRuleThickness: this.minRuleThickness,
      trust: ({ command }) => command === '\\htmlClass',
      strict: (errorCode) => errorCode === "htmlExtension" ? "ignore" : "warn",
    };

    const root = document.createElement(displayMode ? 'div' : 'span');
    const math = this.prepareMath();
    katex.render(math, root, options);

    // first, colorize math augmentations
    const maugs = root.querySelectorAll('.enclosing');
    for (const el of maugs) {
      const id = [...el.classList].find(c => c.startsWith('maug-')).slice('maug-'.length);
      const { color } = this.definitions[+id];
      el.style.color = color;
    }

    // after loading, initialize term definition tooltips
    setTimeout(() => {
      for (const el of maugs) {
        this.renderMaug(katex, el);
      }
    }, 200);

    return root;
  }

  renderMaug(katex, el) {
    // annotate parent nodes to control pointer-events
    let parent = el.parentNode;
    while (parent && parent !== this) {
      parent.classList.add('.maug-parent');
      parent = parent.parentNode;
    }

    // retrieve term definition
    const id = [...el.classList].find(c => c.startsWith('maug-')).slice('maug-'.length);
    let { symbol, definition } = this.definitions[+id];
    symbol = symbol.replaceAll('@', '');
    definition = definition.replaceAll('@', '');

    // create term definition (maug) tooltip
    const maug = document.createElement('span');
    maug.className = 'maug-tooltip';
    katex.render(`${symbol}:\\text{${definition}}`, maug, {
      throwOnError: false,
      displayMode: false,
      leqno: this.leqno,
      fleqn: this.fleqn,
      minRuleThickness: this.minRuleThickness
    });
    el.appendChild(maug);
    el.setAttribute('tabindex', 0);

    // add listeners to trigger maug visibility
    el.addEventListener('focusout', () => {
      maug.style.display = 'none';
    });
    el.addEventListener('keydown', (e) => {
      if (e.key == 'Enter') {
        maug.style.display = 'inline-block';
        e.stopImmediatePropagation();
      } else if (e.key == 'Escape') {
        maug.style.display = 'none';
      }
    });
    el.addEventListener('click', (e) => {
      maug.style.display = 'inline-block';
      e.stopImmediatePropagation();
    });

    // position maug
    const ebox = el.getBoundingClientRect();
    const mbox = maug.getBoundingClientRect();
    const dx = -ebox.width / 2 - mbox.width / 2 - 12;
    maug.style.transform = `translate(${dx}px, -40px)`;

    // add guide line from term to maug
    maug.appendChild(renderGuideLine(ebox, maug.getBoundingClientRect()));

    // hide maug by default
    maug.style.display = 'none';
  }
}


function renderGuideLine(elrect, winRect) {
  const svg = document.createElementNS("http://www.w3.org/2000/svg", 'svg');
  const line = document.createElementNS('http://www.w3.org/2000/svg', 'line');
  const circle = document.createElementNS('http://www.w3.org/2000/svg', 'circle');

  // starting point is right-top of maug
  // set up an SVG that spans the horizontal end points of both elements
  const x0 = Math.min(elrect.left, winRect.left);
  const x1 = Math.max(elrect.right, winRect.right);
  const y0 = winRect.bottom;
  const y1 = elrect.top;
  const dx = x0 - winRect.right + 5; // adjust for 5px of padding
  const dy = winRect.height - 1; // adjust for 1px of padding
  svg.setAttribute('style', `
    min-width: ${x1 - x0}px;
    max-width: ${x1 - x0}px;
    height: ${y1 - y0 + 3}px;
    transform: translate(${dx}px, ${dy}px);
  `); // add 3px of height to accommodate marker

  // position guide lines and marker
  const cx = elrect.left + elrect.width / 2 - x0;
  const cy = y1 - y0 - 2;
  circle.setAttribute('cx', cx);
  circle.setAttribute('cy', cy);
  circle.setAttribute('r', 2);
  line.setAttribute('stroke', 'black');
  line.setAttribute('stroke-width', '1px');
  line.setAttribute('x1', cx);
  line.setAttribute('y1', cy);
  line.setAttribute('x2', winRect.x + winRect.width / 2 - x0);
  line.setAttribute('y2', 0);

  svg.appendChild(line);
  svg.appendChild(circle);
  return svg;
}

class ToggleText extends ArticleElement {
  static get properties() {
    return {
      value: {type: Boolean},
      title: {type: String},
      clickable: {type: Boolean, converter: v => v && v !== 'false'}
    };
  }

  constructor() {
    super();
    this.value = true;
    this.clickable = true;
    this.title = 'Clickable text';
    this.addEventListener('mousedown', e => this.onClick(e));
  }

  initialChildNodes(nodes) {
    this.options = nodes.filter(node => node.nodeType === 1);
  }

  onClick(event) {
    if (!this.clickable) return;
    event.stopImmediatePropagation();
    event.preventDefault();
    this.value = !this.value;
    this.dispatchEvent(new Event('input'));
    this.requestUpdate();
  }

  render() {
    const title = this.clickable ? this.title : null;
    const cls = this.clickable ? 'toggle-text' : null;
    const opt = this.options[this.value ? 0 : 1]; // first element is true
    return x`<span class=${cls} title=${title}>${opt}</span>`;
  }
}

const links = [
  [1,0],[2,0],[3,0],[3,2],[4,0],[5,0],[6,0],[7,0],[8,0],[9,0],[11,10],
  [11,3],[11,2],[11,0],[12,11],[13,11],[14,11],[15,11],[17,16],[18,16],
  [18,17],[19,16],[19,17],[19,18],[20,16],[20,17],[20,18],[20,19],[21,16],
  [21,17],[21,18],[21,19],[21,20],[22,16],[22,17],[22,18],[22,19],[22,20],
  [22,21],[23,16],[23,17],[23,18],[23,19],[23,20],[23,21],[23,22],[23,12],
  [23,11],[24,23],[24,11],[25,24],[25,23],[25,11],[26,24],[26,11],[26,16],
  [26,25],[27,11],[27,23],[27,25],[27,24],[27,26],[28,11],[28,27],[29,23],
  [29,27],[29,11],[30,23],[31,30],[31,11],[31,23],[31,27],[32,11],[33,11],
  [33,27],[34,11],[34,29],[35,11],[35,34],[35,29],[36,34],[36,35],[36,11],
  [36,29],[37,34],[37,35],[37,36],[37,11],[37,29],[38,34],[38,35],[38,36],
  [38,37],[38,11],[38,29],[39,25],[40,25],[41,24],[41,25],[42,41],[42,25],
  [42,24],[43,11],[43,26],[43,27],[44,28],[44,11],[45,28],[47,46],[48,47],
  [48,25],[48,27],[48,11],[49,26],[49,11],[50,49],[50,24],[51,49],[51,26],
  [51,11],[52,51],[52,39],[53,51],[54,51],[54,49],[54,26],[55,51],[55,49],
  [55,39],[55,54],[55,26],[55,11],[55,16],[55,25],[55,41],[55,48],[56,49],
  [56,55],[57,55],[57,41],[57,48],[58,55],[58,48],[58,27],[58,57],[58,11],
  [59,58],[59,55],[59,48],[59,57],[60,48],[60,58],[60,59],[61,48],[61,58],
  [61,60],[61,59],[61,57],[61,55],[62,55],[62,58],[62,59],[62,48],[62,57],
  [62,41],[62,61],[62,60],[63,59],[63,48],[63,62],[63,57],[63,58],[63,61],
  [63,60],[63,55],[64,55],[64,62],[64,48],[64,63],[64,58],[64,61],[64,60],
  [64,59],[64,57],[64,11],[65,63],[65,64],[65,48],[65,62],[65,58],[65,61],
  [65,60],[65,59],[65,57],[65,55],[66,64],[66,58],[66,59],[66,62],[66,65],
  [66,48],[66,63],[66,61],[66,60],[67,57],[68,25],[68,11],[68,24],[68,27],
  [68,48],[68,41],[69,25],[69,68],[69,11],[69,24],[69,27],[69,48],[69,41],
  [70,25],[70,69],[70,68],[70,11],[70,24],[70,27],[70,41],[70,58],[71,27],
  [71,69],[71,68],[71,70],[71,11],[71,48],[71,41],[71,25],[72,26],[72,27],
  [72,11],[73,48],[74,48],[74,73],[75,69],[75,68],[75,25],[75,48],[75,41],
  [75,70],[75,71],[76,64],[76,65],[76,66],[76,63],[76,62],[76,48],[76,58]
];

function network() {
  return {
    nodes: Array.from({ length: 77 }).map(index => ({ index })),
    links: links.map(d => ({source: d[0], target: d[1]}))
  };
}

// helper function to map from d3.pointer array to x/y object
function toPoint(xy) {
  return { x: xy[0], y: xy[1] };
}

function quadtree(d3, dom, opt) {
  const quadColor = '#d5aaaa';
  const pointColor = 'firebrick';

  const graph = network();
  const { nodes, links } = graph;

  // init svg dom
  const w = 514;
  const h = 514;
  const el = d3.select(dom)
    .attr('class', 'quadtree');
  const svg = el.append('svg')
    .attr('width', opt.width)
    .attr('height', opt.height)
    .attr('viewBox', '0 0 514 514');

  const tt = svg.append('title');
  tt.text('Click or drag the probe to explore estimated n-body forces');

  const gg = svg.append('g');
  const eg = gg.append('g');
  const qg = gg.append('g');
  const fg = gg.append('g');
  const lg = gg.append('g');
  const ng = gg.append('g');
  const cg = gg.append('g');

  // constants
  const baseRadius = opt.radius || 4;
  const defaultExtent = [[1, 1], [513, 513]];
  const defaultProbe = {x: w / 2 + 64, y: h / 2 + 64};

  // force simulation
  const nbodyForce = d3.forceManyBody();
  const linkForce = d3.forceLink();
  const xyForce = d3.forceCenter().x(w / 2).y(h / 2);
  const simulation = d3.forceSimulation()
    .force('link', linkForce)
    .force('charge', nbodyForce)
    .force('center', xyForce);

  // state variables
  let theta2 = Math.sqrt(opt.theta) || 0;
  let quad = null;
  let size = 0;
  let layout = true;
  let active = false;
  let probePoint = defaultProbe;
  let probeDown = false;
  let es, ns, obj;

  // -- INITIALIZATION --

  // initialize diagram
  function init() {
    es = eg.selectAll('line')
      .data(links)
      .enter().append('line')
        .style('stroke', '#ccc')
        .style('stroke-width', 1)
        .style('stroke-opacity', 1)
        .style('pointer-events', 'none');

    ns = ng.selectAll('circle')
      .data(nodes)
      .enter().append('circle')
        .attr('cx', d => d.x)
        .attr('cy', d => d.y)
        .attr('r', baseRadius)
        .style('fill', '#666')
        .style('fill-opacity', 1)
        .style('cursor', 'pointer');

    simulation
      .nodes(nodes)
      .on('tick', onTick);

    simulation.force('link')
      .links(links);

    reinit();
    size = 0;
    qg.selectAll('rect').style('opacity', 0);
    ns.style('fill-opacity', 1);

    // add probe interaction to visualization
    svg.on('mousemove', onProbeMove)
       .on('mousedown', onProbeDown);

    // add drag interaction to layout
    ns.call(d3.drag()
      .on('start', onDragStart)
      .on('drag', onDrag)
      .on('end', onDragEnd));

    simulation.tick(200);
    onTick();
    return obj;
  }

  // reinitialize upon state change
  function reinit() {
    if (size != nodes.length) {
      initQuadTree(nodes);
    }
    quad.visitAfter(accumulate);
    quads().clear();
    ns.style('fill-opacity', 0.25);
  }

  // quadtree initialization
  function initQuadTree(nodes) {
    quad = d3.quadtree()
      .extent(defaultExtent)
      .x(d => d.x)
      .y(d => d.y);
    if (nodes) quad.addAll(nodes);
    size = nodes ? nodes.length : 0;
  }


  // -- EVENT LISTENERS --

  function onTick() {
    if (size > 0) {
      initQuadTree(nodes);
      quads();
    }
    es.attr('x1', d => d.source.x)
      .attr('y1', d => d.source.y)
      .attr('x2', d => d.target.x)
      .attr('y2', d => d.target.y);
    ns.attr('cx', d => d.x)
      .attr('cy', d => d.y);
  }

  function onDragStart(event, d) {
    if (!layout) return;
    if (!event.active) simulation.alphaTarget(0.3).restart();
    d.fx = d.x;
    d.fy = d.y;
  }

  function onDrag(event, d) {
    if (!layout) return;
    d.fx = event.x;
    d.fy = event.y;
  }

  function onDragEnd(event, d) {
    if (!layout) return;
    if (!event.active) simulation.alphaTarget(0);
    d.fx = null;
    d.fy = null;
  }

  function onProbeMove(event) {
    if (active && probeDown) {
      probe(toPoint(d3.pointer(event)));
    }
  }

  function onProbeUp() {
    probeDown = false;
    window.removeEventListener('mouseup', onProbeUp);
  }

  function onProbeDown(event) {
    if (!active) return;

    probeDown = true;
    window.addEventListener('mouseup', onProbeUp);

    let t = event.target;
    probe((t && t.localName == 'circle')
      ? t.__data__
      : toPoint(d3.pointer(event)));
  }


  // -- QUADTREE METHODS --

  // computer centers of mass
  function accumulate(quad, x1, y1, x2, y2) {
    let strength = 0, q, c, x, y, i;

    // For internal nodes, accumulate forces from child quadrants.
    if (quad.length) {
      let pid = [x1,y1,x2,y2].join(',');
      for (x = y = i = 0; i < 4; ++i) {
        if ((q = quad[i]) && (c = q.value)) {
          strength += c, x += c * q.x, y += c * q.y;
          q.parent = quad;
          q.pid = pid;
        }
      }
      quad.x = x / strength;
      quad.y = y / strength;
      quad.x1 = x1;
      quad.y1 = y1;
      quad.w = x2 - x1;
      quad.h = y2 - y1;
    }

    // For leaf nodes, accumulate forces from coincident quadrants.
    else {
      q = quad;
      q.x = q.data.x;
      q.y = q.data.y;
      do strength += 1;
      while (q = q.next);
    }

    quad.value = strength;
  }

  // return the quadtree path for a point as an array of extents
  function getPath(p) {
    let path = [];

    quad.visit(function(node, x1, y1, x2, y2) {
      // if point is not contained in node, abandon branch
      if (p.x < x1 || p.x >= x2 || p.y < y1 || p.y >= y2) {
        return true;
      }
      path.push({x1: x1, y1: y1, w: x2 - x1, h: y2 - y1});
    });

    return path;
  }


  // -- DIAGRAM UPDATE METHODS --

  // clear annotations
  function clear() {
    fg.html('');
    lg.html('');
    cg.html('');
    ns.style('fill-opacity', 1);
    return obj;
  }

  // collect and draw quadtree rectangles
  function quads() {
    let boxes = [];

    function processNode(node, extent, depth) {
      if (Array.isArray(node)) {
        processSplit(node, extent, depth);
      }
    }

    function processSplit(node, extent, depth) {
      let lo = extent[0];
      let hi = extent[1];
      let mp = [(lo[0] + hi[0]) >> 1, (lo[1] + hi[1]) >> 1];

      let e = [
        [lo, mp],
        [[mp[0], lo[1]], [hi[0], mp[1]]],
        [[lo[0], mp[1]], [mp[0], hi[1]]],
        [mp, hi]
      ];
      for (let i = 0; i < 4; ++i) {
        boxes.push(e[i]);
        e[i].depth = depth;
        if (node[i]) processNode(node[i], e[i], depth + 1);
      }
    }

    if (quad.root()) {
      // add quadtree root extents
      boxes.push(quad.extent().slice());
      // recurse to process quadtree content
      processNode(quad.root(), quad.extent(), 1);
    }

    qg.html('')
      .selectAll('rect').data(boxes)
     .enter().append('rect')
      .attr('x', q => q[0][0] + 0.5)
      .attr('y', q => q[0][1] + 0.5)
      .attr('width', q => q[1][0] - q[0][0])
      .attr('height', q => q[1][1] - q[0][1])
      .style('fill', 'none')
      .style('stroke', '#ddd')
      .style('line-width', 0.5);

    return obj;
  }

  // set the number of inserted points in the quadtree
  function treeSize(index) {
    let duration = 500;

    initQuadTree();

    if (index < 1) {
      size = 0;
      quads();
      fg.html('');
      cg.html('');
      ns.style('fill-opacity', 0.25);
      return;
    }
    size = index;

    let p = nodes[--index];

    // initialize quadtree
    quad.addAll(nodes.slice(0, index));

    // get initial tree path for point
    let path0 = getPath(p);

    // add point to quadtree
    quad.add(p).visitAfter(accumulate);

    // get updated tree path for point
    let path1 = getPath(p).slice(path0.length);

    if (path1.length) {
      fg.html('')
        .selectAll('rect.foo')
        .data(path1)
       .enter().append('rect')
        .attr('x', d => d.x1)
        .attr('y', d => d.y1)
        .attr('width', d => d.w)
        .attr('height', d => d.h)
        .style('pointer-events', 'none')
        .style('fill', 'none')
        .style('stroke', quadColor)
        .style('stroke-width', 2)
        .style('stroke-opacity', 1)
       .transition()
        .delay(0.5 * duration)
        .duration(duration)
        .style('stroke-opacity', 0)
        .remove();
    }

    quads();
    ns.style('fill-opacity', d => d.index <= index ? 1 : 0.25);

    cg.html('')
      .append('circle')
      .datum(p)
      .attr('cx', d => d.x)
      .attr('cy', d => d.y)
      .attr('r', 0)
      .style('pointer-events', 'none')
      .style('fill', pointColor)
      .style('fill-opacity', 1)
     .transition()
      .duration(duration)
      .ease(d3.easeBackOut.overshoot(2))
      .attr('r', d => baseRadius)
     .transition()
      .delay(duration)
      .duration(duration)
      .style('fill-opacity', 0)
      .remove();
  }

  // play animation of center of mass accumuluation
  function animateAccumulation(flag) {
    if (!flag) return;

    let duration = 400;
    let quads = [];
    let queue = [];
    let map = {};

    reinit();

    // collect non-leaf nodes
    quad.visitAfter(function(quad) {
      if (quad.length) quads.push(quad);
    });
    // group nodes by depth (using width as proxy)
    quads.forEach(function(q) {
      const id = q.w;
      let l = map[id];
      if (!l) queue.push(map[id] = l = []);
      l.push(q);
    });
    // sort groups by ascending width (descending depth)
    queue.sort((a, b) => a[0].w - b[0].w);

    // advance the animation one step
    function advance(index) {
      if (index < 1) {
        cg.html('');
        return;
      }
      index -= 1;

      let qlist = queue[index];

      qlist.forEach(function(q) {
        const points = q.filter(_ => _);

        fg.append('rect')
          .datum(q)
          .attr('x', (d) => d.x1)
          .attr('y', (d) => d.y1)
          .attr('width', (d) => d.w)
          .attr('height', (d) => d.h)
          .style('pointer-events', 'none')
          .style('fill', 'none')
          .style('stroke', quadColor)
          .style('stroke-width', 2)
          .style('stroke-opacity', 1)
        .transition()
          .duration(2 * duration)
          .delay(3 * duration)
          .style('stroke-opacity', 0)
          .remove();

        cg.selectAll('circle.foo')
          .data(points)
        .enter().append('circle')
          .attr('cx', (d) => d.x)
          .attr('cy', (d) => d.y)
          .attr('r', (d) => baseRadius * (Math.sqrt(d.value) || 1))
          .style('pointer-events', 'none')
          .style('fill', pointColor)
        .transition()
          .delay(duration)
          .duration(duration)
          .ease(d3.easeCubicIn)
          .attr('cx', q.x)
          .attr('cy', q.y)
          .remove();

        cg.append('circle')
          .datum(q)
          .attr('cx', (d) => d.x)
          .attr('cy', (d) => d.y)
          .attr('r', 0)
          .style('pointer-events', 'none')
          .style('fill', pointColor)
        .transition()
          .delay(duration * 1.8)
          .duration(duration)
          .ease(d3.easeBackOut)
          .attr('r', (d) => baseRadius * (Math.sqrt(d.value) || 1))
        .transition()
          .delay(duration)
          .duration(duration)
          .style('fill', '#666')
          .style('fill-opacity', 0.25);
      });
    }

    const stepDuration = 3.8 * duration;

    setTimeout(() => {
      // schedule each animation step
      queue.forEach(function(q, i) {
        setTimeout(() => advance(i+1), i * stepDuration);
      });
      // upon animation end, reset view
      setTimeout(() => {
        cg.selectAll('circle')
          .transition()
          .duration(500)
          .style('fill-opacity', 0)
          .remove();
      }, (1 + queue.length) * stepDuration);
    }, 1000);
  }

  // toggle interactive force-directed layout
  function performLayout(state) {
    if (layout === state) return;
    layout = state;
    if (layout) {
      simulation.alpha(0.5).alphaTarget(0).restart();
    } else {
      simulation.stop();
    }
    ns.transition(500).style('fill-opacity', layout ? 1 : 0.25);
    es.transition(500).style('stroke-opacity', +layout);
  }

  // toggle interactive force estimation probe
  function performEstimation(state) {
    if (active === state) return;
    active = state;
    if (active) {
      reinit();
      probe(probePoint);
    } else {
      probePoint = defaultProbe;
      quads().clear();
    }
  }

  // perform force estimation relative to probe point
  function estimate() {
    clear();

    let p = probePoint;
    if (!p) return;

    let charges = [];
    let boxes = [];
    let fx = 0;
    let fy = 0;

    quad.visit((quad, x1, y1, x2, y2) => {
      if (!quad.value) return true;

      let x = quad.x - p.x;
      let y = quad.y - p.y;
      let w = x2 - x1;
      let l = x * x + y * y;

      // Apply the Barnes-Hut approximation.
      if (quad.length && w * w / theta2 < l) {
        const c = {
          x: quad.x,
          y: quad.y,
          v: quad.value,
          s: 5e3 * quad.value / l
        };
        charges.push(c);
        boxes.push({x: x1, y: y1, w: w, h: y2 - y1});

        fx += x * quad.value / l;
        fy += y * quad.value / l;

        return true;
      }

      // Otherwise, process points directly.
      else if (quad.length || !l) return;

      do if (quad.data !== p) {
        charges.push({
          x: quad.data.x,
          y: quad.data.y,
          v: 1,
          s: 5e3 / l
        });
        fx += x / l;
        fy += y / l;
      } while (quad = quad.next);
    });

    fg.selectAll('rect').data(boxes)
      .enter().append('rect')
      .attr('x', d => d.x)
      .attr('y', d => d.y)
      .attr('width', d => d.w)
      .attr('height', d => d.h)
      .style('pointer-events', 'none')
      .style('fill', 'none')
      .style('stroke', quadColor)
      .style('stroke-width', 2);

    lg.selectAll('path').data(charges)
      .enter().append('path')
      .style('pointer-events', 'none')
      .style('stroke', '#991151')
      .style('stroke-opacity', 0.3)
      .style('stroke-dasharray', [5, 5])
      .style('stroke-linecap', 'round')
      .style('stroke-width', d => Math.max(1, Math.min(5, d.s || 1)))
      .attr('d', d => 'M' + d.x + ',' + d.y + 'L' + p.x + ',' + p.y);

    cg.selectAll('circle').data(charges)
      .enter().append('circle')
      .attr('cx', d => d.x)
      .attr('cy', d => d.y)
      .attr('r', d => baseRadius * (Math.sqrt(d.v) || 1))
      .style('pointer-events', 'none')
      .style('fill', pointColor);

    ns.style('fill-opacity', 0.25);

    cg.append('circle')
      .attr('cx', p.x)
      .attr('cy', p.y)
      .attr('r', baseRadius)
      .style('pointer-events', 'none')
      .style('fill', 'white')
      .style('stroke-width', 1.5)
      .style('stroke-linecap', 'round')
      .style('stroke', '#800080');

    fx = p.x - fx * 90,
    fy = p.y - fy * 90;

    cg.append('path')
      .attr('d', 'M' + p.x + ',' + p.y + 'L' + fx + ',' + fy)
      .style('pointer-events', 'none')
      .style('fill', 'none')
      .style('stroke-width', 1.5)
      .style('stroke-linecap', 'round')
      .style('stroke', 'purple');

    return obj;
  }

  // set the probe point
  function probe(point) {
    probePoint = point;
    return estimate();
  }

  // set the Barnes-Hut theta parameter
  function theta(_) {
    theta2 = _ * _;
    return estimate();
  }

  // set the default node charge / mass
  function charge(_) {
    const c = +_;
    if (c === c) {
      nbodyForce.strength(c);
    }
    if (layout) {
      simulation.alpha(0.5).alphaTarget(0).restart();
    }
  }

  // define returned API object
  obj = {
    svg,
    quad,
    init,
    size: treeSize,
    clear,
    theta,
    charge,
    layout: performLayout,
    estimate: performEstimation,
    accumulate: animateAccumulation,
  };

  return init();
}

class BarnesHut extends DependentElement {
  static get dependencies() {
    return [
      {
        name: 'd3',
        version: '7',
        main: 'dist/d3.min.js'
      }
    ]
  }

  static get properties() {
    return {
      width: {type: Number},
      height: {type: Number},
      size: {type: Number},
      theta: {type: Number},
      charge: {type: Number},
      radius: {type: Number},
      accumulate: {type: Number},
      layout: {type: Boolean, converter: v => v !== 'false'},
      estimate: {type: Boolean, converter: v => v !== 'false'}
    };
  }

  constructor() {
    super();
    this.width = 514;
    this.height = 514;
    this.size = 0;
    this.theta = 0;
    this.charge = -30;
    this.radius = 4;
    this.accumulate = false;
    this.layout = true;
    this.estimate = false;
  }

  willUpdate(changedProperties) {
    if (this._sim) {
      changedProperties.forEach((_, key) => {
        this._sim[key](this[key]);
      });
    }
  }

  render() {
    const d3 = this.getDependency('d3');
    if (!d3) return;

    if (!this._root) {
      // initialize component
      this._root = document.createElement('div');
      this._root.setAttribute('class', 'quad');
      this._sim = quadtree(d3, this._root, {
        width:  this.width,
        height: this.height,
        theta:  this.theta,
        radius: this.radius,
      });
      this._sim.layout(this.layout);
      this._sim.estimate(this.estimate);
    }

    return this._root;
  }
}

function cells() {
async function _1(require){
  const req = await require("//cdn.jsdelivr.net/pyodide/v0.20.0/full/pyodide.js");
  const pyodide = await req.loadPyodide({
    indexURL: "https://cdn.jsdelivr.net/pyodide/v0.20.0/full/"
  });
  const py = async (strings, ...expressions) => {
    let globals = {};
    const code = strings.reduce((result, string, index) => {
      if (expressions[index]) {
        const name = `__pyx__${index}`;
        globals[name] = expressions[index];
        return result + string + name;
      }
      return result + string;
    }, '');
    await pyodide.loadPackagesFromImports(code);
    const result = await pyodide.runPythonAsync(code, { globals: pyodide.toPy(globals) });
    return result?.toJs ? result.toJs() : result;
  };
  
  return py;
}

function _2(Scrubber){return(
Scrubber([0, 10], {
  step: 0.05,
  value: 5,
  alternate: true,
  label: 'Rotation',
  format: x => x.toFixed(2)
})
)}

function _3(Scrubber){return(
Scrubber([1, 100], {
  value: 4,
  alternate: true,
  label: 'Separation'
})
)}

function _4(){return(
25
)}

function _5(size,sep){return(
Math.ceil((600 + 4*size) / sep)
)}

function _6(){return(
30
)}

function _7(d3){return(
d3.scaleSequential(d3.interpolateRainbow).domain([360, 0])
)}

function _8(svg,size,pad,d3,n,rot,sep,color){return(
svg`<svg width="${600}" height="${2*size+pad}" viewBox="0 0 600 ${2*size+pad}">
  ${d3.range(0, n).map(i => {
    const a = (i * rot) % 360;
    return svg`<rect
      transform="translate(${i*sep-2*size-1}, ${pad/2}) rotate(${-a}, ${size}, ${size})"
      width="${2*size}" height="${2*size}"
      fill="none" stroke="${color(a)}"></rect>`;
  })}
  </svg>`
)}

function _9(){return(
false
)}

function _10(){return(
true
)}

function _11(){return(
95
)}

function _12(confidenceLevel,bootstrap,logTransform){return(
`${Math.round(confidenceLevel * 10) / 1000}${bootstrap ? "-bootstrapped" : ""}${logTransform ? "-log-transformed" : ""}-bonferroni-adjusted.jpg`
)}

function _13(fileSuffix){return(
`assets/multiverse/fig1-${fileSuffix}`
)}

function _14(){return(
1
)}

function _15(Inputs){return(
Inputs.range([0, 2], { step: 0.1, label: 'Barnes-Hut Θ'})
)}

function _16(){return(
'\\phi = \\frac{1+\\sqrt{5}}{2}'
)}

function _17(Inputs){return(
Inputs.text()
)}

function _18(){return(
128
)}

function _19(Inputs,md){return(
Inputs.range([0, 255], {step: 1, label: md`The variable _v_:`})
)}

function _20(__py__){return(
__py__`import numpy as np
np`
)}

function _21(__py__){return(
__py__`from matplotlib import pyplot as plt
import types
import io
import base64
from js import document

def png(self):
  buf = io.BytesIO()
  self.savefig(buf, format='png')
  buf.seek(0)
  img_str = 'data:image/png;base64,' + base64.b64encode(buf.read()).decode('UTF-8')
  el = document.createElement('img')
  el.src = img_str
  return el

def svg(self):
  buf = io.BytesIO()
  self.savefig(buf, format='svg')
  buf.seek(0)
  div = document.createElement('div')
  div.innerHTML = buf.getvalue().decode('UTF-8')
  return div.querySelector('svg')

plt._show = types.MethodType(plt.show, plt)
plt.show = types.MethodType(png, plt)
plt.png = types.MethodType(png, plt)
plt.svg = types.MethodType(svg, plt)
plt`
)}

function _22(np,sx){return(
np.linspace(0, sx * np.pi, 300)
)}

function _23(plt,x,np){
  const fig = plt.figure();
  fig.set_figwidth(5);
  fig.set_figheight(1.9);
  plt.plot(x, np.sin(x));
  const svg = plt.svg();
  return (plt.close(), svg);
}

function _24(Inputs){return(
Inputs.range([2, 20], { step: 0.1, value: 10 })
)}

return [
  {define:["__py__", ["require"], _1], cell:0},
  {module:[1, define1]},
  {import:[1, "Scrubber"]},
  {define:["viewof rot", ["Scrubber"], _2], cell:2},
  {define:["rot", ["Generators","viewof rot"], (G, _) => G.input(_)]},
  {define:["viewof sep", ["Scrubber"], _3], cell:3},
  {define:["sep", ["Generators","viewof sep"], (G, _) => G.input(_)]},
  {define:["size", [], _4], cell:4},
  {define:["n", ["size","sep"], _5], cell:5},
  {define:["pad", [], _6], cell:6},
  {define:["color", ["d3"], _7], cell:7},
  {define:[null, ["svg","size","pad","d3","n","rot","sep","color"], _8], cell:8},
  {define:["logTransform", [], _9], cell:9},
  {define:["bootstrap", [], _10], cell:10},
  {define:["confidenceLevel", [], _11], cell:11},
  {define:["fileSuffix", ["confidenceLevel","bootstrap","logTransform"], _12], cell:12},
  {define:["multiverseImage", ["fileSuffix"], _13], cell:13},
  {define:["theta", [], _14], cell:14},
  {define:[null, ["Inputs"], _15], cell:15},
  {define:["texcode", [], _16], cell:16},
  {define:[null, ["Inputs"], _17], cell:17},
  {define:["v", [], _18], cell:18},
  {define:[null, ["Inputs","md"], _19], cell:19},
  {define:["np", ["__py__"], _20], cell:20},
  {define:["plt", ["__py__"], _21], cell:21},
  {define:["x", ["np","sx"], _22], cell:22},
  {define:[null, ["plt","x","np"], _23], cell:23},
  {define:["viewof sx", ["Inputs"], _24], cell:24},
  {define:["sx", ["Generators","viewof sx"], (G, _) => G.input(_)]}
];
}

function attrs() {
function _1(multiverseImage){return(
multiverseImage
)}

function _2(theta){return(
theta
)}

function _3(texcode){return(
texcode
)}

function _4(v){return(
`x^2 = ${v}^2 = ${v*v}`
)}

return [
  {define:[null, ["multiverseImage"], _1], cell:0},
  {define:[null, ["theta"], _2], cell:1},
  {define:[null, ["texcode"], _3], cell:2},
  {define:[null, ["v"], _4], cell:3}
];
}

var module = /*#__PURE__*/Object.freeze({
  __proto__: null,
  attrs: attrs,
  cells: cells
});

document.querySelector('article').__data = {"citations":{"bibtex":["@misc{semreader,\n\tauthor = {{Allen Institute for Artificial Intelligence, Semantic Scholar Team}},\n\tyear = {2023},\n\ttitle = {Semantic {Reader}},\n\thowpublished = {\\href{https://www.semanticscholar.org/product/semantic-reader}{https://www.semanticscholar.org/product/semantic-reader}},\n}","@inproceedings{doi:10.18653/v1/N18-3011,\n\tauthor = {Ammar, Waleed and Groeneveld, Dirk and Bhagavatula, Chandra and Beltagy, Iz and Crawford, Miles and Downey, Doug and Dunkelberger, Jason and Elgohary, Ahmed and Feldman, Sergey and Ha, Vu and Kinney, Rodney and Kohlmeier, Sebastian and Lo, Kyle and Murray, Tyler and Ooi, Hsu-Han and Peters, Matthew and Power, Joanna and Skjonsberg, Sam and Wang, Lucy and Willhelm, Chris and Yuan, Zheng and Zuylen, Madeleine and {oren}},\n\tbooktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of\n          the {Association} for {Computational} {Linguistics}: Human {Language}\n          {Technologies}, {Volume} 3 ({Industry} {Papers})},\n\tyear = {2018},\n\torganization = {Association for Computational Linguistics},\n\ttitle = {Construction of the {Literature} {Graph} in {Semantic} {Scholar}},\n\tdoi = {10.18653/v1/n18-3011}\n}","@article{doi:10.48550/arXiv.2203.00130,\n\tauthor = {August, Tal and Wang, Lucy Lu and Bragg, Jonathan and Hearst, Marti A. and Head, Andrew and Lo, Kyle},\n\tyear = {2022},\n\tpublisher = {arXiv},\n\ttitle = {Paper {Plain}: Making {Medical} {Research} {Papers} {Approachable} to {Healthcare} {Consumers} with {Natural} {Language} {Processing}},\n\tdoi = {10.48550/ARXIV.2203.00130}\n}","@article{doi:10.1109/TVCG.2018.2865119,\n\tauthor = {Badam, Sriram Karthik and Liu, Zhicheng and Elmqvist, Niklas},\n\tjournal = {IEEE Transactions on Visualization and Computer Graphics},\n\tnumber = {1},\n\tyear = {2019},\n\tpages = {661--671},\n\tpublisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},\n\ttitle = {Elastic {Documents}: Coupling {Text} and {Tables} through {Contextual} {Visualizations} for {Enhanced} {Document} {Reading}},\n\tvolume = {25},\n\tdoi = {10.1109/tvcg.2018.2865119}\n}","@article{doi:10.1145/179606.179671,\n\tauthor = {Berners-Lee, Tim and Cailliau, Robert and Luotonen, Ari and Nielsen, Henrik Frystyk and Secret, Arthur},\n\tjournal = {Communications of the ACM},\n\tnumber = {8},\n\tyear = {1994},\n\tpages = {76--82},\n\tpublisher = {Association for Computing Machinery (ACM)},\n\ttitle = {The {World}-{Wide} {Web}},\n\tvolume = {37},\n\tdoi = {10.1145/179606.179671}\n}","@inproceedings{doi:10.1145/2851581.2892588,\n\tauthor = {Bigham, Jeffrey P. and Brady, Erin L. and Gleason, Cole and Guo, Anhong and Shamma, David A.},\n\tbooktitle = {Proceedings of the 2016 {CHI} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},\n\tyear = {2016},\n\torganization = {ACM},\n\ttitle = {An {Uninteresting} {Tour} {Through} {Why} {Our} {Research} {Papers} {Aren}'t {Accessible}},\n\tdoi = {10.1145/2851581.2892588}\n}","@article{doi:10.1109/TVCG.2011.185,\n\tauthor = {Bostock, M. and Ogievetsky, V. and Heer, J.},\n\tjournal = {IEEE Transactions on Visualization and Computer Graphics},\n\tnumber = {12},\n\tyear = {2011},\n\tpages = {2301--2309},\n\tpublisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},\n\ttitle = {D3 {Data}-{Driven} {Documents}},\n\tvolume = {17},\n\tdoi = {10.1109/tvcg.2011.185}\n}","@misc{csl,\n\tauthor = {{Citation Style Language}},\n\tyear = {2023},\n\thowpublished = {\\href{https://citationstyles.org/}{https://citationstyles.org/}},\n}","@inproceedings{doi:10.1145/3242587.3242600,\n\tauthor = {Conlen, Matthew and Heer, Jeffrey},\n\tbooktitle = {Proceedings of the 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},\n\tyear = {2018},\n\torganization = {ACM},\n\ttitle = {Idyll},\n\tdoi = {10.1145/3242587.3242600}\n}","@inproceedings{doi:10.1145/3472749.3474731,\n\tauthor = {Conlen, Matthew and Vo, Megan and Tan, Alan and Heer, Jeffrey},\n\tbooktitle = {The 34th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},\n\tyear = {2021},\n\torganization = {ACM},\n\ttitle = {Idyll {Studio}: A {Structured} {Editor} for {Authoring} {Interactive} \\& {Data}-{Driven} {Articles}},\n\tdoi = {10.1145/3472749.3474731}\n}","@article{doi:10.48550/arXiv.2205.09858,\n\tauthor = {Conlen, Matthew and Heer, Jeffrey},\n\tyear = {2022},\n\tpublisher = {arXiv},\n\ttitle = {Fidyll: A {Compiler} for {Cross}-{Format} {Data} {Stories} \\& {Explorable} {Explanations}},\n\tdoi = {10.48550/ARXIV.2205.09858}\n}","@misc{nota,\n\tauthor = {Crichton, Will},\n\tyear = {2023},\n\ttitle = {A {New} {Medium} for {Communicating} {Research} on {Programming} {Languages}},\n\thowpublished = {\\href{https://willcrichton.net/nota/}{https://willcrichton.net/nota/}},\n}","@misc{curvenote,\n\tauthor = {{Curvenote}},\n\tyear = {2023},\n\thowpublished = {\\href{https://curvenote.com/}{https://curvenote.com/}},\n}","@inproceedings{doi:10.1145/3290605.3300295,\n\tauthor = {Dragicevic, Pierre and Jansen, Yvonne and Sarma, Abhraneel and Kay, Matthew and Chevalier, Fanny},\n\tbooktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},\n\tyear = {2019},\n\torganization = {ACM},\n\ttitle = {Increasing the {Transparency} of {Research} {Papers} with {Explorable} {Multiverse} {Analyses}},\n\tdoi = {10.1145/3290605.3300295}\n}","@misc{katex,\n\tauthor = {Eisenberg, Emily and Alpert, Sophie},\n\tyear = {2023},\n\ttitle = {KaTeX: The fastest math typesetting library for the web},\n\thowpublished = {\\href{https://katex.org}{https://katex.org}},\n}","@article{doi:10.48550/arXiv.2205.04561,\n\tauthor = {Fok, Raymond and Kambhamettu, Hita and Soldaini, Luca and Bragg, Jonathan and Lo, Kyle and Head, Andrew and Hearst, Marti A. and Weld, Daniel S.},\n\tjournal = {arXiv},\n\tyear = {2022},\n\tpublisher = {arXiv},\n\ttitle = {Scim: Intelligent {Skimming} {Support} for {Scientific} {Papers}},\n\tdoi = {10.48550/ARXIV.2205.04561}\n}","@article{doi:10.1126/science.aao0185,\n\tauthor = {Fortunato, Santo and Bergstrom, Carl T. and B{\\\" o}rner, Katy and Evans, James A. and Helbing, Dirk and Milojevi{\\' c}, Sta{\\v s}a and Petersen, Alexander M. and Radicchi, Filippo and Sinatra, Roberta and Uzzi, Brian and Vespignani, Alessandro and Waltman, Ludo and Wang, Dashun and Barab{\\' a}si, Albert-L{\\' a}szl{\\' o}},\n\tjournal = {Science},\n\tnumber = {6379},\n\tyear = {2018},\n\tpublisher = {American Association for the Advancement of Science (AAAS)},\n\ttitle = {Science of science},\n\tvolume = {359},\n\tdoi = {10.1126/science.aao0185}\n}","@misc{gscholar,\n\tauthor = {{Google Scholar}},\n\tyear = {2023},\n\thowpublished = {\\href{https://scholar.google.com/}{https://scholar.google.com/}},\n}","@misc{puppeteer,\n\tauthor = {{Google, Inc.}},\n\tyear = {2023},\n\ttitle = {Puppeteer},\n\thowpublished = {\\href{https://pptr.dev/}{https://pptr.dev/}},\n}","@misc{markdown,\n\tauthor = {Gruber, John},\n\tyear = {2004},\n\ttitle = {Markdown},\n\thowpublished = {\\href{https://daringfireball.net/projects/markdown/}{https://daringfireball.net/projects/markdown/}},\n}","@article{doi:10.1145/369825.369829,\n\tauthor = {Harrison, Steve and Minneman, Scott and Back, Maribeth and Balsamo, Anne and Chow, Mark and Gold, Rich and Gorbet, Matt and Mac Donald, Dale},\n\tjournal = {Interactions},\n\teditor = {Ehrlich, Kate and Henderson, Austin},\n\tnumber = {3},\n\tyear = {2001},\n\tpages = {21--30},\n\tpublisher = {Association for Computing Machinery (ACM)},\n\ttitle = {Design: the what of {XFR}},\n\tvolume = {8},\n\tdoi = {10.1145/369825.369829}\n}","@inproceedings{doi:10.1145/3411764.3445648,\n\tauthor = {Head, Andrew and Lo, Kyle and Kang, Dongyeop and Fok, Raymond and Skjonsberg, Sam and Weld, Daniel S. and Hearst, Marti A.},\n\tbooktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},\n\tyear = {2021},\n\torganization = {ACM},\n\ttitle = {Augmenting {Scientific} {Papers} with {Just}-in-{Time}, {Position}-{Sensitive} {Definitions} of {Terms} and {Symbols}},\n\tdoi = {10.1145/3411764.3445648}\n}","@inproceedings{doi:10.1145/3491102.3501932,\n\tauthor = {Head, Andrew and Xie, Amber and Hearst, Marti A.},\n\tbooktitle = {CHI {Conference} on {Human} {Factors} in {Computing} {Systems}},\n\tyear = {2022},\n\torganization = {ACM},\n\ttitle = {Math {Augmentation}: How {Authors} {Enhance} the {Readability} of {Formulas} using {Novel} {Visual} {Design} {Practices}},\n\tdoi = {10.1145/3491102.3501932}\n}","@inproceedings{doi:10.1109/VIS49827.2021.9623323,\n\tauthor = {Heer, Jeffrey},\n\tbooktitle = {2021 {IEEE} {Visualization} {Conference} ({VIS})},\n\tyear = {2021},\n\torganization = {IEEE},\n\ttitle = {Fast \\& {Accurate} {Gaussian} {Kernel} {Density} {Estimation}},\n\tdoi = {10.1109/vis49827.2021.9623323}\n}","@inproceedings{doi:10.1145/142750.142751,\n\tauthor = {Hill, William C. and Hollan, James D. and Wroblewski, Dave and McCandless, Tim},\n\tbooktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems  - {CHI} '92},\n\tyear = {1992},\n\torganization = {ACM Press},\n\ttitle = {Edit wear and read wear},\n\tdoi = {10.1145/142750.142751}\n}","@article{doi:10.1371/journal.pcbi.1007128,\n\tauthor = {Himmelstein, Daniel S. and Rubinetti, Vincent and Slochower, David R. and Hu, Dongbo and Malladi, Venkat S. and Greene, Casey S. and Gitter, Anthony},\n\tjournal = {PLOS Computational Biology},\n\teditor = {Schneidman-Duhovny, Dina},\n\tnumber = {6},\n\tyear = {2019},\n\tpages = {e1007128},\n\tpublisher = {Public Library of Science (PLoS)},\n\ttitle = {Open collaborative writing with {Manubot}},\n\tvolume = {15},\n\tdoi = {10.1371/journal.pcbi.1007128}\n}","@article{doi:10.48550/arXiv.2205.02007,\n\tauthor = {Hope, Tom and Downey, Doug and Etzioni, Oren and Weld, Daniel S. and Horvitz, Eric},\n\tyear = {2022},\n\tpublisher = {arXiv},\n\ttitle = {A {Computational} {Inflection} for {Scientific} {Discovery}},\n\tdoi = {10.48550/ARXIV.2205.02007}\n}","@misc{jupyterbook,\n\tauthor = {{Jupyter Book}},\n\tyear = {2023},\n\thowpublished = {\\href{https://jupyterbook.org/}{https://jupyterbook.org/}},\n}","@article{doi:10.48550/arXiv.2010.05129,\n\tauthor = {Kang, Dongyeop and Head, Andrew and Sidhu, Risham and Lo, Kyle and Weld, Daniel S. and Hearst, Marti A.},\n\tyear = {2020},\n\tpublisher = {arXiv},\n\ttitle = {Document-{Level} {Definition} {Detection} in {Scholarly} {Documents}: Existing {Models}, {Error} {Analyses}, and {Future} {Directions}},\n\tdoi = {10.48550/ARXIV.2010.05129}\n}","@inproceedings{doi:10.1145/3242587.3242617,\n\tauthor = {Kim, Dae Hyun and Hoque, Enamul and Kim, Juho and Agrawala, Maneesh},\n\tbooktitle = {Proceedings of the 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},\n\tyear = {2018},\n\torganization = {ACM},\n\ttitle = {Facilitating {Document} {Reading} by {Linking} {Text} and {Tables}},\n\tdoi = {10.1145/3242587.3242617}\n}","@article{doi:10.48550/arXiv.2301.10140,\n\tauthor = {Kinney, Rodney and Anastasiades, Chloe and Authur, Russell and Beltagy, Iz and Bragg, Jonathan and Buraczynski, Alexandra and Cachola, Isabel and Candra, Stefan and Chandrasekhar, Yoganand and Cohan, Arman and Crawford, Miles and Downey, Doug and Dunkelberger, Jason and Etzioni, Oren and Evans, Rob and Feldman, Sergey and Gorney, Joseph and Graham, David and Hu, Fangzhou and Huff, Regan and King, Daniel and Kohlmeier, Sebastian and Kuehl, Bailey and Langan, Michael and Lin, Daniel and Liu, Haokun and Lo, Kyle and Lochner, Jaron and MacMillan, Kelsey and Murray, Tyler and Newell, Chris and Rao, Smita and Rohatgi, Shaurya and Sayre, Paul and Shen, Zejiang and Singh, Amanpreet and Soldaini, Luca and Subramanian, Shivashankar and Tanaka, Amber and Wade, Alex D. and Wagner, Linda and Wang, Lucy Lu and Wilhelm, Chris and Wu, Caroline and Yang, Jiangjiang and Zamarron, Angele and Van Zuylen, Madeleine and Weld, Daniel S.},\n\tyear = {2023},\n\tpublisher = {arXiv},\n\ttitle = {The {Semantic} {Scholar} {Open} {Data} {Platform}},\n\tdoi = {10.48550/ARXIV.2301.10140}\n}","@inproceedings{doi:10.1145/2807442.2807446,\n\tauthor = {Klokmose, Clemens N. and Eagan, James R. and Baader, Siemen and Mackay, Wendy and Beaudouin-Lafon, Michel},\n\tbooktitle = {Proceedings of the 28th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} \\& {Technology}},\n\tyear = {2015},\n\torganization = {ACM},\n\ttitle = {\\textit{{Webstrates}}},\n\tdoi = {10.1145/2807442.2807446}\n}","@book{jupyter,\n\tauthor = {Kluyver, Thomas and Ragan-Kelley, Benjamin and P{\\' e}rez, Fernando and Granger, Brian E and Bussonnier, Matthias and Frederic, Jonathan and Kelley, Kyle and Hamrick, Jessica B and Grout, Jason and Corlay, Sylvain and {others}},\n\tyear = {2016},\n\ttitle = {Jupyter {Notebooks}-a publishing format for reproducible computational workflows.},\n\tvolume = {2016},\n}","@book{tex,\n\tauthor = {Knuth, D. E.},\n\tyear = {1979},\n\tpublisher = {American Mathematical Society},\n\ttitle = {TEX and {METAFONT}: New directions in typesetting},\n}","@article{doi:10.1093/comjnl/27.2.97,\n\tauthor = {Knuth, D. E.},\n\tjournal = {The Computer Journal},\n\tnumber = {2},\n\tyear = {1984},\n\tpages = {97--111},\n\tpublisher = {Oxford University Press (OUP)},\n\ttitle = {Literate {Programming}},\n\tvolume = {27},\n\tdoi = {10.1093/comjnl/27.2.97}\n}","@book{latex,\n\tauthor = {Lamport, Leslie},\n\tyear = {1985},\n\tpublisher = {Addison-Wesley Professional},\n\ttitle = {LaTeX: A {Document} {Preparation} {System}},\n}","@inbook{doi:10.1007/978-3-642-04346-8_62,\n\tauthor = {Lopez, Patrice},\n\tbooktitle = {Research and {Advanced} {Technology} for {Digital} {Libraries}},\n\tyear = {2009},\n\tpages = {473--474},\n\tpublisher = {Springer Berlin Heidelberg},\n\ttitle = {GROBID: Combining {Automatic} {Bibliographic} {Data} {Recognition} and {Term} {Extraction} for {Scholarship} {Publications}},\n\tdoi = {10.1007/978-3-642-04346-8_62}\n}","@inproceedings{LucasKanade81,\n\tauthor = {Lucas, Bruce D. and Kanade, Takeo},\n\tbooktitle = {International {Joint} {Conference} on {Artificial} {Intelligence}},\n\tyear = {1981},\n\ttitle = {An {Iterative} {Image} {Registration} {Technique} with an {Application} to {Stereo} {Vision}},\n}","@misc{pandoc,\n\tauthor = {MacFarlane, John},\n\tyear = {2023},\n\ttitle = {Pandoc: A {Universal} {Document} {Converter}},\n\thowpublished = {\\href{https://pandoc.org/}{https://pandoc.org/}},\n}","@misc{react,\n\tauthor = {{Meta Open Source}},\n\tyear = {2023},\n\ttitle = {React},\n\thowpublished = {\\href{https://react.dev/}{https://react.dev/}},\n}","@misc{myst,\n\tauthor = {{MyST Markdown}},\n\tyear = {2023},\n\thowpublished = {\\href{https://myst-tools.org/}{https://myst-tools.org/}},\n}","@inproceedings{doi:10.1145/800197.806036,\n\tauthor = {Nelson, T. H.},\n\tbooktitle = {Proceedings of the 1965 20th national conference on   -},\n\tyear = {1965},\n\torganization = {ACM Press},\n\ttitle = {Complex information processing},\n\tdoi = {10.1145/800197.806036}\n}","@book{Nelson:81,\n\tauthor = {Nelson, T. H.},\n\tyear = {1981},\n\tpublisher = {Mindful Press},\n\ttitle = {Literary {Machines}},\n}","@misc{obsinputs,\n\tauthor = {{Observable Inputs}},\n\tyear = {2023},\n\thowpublished = {\\href{https://github.com/observablehq/inputs}{https://github.com/observablehq/inputs}},\n}","@misc{obsruntime,\n\tauthor = {{Observable Runtime}},\n\tyear = {2023},\n\thowpublished = {\\href{https://github.com/observablehq/runtime}{https://github.com/observablehq/runtime}},\n}","@misc{observable,\n\tauthor = {{Observable}},\n\tyear = {2023},\n\thowpublished = {\\href{https://observablehq.com/}{https://observablehq.com/}},\n}","@misc{overleaf,\n\tauthor = {{Overleaf}},\n\tyear = {2023},\n\ttitle = {Online {LaTeX} {Editor}},\n\thowpublished = {\\href{https://www.overleaf.com/}{https://www.overleaf.com/}},\n}","@article{doi:10.1016/S1389-1286(00)00043-8,\n\tauthor = {Phelps, Thomas A and Wilensky, Robert},\n\tjournal = {Computer Networks},\n\tnumber = {1-6},\n\tyear = {2000},\n\tpages = {105--118},\n\tpublisher = {Elsevier BV},\n\ttitle = {Robust intra-document locations},\n\tvolume = {33},\n\tdoi = {10.1016/s1389-1286(00)00043-8}\n}","@misc{quarto,\n\tauthor = {{Quarto}},\n\tyear = {2023},\n\thowpublished = {\\href{https://quarto.org/}{https://quarto.org/}},\n}","@misc{rmarkdown,\n\tauthor = {{RMarkdown}},\n\tyear = {2023},\n\thowpublished = {\\href{https://rmarkdown.rstudio.com/}{https://rmarkdown.rstudio.com/}},\n}","@inproceedings{doi:10.1145/3490099.3511162,\n\tauthor = {Rachatasumrit, Napol and Bragg, Jonathan and Zhang, Amy X. and Weld, Daniel S},\n\tbooktitle = {27th {International} {Conference} on {Intelligent} {User} {Interfaces}},\n\tyear = {2022},\n\torganization = {ACM},\n\ttitle = {CiteRead: Integrating {Localized} {Citation} {Contexts} into {Scientific} {Paper} {Reading}},\n\tdoi = {10.1145/3490099.3511162}\n}","@article{ritchie2022big,\n\tauthor = {Ritchie, Stuart},\n\tjournal = {The Guardian},\n\tyear = {2022},\n\ttitle = {The {Big} {Idea}: Should we get rid of the scientific paper?},\n\thowpublished = {\\href{https://www.theguardian.com/books/2022/apr/11/the-big-idea-should-we-get-rid-of-the-scientific-paper}{https://www.theguardian.com/books/2022/apr/11/the-big-idea-should-we-get-rid-of-the-scientific-paper}},\n\tvolume = {11},\n}","@inproceedings{doi:10.1145/3173574.3173606,\n\tauthor = {Rule, Adam and Tabard, Aur{\\' e}lien and Hollan, James D.},\n\tbooktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},\n\tyear = {2018},\n\torganization = {ACM},\n\ttitle = {Exploration and {Explanation} in {Computational} {Notebooks}},\n\tdoi = {10.1145/3173574.3173606}\n}","@article{doi:10.1109/TVCG.2015.2467091,\n\tauthor = {Satyanarayan, Arvind and Russell, Ryan and Hoffswell, Jane and Heer, Jeffrey},\n\tjournal = {IEEE Transactions on Visualization and Computer Graphics},\n\tnumber = {1},\n\tyear = {2016},\n\tpages = {659--668},\n\tpublisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},\n\ttitle = {Reactive {Vega}: A {Streaming} {Dataflow} {Architecture} for {Declarative} {Interactive} {Visualization}},\n\tvolume = {22},\n\tdoi = {10.1109/tvcg.2015.2467091}\n}","@article{doi:10.1109/TVCG.2016.2599030,\n\tauthor = {Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat, Kanit and Heer, Jeffrey},\n\tjournal = {IEEE Transactions on Visualization and Computer Graphics},\n\tnumber = {1},\n\tyear = {2017},\n\tpages = {341--350},\n\tpublisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},\n\ttitle = {Vega-{Lite}: A {Grammar} of {Interactive} {Graphics}},\n\tvolume = {23},\n\tdoi = {10.1109/tvcg.2016.2599030}\n}","@inproceedings{doi:10.1145/2047196.2047247,\n\tauthor = {Savva, Manolis and Kong, Nicholas and Chhajta, Arti and Fei-Fei, Li and Agrawala, Maneesh and Heer, Jeffrey},\n\tbooktitle = {Proceedings of the 24th annual {ACM} symposium on {User} interface software and technology},\n\tyear = {2011},\n\torganization = {ACM},\n\ttitle = {ReVision},\n\tdoi = {10.1145/2047196.2047247}\n}","@article{doi:10.1162/tacl_a_00466,\n\tauthor = {Shen, Zejiang and Lo, Kyle and Wang, Lucy Lu and Kuehl, Bailey and Weld, Daniel S. and Downey, Doug},\n\tjournal = {Transactions of the Association for Computational Linguistics},\n\tyear = {2022},\n\tpages = {376--392},\n\tpublisher = {MIT Press - Journals},\n\ttitle = {VILA: Improving {Structured} {Content} {Extraction} from {Scientific} {PDFs} {Using} {Visual} {Layout} {Groups}},\n\tvolume = {10},\n\tdoi = {10.1162/tacl_a_00466}\n}","@inproceedings{doi:10.1145/3411764.3445354,\n\tauthor = {Sultanum, Nicole and Chevalier, Fanny and Bylinskii, Zoya and Liu, Zhicheng},\n\tbooktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},\n\tyear = {2021},\n\torganization = {ACM},\n\ttitle = {Leveraging {Text}-{Chart} {Links} to {Support} {Authoring} of {Data}-{Driven} {Articles} with {VizFlow}},\n\tdoi = {10.1145/3411764.3445354}\n}","@article{doi:10.23915/distill.00031,\n\tauthor = {Team, Editorial},\n\tjournal = {Distill},\n\tnumber = {7},\n\tyear = {2021},\n\tpublisher = {Distill Working Group},\n\ttitle = {Distill {Hiatus}},\n\tvolume = {6},\n\tdoi = {10.23915/distill.00031}\n}","@misc{scalar,\n\tauthor = {{The Alliance for Networking Visual Culture}},\n\tyear = {2023},\n\ttitle = {Scalar},\n\thowpublished = {\\href{https://scalar.me/anvc/scalar/}{https://scalar.me/anvc/scalar/}},\n}","@misc{typst,\n\tauthor = {{Typst}},\n\tyear = {2023},\n\ttitle = {Typst: Compose papers faster},\n\thowpublished = {\\href{https://typst.app/}{https://typst.app/}},\n}","@misc{expexp,\n\tauthor = {Victor, Bret},\n\tyear = {2011},\n\ttitle = {Explorable {Explanations}},\n\thowpublished = {\\href{http://worrydream.com/ExplorableExplanations/}{http://worrydream.com/ExplorableExplanations/}},\n}","@inproceedings{doi:10.1145/3441852.3476545,\n\tauthor = {Wang, Lucy Lu and Cachola, Isabel and Bragg, Jonathan and Cheng, Evie Yu-Yen and Haupt, Chelsea and Latzke, Matt and Kuehl, Bailey and van Zuylen, Madeleine N and Wagner, Linda and Weld, Daniel},\n\tbooktitle = {The 23rd {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}},\n\tyear = {2021},\n\torganization = {ACM},\n\ttitle = {SciA11y: Converting {Scientific} {Papers} to {Accessible} {HTML}},\n\tdoi = {10.1145/3441852.3476545}\n}","@misc{citejs,\n\tauthor = {Willighagen, Lars},\n\tyear = {2023},\n\ttitle = {Citation.js},\n\thowpublished = {\\href{https://citation.js.org/}{https://citation.js.org/}},\n}","@inproceedings{xanadu,\n\tauthor = {Wolf, Gary},\n\tbooktitle = {Wired},\n\tyear = {1995},\n\ttitle = {The {Curse} of {Xanadu}},\n\thowpublished = {\\href{https://www.wired.com/1995/06/xanadu/}{https://www.wired.com/1995/06/xanadu/}},\n}","@misc{visxai,\n\tauthor = {{Workshop on Visualization for AI Explainability}},\n\tyear = {2022},\n\thowpublished = {\\href{http://visxai.io/}{http://visxai.io/}},\n}","@inproceedings{doi:10.1145/332040.332440,\n\tauthor = {Zellweger, Polle T. and Regli, Susan Harkness and Mackinlay, Jock D. and Chang, Bay-Wei},\n\tbooktitle = {Proceedings of the {SIGCHI} conference on {Human} {Factors} in {Computing} {Systems}},\n\tyear = {2000},\n\torganization = {ACM},\n\ttitle = {The impact of fluid documents on reading and browsing},\n\tdoi = {10.1145/332040.332440}\n}","@article{doi:10.1111/cgf.14519,\n\tauthor = {Zong, Jonathan and Lee, Crystal and Lundgard, Alan and Jang, JiWoong and Hajas, Daniel and Satyanarayan, Arvind},\n\tjournal = {Computer Graphics Forum},\n\tnumber = {3},\n\tyear = {2022},\n\tpages = {15--27},\n\tpublisher = {Wiley},\n\ttitle = {Rich {Screen} {Reader} {Experiences} for {Accessible} {Data} {Visualization}},\n\tvolume = {41},\n\tdoi = {10.1111/cgf.14519}\n}"],"csl":[{"author":[{"family":"Allen Institute for Artificial Intelligence, Semantic Scholar Team"}],"type":"document","id":"semreader","citation-key":"semreader","issued":{"date-parts":[[2023]]},"title":"Semantic Reader","URL":"https://www.semanticscholar.org/product/semantic-reader"},{"indexed":{"date-parts":[[2023,10,13]],"date-time":"2023-10-13T06:16:46Z","timestamp":1697177806975},"publisher-location":"Stroudsburg, PA, USA","reference-count":0,"publisher":"Association for Computational Linguistics","content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2018]]},"DOI":"10.18653/v1/n18-3011","type":"proceedings-article","created":{"date-parts":[[2018,5,30]],"date-time":"2018-05-30T00:40:16Z","timestamp":1527640816000},"source":"Crossref","is-referenced-by-count":116,"title":"Construction of the Literature Graph in Semantic Scholar","prefix":"10.18653","author":[{"given":"Waleed","family":"Ammar","sequence":"first","affiliation":[]},{"given":"Dirk","family":"Groeneveld","sequence":"additional","affiliation":[]},{"given":"Chandra","family":"Bhagavatula","sequence":"additional","affiliation":[]},{"given":"Iz","family":"Beltagy","sequence":"additional","affiliation":[]},{"given":"Miles","family":"Crawford","sequence":"additional","affiliation":[]},{"given":"Doug","family":"Downey","sequence":"additional","affiliation":[]},{"given":"Jason","family":"Dunkelberger","sequence":"additional","affiliation":[]},{"given":"Ahmed","family":"Elgohary","sequence":"additional","affiliation":[]},{"given":"Sergey","family":"Feldman","sequence":"additional","affiliation":[]},{"given":"Vu","family":"Ha","sequence":"additional","affiliation":[]},{"given":"Rodney","family":"Kinney","sequence":"additional","affiliation":[]},{"given":"Sebastian","family":"Kohlmeier","sequence":"additional","affiliation":[]},{"given":"Kyle","family":"Lo","sequence":"additional","affiliation":[]},{"given":"Tyler","family":"Murray","sequence":"additional","affiliation":[]},{"given":"Hsu-Han","family":"Ooi","sequence":"additional","affiliation":[]},{"given":"Matthew","family":"Peters","sequence":"additional","affiliation":[]},{"given":"Joanna","family":"Power","sequence":"additional","affiliation":[]},{"given":"Sam","family":"Skjonsberg","sequence":"additional","affiliation":[]},{"given":"Lucy","family":"Wang","sequence":"additional","affiliation":[]},{"given":"Chris","family":"Willhelm","sequence":"additional","affiliation":[]},{"given":"Zheng","family":"Yuan","sequence":"additional","affiliation":[]},{"given":"Madeleine","family":"Zuylen","sequence":"additional","affiliation":[]},{"family":"oren","sequence":"additional","affiliation":[]}],"member":"1643","event":"Proceedings of the 2018 Conference of the North American Chapter of\n          the Association for Computational Linguistics: Human Language\n          Technologies, Volume 3 (Industry Papers)","container-title":"Proceedings of the 2018 Conference of the North American Chapter of\n          the Association for Computational Linguistics: Human Language\n          Technologies, Volume 3 (Industry Papers)","original-title":[],"deposited":{"date-parts":[[2018,5,30]],"date-time":"2018-05-30T00:40:19Z","timestamp":1527640819000},"score":1,"resource":{"primary":{"URL":"http://aclweb.org/anthology/N18-3011"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2018]]},"references-count":0,"URL":"http://dx.doi.org/10.18653/v1/N18-3011","relation":{},"published":{"date-parts":[[2018]]},"id":"doi:10.18653/v1/N18-3011"},{"type":"article","id":"doi:10.48550/arXiv.2203.00130","categories":["Human-Computer Interaction (cs.HC)","Computation and Language (cs.CL)","FOS: Computer and information sciences","FOS: Computer and information sciences","H.5.2"],"author":[{"family":"August","given":"Tal"},{"family":"Wang","given":"Lucy Lu"},{"family":"Bragg","given":"Jonathan"},{"family":"Hearst","given":"Marti A."},{"family":"Head","given":"Andrew"},{"family":"Lo","given":"Kyle"}],"issued":{"date-parts":[[2022]]},"abstract":"When seeking information not covered in patient-friendly documents, like medical pamphlets, healthcare consumers may turn to the research literature. Reading medical papers, however, can be a challenging experience. To improve access to medical papers, we introduce a novel interactive interface-Paper Plain-with four features powered by natural language processing: definitions of unfamiliar terms, in-situ plain language section summaries, a collection of key questions that guide readers to answering passages, and plain language summaries of the answering passages. We evaluate Paper Plain, finding that participants who use Paper Plain have an easier time reading and understanding research papers without a loss in paper comprehension compared to those who use a typical PDF reader. Altogether, the study results suggest that guiding readers to relevant passages and providing plain language summaries, or \"gists,\" alongside the original paper content can make reading medical papers easier and give readers more confidence to approach these papers.","DOI":"10.48550/ARXIV.2203.00130","publisher":"arXiv","title":"Paper Plain: Making Medical Research Papers Approachable to Healthcare Consumers with Natural Language Processing","URL":"https://arxiv.org/abs/2203.00130","copyright":"Creative Commons Attribution 4.0 International","version":"1"},{"indexed":{"date-parts":[[2023,10,12]],"date-time":"2023-10-12T03:02:38Z","timestamp":1697079758889},"reference-count":66,"publisher":"Institute of Electrical and Electronics Engineers (IEEE)","issue":"1","license":[{"start":{"date-parts":[[2019,1,1]],"date-time":"2019-01-01T00:00:00Z","timestamp":1546300800000},"content-version":"vor","delay-in-days":0,"URL":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html"},{"start":{"date-parts":[[2019,1,1]],"date-time":"2019-01-01T00:00:00Z","timestamp":1546300800000},"content-version":"stm-asf","delay-in-days":0,"URL":"https://doi.org/10.15223/policy-029"},{"start":{"date-parts":[[2019,1,1]],"date-time":"2019-01-01T00:00:00Z","timestamp":1546300800000},"content-version":"stm-asf","delay-in-days":0,"URL":"https://doi.org/10.15223/policy-037"}],"funder":[{"DOI":"10.13039/100000001","name":"National Science Foundation","doi-asserted-by":"publisher","award":["IIS-1539534"]}],"content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2019,1]]},"DOI":"10.1109/tvcg.2018.2865119","type":"journal-article","created":{"date-parts":[[2018,8,20]],"date-time":"2018-08-20T18:18:53Z","timestamp":1534789133000},"page":"661-671","source":"Crossref","is-referenced-by-count":17,"title":"Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading","prefix":"10.1109","volume":"25","author":[{"given":"Sriram Karthik","family":"Badam","sequence":"first","affiliation":[]},{"given":"Zhicheng","family":"Liu","sequence":"additional","affiliation":[]},{"given":"Niklas","family":"Elmqvist","sequence":"additional","affiliation":[]}],"member":"263","reference":[{"key":"ref39","author":"mikolov","year":"2013","journal-title":"Efficient Estimation of Word Representations in Vector Space"},{"key":"ref38","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2007.70594"},{"key":"ref33","article-title":"On close and distant reading in digital humanities: A survey and future challenges","author":"jänicke","year":"2015","journal-title":"Eurographics Conference on Visualization (EuroVis)-STARs The Eurographics Association"},{"key":"ref32","doi-asserted-by":"publisher","DOI":"10.1145/1012037.1012063"},{"key":"ref31","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2011.255"},{"key":"ref30","doi-asserted-by":"crossref","first-page":"317","DOI":"10.1145/1993316.1993536","article-title":"Spreadsheet table transformations from examples","volume":"46","author":"harris","year":"2011","journal-title":"ACM SIGPLAN Notices"},{"key":"ref37","doi-asserted-by":"publisher","DOI":"10.1111/j.1551-6708.1987.tb00863.x"},{"key":"ref36","doi-asserted-by":"publisher","DOI":"10.1145/2556288.2557241"},{"key":"ref35","first-page":"12","article-title":"Social network analysis and visualization in &#x2018;the papers of thomas jefferson&#x2019;","volume":"4","author":"klein","year":"2012","journal-title":"Proc Digital Humanities"},{"key":"ref34","doi-asserted-by":"publisher","DOI":"10.1145/1978942.1979444"},{"key":"ref60","author":"van den bos","year":"2016","journal-title":"Publication manual of the American Psychological Association"},{"key":"ref62","year":"2012","journal-title":"Trends in maternal mortality 1990 to 2010"},{"key":"ref61","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2009.171"},{"key":"ref63","first-page":"41","article-title":"Raising the bars: Evaluating treemaps vs. wrapped bars for dense visualization of sorted numeric data","author":"yalçin","year":"2017","journal-title":"Proc Conf Graphics Interface"},{"key":"ref28","doi-asserted-by":"publisher","DOI":"10.1145/2702613.2732501"},{"key":"ref64","first-page":"1773","article-title":"pdf2table: A method to extract table information from PDF files","author":"yildiz","year":"2005","journal-title":"Proceedings of the Indian International Conference on Artificial Intelligence"},{"key":"ref27","author":"gregg","year":"2017","journal-title":"Introducing packed bars a new chart form"},{"key":"ref65","doi-asserted-by":"publisher","DOI":"10.1145/2501988.2502036"},{"key":"ref66","doi-asserted-by":"publisher","DOI":"10.1145/332040.332440"},{"key":"ref29","first-page":"195","article-title":"The role of illustrations in text comprehension: what, when, for whom, and why?","author":"gyselinck","year":"1999","journal-title":"The Construction of Mental Representations during Reading"},{"key":"ref2","year":"0","journal-title":"Adobe InDesign"},{"key":"ref1","year":"0","journal-title":"Adobe Acrobat"},{"key":"ref20","doi-asserted-by":"publisher","DOI":"10.1145/2559206.2578881"},{"key":"ref22","doi-asserted-by":"crossref","first-page":"3005","DOI":"10.1145/2556288.2557228","article-title":"NewsViews: an automated pipeline for creating custom geovisualizations for news","author":"gao","year":"2014","journal-title":"Proceedings of the ACM Conference on Human Factors in Computing Systems"},{"key":"ref21","doi-asserted-by":"crossref","first-page":"107","DOI":"10.1177/0022057409189001-208","article-title":"Effective practices for developing reading comprehension","volume":"189","author":"duke","year":"2008","journal-title":"Education Journal"},{"key":"ref24","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2016.2618797"},{"key":"ref23","doi-asserted-by":"publisher","DOI":"10.1016/0749-596X(92)90008-L"},{"key":"ref26","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2014.2346435"},{"key":"ref25","doi-asserted-by":"publisher","DOI":"10.1145/2702613.2732778"},{"key":"ref50","doi-asserted-by":"publisher","DOI":"10.3322/caac.21332"},{"key":"ref51","author":"spence","year":"2001","journal-title":"Information Visualization"},{"key":"ref59","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2009.165"},{"key":"ref58","year":"2015","journal-title":"Levels and trends in child mortality"},{"key":"ref57","author":"tukey","year":"1977","journal-title":"Exploratory Data Analysis"},{"key":"ref56","doi-asserted-by":"publisher","DOI":"10.1145/1978942.1979430"},{"key":"ref55","doi-asserted-by":"publisher","DOI":"10.4300/JGME-D-12-00156.1"},{"key":"ref54","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2009.139"},{"key":"ref53","first-page":"615","article-title":"The design and preliminary evaluation of a finger-mounted camera and feedback system to enable reading of printed text for the blind","author":"stearns","year":"2014","journal-title":"Proceedings of the European Conference on Computer Vision"},{"key":"ref52","doi-asserted-by":"publisher","DOI":"10.1109/INFVIS.2000.885091"},{"key":"ref10","doi-asserted-by":"publisher","DOI":"10.1111/cgf.12104"},{"key":"ref11","author":"card","year":"1999","journal-title":"Readings in Information Visualization Using Vision To Think"},{"key":"ref40","author":"moretti","year":"2013","journal-title":"Distant Reading"},{"key":"ref12","doi-asserted-by":"publisher","DOI":"10.1111/cgf.13180"},{"key":"ref13","doi-asserted-by":"publisher","DOI":"10.1145/288392.288585"},{"key":"ref14","doi-asserted-by":"publisher","DOI":"10.1145/2858036.2858430"},{"key":"ref15","first-page":"1:1","article-title":"Automatic web spreadsheet data extraction","author":"chen","year":"2013","journal-title":"Proceedings of the ACM Workshop on Semantic Search Over the Web"},{"key":"ref16","doi-asserted-by":"publisher","DOI":"10.1145/2623330.2623617"},{"key":"ref17","doi-asserted-by":"publisher","DOI":"10.14778/2536274.2536276"},{"key":"ref18","doi-asserted-by":"publisher","DOI":"10.1177/0956797613504966"},{"key":"ref19","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2016.2598594"},{"key":"ref4","year":"0","journal-title":"SEC Filings"},{"key":"ref3","doi-asserted-by":"publisher","DOI":"10.1145/3025453.3025631"},{"key":"ref6","author":"bird","year":"2009","journal-title":"Natural Language Processing With Python"},{"key":"ref5","author":"bertin","year":"1973","journal-title":"S&#x00E9;miologie graphique Les diagrammes-Les r&#x00E9;seaux-Les cartes"},{"key":"ref8","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2011.185"},{"key":"ref7","doi-asserted-by":"publisher","DOI":"10.1109/MCG.2003.1231178"},{"key":"ref49","doi-asserted-by":"publisher","DOI":"10.3322/caac.21254"},{"key":"ref9","first-page":"89","article-title":"Closing in on close reading","author":"boyles","year":"2012","journal-title":"On Developing Readers Readings from Educational Leadership EL Essentials"},{"key":"ref46","first-page":"318","article-title":"The Table Lens: merging graphical and symbolic representations in an interactive focus+context visualization for tabular information","author":"rao","year":"1994","journal-title":"Proceedings of the ACM Conference on Human Factors in Computing Systems"},{"key":"ref45","doi-asserted-by":"publisher","DOI":"10.1061/(ASCE)1527-6988(2008)9:1(29)"},{"key":"ref48","doi-asserted-by":"publisher","DOI":"10.1145/102377.115768"},{"key":"ref47","doi-asserted-by":"publisher","DOI":"10.1109/ICCITECHN.2016.7860200"},{"key":"ref42","year":"2017","journal-title":"Tropical hurricane report Hurricane Harvey"},{"key":"ref41","year":"2016","journal-title":"Tropical hurricane report Hurricane Alex"},{"key":"ref44","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2014.2346279"},{"key":"ref43","doi-asserted-by":"publisher","DOI":"10.1109/ICDAR.2009.12"}],"container-title":"IEEE Transactions on Visualization and Computer Graphics","original-title":[],"link":[{"URL":"http://xplorestaging.ieee.org/ielx7/2945/8547224/08440810.pdf?arnumber=8440810","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2022,7,13]],"date-time":"2022-07-13T20:54:49Z","timestamp":1657745689000},"score":1,"resource":{"primary":{"URL":"https://ieeexplore.ieee.org/document/8440810/"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2019,1]]},"references-count":66,"journal-issue":{"issue":"1"},"URL":"http://dx.doi.org/10.1109/TVCG.2018.2865119","relation":{},"ISSN":["1077-2626","1941-0506","2160-9306"],"subject":["Computer Graphics and Computer-Aided Design","Computer Vision and Pattern Recognition","Signal Processing","Software"],"container-title-short":"IEEE Trans. Visual. Comput. Graphics","published":{"date-parts":[[2019,1]]},"id":"doi:10.1109/TVCG.2018.2865119"},{"indexed":{"date-parts":[[2023,10,10]],"date-time":"2023-10-10T22:22:50Z","timestamp":1696976570656},"reference-count":0,"publisher":"Association for Computing Machinery (ACM)","issue":"8","content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[1994,8]]},"DOI":"10.1145/179606.179671","type":"journal-article","created":{"date-parts":[[2002,7,27]],"date-time":"2002-07-27T11:37:49Z","timestamp":1027769869000},"page":"76-82","update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":555,"title":"The World-Wide Web","prefix":"10.1145","volume":"37","author":[{"given":"Tim","family":"Berners-Lee","sequence":"first","affiliation":[{"name":"CERN, Geneva, Switzerland"}]},{"given":"Robert","family":"Cailliau","sequence":"additional","affiliation":[{"name":"CERN, Geneva, Switzerland"}]},{"given":"Ari","family":"Luotonen","sequence":"additional","affiliation":[{"name":"CERN, Geneva, Switzerland"}]},{"given":"Henrik Frystyk","family":"Nielsen","sequence":"additional","affiliation":[{"name":"CERN, Geneva, Switzerland"}]},{"given":"Arthur","family":"Secret","sequence":"additional","affiliation":[{"name":"CERN, Geneva, Switzerland"}]}],"member":"320","published-online":{"date-parts":[[1994,8]]},"container-title":"Communications of the ACM","original-title":[],"language":"en","link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/179606.179671","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2022,12,29]],"date-time":"2022-12-29T18:27:23Z","timestamp":1672338443000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/179606.179671"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[1994,8]]},"references-count":0,"journal-issue":{"issue":"8","published-print":{"date-parts":[[1994,8]]}},"alternative-id":["10.1145/179606.179671"],"URL":"http://dx.doi.org/10.1145/179606.179671","relation":{},"ISSN":["0001-0782","1557-7317"],"subject":["General Computer Science"],"container-title-short":"Commun. ACM","published":{"date-parts":[[1994,8]]},"assertion":[{"value":"1994-08-01","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/179606.179671"},{"indexed":{"date-parts":[[2023,9,9]],"date-time":"2023-09-09T05:00:14Z","timestamp":1694235614736},"publisher-location":"New York, NY, USA","reference-count":26,"publisher":"ACM","license":[{"start":{"date-parts":[[2016,5,7]],"date-time":"2016-05-07T00:00:00Z","timestamp":1462579200000},"content-version":"vor","delay-in-days":0,"URL":"http://www.acm.org/publications/policies/copyright_policy#Background"}],"content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2016,5,7]]},"DOI":"10.1145/2851581.2892588","type":"proceedings-article","created":{"date-parts":[[2016,5,6]],"date-time":"2016-05-06T19:56:09Z","timestamp":1462564569000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":12,"title":"An Uninteresting Tour Through Why Our Research Papers Aren't Accessible","prefix":"10.1145","author":[{"given":"Jeffrey P.","family":"Bigham","sequence":"first","affiliation":[{"name":"Carnegie Mellon University, Pittsburgh, PA, USA"}]},{"given":"Erin L.","family":"Brady","sequence":"additional","affiliation":[{"name":"Indiana University - Purdue University Indianapolis, Indianapolis, IN, USA"}]},{"given":"Cole","family":"Gleason","sequence":"additional","affiliation":[{"name":"Carnegie Mellon University, Pittsburgh, PA, USA"}]},{"given":"Anhong","family":"Guo","sequence":"additional","affiliation":[{"name":"Carnegie Mellon University, Pittsburgh, PA, USA"}]},{"given":"David A.","family":"Shamma","sequence":"additional","affiliation":[{"name":"Yahoo Labs, San Fransisco, CA, USA"}]}],"member":"320","published-online":{"date-parts":[[2016,5,7]]},"reference":[{"key":"e_1_3_2_1_1_1","volume-title":"Portable Document Format Reference Manual (1 ed.). Adobe Systems Incorporated","author":"Adobe Systems","unstructured":"Adobe Systems Incorporated 1993. Portable Document Format Reference Manual (1 ed.). Adobe Systems Incorporated , Reading, Massachusetts . Adobe Systems Incorporated 1993. Portable Document Format Reference Manual (1 ed.). Adobe Systems Incorporated, Reading, Massachusetts."},{"key":"e_1_3_2_1_2_1","volume-title":"Portable Document Format Reference Manual (2 ed.). Adobe Systems Incorporated","author":"Adobe Systems","unstructured":"Adobe Systems Incorporated 2000. Portable Document Format Reference Manual (2 ed.). Adobe Systems Incorporated , Reading, Massachusetts . Adobe Systems Incorporated 2000. Portable Document Format Reference Manual (2 ed.). Adobe Systems Incorporated, Reading, Massachusetts."},{"key":"e_1_3_2_1_3_1","volume-title":"Portable Document Format Reference Manual (6 ed.). Adobe Systems Incorporated","author":"Adobe Systems","unstructured":"Adobe Systems Incorporated 2006. Portable Document Format Reference Manual (6 ed.). Adobe Systems Incorporated , Reading, Massachusetts . Adobe Systems Incorporated 2006. Portable Document Format Reference Manual (6 ed.). Adobe Systems Incorporated, Reading, Massachusetts."},{"key":"e_1_3_2_1_4_1","unstructured":"Adobe Systems Incorporated 2012. Adobe Acrobat XI Pro Accessibility Guide: Best Practices for PDF Accessibility. Adobe Systems Incorporated 345 Park Avenue San Jose CA 95110--2704 USA. http://www.adobe.com/accessibility/products/acrobat.html.  Adobe Systems Incorporated 2012. Adobe Acrobat XI Pro Accessibility Guide: Best Practices for PDF Accessibility. Adobe Systems Incorporated 345 Park Avenue San Jose CA 95110--2704 USA. http://www.adobe.com/accessibility/products/acrobat.html."},{"key":"e_1_3_2_1_5_1","doi-asserted-by":"publisher","DOI":"10.1145/2745555.2746665"},{"key":"e_1_3_2_1_6_1","doi-asserted-by":"publisher","DOI":"10.1145/2700648.2809864"},{"key":"e_1_3_2_1_7_1","volume-title":"Web content accessibility guidelines (WCAG) 2.0","author":"Caldwell Ben","unstructured":"Ben Caldwell , Michael Cooper , L Guarino Reid , and Gregg Vanderheiden . 2008. Web content accessibility guidelines (WCAG) 2.0 . Vol. 11 . W3C. Ben Caldwell, Michael Cooper, L Guarino Reid, and Gregg Vanderheiden. 2008. Web content accessibility guidelines (WCAG) 2.0. Vol. 11. W3C."},{"key":"e_1_3_2_1_8_1","doi-asserted-by":"publisher","DOI":"10.1109/HICSS.2008.497"},{"key":"e_1_3_2_1_9_1","doi-asserted-by":"publisher","DOI":"10.1145/1029014.1028638"},{"key":"e_1_3_2_1_10_1","volume-title":"Document management applications -- Electronic document file format enhancement for accessibility. Standard","author":"ISO","unstructured":"ISO 14289--1:2014 2014. Document management applications -- Electronic document file format enhancement for accessibility. Standard . International Organization for Standardization . ISO 14289--1:2014 2014. Document management applications -- Electronic document file format enhancement for accessibility. Standard. International Organization for Standardization."},{"key":"e_1_3_2_1_11_1","volume-title":"Document management -- Electronic document file format for long-term preservation. Standard","author":"ISO","unstructured":"ISO 19005--2:2011 2011. Document management -- Electronic document file format for long-term preservation. Standard . International Organization for Standardization . ISO 19005--2:2011 2011. Document management -- Electronic document file format for long-term preservation. Standard. International Organization for Standardization."},{"key":"e_1_3_2_1_12_1","doi-asserted-by":"publisher","DOI":"10.1145/1243441.1243472"},{"key":"e_1_3_2_1_13_1","doi-asserted-by":"publisher","DOI":"10.1145/2702613.2732497"},{"key":"e_1_3_2_1_14_1","doi-asserted-by":"publisher","DOI":"10.1145/1090785.1090792"},{"key":"e_1_3_2_1_15_1","doi-asserted-by":"publisher","DOI":"10.1080/10447310709336964"},{"key":"e_1_3_2_1_16_1","doi-asserted-by":"publisher","DOI":"10.1016/j.chb.2003.10.018"},{"key":"e_1_3_2_1_17_1","unstructured":"John MacFarlane. 2013. Pandoc: a universal document converter. (2013).  John MacFarlane. 2013. Pandoc: a universal document converter. (2013)."},{"key":"e_1_3_2_1_18_1","doi-asserted-by":"crossref","unstructured":"Valerie S Morash Yue-Ting Siu Joshua A Miele Lucia Hasty and Steven Landau. 2015. Guiding Novice Web Workers in Making Image Descriptions Using Templates. (2015).  Valerie S Morash Yue-Ting Siu Joshua A Miele Lucia Hasty and Steven Landau. 2015. Guiding Novice Web Workers in Making Image Descriptions Using Templates. (2015).","DOI":"10.1145/2764916"},{"key":"e_1_3_2_1_19_1","unstructured":"Jakob Nielson. 2001. Avoid PDF for On-Screen Reading. (2001). https://www.nngroup.com/articles/avoid-pdf-for-on-screen-reading/.  Jakob Nielson. 2001. Avoid PDF for On-Screen Reading. (2001). https://www.nngroup.com/articles/avoid-pdf-for-on-screen-reading/."},{"key":"e_1_3_2_1_20_1","volume-title":"PDF: Unfit for Human Consumption.","author":"Nielson Jakob","year":"2003","unstructured":"Jakob Nielson . 2003 . PDF: Unfit for Human Consumption. (2003). https://www.nngroup.com/articles/pdf-unfit-for-human-consumption/. Jakob Nielson. 2003. PDF: Unfit for Human Consumption. (2003). https://www.nngroup.com/articles/pdf-unfit-for-human-consumption/."},{"key":"e_1_3_2_1_21_1","unstructured":"Thomas Park. 2015. PubCSS: Formatting Academic Publications in HTML & CSS. (2015).  Thomas Park. 2015. PubCSS: Formatting Academic Publications in HTML & CSS. (2015)."},{"key":"e_1_3_2_1_22_1","volume-title":"E-learning and disability in higher education: accessibility research and practice","author":"Seale Jane","unstructured":"Jane Seale . 2013. E-learning and disability in higher education: accessibility research and practice . Routledge . Jane Seale. 2013. E-learning and disability in higher education: accessibility research and practice. Routledge."},{"key":"e_1_3_2_1_23_1","doi-asserted-by":"publisher","DOI":"10.1145/1414471.1414507"},{"key":"e_1_3_2_1_24_1","doi-asserted-by":"publisher","DOI":"10.1080/08841230903022118"},{"key":"e_1_3_2_1_25_1","unstructured":"John Warnock. 1991. The Camelot Project. (1991). http://bit.ly/pdfwhitepaper  John Warnock. 1991. The Camelot Project. (1991). http://bit.ly/pdfwhitepaper"},{"key":"e_1_3_2_1_26_1","volume-title":"Retrofitting accessibility: The legal inequality of after-the-fact online access for persons with disabilities in the USA. First Monday 16, 11","author":"Wentz Brian","year":"2011","unstructured":"Brian Wentz , Paul T Jaeger , and Jonathan Lazar . 2011. Retrofitting accessibility: The legal inequality of after-the-fact online access for persons with disabilities in the USA. First Monday 16, 11 ( 2011 ). Brian Wentz, Paul T Jaeger, and Jonathan Lazar. 2011. Retrofitting accessibility: The legal inequality of after-the-fact online access for persons with disabilities in the USA. First Monday 16, 11 (2011)."}],"event":"CHI'16: CHI Conference on Human Factors in Computing Systems","container-title":"Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/2851581.2892588","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,2,15]],"date-time":"2023-02-15T21:22:36Z","timestamp":1676496156000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/2851581.2892588"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2016,5,7]]},"references-count":26,"alternative-id":["10.1145/2851581.2892588","10.1145/2851581"],"URL":"http://dx.doi.org/10.1145/2851581.2892588","relation":{},"published":{"date-parts":[[2016,5,7]]},"assertion":[{"value":"2016-05-07","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/2851581.2892588"},{"indexed":{"date-parts":[[2023,10,20]],"date-time":"2023-10-20T18:41:19Z","timestamp":1697827279069},"reference-count":41,"publisher":"Institute of Electrical and Electronics Engineers (IEEE)","issue":"12","license":[{"start":{"date-parts":[[2011,12,1]],"date-time":"2011-12-01T00:00:00Z","timestamp":1322697600000},"content-version":"vor","delay-in-days":0,"URL":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html"}],"content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2011,12]]},"DOI":"10.1109/tvcg.2011.185","type":"journal-article","created":{"date-parts":[[2011,11,4]],"date-time":"2011-11-04T22:02:45Z","timestamp":1320444165000},"page":"2301-2309","source":"Crossref","is-referenced-by-count":1932,"title":"D³ Data-Driven Documents","prefix":"10.1109","volume":"17","author":[{"given":"M.","family":"Bostock","sequence":"first","affiliation":[]},{"given":"V.","family":"Ogievetsky","sequence":"additional","affiliation":[]},{"given":"J.","family":"Heer","sequence":"additional","affiliation":[]}],"member":"263","reference":[{"key":"bibttg201112230137","doi-asserted-by":"publisher","DOI":"10.1109/INFVIS.2005.1532122"},{"key":"bibttg201112230113","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2010.144"},{"key":"bibttg201112230136","author":"tufte","year":"2001"},{"key":"bibttg201112230112","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2006.178"},{"key":"bibttg201112230139","author":"wickham","year":"2009","journal-title":"ggplot2 Elegant Graphics for Data Analysis"},{"key":"bibttg201112230111","doi-asserted-by":"publisher","DOI":"10.1109/INFVIS.2000.885098"},{"key":"bibttg201112230138","doi-asserted-by":"publisher","DOI":"10.1109/INFVIS.2004.12"},{"key":"bibttg201112230110","doi-asserted-by":"publisher","DOI":"10.1179/000870403235002042"},{"key":"bibttg201112230118","year":"2011"},{"key":"bibttg201112230130","year":"2011"},{"key":"bibttg201112230119","year":"2011"},{"key":"bibttg201112230131","doi-asserted-by":"publisher","DOI":"10.1145/102377.115768"},{"key":"bibttg201112230116","article-title":"Building domain-specific embedded languages. ACM Computing Surveys","author":"hudak","year":"1996"},{"key":"bibttg201112230132","doi-asserted-by":"publisher","DOI":"10.1109/INFVIS.2000.885091"},{"key":"bibttg201112230117","doi-asserted-by":"publisher","DOI":"10.1145/168642.168648"},{"key":"bibttg201112230133","year":"2011"},{"key":"bibttg201112230134","year":"2008"},{"key":"bibttg201112230114","first-page":"421","article-title":"prefuse: a toolkit for interactive information visualization.","author":"heer","year":"2005","journal-title":"In Proc ACM CHI"},{"key":"bibttg201112230135","year":"2011"},{"key":"bibttg201112230115","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2007.70539"},{"key":"bibttg20111223019","year":"2011"},{"key":"bibttg20111223017","doi-asserted-by":"publisher","DOI":"10.1111/j.1467-8659.2009.01449.x"},{"key":"bibttg20111223018","doi-asserted-by":"publisher","DOI":"10.1109/INFVIS.2004.64"},{"key":"bibttg20111223015","author":"card","year":"1999","journal-title":"Readings in Information Visualization Using Vision To Think"},{"key":"bibttg20111223016","year":"2011"},{"key":"bibttg20111223013","first-page":"33","article-title":"Squarified treemaps.","author":"bruls","year":"1999","journal-title":"Proc Joint Eurographics-IEEE TCVG Symp Visualization"},{"key":"bibttg201112230128","year":"2011"},{"key":"bibttg20111223014","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2008.166"},{"key":"bibttg201112230127","doi-asserted-by":"publisher","DOI":"10.1145/166117.166125"},{"key":"bibttg20111223011","doi-asserted-by":"publisher","DOI":"10.1080/00401706.1987.10488204"},{"key":"bibttg201112230126","author":"penner","year":"2011"},{"key":"bibttg20111223012","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2009.174"},{"key":"bibttg201112230125","doi-asserted-by":"publisher","DOI":"10.1111/j.0033-0124.1976.00371.x"},{"key":"bibttg201112230129","year":"2011"},{"key":"bibttg201112230120","doi-asserted-by":"publisher","DOI":"10.1101/gr.092759.109"},{"key":"bibttg201112230141","year":"1999"},{"key":"bibttg201112230123","year":"2011"},{"key":"bibttg201112230124","author":"norman","year":"1988","journal-title":"The Psychology of Everyday Things"},{"key":"bibttg201112230121","author":"lie","year":"2005","journal-title":"Cascading Style Sheets"},{"key":"bibttg201112230140","author":"wilkinson","year":"2005","journal-title":"The Grammar of Graphics (Statistics and Computing)"},{"key":"bibttg201112230122","author":"mayer","year":"2008"}],"container-title":"IEEE Transactions on Visualization and Computer Graphics","original-title":[],"link":[{"URL":"http://xplorestaging.ieee.org/ielx5/2945/6064926/06064996.pdf?arnumber=6064996","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2021,11,29]],"date-time":"2021-11-29T20:55:20Z","timestamp":1638219320000},"score":1,"resource":{"primary":{"URL":"http://ieeexplore.ieee.org/document/6064996/"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2011,12]]},"references-count":41,"journal-issue":{"issue":"12"},"URL":"http://dx.doi.org/10.1109/TVCG.2011.185","relation":{},"ISSN":["1077-2626"],"subject":["Computer Graphics and Computer-Aided Design","Computer Vision and Pattern Recognition","Signal Processing","Software"],"container-title-short":"IEEE Trans. Visual. Comput. Graphics","published":{"date-parts":[[2011,12]]},"id":"doi:10.1109/TVCG.2011.185"},{"author":[{"family":"Citation Style Language"}],"type":"document","id":"csl","citation-key":"csl","issued":{"date-parts":[[2023]]},"URL":"https://citationstyles.org/"},{"indexed":{"date-parts":[[2023,10,12]],"date-time":"2023-10-12T03:02:08Z","timestamp":1697079728048},"publisher-location":"New York, NY, USA","reference-count":46,"publisher":"ACM","license":[{"start":{"date-parts":[[2018,10,11]],"date-time":"2018-10-11T00:00:00Z","timestamp":1539216000000},"content-version":"vor","delay-in-days":0,"URL":"http://www.acm.org/publications/policies/copyright_policy#Background"}],"content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2018,10,11]]},"DOI":"10.1145/3242587.3242600","type":"proceedings-article","created":{"date-parts":[[2018,10,16]],"date-time":"2018-10-16T13:30:26Z","timestamp":1539696626000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":36,"title":"Idyll","prefix":"10.1145","author":[{"given":"Matthew","family":"Conlen","sequence":"first","affiliation":[{"name":"University of Washington, Seattle, WA, USA"}]},{"given":"Jeffrey","family":"Heer","sequence":"additional","affiliation":[{"name":"University of Washington, Seattle, WA, USA"}]}],"member":"320","published-online":{"date-parts":[[2018,10,11]]},"reference":[{"key":"e_1_3_2_2_1_1","volume-title":"Retrieved","year":"2008","unstructured":"2008. Jekyll. ( 2008 ). Retrieved August 1, 2017 from https://jekyllrb.com/ 2008. Jekyll. (2008). Retrieved August 1, 2017 from https://jekyllrb.com/"},{"key":"e_1_3_2_2_2_1","volume-title":"Retrieved","year":"2013","unstructured":"2013. Fangle. ( 2013 ). Retrieved September 19, 2017 from https://github.com/jotux/fangle 2013. Fangle. (2013). Retrieved September 19, 2017 from https://github.com/jotux/fangle"},{"key":"e_1_3_2_2_3_1","volume-title":"Retrieved","year":"2015","unstructured":"2015. React. ( 2015 ). Retrieved August 1, 2017 from https://facebook.github.io/react/ 2015. React. (2015). Retrieved August 1, 2017 from https://facebook.github.io/react/"},{"key":"e_1_3_2_2_4_1","volume-title":"Explorable Explanations Web Catalog. (2017). Retrieved","year":"2017","unstructured":"2017. Explorable Explanations Web Catalog. (2017). Retrieved August 1, 2017 from http://explorabl.es/ 2017. Explorable Explanations Web Catalog. (2017). Retrieved August 1, 2017 from http://explorabl.es/"},{"key":"e_1_3_2_2_5_1","volume-title":"Idyll download count. (2017). Retrieved","year":"2017","unstructured":"2017. Idyll download count. (2017). Retrieved August 1, 2017 from https://npm-stat.com/charts.html?package=idyll 2017. Idyll download count. (2017). Retrieved August 1, 2017 from https://npm-stat.com/charts.html?package=idyll"},{"key":"e_1_3_2_2_6_1","doi-asserted-by":"publisher","DOI":"10.1145/3025453.3025631"},{"key":"e_1_3_2_2_7_1","unstructured":"Bill Atkinson. 1988. Hypercard. Apple Computer.  Bill Atkinson. 1988. Hypercard. Apple Computer."},{"key":"e_1_3_2_2_8_1","doi-asserted-by":"publisher","DOI":"10.1145/2501654.2501666"},{"key":"e_1_3_2_2_9_1","volume-title":"Retrieved","author":"Bollweg Nicholas","year":"2011","unstructured":"Nicholas Bollweg . 2011 . TangleDown. (2011) . Retrieved September 19, 2017 from https://github.com/bollwyvl/TangleDown Nicholas Bollweg. 2011. TangleDown. (2011). Retrieved September 19, 2017 from https://github.com/bollwyvl/TangleDown"},{"key":"e_1_3_2_2_10_1","volume-title":"D3: Data-Driven Documents","author":"Bostock Michael","year":"2011","unstructured":"Michael Bostock , Vadim Ogievetsky , and Jeffrey Heer . 2011. D3: Data-Driven Documents . IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis) ( 2011 ). http://vis.stanford.edu/papers/d3 Michael Bostock, Vadim Ogievetsky, and Jeffrey Heer. 2011. D3: Data-Driven Documents. IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis) (2011). http://vis.stanford.edu/papers/d3"},{"key":"e_1_3_2_2_11_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2016.2614803"},{"key":"e_1_3_2_2_12_1","unstructured":"Bill Burdick. 2011. leisure. https://github.com/zot/Leisure. (2011).  Bill Burdick. 2011. leisure. https://github.com/zot/Leisure. (2011)."},{"key":"e_1_3_2_2_13_1","doi-asserted-by":"publisher","DOI":"10.1016/j.jvlc.2016.07.004"},{"key":"e_1_3_2_2_14_1","volume-title":"Retrieved","year":"2017","unstructured":"Distill. 2017 . Latest articles about machine learning. (2017) . Retrieved September 19, 2017 from https://distill.pub/ Distill. 2017. Latest articles about machine learning. (2017). Retrieved September 19, 2017 from https://distill.pub/"},{"key":"e_1_3_2_2_15_1","doi-asserted-by":"publisher","DOI":"10.1145/258948.258973"},{"key":"e_1_3_2_2_16_1","volume-title":"Retrieved","author":"Gruber John","year":"2004","unstructured":"John Gruber . 2004. Markdown. ( 2004 ). Retrieved August 1, 2017 from https://daringfireball.net/projects/markdown/syntax/ John Gruber. 2004. Markdown. (2004). Retrieved August 1, 2017 from https://daringfireball.net/projects/markdown/syntax/"},{"key":"e_1_3_2_2_17_1","volume-title":"Retrieved","author":"Kapoor Amit","year":"2016","unstructured":"Amit Kapoor . 2016. Visdown. ( 2016 ). Retrieved August 1, 2017 from http://visdown.amitkaps.com/ Amit Kapoor. 2016. Visdown. (2016). Retrieved August 1, 2017 from http://visdown.amitkaps.com/"},{"key":"e_1_3_2_2_18_1","doi-asserted-by":"publisher","DOI":"10.1145/2702123.2702140"},{"key":"e_1_3_2_2_19_1","doi-asserted-by":"publisher","DOI":"10.1109/MC.2013.36"},{"key":"e_1_3_2_2_20_1","unstructured":"Maarten Lambrechts. 2016. Rock 'n Poll: Polls explained with interactive graphics. https://web.archive.org/web/20180307013513/http://rocknpoll.graphics/. (2016).  Maarten Lambrechts. 2016. Rock 'n Poll: Polls explained with interactive graphics. https://web.archive.org/web/20180307013513/http://rocknpoll.graphics/. (2016)."},{"key":"e_1_3_2_2_21_1","volume-title":"Petra Isenberg, and Sheelagh Carpendale.","author":"Lee Bongshin","year":"2015","unstructured":"Bongshin Lee , Nathalie Henry Riche , Petra Isenberg, and Sheelagh Carpendale. 2015 . More than telling a story: Transforming data into visually shared stories. IEEE computer graphics and applications 35, 5 (2015), 84--90. Bongshin Lee, Nathalie Henry Riche, Petra Isenberg, and Sheelagh Carpendale. 2015. More than telling a story: Transforming data into visually shared stories. IEEE computer graphics and applications 35, 5 (2015), 84--90."},{"key":"e_1_3_2_2_22_1","volume-title":"Cascading style sheets: designing for the Web","author":"Lie Hakon Wium","unstructured":"Hakon Wium Lie and Bert Bos . 2005. Cascading style sheets: designing for the Web . Addison-Wesley Professional . Hakon Wium Lie and Bert Bos. 2005. Cascading style sheets: designing for the Web. Addison-Wesley Professional."},{"key":"e_1_3_2_2_23_1","doi-asserted-by":"publisher","DOI":"10.1109/MCG.2012.24"},{"key":"e_1_3_2_2_24_1","doi-asserted-by":"publisher","DOI":"10.1111/cgf.13195"},{"key":"e_1_3_2_2_25_1","doi-asserted-by":"publisher","DOI":"10.1145/1639949.1640091"},{"key":"e_1_3_2_2_26_1","doi-asserted-by":"publisher","DOI":"10.1145/344949.344959"},{"key":"e_1_3_2_2_27_1","unstructured":"Observable 2018. Observable. https://observablehq.com/. (2018).  Observable 2018. Observable. https://observablehq.com/. (2018)."},{"key":"e_1_3_2_2_28_1","volume-title":"Research Debt. Distill","author":"Olah Chris","year":"2017","unstructured":"Chris Olah and Shan Carter . 2017. Research Debt. Distill ( 2017 ). Retrieved August 1, 2017 from http://distill.pub/2017/research-debt Chris Olah and Shan Carter. 2017. Research Debt. Distill (2017). Retrieved August 1, 2017 from http://distill.pub/2017/research-debt"},{"key":"e_1_3_2_2_29_1","doi-asserted-by":"publisher","DOI":"10.1109/MCSE.2007.53"},{"key":"e_1_3_2_2_30_1","unstructured":"Polymer Project 2017. Polymer Project. https://www.polymer-project.org/. (2017).  Polymer Project 2017. Polymer Project. https://www.polymer-project.org/. (2017)."},{"key":"e_1_3_2_2_31_1","unstructured":"National Public Radio. 2016. dailygraphics. https://github.com/nprapps/dailygraphics. (2016).  National Public Radio. 2016. dailygraphics. https://github.com/nprapps/dailygraphics. (2016)."},{"key":"e_1_3_2_2_32_1","doi-asserted-by":"publisher","DOI":"10.1145/3126594.3126642"},{"key":"e_1_3_2_2_33_1","first-page":"3","article-title":"Authoring Narrative Visualizations with","volume":"33","author":"Satyanarayan Arvind","year":"2014","unstructured":"Arvind Satyanarayan and Jeffrey Heer . 2014 . Authoring Narrative Visualizations with Ellipsis. Comput. Graph. Forum 33 , 3 (June 2014), 361--370. Arvind Satyanarayan and Jeffrey Heer. 2014. Authoring Narrative Visualizations with Ellipsis. Comput. Graph. Forum 33, 3 (June 2014), 361--370.","journal-title":"Ellipsis. Comput. Graph. Forum"},{"key":"e_1_3_2_2_34_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2016.2599030"},{"key":"e_1_3_2_2_35_1","doi-asserted-by":"publisher","DOI":"10.1145/2642918.2647360"},{"key":"e_1_3_2_2_36_1","unstructured":"Toby Schachman and Joshua Horowitz. 2016. Apparatus. https://github.com/cdglabs. (2016).  Toby Schachman and Joshua Horowitz. 2016. Apparatus. https://github.com/cdglabs. (2016)."},{"key":"e_1_3_2_2_37_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2010.179"},{"key":"e_1_3_2_2_38_1","volume-title":"Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories","author":"Stolper Charles D","year":"2016","unstructured":"Charles D Stolper , Bongshin Lee , N Henry Riche , and John Stasko . 2016. Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories . Microsoft Research , Washington, USA ( 2016 ). Charles D Stolper, Bongshin Lee, N Henry Riche, and John Stasko. 2016. Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories. Microsoft Research, Washington, USA (2016)."},{"key":"e_1_3_2_2_39_1","volume-title":"Archie Markup Language (ArchieML). (2015). Retrieved","author":"Strickland Michael","year":"2017","unstructured":"Michael Strickland , Archie Tse , Matthew Ericson , and Tom Giratikanon . 2015. Archie Markup Language (ArchieML). (2015). Retrieved August 1, 2017 from http://archieml.org/ Michael Strickland, Archie Tse, Matthew Ericson, and Tom Giratikanon. 2015. Archie Markup Language (ArchieML). (2015). Retrieved August 1, 2017 from http://archieml.org/"},{"key":"e_1_3_2_2_40_1","unstructured":"Tampa Bay Times. 2016. lede. https://github.com/tbtimes/lede. (2016).  Tampa Bay Times. 2016. lede. https://github.com/tbtimes/lede. (2016)."},{"key":"e_1_3_2_2_41_1","unstructured":"The New York Times. 2017. kyt. https://github.com/NYTimes/kyt. (2017).  The New York Times. 2017. kyt. https://github.com/NYTimes/kyt. (2017)."},{"key":"e_1_3_2_2_42_1","doi-asserted-by":"publisher","DOI":"10.1145/2984511.2984551"},{"key":"e_1_3_2_2_43_1","volume-title":"Magic Ink: Information Software and the Graphical Interface. Retrieved","author":"Victor Bret","year":"2006","unstructured":"Bret Victor . 2006 . Magic Ink: Information Software and the Graphical Interface. Retrieved August 1, 2017 from http://worrydream.com/MagicInk/ Bret Victor. 2006. Magic Ink: Information Software and the Graphical Interface. Retrieved August 1, 2017 from http://worrydream.com/MagicInk/"},{"key":"e_1_3_2_2_44_1","unstructured":"Bret Victor. 2011a. Explorable Explorations. Retrieved August 1 2017 from http://worrydream.com/ExplorableExplanations/  Bret Victor. 2011a. Explorable Explorations. Retrieved August 1 2017 from http://worrydream.com/ExplorableExplanations/"},{"key":"e_1_3_2_2_45_1","unstructured":"Bret Victor. 2011b. Scientific Communication As Sequential Art. http://worrydream.com/ScientificCommunicationAsSequentialArt/.  Bret Victor. 2011b. Scientific Communication As Sequential Art. http://worrydream.com/ScientificCommunicationAsSequentialArt/."},{"key":"e_1_3_2_2_46_1","volume-title":"Tangle: a JavaScript library for reactive documents. Retrieved","author":"Victor Bret","year":"2017","unstructured":"Bret Victor . 2011c. Tangle: a JavaScript library for reactive documents. Retrieved August 1, 2017 from http://worrydream.com/Tangle/ Bret Victor. 2011c. Tangle: a JavaScript library for reactive documents. Retrieved August 1, 2017 from http://worrydream.com/Tangle/"}],"event":"UIST '18: The 31st Annual ACM Symposium on User Interface Software and Technology","container-title":"Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/3242587.3242600","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,1,6]],"date-time":"2023-01-06T16:09:14Z","timestamp":1673021354000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/3242587.3242600"}},"subtitle":["A Markup Language for Authoring and Publishing Interactive Articles on the Web"],"short-title":[],"issued":{"date-parts":[[2018,10,11]]},"references-count":46,"alternative-id":["10.1145/3242587.3242600","10.1145/3242587"],"URL":"http://dx.doi.org/10.1145/3242587.3242600","relation":{},"published":{"date-parts":[[2018,10,11]]},"assertion":[{"value":"2018-10-11","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/3242587.3242600"},{"indexed":{"date-parts":[[2023,10,12]],"date-time":"2023-10-12T02:49:42Z","timestamp":1697078982136},"publisher-location":"New York, NY, USA","reference-count":77,"publisher":"ACM","content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2021,10,10]]},"DOI":"10.1145/3472749.3474731","type":"proceedings-article","created":{"date-parts":[[2021,10,13]],"date-time":"2021-10-13T01:11:21Z","timestamp":1634087481000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":1,"title":"Idyll Studio: A Structured Editor for Authoring Interactive &amp; Data-Driven Articles","prefix":"10.1145","author":[{"given":"Matthew","family":"Conlen","sequence":"first","affiliation":[{"name":"University of Washington, United States"}]},{"given":"Megan","family":"Vo","sequence":"additional","affiliation":[{"name":"Idyll Collective, United States"}]},{"given":"Alan","family":"Tan","sequence":"additional","affiliation":[{"name":"Idyll Collective, United States"}]},{"given":"Jeffrey","family":"Heer","sequence":"additional","affiliation":[{"name":"Paul G. Allen School of Computer Science &amp; Engineering University of Washington, United States"}]}],"member":"320","published-online":{"date-parts":[[2021,10,12]]},"reference":[{"key":"e_1_3_2_1_1_1","doi-asserted-by":"publisher","DOI":"10.1145/2702123.2702431"},{"key":"e_1_3_2_1_2_1","volume-title":"A note on reflection in Python 1.5","author":"Andersen Anders","year":"1998","unstructured":"Anders Andersen . 1998. A note on reflection in Python 1.5 . Lancaster University 46( 1998 ). Anders Andersen. 1998. A note on reflection in Python 1.5. Lancaster University 46(1998)."},{"key":"e_1_3_2_1_3_1","volume-title":"Cupertino","author":"Atkinson B","year":"1987","unstructured":"B Atkinson . 1987. HyperCard [computer program]. Cupertino , CA : Apple Computer( 1987 ). B Atkinson. 1987. HyperCard [computer program]. Cupertino, CA: Apple Computer(1987)."},{"key":"e_1_3_2_1_4_1","doi-asserted-by":"publisher","DOI":"10.1145/2858036.2858387"},{"key":"e_1_3_2_1_5_1","doi-asserted-by":"publisher","DOI":"10.1145/3173574.3173612"},{"key":"e_1_3_2_1_6_1","volume-title":"Vistrates: A component model for ubiquitous analytics","author":"Badam Sriram Karthik","year":"2018","unstructured":"Sriram Karthik Badam , Andreas Mathisen , Roman Rädle , Clemens  N Klokmose , and Niklas Elmqvist . 2018 . Vistrates: A component model for ubiquitous analytics . IEEE transactions on visualization and computer graphics 25, 1(2018), 586–596. Sriram Karthik Badam, Andreas Mathisen, Roman Rädle, Clemens N Klokmose, and Niklas Elmqvist. 2018. Vistrates: A component model for ubiquitous analytics. IEEE transactions on visualization and computer graphics 25, 1(2018), 586–596."},{"key":"e_1_3_2_1_7_1","doi-asserted-by":"publisher","DOI":"10.1145/332040.332473"},{"key":"e_1_3_2_1_8_1","doi-asserted-by":"publisher","DOI":"10.1145/345513.345267"},{"key":"e_1_3_2_1_9_1","volume-title":"D3: Data-Driven Documents","author":"Bostock Michael","year":"2011","unstructured":"Michael Bostock , Vadim Ogievetsky , and Jeffrey Heer . 2011. D3: Data-Driven Documents . IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis) ( 2011 ). http://idl.cs.washington.edu/papers/d3 Michael Bostock, Vadim Ogievetsky, and Jeffrey Heer. 2011. D3: Data-Driven Documents. IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis) (2011). http://idl.cs.washington.edu/papers/d3"},{"key":"e_1_3_2_1_10_1","doi-asserted-by":"publisher","DOI":"10.1177/1473871620925071"},{"key":"e_1_3_2_1_11_1","unstructured":"Bill Burdick. 2011. leisure. https://github.com/zot/Leisure.  Bill Burdick. 2011. leisure. https://github.com/zot/Leisure."},{"key":"e_1_3_2_1_12_1","doi-asserted-by":"publisher","DOI":"10.1109/MS.2018.2141016"},{"key":"e_1_3_2_1_13_1","volume-title":"Using Apparatus with Idyll. Retrieved","author":"Conlen Matthew","year":"2021","unstructured":"Matthew Conlen . 2017. Using Apparatus with Idyll. Retrieved March 1, 2021 from https://mathisonian.com/writing/apparatus Matthew Conlen. 2017. Using Apparatus with Idyll. Retrieved March 1, 2021 from https://mathisonian.com/writing/apparatus"},{"key":"e_1_3_2_1_14_1","doi-asserted-by":"publisher","DOI":"10.1145/3242587.3242600"},{"key":"e_1_3_2_1_15_1","volume-title":"Dimensionality Reduction. Workshop on Visualization for AI Explainability (VISxAI) at IEEE VIS","author":"Conlen Matthew","year":"2018","unstructured":"Matthew Conlen and Fred Hohman . 2018 . The Beginner’s Guide to Dimensionality Reduction. Workshop on Visualization for AI Explainability (VISxAI) at IEEE VIS (2018). https://idyll.pub/post/dimensionality-reduction-293e465c2a3443e8941b016d/ Matthew Conlen and Fred Hohman. 2018. The Beginner’s Guide to Dimensionality Reduction. Workshop on Visualization for AI Explainability (VISxAI) at IEEE VIS (2018). https://idyll.pub/post/dimensionality-reduction-293e465c2a3443e8941b016d/"},{"key":"e_1_3_2_1_16_1","doi-asserted-by":"crossref","unstructured":"Matthew Conlen and Fred Hohman. 2019. Launching the parametric press. (2019).  Matthew Conlen and Fred Hohman. 2019. Launching the parametric press. (2019).","DOI":"10.31219/osf.io/53uzt"},{"key":"e_1_3_2_1_17_1","volume-title":"Computer Graphics Forum, Vol. 38","author":"Conlen Matthew","unstructured":"Matthew Conlen , Alex Kale , and Jeffrey Heer . 2019. Capture & analysis of active reading behaviors for interactive articles on the web. In Computer Graphics Forum, Vol. 38 . Wiley Online Library , 687–698. Matthew Conlen, Alex Kale, and Jeffrey Heer. 2019. Capture & analysis of active reading behaviors for interactive articles on the web. In Computer Graphics Forum, Vol. 38. Wiley Online Library, 687–698."},{"key":"e_1_3_2_1_18_1","doi-asserted-by":"publisher","DOI":"10.1145/1753326.1753554"},{"key":"e_1_3_2_1_19_1","doi-asserted-by":"publisher","DOI":"10.1145/2207676.2208734"},{"key":"e_1_3_2_1_20_1","doi-asserted-by":"publisher","DOI":"10.1145/3290605.3300295"},{"key":"e_1_3_2_1_21_1","doi-asserted-by":"publisher","DOI":"10.1145/2047196.2047226"},{"key":"e_1_3_2_1_22_1","doi-asserted-by":"publisher","DOI":"10.1145/1866029.1866055"},{"key":"e_1_3_2_1_23_1","volume-title":"A description of think aloud method and protocol analysis. Qualitative health research 3, 4","author":"Fonteyn E","year":"1993","unstructured":"Marsha  E Fonteyn , Benjamin Kuipers , and Susan  J Grobe . 1993. A description of think aloud method and protocol analysis. Qualitative health research 3, 4 ( 1993 ), 430–441. Marsha E Fonteyn, Benjamin Kuipers, and Susan J Grobe. 1993. A description of think aloud method and protocol analysis. Qualitative health research 3, 4 (1993), 430–441."},{"key":"e_1_3_2_1_24_1","unstructured":"Ira R Forman Nate Forman and John Vlissides Ibm. 2004. Java reflection in action. (2004).  Ira R Forman Nate Forman and John Vlissides Ibm. 2004. Java reflection in action. (2004)."},{"key":"e_1_3_2_1_25_1","doi-asserted-by":"publisher","DOI":"10.1016/j.artint.2010.05.005"},{"key":"e_1_3_2_1_26_1","doi-asserted-by":"publisher","DOI":"10.1145/381641.381653"},{"key":"e_1_3_2_1_27_1","doi-asserted-by":"publisher","DOI":"10.1109/32.92911"},{"key":"e_1_3_2_1_28_1","doi-asserted-by":"publisher","DOI":"10.1080/21670811.2018.1488598"},{"key":"e_1_3_2_1_29_1","doi-asserted-by":"publisher","DOI":"10.1145/2984511.2984575"},{"key":"e_1_3_2_1_30_1","doi-asserted-by":"publisher","DOI":"10.1145/3180155.3180165"},{"key":"e_1_3_2_1_31_1","doi-asserted-by":"publisher","DOI":"10.23915/distill.00028"},{"key":"e_1_3_2_1_32_1","volume-title":"Visualization rhetoric: Framing effects in narrative visualization","author":"Hullman Jessica","year":"2011","unstructured":"Jessica Hullman and Nick Diakopoulos . 2011. Visualization rhetoric: Framing effects in narrative visualization . IEEE transactions on visualization and computer graphics 17, 12( 2011 ), 2231–2240. Jessica Hullman and Nick Diakopoulos. 2011. Visualization rhetoric: Framing effects in narrative visualization. IEEE transactions on visualization and computer graphics 17, 12(2011), 2231–2240."},{"key":"e_1_3_2_1_33_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2013.119"},{"key":"e_1_3_2_1_34_1","doi-asserted-by":"publisher","DOI":"10.1145/2642918.2647375"},{"key":"e_1_3_2_1_35_1","doi-asserted-by":"publisher","DOI":"10.1109/MS.2010.76"},{"key":"e_1_3_2_1_36_1","doi-asserted-by":"publisher","DOI":"10.1145/3025453.3025592"},{"key":"e_1_3_2_1_37_1","volume-title":"Track changes: A literary history of word processing","author":"Kirschenbaum G","unstructured":"Matthew  G Kirschenbaum . 2016. Track changes: A literary history of word processing . Harvard University Press . Matthew G Kirschenbaum. 2016. Track changes: A literary history of word processing. Harvard University Press."},{"key":"e_1_3_2_1_38_1","doi-asserted-by":"publisher","DOI":"10.1145/2807442.2807446"},{"key":"e_1_3_2_1_39_1","doi-asserted-by":"publisher","DOI":"10.1093/comjnl/27.2.97"},{"key":"e_1_3_2_1_40_1","volume-title":"Design requirements for more flexible structured editors","author":"Ko Amy","unstructured":"Amy Ko , Htet Htet Aung , and Brad  A Myers . 2005. Design requirements for more flexible structured editors from a study of programmers’ text editing. In CHI’ 05 extended abstracts on human factors in computing systems. 1557–1560. Amy Ko, Htet Htet Aung, and Brad A Myers. 2005. Design requirements for more flexible structured editors from a study of programmers’ text editing. In CHI’05 extended abstracts on human factors in computing systems. 1557–1560."},{"key":"e_1_3_2_1_41_1","doi-asserted-by":"publisher","DOI":"10.1145/1124772.1124831"},{"key":"e_1_3_2_1_42_1","volume-title":"Data Theater: A Live Programming Environment for Prototyping Data-Driven Explorable Explanations. In Workshop on Live Programming (LIVE).","author":"Lau Sam","year":"2020","unstructured":"Sam Lau and Philip  J Guo . 2020 . Data Theater: A Live Programming Environment for Prototyping Data-Driven Explorable Explanations. In Workshop on Live Programming (LIVE). Sam Lau and Philip J Guo. 2020. Data Theater: A Live Programming Environment for Prototyping Data-Driven Explorable Explanations. In Workshop on Live Programming (LIVE)."},{"key":"e_1_3_2_1_43_1","volume-title":"More than telling a story: Transforming data into visually shared stories","author":"Lee Bongshin","year":"2015","unstructured":"Bongshin Lee , Nathalie Henry Riche , Petra Isenberg , and Sheelagh Carpendale . 2015. More than telling a story: Transforming data into visually shared stories . IEEE computer graphics and applications 35, 5 ( 2015 ), 84–90. Bongshin Lee, Nathalie Henry Riche, Petra Isenberg, and Sheelagh Carpendale. 2015. More than telling a story: Transforming data into visually shared stories. IEEE computer graphics and applications 35, 5 (2015), 84–90."},{"key":"e_1_3_2_1_44_1","doi-asserted-by":"publisher","DOI":"10.1145/38807.38821"},{"key":"e_1_3_2_1_45_1","volume-title":"Psychology of learning and motivation. Vol. 41","author":"Mayer E","unstructured":"Richard  E Mayer . 2002. Multimedia learning . In Psychology of learning and motivation. Vol. 41 . Elsevier , 85–139. Richard E Mayer. 2002. Multimedia learning. In Psychology of learning and motivation. Vol. 41. Elsevier, 85–139."},{"key":"e_1_3_2_1_46_1","volume-title":"Computer Graphics Forum, Vol. 36","author":"McKenna Sean","unstructured":"Sean McKenna , N Henry Riche , Bongshin Lee , Jeremy Boy , and Miriah Meyer . 2017. Visual narrative flow: Exploring factors shaping data visualization story reading experiences . In Computer Graphics Forum, Vol. 36 . Wiley Online Library , 377–387. Sean McKenna, N Henry Riche, Bongshin Lee, Jeremy Boy, and Miriah Meyer. 2017. Visual narrative flow: Exploring factors shaping data visualization story reading experiences. In Computer Graphics Forum, Vol. 36. Wiley Online Library, 377–387."},{"key":"e_1_3_2_1_47_1","doi-asserted-by":"publisher","DOI":"10.1109/MC.2004.48"},{"key":"e_1_3_2_1_48_1","unstructured":"Graham McNeill and S Hale. 2019. Viz-Blocks: Building Visualizations and Documents in the Browser. (2019).  Graham McNeill and S Hale. 2019. Viz-Blocks: Building Visualizations and Documents in the Browser. (2019)."},{"key":"e_1_3_2_1_49_1","doi-asserted-by":"publisher","DOI":"10.1109/BLOCKS.2015.7369001"},{"key":"e_1_3_2_1_50_1","doi-asserted-by":"publisher","DOI":"10.1145/344949.344959"},{"key":"e_1_3_2_1_51_1","volume-title":"Stretchtext – hypertext note #8. Project Xanadu","author":"Nelson Ted","year":"1967","unstructured":"Ted Nelson . 1967. Stretchtext – hypertext note #8. Project Xanadu ( 1967 ). Ted Nelson. 1967. Stretchtext – hypertext note #8. Project Xanadu (1967)."},{"key":"e_1_3_2_1_52_1","unstructured":"Observable 2018. Observable. https://observablehq.com/.  Observable 2018. Observable. https://observablehq.com/."},{"key":"e_1_3_2_1_53_1","doi-asserted-by":"publisher","DOI":"10.1145/2509578.2509590"},{"key":"e_1_3_2_1_54_1","doi-asserted-by":"publisher","DOI":"10.1145/302979.303038"},{"key":"e_1_3_2_1_55_1","volume-title":"IPython: a system for interactive scientific computing. Computing in science & engineering 9, 3","author":"Pérez Fernando","year":"2007","unstructured":"Fernando Pérez and Brian  E Granger . 2007. IPython: a system for interactive scientific computing. Computing in science & engineering 9, 3 ( 2007 ), 21–29. Fernando Pérez and Brian E Granger. 2007. IPython: a system for interactive scientific computing. Computing in science & engineering 9, 3 (2007), 21–29."},{"key":"e_1_3_2_1_56_1","volume-title":"Why Jupyter is data scientists","author":"Perkel M","year":"2018","unstructured":"Jeffrey  M Perkel . 2018. Why Jupyter is data scientists ’ computational notebook of choice.Nature 563, 7732 ( 2018 ), 145–147. Jeffrey M Perkel. 2018. Why Jupyter is data scientists’ computational notebook of choice.Nature 563, 7732 (2018), 145–147."},{"key":"e_1_3_2_1_57_1","volume-title":"Proceedings of the International Conference. 200–312","author":"Quint Vincent","year":"1986","unstructured":"Vincent Quint and Irene Vatton . 1986 . Grif: An interactive system for structured document manipulation. In Text Processing and Document Manipulation , Proceedings of the International Conference. 200–312 . Vincent Quint and Irene Vatton. 1986. Grif: An interactive system for structured document manipulation. In Text Processing and Document Manipulation, Proceedings of the International Conference. 200–312."},{"key":"e_1_3_2_1_58_1","doi-asserted-by":"publisher","DOI":"10.1145/3126594.3126642"},{"key":"e_1_3_2_1_59_1","volume-title":"Processing: a programming handbook for visual designers and artists","author":"Reas Casey","unstructured":"Casey Reas and Ben Fry . 2007. Processing: a programming handbook for visual designers and artists . Mit Press . Casey Reas and Ben Fry. 2007. Processing: a programming handbook for visual designers and artists. Mit Press."},{"key":"e_1_3_2_1_60_1","doi-asserted-by":"publisher","DOI":"10.1145/3173574.3173606"},{"key":"e_1_3_2_1_61_1","volume-title":"Computer Graphics Forum, Vol. 33","author":"Satyanarayan Arvind","unstructured":"Arvind Satyanarayan and Jeffrey Heer . 2014. Authoring narrative visualizations with ellipsis . In Computer Graphics Forum, Vol. 33 . Wiley Online Library , 361–370. Arvind Satyanarayan and Jeffrey Heer. 2014. Authoring narrative visualizations with ellipsis. In Computer Graphics Forum, Vol. 33. Wiley Online Library, 361–370."},{"key":"e_1_3_2_1_62_1","volume-title":"Lyra: An interactive visualization design environment. In Computer Graphics Forum, Vol. 33","author":"Satyanarayan Arvind","year":"2014","unstructured":"Arvind Satyanarayan and Jeffrey Heer . 2014 . Lyra: An interactive visualization design environment. In Computer Graphics Forum, Vol. 33 . Wiley Online Library , 351–360. Arvind Satyanarayan and Jeffrey Heer. 2014. Lyra: An interactive visualization design environment. In Computer Graphics Forum, Vol. 33. Wiley Online Library, 351–360."},{"key":"e_1_3_2_1_63_1","volume-title":"Vega-Lite: A Grammar of Interactive Graphics","author":"Satyanarayan Arvind","year":"2017","unstructured":"Arvind Satyanarayan , Dominik Moritz , Kanit Wongsuphasawat , and Jeffrey Heer . 2017. Vega-Lite: A Grammar of Interactive Graphics . IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis) ( 2017 ). http://idl.cs.washington.edu/papers/vega-lite Arvind Satyanarayan, Dominik Moritz, Kanit Wongsuphasawat, and Jeffrey Heer. 2017. Vega-Lite: A Grammar of Interactive Graphics. IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis) (2017). http://idl.cs.washington.edu/papers/vega-lite"},{"key":"e_1_3_2_1_64_1","volume-title":"Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization","author":"Satyanarayan Arvind","year":"2016","unstructured":"Arvind Satyanarayan , Ryan Russell , Jane Hoffswell , and Jeffrey Heer . 2016 . Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization . IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis) ( 2016). http://idl.cs.washington.edu/papers/reactive-vega-architecture Arvind Satyanarayan, Ryan Russell, Jane Hoffswell, and Jeffrey Heer. 2016. Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization. IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis) (2016). http://idl.cs.washington.edu/papers/reactive-vega-architecture"},{"key":"e_1_3_2_1_65_1","unstructured":"Toby Schachman and Joshua Horowitz. 2016. Apparatus. https://github.com/cdglabs.  Toby Schachman and Joshua Horowitz. 2016. Apparatus. https://github.com/cdglabs."},{"key":"e_1_3_2_1_66_1","doi-asserted-by":"publisher","DOI":"10.17645/mac.v8i1.2507"},{"key":"e_1_3_2_1_67_1","volume-title":"Narrative visualization: Telling stories with data","author":"Segel Edward","year":"2010","unstructured":"Edward Segel and Jeffrey Heer . 2010. Narrative visualization: Telling stories with data . IEEE transactions on visualization and computer graphics 16, 6( 2010 ), 1139–1148. Edward Segel and Jeffrey Heer. 2010. Narrative visualization: Telling stories with data. IEEE transactions on visualization and computer graphics 16, 6(2010), 1139–1148."},{"key":"e_1_3_2_1_69_1","volume-title":"Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories","author":"Stolper D","year":"2016","unstructured":"Charles  D Stolper , Bongshin Lee , N Henry Riche , and John Stasko . 2016. Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories . Microsoft Research , Washington, USA( 2016 ). Charles D Stolper, Bongshin Lee, N Henry Riche, and John Stasko. 2016. Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories. Microsoft Research, Washington, USA(2016)."},{"key":"e_1_3_2_1_70_1","volume-title":"Psychology of learning and motivation. Vol. 55","author":"Sweller John","unstructured":"John Sweller . 2011. Cognitive load theory . In Psychology of learning and motivation. Vol. 55 . Elsevier , 37–76. John Sweller. 2011. Cognitive load theory. In Psychology of learning and motivation. Vol. 55. Elsevier, 37–76."},{"key":"e_1_3_2_1_71_1","doi-asserted-by":"publisher","DOI":"10.1145/358746.358755"},{"key":"e_1_3_2_1_72_1","doi-asserted-by":"publisher","DOI":"10.1145/253671.253708"},{"key":"e_1_3_2_1_73_1","unstructured":"Bret Victor. 2011. Explorable Explorations. Retrieved March 1 2021 from http://worrydream.com/ExplorableExplanations/  Bret Victor. 2011. Explorable Explorations. Retrieved March 1 2021 from http://worrydream.com/ExplorableExplanations/"},{"key":"e_1_3_2_1_74_1","volume-title":"Tangle: a JavaScript library for reactive documents. Retrieved","author":"Victor Bret","year":"2017","unstructured":"Bret Victor . 2011. Tangle: a JavaScript library for reactive documents. Retrieved August 1, 2017 from http://worrydream.com/Tangle/ Bret Victor. 2011. Tangle: a JavaScript library for reactive documents. Retrieved August 1, 2017 from http://worrydream.com/Tangle/"},{"key":"e_1_3_2_1_75_1","volume-title":"Mind in society: The development of higher psychological processes","author":"Vygotsky Lev Semenovich","unstructured":"Lev Semenovich Vygotsky . 1980. Mind in society: The development of higher psychological processes . Harvard university press . Lev Semenovich Vygotsky. 1980. Mind in society: The development of higher psychological processes. Harvard university press."},{"key":"e_1_3_2_1_76_1","doi-asserted-by":"publisher","DOI":"10.1145/3359141"},{"key":"e_1_3_2_1_77_1","volume-title":"Computer Graphics Forum, Vol. 38","author":"Zhi Qiyu","unstructured":"Qiyu Zhi , Alvitta Ottley , and Ronald Metoyer . 2019. Linking and layout: Exploring the integration of text and visualization in storytelling . In Computer Graphics Forum, Vol. 38 . Wiley Online Library , 675–685. Qiyu Zhi, Alvitta Ottley, and Ronald Metoyer. 2019. Linking and layout: Exploring the integration of text and visualization in storytelling. In Computer Graphics Forum, Vol. 38. Wiley Online Library, 675–685."},{"key":"e_1_3_2_1_78_1","volume-title":"Lyra 2: Designing interactive visualizations by demonstration","author":"Zong Jonathan","year":"2020","unstructured":"Jonathan Zong , Dhiraj Barnwal , Rupayan Neogy , and Arvind Satyanarayan . 2020. Lyra 2: Designing interactive visualizations by demonstration . IEEE Transactions on Visualization and Computer Graphics ( 2020 ). Jonathan Zong, Dhiraj Barnwal, Rupayan Neogy, and Arvind Satyanarayan. 2020. Lyra 2: Designing interactive visualizations by demonstration. IEEE Transactions on Visualization and Computer Graphics (2020)."}],"event":"UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology","container-title":"The 34th Annual ACM Symposium on User Interface Software and Technology","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/3472749.3474731","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,1,9]],"date-time":"2023-01-09T07:52:38Z","timestamp":1673250758000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/3472749.3474731"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2021,10,10]]},"references-count":77,"alternative-id":["10.1145/3472749.3474731","10.1145/3472749"],"URL":"http://dx.doi.org/10.1145/3472749.3474731","relation":{},"published":{"date-parts":[[2021,10,10]]},"assertion":[{"value":"2021-10-12","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/3472749.3474731"},{"type":"article","id":"doi:10.48550/arXiv.2205.09858","categories":["Human-Computer Interaction (cs.HC)","FOS: Computer and information sciences","FOS: Computer and information sciences"],"author":[{"family":"Conlen","given":"Matthew"},{"family":"Heer","given":"Jeffrey"}],"issued":{"date-parts":[[2022]]},"abstract":"Narrative visualization is a powerful communicative tool that can take on various formats such as interactive articles, slideshows, and data videos. These formats each have their strengths and weaknesses, but existing authoring tools only support one output target. We conducted a series of formative interviews with seven domain experts to understand needs and practices around cross-format data stories, and developed Fidyll, a cross-format compiler for authoring interactive data stories and explorable explanations. Our open-source tool can be used to rapidly create formats including static articles, low-motion articles, interactive articles, slideshows, and videos. We evaluate our system through a series of real-world usage scenarios, showing how it benefits authors in the domains of data journalism, scientific publishing, and nonprofit advocacy. We show how Fidyll, provides expressive leverage by reducing the amount of non-narrative markup that authors need to write by 80-90% compared to Idyll, an existing markup language for authoring interactive articles.","DOI":"10.48550/ARXIV.2205.09858","publisher":"arXiv","title":"Fidyll: A Compiler for Cross-Format Data Stories &amp; Explorable Explanations","URL":"https://arxiv.org/abs/2205.09858","copyright":"Creative Commons Attribution 4.0 International","version":"1"},{"author":[{"given":"Will","family":"Crichton"}],"type":"document","id":"nota","citation-key":"nota","issued":{"date-parts":[[2023]]},"title":"A New Medium for Communicating Research on Programming Languages","URL":"https://willcrichton.net/nota/"},{"author":[{"family":"Curvenote"}],"type":"document","id":"curvenote","citation-key":"curvenote","issued":{"date-parts":[[2023]]},"URL":"https://curvenote.com/"},{"indexed":{"date-parts":[[2023,10,12]],"date-time":"2023-10-12T02:48:30Z","timestamp":1697078910463},"publisher-location":"New York, NY, USA","reference-count":101,"publisher":"ACM","license":[{"start":{"date-parts":[[2019,5,2]],"date-time":"2019-05-02T00:00:00Z","timestamp":1556755200000},"content-version":"vor","delay-in-days":0,"URL":"http://www.acm.org/publications/policies/copyright_policy#Background"}],"content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2019,5,2]]},"DOI":"10.1145/3290605.3300295","type":"proceedings-article","created":{"date-parts":[[2019,4,29]],"date-time":"2019-04-29T17:04:32Z","timestamp":1556557472000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":57,"title":"Increasing the Transparency of Research Papers with Explorable Multiverse Analyses","prefix":"10.1145","author":[{"given":"Pierre","family":"Dragicevic","sequence":"first","affiliation":[{"name":"Inria, Saclay, France"}]},{"given":"Yvonne","family":"Jansen","sequence":"additional","affiliation":[{"name":"CNRS - Sorbonne Université, Paris, France"}]},{"given":"Abhraneel","family":"Sarma","sequence":"additional","affiliation":[{"name":"University of Michigan, Ann Arbor, MI, USA"}]},{"given":"Matthew","family":"Kay","sequence":"additional","affiliation":[{"name":"University of Michigan, Ann Arbor, MI, USA"}]},{"given":"Fanny","family":"Chevalier","sequence":"additional","affiliation":[{"name":"University of Toronto, Toronto, ON, Canada"}]}],"member":"320","published-online":{"date-parts":[[2019,5,2]]},"reference":[{"key":"e_1_3_2_1_1_1","unstructured":"{n. d.}. Distill. https://distill.pub/. Accessed: 2018-09--15.  {n. d.}. Distill. https://distill.pub/. Accessed: 2018-09--15."},{"key":"e_1_3_2_1_2_1","unstructured":"{n. d.}. Jupyter. http://jupyter.org/. Accessed: 2018-09--15.  {n. d.}. Jupyter. http://jupyter.org/. Accessed: 2018-09--15."},{"key":"e_1_3_2_1_3_1","unstructured":"{n. d.}. R Markdown Gallery. https://rmarkdown.rstudio.com/gallery. html. Accessed: 2018-09--15.  {n. d.}. R Markdown Gallery. https://rmarkdown.rstudio.com/gallery. html. Accessed: 2018-09--15."},{"key":"e_1_3_2_1_4_1","unstructured":"{n. d.}. Radix for R Markdown. https://rstudio.github.io/radix/. Accessed: 2018-09--16.  {n. d.}. Radix for R Markdown. https://rstudio.github.io/radix/. Accessed: 2018-09--16."},{"key":"e_1_3_2_1_5_1","unstructured":"{n. d.}. Shiny. https://shiny.rstudio.com/. Accessed: 2018-09--15.  {n. d.}. Shiny. https://shiny.rstudio.com/. Accessed: 2018-09--15."},{"key":"e_1_3_2_1_6_1","doi-asserted-by":"publisher","DOI":"10.5555/3183947.3183950"},{"key":"e_1_3_2_1_7_1","doi-asserted-by":"publisher","DOI":"10.3998/3336451.0018.201"},{"key":"e_1_3_2_1_8_1","volume-title":"The Publication manual of the APA","author":"APA.","unstructured":"APA. 2010. The Publication manual of the APA ( 6 th ed.). Washington , DC. APA. 2010. The Publication manual of the APA (6th ed.). Washington, DC.","edition":"6"},{"key":"e_1_3_2_1_9_1","unstructured":"Christie Aschwanden. 2015. Science is not broken. https:// fivethirtyeight.com/features/science-isnt-broken/. Accessed: 201809--15.  Christie Aschwanden. 2015. Science is not broken. https:// fivethirtyeight.com/features/science-isnt-broken/. Accessed: 201809--15."},{"key":"e_1_3_2_1_10_1","volume-title":"Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading","author":"Badam Sriram Karthik","year":"2019","unstructured":"Sriram Karthik Badam , Zhicheng Liu , and Niklas Elmqvist . 2019 . Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading . IEEE Transactions on Visualization & Computer Graphics ( 2019). http://www.umiacs. umd.edu/~elm/projects/elastic-documents/elastic-documents.pdf Sriram Karthik Badam, Zhicheng Liu, and Niklas Elmqvist. 2019. Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading. IEEE Transactions on Visualization & Computer Graphics (2019). http://www.umiacs. umd.edu/~elm/projects/elastic-documents/elastic-documents.pdf"},{"key":"e_1_3_2_1_11_1","doi-asserted-by":"publisher","DOI":"10.1016/j.newast.2008.03.008"},{"key":"e_1_3_2_1_12_1","doi-asserted-by":"publisher","DOI":"10.1145/642611.642695"},{"key":"e_1_3_2_1_13_1","doi-asserted-by":"publisher","DOI":"10.1145/1166253.1166280"},{"key":"e_1_3_2_1_14_1","doi-asserted-by":"publisher","DOI":"10.1145/332040.332473"},{"key":"e_1_3_2_1_15_1","doi-asserted-by":"publisher","DOI":"10.1038/s41562-017-0189-z"},{"key":"e_1_3_2_1_17_1","doi-asserted-by":"publisher","DOI":"10.1093/jnci/djs301"},{"key":"e_1_3_2_1_18_1","doi-asserted-by":"publisher","DOI":"10.1145/1166253.1166279"},{"key":"e_1_3_2_1_19_1","doi-asserted-by":"publisher","DOI":"10.1111/j.1751-5823.1997.tb00399.x"},{"key":"e_1_3_2_1_20_1","unstructured":"Leen Breure Hans Voorbij and Maarten Hoogerwerf. {n. d.}. Rich Internet Publications:\" Show What You Tell\". Journal of Digital Information 12 1 ({n. d.}).  Leen Breure Hans Voorbij and Maarten Hoogerwerf. {n. d.}. Rich Internet Publications:\" Show What You Tell\". Journal of Digital Information 12 1 ({n. d.})."},{"key":"e_1_3_2_1_21_1","volume-title":"Wavelets and statistics","author":"Buckheit Jonathan B","unstructured":"Jonathan B Buckheit and David L Donoho . 1995. Wavelab and reproducible research . In Wavelets and statistics . Springer , 55--81. Jonathan B Buckheit and David L Donoho. 1995. Wavelab and reproducible research. In Wavelets and statistics. Springer, 55--81."},{"key":"e_1_3_2_1_22_1","volume-title":"Amy JC Cuddy, and Andy J Yap","author":"Carney Dana R","year":"2010","unstructured":"Dana R Carney , Amy JC Cuddy, and Andy J Yap . 2010 . Power posing: Brief nonverbal displays affect neuroendocrine levels and risk tolerance. Psychological science 21, 10 (2010), 1363--1368. Dana R Carney, Amy JC Cuddy, and Andy J Yap. 2010. Power posing: Brief nonverbal displays affect neuroendocrine levels and risk tolerance. Psychological science 21, 10 (2010), 1363--1368."},{"key":"e_1_3_2_1_23_1","doi-asserted-by":"publisher","DOI":"10.1145/1753326.1753427"},{"key":"e_1_3_2_1_24_1","doi-asserted-by":"publisher","DOI":"10.1145/3173574.3173715"},{"key":"e_1_3_2_1_25_1","doi-asserted-by":"publisher","DOI":"10.1145/3242587.3242600"},{"key":"e_1_3_2_1_26_1","unstructured":"Geoff Cumming. {n. d.}. Exploratory Software for Confidence Intervals. https://thenewstatistics.com/itns/esci/. Accessed: 2018-09--15.  Geoff Cumming. {n. d.}. Exploratory Software for Confidence Intervals. https://thenewstatistics.com/itns/esci/. Accessed: 2018-09--15."},{"key":"e_1_3_2_1_27_1","volume-title":"Proceedings of the Sixth International Conference on Teaching of Statistics, Cape Town. Voorburg","author":"Cumming Geoff","year":"2002","unstructured":"Geoff Cumming . 2002 . Live figures: Interactive diagrams for statistical understanding . In Proceedings of the Sixth International Conference on Teaching of Statistics, Cape Town. Voorburg , The Netherlands: International Statistical Institute. Geoff Cumming. 2002. Live figures: Interactive diagrams for statistical understanding. In Proceedings of the Sixth International Conference on Teaching of Statistics, Cape Town. Voorburg, The Netherlands: International Statistical Institute."},{"key":"e_1_3_2_1_28_1","unstructured":"Geoff Cumming. 2009. The dance of p-values (video). https://www. youtube.com/watch?v=ez4DgdurRPg  Geoff Cumming. 2009. The dance of p-values (video). https://www. youtube.com/watch?v=ez4DgdurRPg"},{"key":"e_1_3_2_1_29_1","doi-asserted-by":"publisher","DOI":"10.1177/0956797613504966"},{"key":"e_1_3_2_1_30_1","doi-asserted-by":"publisher","DOI":"10.1037/0003-066X.60.2.170"},{"key":"e_1_3_2_1_31_1","volume-title":"Fair statistical communication in HCI","author":"Dragicevic Pierre","unstructured":"Pierre Dragicevic . 2016. Fair statistical communication in HCI . In Modern Statistical Methods for HCI. Springer , 291--330. Pierre Dragicevic. 2016. Fair statistical communication in HCI. In Modern Statistical Methods for HCI. Springer, 291--330."},{"key":"e_1_3_2_1_32_1","volume-title":"Statistical Dances: Why no Statistical Analysis is Reliable and What to do About it (video). https: //www.youtube.com/watch?v=UKX9iN0p5_A","author":"Dragicevic Pierre","year":"2017","unstructured":"Pierre Dragicevic . 2017 . Statistical Dances: Why no Statistical Analysis is Reliable and What to do About it (video). https: //www.youtube.com/watch?v=UKX9iN0p5_A Pierre Dragicevic. 2017. Statistical Dances: Why no Statistical Analysis is Reliable and What to do About it (video). https: //www.youtube.com/watch?v=UKX9iN0p5_A"},{"key":"e_1_3_2_1_33_1","unstructured":"Pierre Dragicevic. 2018. Adding Inferential Information to Plots using Resampling and Animations. (2018). https://explorablemultiverse. github.io/examples/dance/  Pierre Dragicevic. 2018. Adding Inferential Information to Plots using Resampling and Animations. (2018). https://explorablemultiverse. github.io/examples/dance/"},{"key":"e_1_3_2_1_34_1","unstructured":"Pierre Dragicevic. 2018. An Explorable Multiverse Analysis of Durante et al. (2013). (2018). https://explorablemultiverse.github.io/ examples/dataverse/  Pierre Dragicevic. 2018. An Explorable Multiverse Analysis of Durante et al. (2013). (2018). https://explorablemultiverse.github.io/ examples/dataverse/"},{"key":"e_1_3_2_1_35_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2017.2744298"},{"key":"e_1_3_2_1_36_1","unstructured":"Pierre Dragicevic and Yvonne Jansen. 2018. Re-Evaluating the Efficiency of Physical Visualizations: A Simple Multiverse Analysis. (2018). https://explorablemultiverse.github.io/examples/frequentist/  Pierre Dragicevic and Yvonne Jansen. 2018. Re-Evaluating the Efficiency of Physical Visualizations: A Simple Multiverse Analysis. (2018). https://explorablemultiverse.github.io/examples/frequentist/"},{"key":"e_1_3_2_1_37_1","doi-asserted-by":"publisher","DOI":"10.1145/1357054.1357096"},{"key":"e_1_3_2_1_38_1","doi-asserted-by":"publisher","DOI":"10.1177/0956797612466416"},{"key":"e_1_3_2_1_39_1","volume-title":"Breakthroughs in statistics","author":"Efron Bradley","unstructured":"Bradley Efron . 1992. Bootstrap methods: another look at the jackknife . In Breakthroughs in statistics . Springer , 569--593. Bradley Efron. 1992. Bootstrap methods: another look at the jackknife. In Breakthroughs in statistics. Springer, 569--593."},{"key":"e_1_3_2_1_40_1","unstructured":"Andrew Gelman and Eric Loken. 2013. The garden of forking paths: Why multiple comparisons can be a problem even when there is no \"fishing expedition\" or \"p-hacking\" and the research hypothesis was posited ahead of time. Department of Statistics Columbia University (2013).  Andrew Gelman and Eric Loken. 2013. The garden of forking paths: Why multiple comparisons can be a problem even when there is no \"fishing expedition\" or \"p-hacking\" and the research hypothesis was posited ahead of time. Department of Statistics Columbia University (2013)."},{"key":"e_1_3_2_1_41_1","doi-asserted-by":"publisher","DOI":"10.1198/106186007X178663"},{"key":"e_1_3_2_1_42_1","doi-asserted-by":"publisher","DOI":"10.1177/1745691612457576"},{"key":"e_1_3_2_1_43_1","doi-asserted-by":"publisher","DOI":"10.1080/1047840X.2012.706506"},{"key":"e_1_3_2_1_44_1","volume-title":"The data journalism handbook: How journalists can use data to improve the news. \" O'Reilly Media","author":"Gray Jonathan","unstructured":"Jonathan Gray , Lucy Chambers , and Liliana Bounegru . 2012. The data journalism handbook: How journalists can use data to improve the news. \" O'Reilly Media , Inc .\". Jonathan Gray, Lucy Chambers, and Liliana Bounegru. 2012. The data journalism handbook: How journalists can use data to improve the news. \" O'Reilly Media, Inc.\"."},{"key":"e_1_3_2_1_45_1","volume-title":"Bridgesampling: an r package for estimating normalizing constants. arXiv preprint arXiv:1710.08162","author":"Gronau Quentin F","year":"2017","unstructured":"Quentin F Gronau , Henrik Singmann , and Eric-Jan Wagenmakers . 2017. Bridgesampling: an r package for estimating normalizing constants. arXiv preprint arXiv:1710.08162 ( 2017 ). Quentin F Gronau, Henrik Singmann, and Eric-Jan Wagenmakers. 2017. Bridgesampling: an r package for estimating normalizing constants. arXiv preprint arXiv:1710.08162 (2017)."},{"key":"e_1_3_2_1_46_1","doi-asserted-by":"publisher","DOI":"10.1080/23743603.2017.1326760"},{"key":"e_1_3_2_1_47_1","doi-asserted-by":"publisher","DOI":"10.1145/2949762"},{"key":"e_1_3_2_1_48_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2014.2346979"},{"key":"e_1_3_2_1_49_1","unstructured":"James Heathers. 2017. Life In The Tinderbox. Online. https://medium. com/@jamesheathers/life-in-the-tinderbox-6b2e9760f3aa.  James Heathers. 2017. Life In The Tinderbox. Online. https://medium. com/@jamesheathers/life-in-the-tinderbox-6b2e9760f3aa."},{"key":"e_1_3_2_1_50_1","doi-asserted-by":"publisher","DOI":"10.1371/journal.pone.0142444"},{"key":"e_1_3_2_1_51_1","doi-asserted-by":"publisher","DOI":"10.1145/2470654.2481359"},{"key":"e_1_3_2_1_52_1","doi-asserted-by":"publisher","DOI":"10.1145/3173574.3173588"},{"key":"e_1_3_2_1_53_1","volume-title":"Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data","author":"Kale Alex","year":"2018","unstructured":"Alex Kale , Francis Nguyen , Matthew Kay , and Jessica Hullman . 2018. Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data . IEEE transactions on visualization and computer graphics ( 2018 ). Alex Kale, Francis Nguyen, Matthew Kay, and Jessica Hullman. 2018. Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data. IEEE transactions on visualization and computer graphics (2018)."},{"key":"e_1_3_2_1_54_1","doi-asserted-by":"publisher","DOI":"10.1145/1753326.1753686"},{"key":"e_1_3_2_1_55_1","unstructured":"Matthew Kay and Pierre Dragicevic. 2018. A Multiverse Reanalysis of Likert-Type Responses. (2018). https://explorablemultiverse.github. io/examples/likert/  Matthew Kay and Pierre Dragicevic. 2018. A Multiverse Reanalysis of Likert-Type Responses. (2018). https://explorablemultiverse.github. io/examples/likert/"},{"key":"e_1_3_2_1_56_1","doi-asserted-by":"publisher","DOI":"10.1145/2851581.2886442"},{"key":"e_1_3_2_1_57_1","doi-asserted-by":"publisher","DOI":"10.1145/3027063.3027084"},{"key":"e_1_3_2_1_58_1","doi-asserted-by":"publisher","DOI":"10.1145/2858036.2858465"},{"key":"e_1_3_2_1_59_1","volume-title":"BootES: An R package for bootstrap confidence intervals on effect sizes. Behavior research methods 45, 4","author":"Kirby Kris N","year":"2013","unstructured":"Kris N Kirby and Daniel Gerlanc . 2013. BootES: An R package for bootstrap confidence intervals on effect sizes. Behavior research methods 45, 4 ( 2013 ), 905--927. Kris N Kirby and Daniel Gerlanc. 2013. BootES: An R package for bootstrap confidence intervals on effect sizes. Behavior research methods 45, 4 (2013), 905--927."},{"key":"e_1_3_2_1_60_1","doi-asserted-by":"publisher","DOI":"10.1093/comjnl/27.2.97"},{"key":"e_1_3_2_1_61_1","volume-title":"Executable papers in computer science go live on ScienceDirect. Available at)(Accessed","author":"Koers Hylke","year":"2018","unstructured":"Hylke Koers , Ann Gabriel , and Rebecca Capone . 2013. Executable papers in computer science go live on ScienceDirect. Available at)(Accessed August 6, 2018 ) ElsevierConnect ( 2013). Hylke Koers, Ann Gabriel, and Rebecca Capone. 2013. Executable papers in computer science go live on ScienceDirect. Available at)(Accessed August 6, 2018) ElsevierConnect (2013)."},{"key":"e_1_3_2_1_62_1","doi-asserted-by":"publisher","DOI":"10.1016/j.procs.2011.04.068"},{"key":"e_1_3_2_1_63_1","unstructured":"Daniel Kunin Jingru Guo Tyler Dae Devlin and Daniel Xiang. {n. d.}. Seeing theory. https://students.brown.edu/seeing-theory/index.html. Accessed: 2018-09--15.  Daniel Kunin Jingru Guo Tyler Dae Devlin and Daniel Xiang. {n. d.}. Seeing theory. https://students.brown.edu/seeing-theory/index.html. Accessed: 2018-09--15."},{"key":"e_1_3_2_1_64_1","unstructured":"Kristoffer Magnusson. {n. d.}. R Psychologist. http://rpsychologist. com/d3/CI/. Accessed: 2018-09--15.  Kristoffer Magnusson. {n. d.}. R Psychologist. http://rpsychologist. com/d3/CI/. Accessed: 2018-09--15."},{"key":"e_1_3_2_1_65_1","doi-asserted-by":"publisher","DOI":"10.1016/j.immuni.2009.10.005"},{"key":"e_1_3_2_1_66_1","doi-asserted-by":"publisher","DOI":"10.1201/9781315372495"},{"key":"e_1_3_2_1_68_1","doi-asserted-by":"publisher","DOI":"10.1148/rg.323115152"},{"key":"e_1_3_2_1_69_1","doi-asserted-by":"publisher","DOI":"10.1038/s41562-016-0021"},{"key":"e_1_3_2_1_70_1","volume-title":"Psychology's renaissance. Annual review of psychology 69","author":"Nelson Leif D","year":"2018","unstructured":"Leif D Nelson , Joseph Simmons , and Uri Simonsohn . 2018. Psychology's renaissance. Annual review of psychology 69 ( 2018 ). Leif D Nelson, Joseph Simmons, and Uri Simonsohn. 2018. Psychology's renaissance. Annual review of psychology 69 (2018)."},{"key":"e_1_3_2_1_71_1","doi-asserted-by":"publisher","DOI":"10.1111/j.1751-5823.2007.00025.x"},{"key":"e_1_3_2_1_72_1","doi-asserted-by":"crossref","unstructured":"Brian A Nosek George Alter George C Banks Denny Borsboom Sara D Bowman Steven J Breckler Stuart Buck Christopher D Chambers Gilbert Chin Garret Christensen etal 2015. Promoting an open research culture. Science 348 6242 (2015) 1422--1425.  Brian A Nosek George Alter George C Banks Denny Borsboom Sara D Bowman Steven J Breckler Stuart Buck Christopher D Chambers Gilbert Chin Garret Christensen et al. 2015. Promoting an open research culture. Science 348 6242 (2015) 1422--1425.","DOI":"10.1126/science.aab2374"},{"key":"e_1_3_2_1_73_1","doi-asserted-by":"publisher","DOI":"10.1045/january2017-nuest"},{"key":"e_1_3_2_1_74_1","doi-asserted-by":"publisher","DOI":"10.1087/20110309"},{"key":"e_1_3_2_1_75_1","unstructured":"Victor Powell and Lewis Lehe. {n. d.}. Setosa. http://setosa.io/. Accessed: 2018-09--15.  Victor Powell and Lewis Lehe. {n. d.}. Setosa. http://setosa.io/. Accessed: 2018-09--15."},{"key":"e_1_3_2_1_76_1","doi-asserted-by":"publisher","DOI":"10.1109/CMV.2007.20"},{"key":"e_1_3_2_1_77_1","unstructured":"Anthony Rossini and Friedrich Leisch. 2003. Literate statistical practice. (2003).  Anthony Rossini and Friedrich Leisch. 2003. Literate statistical practice. (2003)."},{"key":"e_1_3_2_1_78_1","unstructured":"Abhraneel Sarma Yvonne Jansen and Matthew Kay. 2018. A Multiverse Analysis Considering Different Priors for Incidental Power Poses in HCI. (2018). https://explorablemultiverse.github.io/ examples/prior/  Abhraneel Sarma Yvonne Jansen and Matthew Kay. 2018. A Multiverse Analysis Considering Different Priors for Incidental Power Poses in HCI. (2018). https://explorablemultiverse.github.io/ examples/prior/"},{"key":"e_1_3_2_1_79_1","doi-asserted-by":"publisher","DOI":"10.1145/1753326.1753679"},{"key":"e_1_3_2_1_80_1","doi-asserted-by":"publisher","DOI":"10.1007/s001800200091"},{"key":"e_1_3_2_1_81_1","doi-asserted-by":"publisher","DOI":"10.1145/274644.274680"},{"key":"e_1_3_2_1_82_1","volume-title":"Visual parameter space analysis: A conceptual framework. Visualization and Computer Graphics","author":"Sedlmair Michael","year":"2014","unstructured":"Michael Sedlmair , Christoph Heinzl , Stefan Bruckner , Harald Piringer , and Torsten Möller . 2014. Visual parameter space analysis: A conceptual framework. Visualization and Computer Graphics , IEEE Transactions on 99 ( 2014 ). Michael Sedlmair, Christoph Heinzl, Stefan Bruckner, Harald Piringer, and Torsten Möller. 2014. Visual parameter space analysis: A conceptual framework. Visualization and Computer Graphics, IEEE Transactions on 99 (2014)."},{"key":"e_1_3_2_1_83_1","volume-title":"Adventures in semantic publishing: exemplar semantic enhancements of a research article. PLoS computational biology 5, 4","author":"Shotton David","year":"2009","unstructured":"David Shotton , Katie Portwin , Graham Klyne , and Alistair Miles . 2009. Adventures in semantic publishing: exemplar semantic enhancements of a research article. PLoS computational biology 5, 4 ( 2009 ), e1000361. David Shotton, Katie Portwin, Graham Klyne, and Alistair Miles. 2009. Adventures in semantic publishing: exemplar semantic enhancements of a research article. PLoS computational biology 5, 4 (2009), e1000361."},{"key":"e_1_3_2_1_84_1","volume-title":"Dan Martin, Pasquale Anselmi, Frederik Aust, Eli C Awtrey, Stepán Bahník, Feng Bai, Colin Bannard, Evelina Bonnier, et al.","author":"Silberzahn Raphael","year":"2017","unstructured":"Raphael Silberzahn , Eric Luis Uhlmann , Dan Martin, Pasquale Anselmi, Frederik Aust, Eli C Awtrey, Stepán Bahník, Feng Bai, Colin Bannard, Evelina Bonnier, et al. 2017 . Many analysts, one dataset: Making transparent how variations in analytical choices affect results. (2017). Raphael Silberzahn, Eric Luis Uhlmann, Dan Martin, Pasquale Anselmi, Frederik Aust, Eli C Awtrey, Stepán Bahník, Feng Bai, Colin Bannard, Evelina Bonnier, et al. 2017. Many analysts, one dataset: Making transparent how variations in analytical choices affect results. (2017)."},{"key":"e_1_3_2_1_85_1","volume-title":"Falsepositive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science 22, 11","author":"Simmons Joseph P","year":"2011","unstructured":"Joseph P Simmons , Leif D Nelson , and Uri Simonsohn . 2011. Falsepositive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science 22, 11 ( 2011 ), 1359--1366. Joseph P Simmons, Leif D Nelson, and Uri Simonsohn. 2011. Falsepositive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science 22, 11 (2011), 1359--1366."},{"key":"e_1_3_2_1_86_1","volume-title":"Specification Curve: Descriptive and Inferential Statistics on All Reasonable Specifications.","author":"Simonsohn Uri","year":"2015","unstructured":"Uri Simonsohn , Joseph P Simmons , and Leif D Nelson . 2015 . Specification Curve: Descriptive and Inferential Statistics on All Reasonable Specifications. (2015). Uri Simonsohn, Joseph P Simmons, and Leif D Nelson. 2015. Specification Curve: Descriptive and Inferential Statistics on All Reasonable Specifications. (2015)."},{"key":"e_1_3_2_1_87_1","doi-asserted-by":"publisher","DOI":"10.1177/1745691616658637"},{"key":"e_1_3_2_1_88_1","doi-asserted-by":"crossref","unstructured":"Rudolf J Strijkers Reginald Cushing Dmitry Vasyunin Cees de Laat Adam Belloum Robert J Meijer etal 2011. Toward Executable Scientific Publications.. In ICCS. 707--715.  Rudolf J Strijkers Reginald Cushing Dmitry Vasyunin Cees de Laat Adam Belloum Robert J Meijer et al. 2011. Toward Executable Scientific Publications.. In ICCS. 707--715.","DOI":"10.1016/j.procs.2011.04.074"},{"key":"e_1_3_2_1_89_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2009.139"},{"key":"e_1_3_2_1_90_1","doi-asserted-by":"publisher","DOI":"10.1098/rsta.2012.0090"},{"key":"e_1_3_2_1_91_1","volume-title":"RStan: the R interface to Stan. R package version 2, 1","author":"Team Stan Development","year":"2016","unstructured":"Stan Development Team . 2016. RStan: the R interface to Stan. R package version 2, 1 ( 2016 ). Stan Development Team. 2016. RStan: the R interface to Stan. R package version 2, 1 (2016)."},{"key":"e_1_3_2_1_92_1","doi-asserted-by":"publisher","DOI":"10.1016/j.websem.2010.04.001"},{"key":"e_1_3_2_1_93_1","doi-asserted-by":"publisher","DOI":"10.1006/ijhc.2002.1017"},{"key":"e_1_3_2_1_94_1","unstructured":"Bret Victor. 2011. Explorable Explanations. Online. http:// worrydream.com/ExplorableExplanations/.  Bret Victor. 2011. Explorable Explanations. Online. http:// worrydream.com/ExplorableExplanations/."},{"key":"e_1_3_2_1_95_1","unstructured":"Bret Victor. 2011. Scientific Communication As Sequential Art. Online. http://worrydream.com/ScientificCommunicationAsSequentialArt/.  Bret Victor. 2011. Scientific Communication As Sequential Art. Online. http://worrydream.com/ScientificCommunicationAsSequentialArt/."},{"key":"e_1_3_2_1_96_1","doi-asserted-by":"publisher","DOI":"10.1145/3170427.3185374"},{"key":"e_1_3_2_1_97_1","doi-asserted-by":"publisher","DOI":"10.1145/2702123.2702347"},{"key":"e_1_3_2_1_98_1","doi-asserted-by":"publisher","DOI":"10.3389/fpsyg.2016.01832"},{"key":"e_1_3_2_1_99_1","doi-asserted-by":"publisher","DOI":"10.1145/1978942.1978963"},{"key":"e_1_3_2_1_100_1","doi-asserted-by":"publisher","DOI":"10.1177/1094428105280059"},{"key":"e_1_3_2_1_101_1","doi-asserted-by":"publisher","DOI":"10.1145/2501988.2502036"},{"key":"e_1_3_2_1_102_1","doi-asserted-by":"publisher","DOI":"10.1145/276627.276633"},{"key":"e_1_3_2_1_103_1","doi-asserted-by":"publisher","DOI":"10.1145/513338.513353"}],"event":"CHI '19: CHI Conference on Human Factors in Computing Systems","container-title":"Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/3290605.3300295","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,1,9]],"date-time":"2023-01-09T13:34:42Z","timestamp":1673271282000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/3290605.3300295"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2019,5,2]]},"references-count":101,"alternative-id":["10.1145/3290605.3300295","10.1145/3290605"],"URL":"http://dx.doi.org/10.1145/3290605.3300295","relation":{},"published":{"date-parts":[[2019,5,2]]},"assertion":[{"value":"2019-05-02","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/3290605.3300295"},{"author":[{"given":"Emily","family":"Eisenberg"},{"given":"Sophie","family":"Alpert"}],"type":"document","id":"katex","citation-key":"katex","issued":{"date-parts":[[2023]]},"title":"KaTeX: The fastest math typesetting library for the web","URL":"https://katex.org"},{"type":"article-journal","id":"doi:10.48550/arXiv.2205.04561","categories":["Human-Computer Interaction (cs.HC)","FOS: Computer and information sciences","FOS: Computer and information sciences"],"author":[{"family":"Fok","given":"Raymond"},{"family":"Kambhamettu","given":"Hita"},{"family":"Soldaini","given":"Luca"},{"family":"Bragg","given":"Jonathan"},{"family":"Lo","given":"Kyle"},{"family":"Head","given":"Andrew"},{"family":"Hearst","given":"Marti A."},{"family":"Weld","given":"Daniel S."}],"issued":{"date-parts":[[2022]]},"abstract":"Researchers need to keep up with immense literatures, though it is time-consuming and difficult to do so. In this paper, we investigate the role that intelligent interfaces can play in helping researchers skim papers, that is, rapidly reviewing a paper to attain a cursory understanding of its contents. After conducting formative interviews and a design probe, we suggest that skimming aids should aim to thread the needle of highlighting content that is simultaneously diverse, evenly-distributed, and important. We introduce Scim, a novel intelligent skimming interface that reifies this aim, designed to support the skimming process by highlighting salient paper contents to direct a skimmer's focus. Key to the design is that the highlights are faceted by content type, evenly-distributed across a paper, with a density configurable by readers at both the global and local level. We evaluate Scim with an in-lab usability study and deployment study, revealing how skimming aids can support readers throughout the skimming experience and yielding design considerations and tensions for the design of future intelligent skimming tools.","container-title":"arXiv","DOI":"10.48550/ARXIV.2205.04561","publisher":"arXiv","title":"Scim: Intelligent Skimming Support for Scientific Papers","URL":"https://arxiv.org/abs/2205.04561","copyright":"Creative Commons Attribution 4.0 International","version":"3"},{"indexed":{"date-parts":[[2023,10,20]],"date-time":"2023-10-20T07:31:35Z","timestamp":1697787095829},"reference-count":106,"publisher":"American Association for the Advancement of Science (AAAS)","issue":"6379","funder":[{"DOI":"10.13039/100000052","name":"NIH Office of the Director","doi-asserted-by":"publisher","award":["P01 AG039347"]},{"DOI":"10.13039/100000052","name":"NIH Office of the Director","doi-asserted-by":"publisher","award":["U01CA198934"]},{"DOI":"10.13039/100000052","name":"NIH Office of the Director","doi-asserted-by":"publisher","award":["IIS-0910664"]},{"DOI":"10.13039/100000179","name":"NSF Office of the Director","doi-asserted-by":"publisher","award":["NCSE 1538763"]},{"DOI":"10.13039/100000179","name":"NSF Office of the Director","doi-asserted-by":"publisher","award":["EAGER1566393"]},{"DOI":"10.13039/100000181","name":"AFOSR","doi-asserted-by":"crossref","award":["FA9550-15-1-0077"]},{"DOI":"10.13039/501100000780","name":"European Commission","doi-asserted-by":"publisher","award":["641191"]},{"DOI":"10.13039/100000179","name":"NSF Office of the Director","doi-asserted-by":"publisher","award":["NCN CP Supplement 1553044"]},{"DOI":"10.13039/100000181","name":"AFOSR","doi-asserted-by":"crossref","award":["FA9550-15-1-0162"]},{"DOI":"10.13039/100000181","name":"AFOSR","doi-asserted-by":"crossref","award":["FA9550-17-1-0089"]},{"DOI":"10.13039/100000181","name":"AFOSR","doi-asserted-by":"crossref","award":["FA9550-15-1-0077"]},{"DOI":"10.13039/100000181","name":"Air Force Office of Scientific Research","doi-asserted-by":"publisher","award":["FA9550-15-1-0364"]},{"DOI":"10.13039/100000183","name":"Army Research Office","doi-asserted-by":"publisher","award":["W911NF-15-1-0577"]}],"content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2018,3,2]]},"abstract":"<jats:title>The whys and wherefores of SciSci</jats:title>\n          <jats:p>\n            The science of science (SciSci) is based on a transdisciplinary approach that uses large data sets to study the mechanisms underlying the doing of science—from the choice of a research problem to career trajectories and progress within a field. In a Review, Fortunato\n            <jats:italic>et al.</jats:italic>\n            explain that the underlying rationale is that with a deeper understanding of the precursors of impactful science, it will be possible to develop systems and policies that improve each scientist's ability to succeed and enhance the prospects of science as a whole.\n          </jats:p>\n          <jats:p>\n            <jats:italic>Science</jats:italic>\n            , this issue p.\n            <jats:related-article xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"doi\" related-article-type=\"in-this-issue\" xlink:href=\"10.1126/science.aao0185\">eaao0185</jats:related-article>\n          </jats:p>","DOI":"10.1126/science.aao0185","type":"journal-article","created":{"date-parts":[[2018,3,1]],"date-time":"2018-03-01T19:05:42Z","timestamp":1519931142000},"source":"Crossref","is-referenced-by-count":608,"title":"Science of science","prefix":"10.1126","volume":"359","author":[{"ORCID":"http://orcid.org/0000-0002-9039-4730","authenticated-orcid":true,"given":"Santo","family":"Fortunato","sequence":"first","affiliation":[{"name":"Center for Complex Networks and Systems Research, School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN 47408, USA."},{"name":"Indiana University Network Science Institute, Indiana University, Bloomington, IN 47408, USA."}]},{"given":"Carl T.","family":"Bergstrom","sequence":"additional","affiliation":[{"name":"Department of Biology, University of Washington, Seattle, WA 98195-1800, USA."}]},{"ORCID":"http://orcid.org/0000-0002-3321-6137","authenticated-orcid":true,"given":"Katy","family":"Börner","sequence":"additional","affiliation":[{"name":"Indiana University Network Science Institute, Indiana University, Bloomington, IN 47408, USA."},{"name":"Cyberinfrastructure for Network Science Center, School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN 47408, USA."}]},{"ORCID":"http://orcid.org/0000-0001-9838-0707","authenticated-orcid":true,"given":"James A.","family":"Evans","sequence":"additional","affiliation":[{"name":"Department of Sociology, University of Chicago, Chicago, IL 60637, USA."}]},{"given":"Dirk","family":"Helbing","sequence":"additional","affiliation":[{"name":"Computational Social Science, ETH Zurich, Zurich, Switzerland."}]},{"given":"Staša","family":"Milojević","sequence":"additional","affiliation":[{"name":"Center for Complex Networks and Systems Research, School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN 47408, USA."}]},{"ORCID":"http://orcid.org/0000-0002-0955-3483","authenticated-orcid":true,"given":"Alexander M.","family":"Petersen","sequence":"additional","affiliation":[{"name":"Ernest and Julio Gallo Management Program, School of Engineering, University of California, Merced, CA 95343, USA."}]},{"given":"Filippo","family":"Radicchi","sequence":"additional","affiliation":[{"name":"Center for Complex Networks and Systems Research, School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN 47408, USA."}]},{"ORCID":"http://orcid.org/0000-0002-7558-1028","authenticated-orcid":true,"given":"Roberta","family":"Sinatra","sequence":"additional","affiliation":[{"name":"Center for Network Science, Central European University, Budapest 1052, Hungary."},{"name":"Department of Mathematics, Central European University, Budapest 1051, Hungary."},{"name":"Institute for Network Science, Northeastern University, Boston, MA 02115, USA."}]},{"given":"Brian","family":"Uzzi","sequence":"additional","affiliation":[{"name":"Kellogg School of Management, Northwestern University, Evanston, IL 60208, USA."},{"name":"Northwestern Institute on Complex Systems, Northwestern University, Evanston, IL 60208, USA."}]},{"given":"Alessandro","family":"Vespignani","sequence":"additional","affiliation":[{"name":"Institute for Network Science, Northeastern University, Boston, MA 02115, USA."},{"name":"Laboratory for the Modeling of Biological and Sociotechnical Systems, Northeastern University, Boston, MA 02115, USA."},{"name":"ISI Foundation, Turin 10133, Italy."}]},{"ORCID":"http://orcid.org/0000-0001-8249-1752","authenticated-orcid":true,"given":"Ludo","family":"Waltman","sequence":"additional","affiliation":[{"name":"Centre for Science and Technology Studies, Leiden University, Leiden, Netherlands."}]},{"ORCID":"http://orcid.org/0000-0002-7054-2206","authenticated-orcid":true,"given":"Dashun","family":"Wang","sequence":"additional","affiliation":[{"name":"Kellogg School of Management, Northwestern University, Evanston, IL 60208, USA."},{"name":"Northwestern Institute on Complex Systems, Northwestern University, Evanston, IL 60208, USA."}]},{"ORCID":"http://orcid.org/0000-0002-4028-3522","authenticated-orcid":true,"given":"Albert-László","family":"Barabási","sequence":"additional","affiliation":[{"name":"Center for Network Science, Central European University, Budapest 1052, Hungary."},{"name":"Institute for Network Science, Northeastern University, Boston, MA 02115, USA."},{"name":"Center for Cancer Systems Biology, Dana-Farber Cancer Institute, Boston, MA 02115, USA."}]}],"member":"221","reference":[{"key":"e_1_3_2_2_2","doi-asserted-by":"publisher","DOI":"10.1126/science.122.3159.108"},{"key":"e_1_3_2_3_2","doi-asserted-by":"crossref","unstructured":"D. J. S. Price Little Science Big Science (Columbia Univ. Press 1963).","DOI":"10.7312/pric91844"},{"key":"e_1_3_2_4_2","doi-asserted-by":"crossref","first-page":"875","DOI":"10.1177/0003122415601618","article-title":"Tradition and innovation in scientists’ research strategies","volume":"80","author":"Foster J. G.","year":"2015","unstructured":"J. G. Foster, A. Rzhetsky, J. A. Evans, Tradition and innovation in scientists’ research strategies. Am. Sociol. Rev. 80, 875–908 (2015). 10.1177/0003122415601618","journal-title":"Am. Sociol. Rev."},{"key":"e_1_3_2_5_2","doi-asserted-by":"crossref","first-page":"962","DOI":"10.1016/j.joi.2015.10.005","article-title":"Quantifying the cognitive extent of science","volume":"9","author":"Milojević S.","year":"2015","unstructured":"S. Milojević, Quantifying the cognitive extent of science. J. Informetr. 9, 962–973 (2015). 10.1016/j.joi.2015.10.005","journal-title":"J. Informetr."},{"key":"e_1_3_2_6_2","first-page":"041036","article-title":"Inheritance patterns in citation networks reveal scientific memes","volume":"4","author":"Kuhn T.","year":"2014","unstructured":"T. Kuhn, M. Perc, D. Helbing, Inheritance patterns in citation networks reveal scientific memes. Phys. Rev. X 4, 041036 (2014). 10.1103/PhysRevX.4.041036","journal-title":"Phys. Rev. X"},{"key":"e_1_3_2_7_2","doi-asserted-by":"crossref","first-page":"984","DOI":"10.1002/asi.23734","article-title":"Which type of citation analysis generates the most accurate taxonomy of scientific and technical knowledge?","volume":"68","author":"Klavans R.","year":"2016","unstructured":"R. Klavans, K. W. Boyack, Which type of citation analysis generates the most accurate taxonomy of scientific and technical knowledge? J. Assoc. Inf. Sci. Technol. 68, 984–998 (2016). 10.1002/asi.23734","journal-title":"J. Assoc. Inf. Sci. Technol."},{"key":"e_1_3_2_8_2","doi-asserted-by":"crossref","first-page":"817","DOI":"10.1177/0003122410388488","article-title":"The temporal structure of scientific consensus formation","volume":"75","author":"Shwed U.","year":"2010","unstructured":"U. Shwed, P. S. Bearman, The temporal structure of scientific consensus formation. Am. Sociol. Rev. 75, 817–840 (2010). 10.1177/000312241038848821886269","journal-title":"Am. Sociol. Rev."},{"key":"e_1_3_2_9_2","doi-asserted-by":"crossref","first-page":"1050","DOI":"10.1177/0003122412463574","article-title":"Detecting communities through network data","volume":"77","author":"Bruggeman J.","year":"2012","unstructured":"J. Bruggeman, V. A. Traag, J. Uitermark, Detecting communities through network data. Am. Sociol. Rev. 77, 1050–1063 (2012). 10.1177/0003122412463574","journal-title":"Am. Sociol. Rev."},{"key":"e_1_3_2_10_2","doi-asserted-by":"crossref","first-page":"73","DOI":"10.1016/j.socnet.2015.02.006","article-title":"Weaving the fabric of science: Dynamic network models of science’s unfolding structure","volume":"43","author":"Shi F.","year":"2015","unstructured":"F. Shi, J. G. Foster, J. A. Evans, Weaving the fabric of science: Dynamic network models of science’s unfolding structure. Soc. Networks 43, 73–85 (2015). 10.1016/j.socnet.2015.02.006","journal-title":"Soc. Networks"},{"key":"e_1_3_2_11_2","doi-asserted-by":"crossref","first-page":"210","DOI":"10.1016/j.joi.2009.03.001","article-title":"Scientific discovery and topological transitions in collaboration networks","volume":"3","author":"Bettencourt L. M. A.","year":"2009","unstructured":"L. M. A. Bettencourt, D. I. Kaiser, J. Kaur, Scientific discovery and topological transitions in collaboration networks. J. Informetr. 3, 210–221 (2009). 10.1016/j.joi.2009.03.001","journal-title":"J. Informetr."},{"key":"e_1_3_2_12_2","doi-asserted-by":"crossref","first-page":"1069","DOI":"10.1038/srep01069","article-title":"Social dynamics of science","volume":"3","author":"Sun X.","year":"2013","unstructured":"X. Sun, J. Kaur, S. Milojević, A. Flammini, F. Menczer, Social dynamics of science. Sci. Rep. 3, 1069 (2013). 10.1038/srep0106923323212","journal-title":"Sci. Rep."},{"key":"e_1_3_2_13_2","doi-asserted-by":"crossref","unstructured":"T. S. Kuhn The Essential Tension: Selected Studies in Scientific Tradition and Change (Univ. of Chicago Press 1977).","DOI":"10.7208/chicago/9780226217239.001.0001"},{"key":"e_1_3_2_14_2","doi-asserted-by":"crossref","first-page":"19","DOI":"10.1177/053901847501400602","article-title":"The specificity of the scientific field and the social conditions of the progress of reasons","volume":"14","author":"Bourdieu P.","year":"1975","unstructured":"P. Bourdieu, The specificity of the scientific field and the social conditions of the progress of reasons. Soc. Sci. Inf. (Paris) 14, 19–47 (1975). 10.1177/053901847501400602","journal-title":"Soc. Sci. Inf. (Paris)"},{"key":"e_1_3_2_15_2","doi-asserted-by":"crossref","first-page":"0078","DOI":"10.1038/s41562-017-0078","article-title":"Quantifying patterns of research-interest evolution","volume":"1","author":"Jia T.","year":"2017","unstructured":"T. Jia, D. Wang, B. K. Szymanski, Quantifying patterns of research-interest evolution. Nat. Hum. Behav. 1, 0078 (2017). 10.1038/s41562-017-0078","journal-title":"Nat. Hum. Behav."},{"key":"e_1_3_2_16_2","doi-asserted-by":"crossref","first-page":"14569","DOI":"10.1073/pnas.1509757112","article-title":"Choosing experiments to accelerate collective discovery","volume":"112","author":"Rzhetsky A.","year":"2015","unstructured":"A. Rzhetsky, J. G. Foster, I. T. Foster, J. A. Evans, Choosing experiments to accelerate collective discovery. Proc. Natl. Acad. Sci. U.S.A. 112, 14569–14574 (2015). 10.1073/pnas.150975711226554009","journal-title":"Proc. Natl. Acad. Sci. U.S.A."},{"key":"e_1_3_2_17_2","doi-asserted-by":"publisher","DOI":"10.1037/0033-2909.86.3.638"},{"key":"e_1_3_2_18_2","doi-asserted-by":"crossref","first-page":"e21451","DOI":"10.7554/eLife.21451","article-title":"Publication bias and the canonization of false facts","volume":"5","author":"Nissen S. B.","year":"2016","unstructured":"S. B. Nissen, T. Magidson, K. Gross, C. T. Bergstrom, Publication bias and the canonization of false facts. eLife 5, e21451 (2016). 10.7554/eLife.2145127995896","journal-title":"eLife"},{"key":"e_1_3_2_19_2","doi-asserted-by":"crossref","first-page":"807","DOI":"10.1038/nbt.3276","article-title":"Health ROI as a measure of misalignment of biomedical needs and resources","volume":"33","author":"Yao L.","year":"2015","unstructured":"L. Yao, Y. Li, S. Ghosh, J. A. Evans, A. Rzhetsky, Health ROI as a measure of misalignment of biomedical needs and resources. Nat. Biotechnol. 33, 807–811 (2015). 10.1038/nbt.327626252133","journal-title":"Nat. Biotechnol."},{"key":"e_1_3_2_20_2","doi-asserted-by":"crossref","first-page":"14","DOI":"10.1016/j.joi.2010.06.004","article-title":"Approaches to understanding and measuring interdisciplinary scientific research (IDR): A review of the literature","volume":"5","author":"Wagner C. S.","year":"2011","unstructured":"C. S. Wagner, J. D. Roessner, K. Bobb, J. T. Klein, K. W. Boyack, J. Keyton, I. Rafols, K. Börner, Approaches to understanding and measuring interdisciplinary scientific research (IDR): A review of the literature. J. Informetr. 5, 14–26 (2011). 10.1016/j.joi.2010.06.004","journal-title":"J. Informetr."},{"key":"e_1_3_2_21_2","doi-asserted-by":"crossref","first-page":"e0122565","DOI":"10.1371/journal.pone.0122565","article-title":"Long-distance interdisciplinarity leads to higher scientific impact","volume":"10","author":"Larivière V.","year":"2015","unstructured":"V. Larivière, S. Haustein, K. Börner, Long-distance interdisciplinarity leads to higher scientific impact. PLOS ONE 10, e0122565 (2015). 10.1371/journal.pone.012256525822658","journal-title":"PLOS ONE"},{"key":"e_1_3_2_22_2","doi-asserted-by":"crossref","first-page":"2765","DOI":"10.1287/mnsc.2015.2285","article-title":"Looking across and looking beyond the knowledge frontier: Intellectual distance, novelty, and resource allocation in science","volume":"62","author":"Boudreau K. J.","year":"2016","unstructured":"K. J. Boudreau, E. C. Guinan, K. R. Lakhani, C. Riedl, Looking across and looking beyond the knowledge frontier: Intellectual distance, novelty, and resource allocation in science. Manage. Sci. 62, 2765–2783 (2016). 10.1287/mnsc.2015.228527746512","journal-title":"Manage. Sci."},{"key":"e_1_3_2_23_2","doi-asserted-by":"crossref","first-page":"228","DOI":"10.1177/2329496514540131","article-title":"Sociological innovation through subfield integration","volume":"1","author":"Leahey E.","year":"2014","unstructured":"E. Leahey, J. Moody, Sociological innovation through subfield integration. Soc. Currents 1, 228–256 (2014). 10.1177/2329496514540131","journal-title":"Soc. Currents"},{"key":"e_1_3_2_24_2","doi-asserted-by":"crossref","first-page":"e0135095","DOI":"10.1371/journal.pone.0135095","article-title":"Does interdisciplinary research lead to higher citation impact? The different effect of proximal and distal interdisciplinarity","volume":"10","author":"Yegros-Yegros A.","year":"2015","unstructured":"A. Yegros-Yegros, I. Rafols, P. D’Este, Does interdisciplinary research lead to higher citation impact? The different effect of proximal and distal interdisciplinarity. PLOS ONE 10, e0135095 (2015). 10.1371/journal.pone.013509526266805","journal-title":"PLOS ONE"},{"key":"e_1_3_2_25_2","doi-asserted-by":"crossref","first-page":"684","DOI":"10.1038/nature18315","article-title":"Interdisciplinary research has consistently lower funding success","volume":"534","author":"Bromham L.","year":"2016","unstructured":"L. Bromham, R. Dinnage, X. Hua, Interdisciplinary research has consistently lower funding success. Nature 534, 684–687 (2016). 10.1038/nature1831527357795","journal-title":"Nature"},{"key":"e_1_3_2_26_2","doi-asserted-by":"crossref","first-page":"8","DOI":"10.1140/epjds/s13688-016-0069-1","article-title":"Technological novelty profile and inventions future impact","volume":"5","author":"Kim D.","year":"2016","unstructured":"D. Kim, D. B. Cerigo, H. Jeong, H. Youn, Technological novelty profile and inventions future impact. EPJ Data Sci. 5, 8 (2016). 10.1140/epjds/s13688-016-0069-1","journal-title":"EPJ Data Sci."},{"key":"e_1_3_2_27_2","doi-asserted-by":"publisher","DOI":"10.1126/science.1240474"},{"key":"e_1_3_2_28_2","doi-asserted-by":"crossref","unstructured":"J. Wang R. Veugelers P. Stephan “Bias against novelty in science: A cautionary tale for users of bibliometric indicators” (NBER Working Paper No. 22180 National Bureau of Economic Research 2016).","DOI":"10.3386/w22180"},{"key":"e_1_3_2_29_2","doi-asserted-by":"crossref","first-page":"1584","DOI":"10.1016/j.respol.2015.04.010","article-title":"The bureaucratization of science","volume":"44","author":"Walsh J. P.","year":"2015","unstructured":"J. P. Walsh, Y.-N. Lee, The bureaucratization of science. Res. Policy 44, 1584–1600 (2015). 10.1016/j.respol.2015.04.010","journal-title":"Res. Policy"},{"key":"e_1_3_2_30_2","doi-asserted-by":"crossref","first-page":"5213","DOI":"10.1073/pnas.1121429109","article-title":"Persistence and uncertainty in the academic career","volume":"109","author":"Petersen A. M.","year":"2012","unstructured":"A. M. Petersen, M. Riccaboni, H. E. Stanley, F. Pammolli, Persistence and uncertainty in the academic career. Proc. Natl. Acad. Sci. U.S.A. 109, 5213–5218 (2012). 10.1073/pnas.112142910922431620","journal-title":"Proc. Natl. Acad. Sci. U.S.A."},{"key":"e_1_3_2_31_2","doi-asserted-by":"crossref","unstructured":"P. E. Stephan How Economics Shapes Science (Harvard Univ. Press 2012).","DOI":"10.4159/harvard.9780674062757"},{"key":"e_1_3_2_32_2","doi-asserted-by":"crossref","first-page":"527","DOI":"10.1111/j.1756-2171.2011.00140.x","article-title":"Incentives and creativity: Evidence from the academic life sciences","volume":"42","author":"Azoulay P.","year":"2011","unstructured":"P. Azoulay, J. S. Graff Zivin, G. Manso, Incentives and creativity: Evidence from the academic life sciences. Rand J. Econ. 42, 527–554 (2011). 10.1111/j.1756-2171.2011.00140.x","journal-title":"Rand J. Econ."},{"key":"e_1_3_2_33_2","doi-asserted-by":"publisher","DOI":"10.1126/science.1067477"},{"key":"e_1_3_2_34_2","doi-asserted-by":"publisher","DOI":"10.1126/science.1201765"},{"key":"e_1_3_2_35_2","doi-asserted-by":"crossref","first-page":"211","DOI":"10.1038/504211a","article-title":"Bibliometrics: Global gender disparities in science","volume":"504","author":"Larivière V.","year":"2013","unstructured":"V. Larivière, C. Ni, Y. Gingras, B. Cronin, C. R. Sugimoto, Bibliometrics: Global gender disparities in science. Nature 504, 211–213 (2013). 10.1038/504211a24350369","journal-title":"Nature"},{"key":"e_1_3_2_36_2","unstructured":"S. F. Way D. B. Larremore A. Clauset in Proceedings of the 25th International Conference on World Wide Web (WWW ‘16) (ACM 2016) pp. 1169–1179."},{"key":"e_1_3_2_37_2","doi-asserted-by":"crossref","first-page":"e51332","DOI":"10.1371/journal.pone.0051332","article-title":"The possible role of resource requirements and academic career-choice risk on gender differences in publication rate and impact","volume":"7","author":"Duch J.","year":"2012","unstructured":"J. Duch, X. H. T. Zeng, M. Sales-Pardo, F. Radicchi, S. Otis, T. K. Woodruff, L. A. Nunes Amaral, The possible role of resource requirements and academic career-choice risk on gender differences in publication rate and impact. PLOS ONE 7, e51332 (2012). 10.1371/journal.pone.005133223251502","journal-title":"PLOS ONE"},{"key":"e_1_3_2_38_2","doi-asserted-by":"crossref","first-page":"e66212","DOI":"10.1371/journal.pone.0066212","article-title":"The role of gender in scholarly authorship","volume":"8","author":"West J. D.","year":"2013","unstructured":"J. D. West, J. Jacquet, M. M. King, S. J. Correll, C. T. Bergstrom, The role of gender in scholarly authorship. PLOS ONE 8, e66212 (2013). 10.1371/journal.pone.006621223894278","journal-title":"PLOS ONE"},{"key":"e_1_3_2_39_2","doi-asserted-by":"crossref","first-page":"e1002573","DOI":"10.1371/journal.pbio.1002573","article-title":"Differences in collaboration patterns across discipline, career stage, and gender","volume":"14","author":"Zeng X. H. T.","year":"2016","unstructured":"X. H. T. Zeng, J. Duch, M. Sales-Pardo, J. A. G. Moreira, F. Radicchi, H. V. Ribeiro, T. K. Woodruff, L. A. N. Amaral, Differences in collaboration patterns across discipline, career stage, and gender. PLOS Biol. 14, e1002573 (2016). 10.1371/journal.pbio.100257327814355","journal-title":"PLOS Biol."},{"key":"e_1_3_2_40_2","doi-asserted-by":"publisher","DOI":"10.1126/science.1165878"},{"key":"e_1_3_2_41_2","doi-asserted-by":"crossref","first-page":"16474","DOI":"10.1073/pnas.1211286109","article-title":"Science faculty’s subtle gender biases favor male students","volume":"109","author":"Moss-Racusin C. A.","year":"2012","unstructured":"C. A. Moss-Racusin, J. F. Dovidio, V. L. Brescoll, M. J. Graham, J. Handelsman, Science faculty’s subtle gender biases favor male students. Proc. Natl. Acad. Sci. U.S.A. 109, 16474–16479 (2012). 10.1073/pnas.121128610922988126","journal-title":"Proc. Natl. Acad. Sci. U.S.A."},{"key":"e_1_3_2_42_2","doi-asserted-by":"crossref","first-page":"326","DOI":"10.1038/490326a","article-title":"Global mobility: Science on the move","volume":"490","author":"Van Noorden R.","year":"2012","unstructured":"R. Van Noorden, Global mobility: Science on the move. Nature 490, 326–329 (2012). 10.1038/490326a23075963","journal-title":"Nature"},{"key":"e_1_3_2_43_2","doi-asserted-by":"publisher","DOI":"10.1126/sciadv.1602232"},{"key":"e_1_3_2_44_2","doi-asserted-by":"crossref","first-page":"89","DOI":"10.1016/j.econlet.2013.10.040","article-title":"The mover’s advantage: The superior performance of migrant scientists","volume":"122","author":"Franzoni C.","year":"2014","unstructured":"C. Franzoni, G. Scellato, P. Stephan, The mover’s advantage: The superior performance of migrant scientists. Econ. Lett. 122, 89–93 (2014). 10.1016/j.econlet.2013.10.040","journal-title":"Econ. Lett."},{"key":"e_1_3_2_45_2","doi-asserted-by":"crossref","first-page":"29","DOI":"10.1038/550029a","article-title":"Scientists have most impact when they’re free to move","volume":"550","author":"Sugimoto C. R.","year":"2017","unstructured":"C. R. Sugimoto, N. Robinson-Garcia, D. S. Murray, A. Yegros-Yegros, R. Costas, V. Larivière, Scientists have most impact when they’re free to move. Nature 550, 29–31 (2017). 10.1038/550029a28980663","journal-title":"Nature"},{"key":"e_1_3_2_46_2","doi-asserted-by":"publisher","DOI":"10.1126/sciadv.1400005"},{"key":"e_1_3_2_47_2","doi-asserted-by":"crossref","first-page":"4770","DOI":"10.1038/srep04770","article-title":"Career on the move: Geography, stratification, and scientific impact","volume":"4","author":"Deville P.","year":"2014","unstructured":"P. Deville, D. Wang, R. Sinatra, C. Song, V. D. Blondel, A. L. Barabási, Career on the move: Geography, stratification, and scientific impact. Sci. Rep. 4, 4770 (2014). 24759743","journal-title":"Sci. Rep."},{"key":"e_1_3_2_48_2","doi-asserted-by":"crossref","first-page":"15316","DOI":"10.1073/pnas.1323111111","article-title":"Reputation and impact in academic careers","volume":"111","author":"Petersen A. M.","year":"2014","unstructured":"A. M. Petersen, S. Fortunato, R. K. Pan, K. Kaski, O. Penner, A. Rungi, M. Riccaboni, H. E. Stanley, F. Pammolli, Reputation and impact in academic careers. Proc. Natl. Acad. Sci. U.S.A. 111, 15316–15321 (2014). 10.1073/pnas.132311111125288774","journal-title":"Proc. Natl. Acad. Sci. U.S.A."},{"key":"e_1_3_2_49_2","doi-asserted-by":"crossref","first-page":"66","DOI":"10.1037/0033-295X.104.1.66","article-title":"Creative productivity: A predictive and explanatory model of career trajectories and landmarks","volume":"104","author":"Simonton D. K.","year":"1997","unstructured":"D. K. Simonton, Creative productivity: A predictive and explanatory model of career trajectories and landmarks. Psychol. Rev. 104, 66–89 (1997). 10.1037/0033-295X.104.1.66","journal-title":"Psychol. Rev."},{"key":"e_1_3_2_50_2","doi-asserted-by":"publisher","DOI":"10.1126/science.aaf5239"},{"key":"e_1_3_2_51_2","doi-asserted-by":"publisher","DOI":"10.1126/science.1136099"},{"key":"e_1_3_2_52_2","unstructured":"N. J. Cooke M. L. Hilton Eds. Enhancing the Effectiveness of Team Science (National Academies Press 2015)."},{"key":"e_1_3_2_53_2","doi-asserted-by":"publisher","DOI":"10.1002/asi.23266"},{"key":"e_1_3_2_54_2","doi-asserted-by":"crossref","unstructured":"L. Wu D. Wang J. A. Evans Large teams have developed science and technology; small teams have disrupted it. arXiv:1709.02445 [physics.soc-ph] (7 September 2017).","DOI":"10.2139/ssrn.3034125"},{"key":"e_1_3_2_55_2","doi-asserted-by":"crossref","first-page":"283","DOI":"10.1111/j.1467-937X.2008.00531.x","article-title":"The burden of knowledge and the “death of the renaissance man”: Is innovation getting harder?","volume":"76","author":"Jones B. F.","year":"2009","unstructured":"B. F. Jones, The burden of knowledge and the “death of the renaissance man”: Is innovation getting harder? Rev. Econ. Stud. 76, 283–317 (2009). 10.1111/j.1467-937X.2008.00531.x","journal-title":"Rev. Econ. Stud."},{"key":"e_1_3_2_56_2","doi-asserted-by":"crossref","first-page":"3984","DOI":"10.1073/pnas.1309723111","article-title":"Principles of scientific research team formation and evolution","volume":"111","author":"Milojević S.","year":"2014","unstructured":"S. Milojević, Principles of scientific research team formation and evolution. Proc. Natl. Acad. Sci. U.S.A. 111, 3984–3989 (2014). 10.1073/pnas.130972311124591626","journal-title":"Proc. Natl. Acad. Sci. U.S.A."},{"key":"e_1_3_2_57_2","doi-asserted-by":"crossref","first-page":"664","DOI":"10.1038/nature05670","article-title":"Quantifying social group evolution","volume":"446","author":"Palla G.","year":"2007","unstructured":"G. Palla, A.-L. Barabási, T. Vicsek, Quantifying social group evolution. Nature 446, 664–667 (2007). 10.1038/nature0567017410175","journal-title":"Nature"},{"key":"e_1_3_2_58_2","doi-asserted-by":"crossref","first-page":"1104","DOI":"10.1162/REST_a_00472","article-title":"Which peers matter? The relative impacts of collaborators, colleagues, and competitors","volume":"97","author":"Borjas G. J.","year":"2015","unstructured":"G. J. Borjas, K. B. Doran, Which peers matter? The relative impacts of collaborators, colleagues, and competitors. Rev. Econ. Stat. 97, 1104–1117 (2015). 10.1162/REST_a_00472","journal-title":"Rev. Econ. Stat."},{"key":"e_1_3_2_59_2","doi-asserted-by":"crossref","first-page":"549","DOI":"10.1162/qjec.2010.125.2.549","article-title":"Superstar extinction","volume":"125","author":"Azoulay P.","year":"2010","unstructured":"P. Azoulay, J. G. Zivin, J. Wang, Superstar extinction. Q. J. Econ. 125, 549–589 (2010). 10.1162/qjec.2010.125.2.549","journal-title":"Q. J. Econ."},{"key":"e_1_3_2_60_2","doi-asserted-by":"crossref","first-page":"E4671","DOI":"10.1073/pnas.1501444112","article-title":"Quantifying the impact of weak, strong, and super ties in scientific careers","volume":"112","author":"Petersen A. M.","year":"2015","unstructured":"A. M. Petersen, Quantifying the impact of weak, strong, and super ties in scientific careers. Proc. Natl. Acad. Sci. U.S.A. 112, E4671–E4680 (2015). 10.1073/pnas.150144411226261301","journal-title":"Proc. Natl. Acad. Sci. U.S.A."},{"key":"e_1_3_2_61_2","doi-asserted-by":"publisher","DOI":"10.1126/science.159.3810.56"},{"key":"e_1_3_2_62_2","doi-asserted-by":"crossref","first-page":"312","DOI":"10.1038/508312a","article-title":"Publishing: Credit where credit is due","volume":"508","author":"Allen L.","year":"2014","unstructured":"L. Allen, J. Scott, A. Brand, M. Hlava, M. Altman, Publishing: Credit where credit is due. Nature 508, 312–313 (2014). 10.1038/508312a24745070","journal-title":"Nature"},{"key":"e_1_3_2_63_2","doi-asserted-by":"crossref","first-page":"12325","DOI":"10.1073/pnas.1401992111","article-title":"Collective credit allocation in science","volume":"111","author":"Shen H.-W.","year":"2014","unstructured":"H.-W. Shen, A.-L. Barabási, Collective credit allocation in science. Proc. Natl. Acad. Sci. U.S.A. 111, 12325–12330 (2014). 10.1073/pnas.140199211125114238","journal-title":"Proc. Natl. Acad. Sci. U.S.A."},{"key":"e_1_3_2_64_2","doi-asserted-by":"crossref","first-page":"365","DOI":"10.1016/j.joi.2016.02.007","article-title":"A review of the literature on citation impact indicators","volume":"10","author":"Waltman L.","year":"2016","unstructured":"L. Waltman, A review of the literature on citation impact indicators. J. Informetr. 10, 365–391 (2016). 10.1016/j.joi.2016.02.007","journal-title":"J. Informetr."},{"key":"e_1_3_2_65_2","doi-asserted-by":"crossref","first-page":"16569","DOI":"10.1073/pnas.0507655102","article-title":"An index to quantify an individual’s scientific research output","volume":"102","author":"Hirsch J. E.","year":"2005","unstructured":"J. E. Hirsch, An index to quantify an individual’s scientific research output. Proc. Natl. Acad. Sci. U.S.A. 102, 16569–16572 (2005). 10.1073/pnas.050765510216275915","journal-title":"Proc. Natl. Acad. Sci. U.S.A."},{"key":"e_1_3_2_66_2","unstructured":"H. F. Moed Citation Analysis in Research Evaluation (Springer 2010)."},{"key":"e_1_3_2_67_2","doi-asserted-by":"publisher","DOI":"10.1126/science.178.4060.471"},{"key":"e_1_3_2_68_2","doi-asserted-by":"crossref","first-page":"510","DOI":"10.1126/science.149.3683.510","article-title":"Networks of scientific papers","volume":"149","author":"de Solla Price D. J.","year":"1965","unstructured":"D. J. de Solla Price, Networks of scientific papers. Science 149, 510–515 (1965). 10.1126/science.149.3683.51014325149","journal-title":"Science"},{"key":"e_1_3_2_69_2","doi-asserted-by":"crossref","first-page":"1640","DOI":"10.1038/srep01640","article-title":"Characterizing scientific production and consumption in physics","volume":"3","author":"Zhang Q.","year":"2013","unstructured":"Q. Zhang, N. Perra, B. Gonçalves, F. Ciulla, A. Vespignani, Characterizing scientific production and consumption in physics. Sci. Rep. 3, 1640 (2013). 10.1038/srep0164023571320","journal-title":"Sci. Rep."},{"key":"e_1_3_2_70_2","doi-asserted-by":"crossref","first-page":"17268","DOI":"10.1073/pnas.0806977105","article-title":"Universality of citation distributions: Toward an objective measure of scientific impact","volume":"105","author":"Radicchi F.","year":"2008","unstructured":"F. Radicchi, S. Fortunato, C. Castellano, Universality of citation distributions: Toward an objective measure of scientific impact. Proc. Natl. Acad. Sci. U.S.A. 105, 17268–17272 (2008). 10.1073/pnas.080697710518978030","journal-title":"Proc. Natl. Acad. Sci. U.S.A."},{"key":"e_1_3_2_71_2","doi-asserted-by":"crossref","first-page":"72","DOI":"10.1002/asi.21671","article-title":"Universality of citation distributions revisited","volume":"63","author":"Waltman L.","year":"2012","unstructured":"L. Waltman, N. J. van Eck, A. F. J. van Raan, Universality of citation distributions revisited. J. Assoc. Inf. Sci. Technol. 63, 72–77 (2012). 10.1002/asi.21671","journal-title":"J. Assoc. Inf. Sci. Technol."},{"key":"e_1_3_2_72_2","doi-asserted-by":"crossref","first-page":"303","DOI":"10.1140/epjst/e2012-01576-4","article-title":"Runaway events dominate the heavy tail of citation distributions","volume":"205","author":"Golosovsky M.","year":"2012","unstructured":"M. Golosovsky, S. Solomon, Runaway events dominate the heavy tail of citation distributions. Eur. Phys. J. Spec. Top. 205, 303–311 (2012). 10.1140/epjst/e2012-01576-4","journal-title":"Eur. Phys. J. Spec. Top."},{"key":"e_1_3_2_73_2","doi-asserted-by":"crossref","first-page":"642","DOI":"10.1016/j.joi.2015.06.005","article-title":"Predicting the long-term citation impact of recent publications","volume":"9","author":"Stegehuis C.","year":"2015","unstructured":"C. Stegehuis, N. Litvak, L. Waltman, Predicting the long-term citation impact of recent publications. J. Informetr. 9, 642–657 (2015). 10.1016/j.joi.2015.06.005","journal-title":"J. Informetr."},{"key":"e_1_3_2_74_2","doi-asserted-by":"crossref","first-page":"336","DOI":"10.1016/j.joi.2015.12.007","article-title":"The discretised lognormal and hooked power law distributions for complete citation data: Best options for modelling and regression","volume":"10","author":"Thelwall M.","year":"2016","unstructured":"M. Thelwall, The discretised lognormal and hooked power law distributions for complete citation data: Best options for modelling and regression. J. Informetr. 10, 336–346 (2016). 10.1016/j.joi.2015.12.007","journal-title":"J. Informetr."},{"key":"e_1_3_2_75_2","doi-asserted-by":"crossref","first-page":"292","DOI":"10.1002/asi.4630270505","article-title":"A general theory of bibliometric and other cumulative advantage processes","volume":"27","author":"de Solla Price D.","year":"1976","unstructured":"D. de Solla Price, A general theory of bibliometric and other cumulative advantage processes. J. Am. Soc. Inf. Sci. 27, 292–306 (1976). 10.1002/asi.4630270505","journal-title":"J. Am. Soc. Inf. Sci."},{"key":"e_1_3_2_76_2","doi-asserted-by":"publisher","DOI":"10.1126/science.286.5439.509"},{"key":"e_1_3_2_77_2","doi-asserted-by":"crossref","first-page":"734","DOI":"10.1016/j.joi.2015.07.006","article-title":"Attention decay in science","volume":"9","author":"Parolo P. D. B.","year":"2015","unstructured":"P. D. B. Parolo, R. K. Pan, R. Ghosh, B. A. Huberman, K. Kaski, S. Fortunato, Attention decay in science. J. Informetr. 9, 734–745 (2015). 10.1016/j.joi.2015.07.006","journal-title":"J. Informetr."},{"key":"e_1_3_2_78_2","doi-asserted-by":"publisher","DOI":"10.1126/science.1237825"},{"key":"e_1_3_2_79_2","doi-asserted-by":"crossref","first-page":"e24926","DOI":"10.1371/journal.pone.0024926","article-title":"Characterizing and modeling citation dynamics","volume":"6","author":"Eom Y.-H.","year":"2011","unstructured":"Y.-H. Eom, S. Fortunato, Characterizing and modeling citation dynamics. PLOS ONE 6, e24926 (2011). 10.1371/journal.pone.002492621966387","journal-title":"PLOS ONE"},{"key":"e_1_3_2_80_2","doi-asserted-by":"crossref","first-page":"098701","DOI":"10.1103/PhysRevLett.109.098701","article-title":"Stochastic dynamical model of a growing citation network based on a self-exciting point process","volume":"109","author":"Golosovsky M.","year":"2012","unstructured":"M. Golosovsky, S. Solomon, Stochastic dynamical model of a growing citation network based on a self-exciting point process. Phys. Rev. Lett. 109, 098701 (2012). 10.1103/PhysRevLett.109.09870123002894","journal-title":"Phys. Rev. Lett."},{"key":"e_1_3_2_81_2","doi-asserted-by":"crossref","first-page":"467","DOI":"10.1023/B:SCIE.0000018543.82441.f1","article-title":"Sleeping Beauties in science","volume":"59","author":"van Raan A. F. J.","year":"2004","unstructured":"A. F. J. van Raan, Sleeping Beauties in science. Scientometrics 59, 467–472 (2004). 10.1023/B:SCIE.0000018543.82441.f1","journal-title":"Scientometrics"},{"key":"e_1_3_2_82_2","doi-asserted-by":"crossref","first-page":"7426","DOI":"10.1073/pnas.1424329112","article-title":"Defining and identifying Sleeping Beauties in science","volume":"112","author":"Ke Q.","year":"2015","unstructured":"Q. Ke, E. Ferrara, F. Radicchi, A. Flammini, Defining and identifying Sleeping Beauties in science. Proc. Natl. Acad. Sci. U.S.A. 112, 7426–7431 (2015). 10.1073/pnas.142432911226015563","journal-title":"Proc. Natl. Acad. Sci. U.S.A."},{"key":"e_1_3_2_83_2","doi-asserted-by":"crossref","first-page":"1195","DOI":"10.1007/s11192-016-1889-2","article-title":"Factors affecting number of citations: A comprehensive review of the literature","volume":"107","author":"Tahamtan I.","year":"2016","unstructured":"I. Tahamtan, A. Safipour Afshar, K. Ahamdzadeh, Factors affecting number of citations: A comprehensive review of the literature. Scientometrics 107, 1195–1225 (2016). 10.1007/s11192-016-1889-2","journal-title":"Scientometrics"},{"key":"e_1_3_2_84_2","doi-asserted-by":"crossref","first-page":"19193","DOI":"10.1073/pnas.0707962104","article-title":"Does the h index have predictive power?","volume":"104","author":"Hirsch J. E.","year":"2007","unstructured":"J. E. Hirsch, Does the h index have predictive power? Proc. Natl. Acad. Sci. U.S.A. 104, 19193–19198 (2007). 10.1073/pnas.070796210418040045","journal-title":"Proc. Natl. Acad. Sci. U.S.A."},{"key":"e_1_3_2_85_2","doi-asserted-by":"crossref","first-page":"201","DOI":"10.1038/489201a","article-title":"Future impact: Predicting scientific success","volume":"489","author":"Acuna D. E.","year":"2012","unstructured":"D. E. Acuna, S. Allesina, K. P. Kording, Future impact: Predicting scientific success. Nature 489, 201–202 (2012). 10.1038/489201a22972278","journal-title":"Nature"},{"key":"e_1_3_2_86_2","doi-asserted-by":"crossref","first-page":"3052","DOI":"10.1038/srep03052","article-title":"On the predictability of future impact in science","volume":"3","author":"Penner O.","year":"2013","unstructured":"O. Penner, R. K. Pan, A. M. Petersen, K. Kaski, S. Fortunato, On the predictability of future impact in science. Sci. Rep. 3, 3052 (2013). 10.1038/srep0305224165898","journal-title":"Sci. Rep."},{"key":"e_1_3_2_87_2","unstructured":"J. R. Cole H. Zuckerman in The Idea of Social Structure: Papers in Honor of Robert K. Merton L. A. Coser Ed. (Harcourt Brace Jovanovich 1975) pp. 139–174."},{"key":"e_1_3_2_88_2","doi-asserted-by":"crossref","first-page":"31","DOI":"10.1038/484031a","article-title":"Research efficiency: Turn the scientific method on ourselves","volume":"484","author":"Azoulay P.","year":"2012","unstructured":"P. Azoulay, Research efficiency: Turn the scientific method on ourselves. Nature 484, 31–32 (2012). 10.1038/484031a22481340","journal-title":"Nature"},{"key":"e_1_3_2_89_2","first-page":"587","article-title":"Web indicators for research evaluation. Part 1: Citations and links to academic articles from the Web","volume":"24","author":"Thelwall M.","year":"2015","unstructured":"M. Thelwall, K. Kousha, Web indicators for research evaluation. Part 1: Citations and links to academic articles from the Web. Prof. Inf. 24, 587–606 (2015). 10.3145/epi.2015.sep.08","journal-title":"Prof. Inf."},{"key":"e_1_3_2_90_2","first-page":"607","article-title":"Web indicators for research evaluation. Part 2: Social media metrics","volume":"24","author":"Thelwall M.","year":"2015","unstructured":"M. Thelwall, K. Kousha, Web indicators for research evaluation. Part 2: Social media metrics. Prof. Inf. 24, 607–620 (2015). 10.3145/epi.2015.sep.09","journal-title":"Prof. Inf."},{"key":"e_1_3_2_91_2","first-page":"217","article-title":"What is societal impact of research and how can it be assessed? A literature survey","volume":"64","author":"Bornmann L.","year":"2013","unstructured":"L. Bornmann, What is societal impact of research and how can it be assessed? A literature survey. Adv. Inf. Sci. 64, 217–233 (2013).","journal-title":"Adv. Inf. Sci."},{"key":"e_1_3_2_92_2","doi-asserted-by":"crossref","first-page":"465","DOI":"10.1016/j.respol.2013.08.017","article-title":"Specific and general information sharing among competing academic researchers","volume":"43","author":"Haeussler C.","year":"2014","unstructured":"C. Haeussler, L. Jiang, J. Thursby, M. Thursby, Specific and general information sharing among competing academic researchers. Res. Policy 43, 465–475 (2014). 10.1016/j.respol.2013.08.017","journal-title":"Res. Policy"},{"key":"e_1_3_2_93_2","doi-asserted-by":"crossref","first-page":"496","DOI":"10.1038/489496a","article-title":"Sociology: Honour the helpful","volume":"489","author":"Oettl A.","year":"2012","unstructured":"A. Oettl, Sociology: Honour the helpful. Nature 489, 496–497 (2012). 10.1038/489496a23018949","journal-title":"Nature"},{"key":"e_1_3_2_94_2","unstructured":"S. Ravindran “Getting credit for peer review ” Science 8 February 2016; www.sciencemag.org/careers/2016/02/getting-credit-peer-review."},{"key":"e_1_3_2_95_2","doi-asserted-by":"crossref","first-page":"2003","DOI":"10.1002/asi.23309","article-title":"Do “altmetrics” correlate with citations? Extensive comparison of altmetric indicators with citations from a multidisciplinary perspective","volume":"66","author":"Costas R.","year":"2015","unstructured":"R. Costas, Z. Zahedi, P. Wouters, Do “altmetrics” correlate with citations? Extensive comparison of altmetric indicators with citations from a multidisciplinary perspective. J. Assoc. Inf. Sci. Technol. 66, 2003–2019 (2015). 10.1002/asi.23309","journal-title":"J. Assoc. Inf. Sci. Technol."},{"key":"e_1_3_2_96_2","doi-asserted-by":"publisher","DOI":"10.1126/science.aal4217"},{"key":"e_1_3_2_97_2","doi-asserted-by":"crossref","first-page":"301","DOI":"10.1016/S0140-6736(97)11129-1","article-title":"Peer review of grant applications: What do we know?","volume":"352","author":"Wessely S.","year":"1998","unstructured":"S. Wessely, Peer review of grant applications: What do we know? Lancet 352, 301–305 (1998). 10.1016/S0140-6736(97)11129-19690424","journal-title":"Lancet"},{"key":"e_1_3_2_98_2","unstructured":"N. Geard J. Noble paper presented at the 3rd World Congress on Social Simulation Kassel Germany 6 to 9 September 2010."},{"key":"e_1_3_2_99_2","doi-asserted-by":"crossref","first-page":"1002","DOI":"10.1038/4681002a","article-title":"Calm in a crisis","volume":"468","year":"2010","unstructured":"Calm in a crisis. Nature 468, 1002 (2010). 10.1038/4681002a21170024","journal-title":"Nature"},{"key":"e_1_3_2_100_2","doi-asserted-by":"crossref","first-page":"73","DOI":"10.1177/016224398501000309","article-title":"Funding science: The real defects of peer review and an alternative to it","volume":"10","author":"Roy R.","year":"1985","unstructured":"R. Roy, Funding science: The real defects of peer review and an alternative to it. Sci. Technol. Human Values 10, 73–81 (1985). 10.1177/016224398501000309","journal-title":"Sci. Technol. Human Values"},{"key":"e_1_3_2_101_2","doi-asserted-by":"crossref","first-page":"521","DOI":"10.1007/s11192-016-2110-3","article-title":"An efficient system to fund science: From proposal review to peer-to-peer distributions","volume":"110","author":"Bollen J.","year":"2017","unstructured":"J. Bollen, D. Crandall, D. Junk, Y. Ding, K. Börner, An efficient system to fund science: From proposal review to peer-to-peer distributions. Scientometrics 110, 521–528 (2017). 10.1007/s11192-016-2110-3","journal-title":"Scientometrics"},{"key":"e_1_3_2_102_2","first-page":"154","article-title":"IBM’s health analytics and clinical decision support","volume":"9","author":"Kohn M. S.","year":"2014","unstructured":"M. S. Kohn, J. Sun, S. Knoop, A. Shabo, B. Carmeli, D. Sow, T. Syed-Mahmood, W. Rapp, IBM’s health analytics and clinical decision support. Yearb. Med. Inform. 9, 154–162 (2014). 10.15265/IY-2014-000225123736","journal-title":"Yearb. Med. Inform."},{"key":"e_1_3_2_103_2","doi-asserted-by":"crossref","unstructured":"J. Kleinberg H. Lakkaraju J. Leskovec J. Ludwig S. Mullainathan “Human decisions and machine predictions” (National Bureau of Economic Research 2017).","DOI":"10.3386/w23180"},{"key":"e_1_3_2_104_2","doi-asserted-by":"crossref","first-page":"e0144945","DOI":"10.1371/journal.pone.0144945","article-title":"Do emotions expressed online correlate with actual changes in decision-making?: The case of stock day traders","volume":"11","author":"Liu B.","year":"2016","unstructured":"B. Liu, R. Govindan, B. Uzzi, Do emotions expressed online correlate with actual changes in decision-making?: The case of stock day traders. PLOS ONE 11, e0144945 (2016). 10.1371/journal.pone.014494526765539","journal-title":"PLOS ONE"},{"key":"e_1_3_2_105_2","doi-asserted-by":"publisher","DOI":"10.1073/pnas.98.2.404"},{"key":"e_1_3_2_106_2","doi-asserted-by":"publisher","DOI":"10.1126/science.1106340"},{"key":"e_1_3_2_107_2","doi-asserted-by":"publisher","DOI":"10.1371/journal.pone.0001683"}],"container-title":"Science","original-title":[],"language":"en","link":[{"URL":"https://syndication.highwire.org/content/doi/10.1126/science.aao0185","content-type":"unspecified","content-version":"vor","intended-application":"syndication"},{"URL":"https://syndication.highwire.org/content/doi/10.1126/science.aao0185","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2022,1,13]],"date-time":"2022-01-13T20:53:24Z","timestamp":1642107204000},"score":1,"resource":{"primary":{"URL":"https://www.science.org/doi/10.1126/science.aao0185"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2018,3,2]]},"references-count":106,"journal-issue":{"issue":"6379","published-print":{"date-parts":[[2018,3,2]]}},"alternative-id":["10.1126/science.aao0185"],"URL":"http://dx.doi.org/10.1126/science.aao0185","relation":{},"ISSN":["0036-8075","1095-9203"],"subject":["Multidisciplinary"],"container-title-short":"Science","published":{"date-parts":[[2018,3,2]]},"id":"doi:10.1126/science.aao0185"},{"author":[{"family":"Google Scholar"}],"type":"document","id":"gscholar","citation-key":"gscholar","issued":{"date-parts":[[2023]]},"URL":"https://scholar.google.com/"},{"author":[{"family":"Google, Inc."}],"type":"document","id":"puppeteer","citation-key":"puppeteer","issued":{"date-parts":[[2023]]},"title":"Puppeteer","URL":"https://pptr.dev/"},{"author":[{"given":"John","family":"Gruber"}],"type":"document","id":"markdown","citation-key":"markdown","issued":{"date-parts":[[2004]]},"title":"Markdown","URL":"https://daringfireball.net/projects/markdown/"},{"indexed":{"date-parts":[[2023,1,14]],"date-time":"2023-01-14T08:12:55Z","timestamp":1673683975305},"reference-count":0,"publisher":"Association for Computing Machinery (ACM)","issue":"3","content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2001,5]]},"DOI":"10.1145/369825.369829","type":"journal-article","created":{"date-parts":[[2002,7,27]],"date-time":"2002-07-27T11:26:13Z","timestamp":1027769173000},"page":"21-30","update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":12,"title":"Design: the what of XFR","prefix":"10.1145","volume":"8","author":[{"given":"Steve","family":"Harrison","sequence":"first","affiliation":[{"name":"Xerox Palo Alto, Reasearch Center, Palo Alto, CA"}]},{"given":"Scott","family":"Minneman","sequence":"additional","affiliation":[{"name":"Xerox Palo Alto, Reasearch Center, Palo Alto, CA"}]},{"given":"Maribeth","family":"Back","sequence":"additional","affiliation":[{"name":"Xerox Palo Alto, Reasearch Center, Palo Alto, CA"}]},{"given":"Anne","family":"Balsamo","sequence":"additional","affiliation":[{"name":"Xerox Palo Alto, Reasearch Center, Palo Alto, CA"}]},{"given":"Mark","family":"Chow","sequence":"additional","affiliation":[{"name":"Xerox Palo Alto, Reasearch Center, Palo Alto, CA"}]},{"given":"Rich","family":"Gold","sequence":"additional","affiliation":[]},{"given":"Matt","family":"Gorbet","sequence":"additional","affiliation":[]},{"given":"Dale","family":"Mac Donald","sequence":"additional","affiliation":[]}],"member":"320","published-online":{"date-parts":[[2001,5]]},"container-title":"Interactions","original-title":[],"language":"en","link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/369825.369829","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,1,2]],"date-time":"2023-01-02T09:18:01Z","timestamp":1672651081000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/369825.369829"}},"subtitle":["eXperiments in the future of reading"],"editor":[{"given":"Kate","family":"Ehrlich","sequence":"additional","affiliation":[]},{"given":"Austin","family":"Henderson","sequence":"additional","affiliation":[]}],"short-title":[],"issued":{"date-parts":[[2001,5]]},"references-count":0,"journal-issue":{"issue":"3","published-print":{"date-parts":[[2001,5]]}},"alternative-id":["10.1145/369825.369829"],"URL":"http://dx.doi.org/10.1145/369825.369829","relation":{},"ISSN":["1072-5520","1558-3449"],"subject":["Human-Computer Interaction"],"container-title-short":"interactions","published":{"date-parts":[[2001,5]]},"assertion":[{"value":"2001-05-01","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/369825.369829"},{"indexed":{"date-parts":[[2023,10,18]],"date-time":"2023-10-18T23:23:18Z","timestamp":1697671398390},"publisher-location":"New York, NY, USA","reference-count":109,"publisher":"ACM","license":[{"start":{"date-parts":[[2021,5,7]],"date-time":"2021-05-07T00:00:00Z","timestamp":1620345600000},"content-version":"vor","delay-in-days":1,"URL":"http://www.acm.org/publications/policies/copyright_policy#Background"}],"funder":[{"DOI":"10.13039/100000879","name":"Alfred P. Sloan Foundation","doi-asserted-by":"publisher","award":["9022"]},{"DOI":"10.13039/100000006","name":"Office of Naval Research","doi-asserted-by":"publisher","award":["N00014-15-1-2774"]}],"content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2021,5,6]]},"DOI":"10.1145/3411764.3445648","type":"proceedings-article","created":{"date-parts":[[2021,5,8]],"date-time":"2021-05-08T02:27:22Z","timestamp":1620440842000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":29,"title":"Augmenting Scientific Papers with Just-in-Time, Position-Sensitive Definitions of Terms and Symbols","prefix":"10.1145","author":[{"given":"Andrew","family":"Head","sequence":"first","affiliation":[{"name":"Computer Science, UC Berkeley, United States"}]},{"given":"Kyle","family":"Lo","sequence":"additional","affiliation":[{"name":"Allen Institute for Artificial Intelligence, United States"}]},{"given":"Dongyeop","family":"Kang","sequence":"additional","affiliation":[{"name":"Computer Science, UC Berkeley, United States"}]},{"given":"Raymond","family":"Fok","sequence":"additional","affiliation":[{"name":"Paul G. Allen School of Computer Science &amp; Engineering University of Washington, United States"}]},{"given":"Sam","family":"Skjonsberg","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Daniel S.","family":"Weld","sequence":"additional","affiliation":[{"name":"Paul G. Allen School of Computer Science &amp; Engineering University of Washington and Allen Institute for AI, United States"}]},{"given":"Marti A.","family":"Hearst","sequence":"additional","affiliation":[{"name":"Computer Science, UC Berkeley, United States"}]}],"member":"320","published-online":{"date-parts":[[2021,5,7]]},"reference":[{"key":"e_1_3_2_2_1_1","volume-title":"Proceedings of the International Conference on Computational Linguistics. International Conference on Computational Linguistics, 136–140","author":"Abekawa Takeshi","year":"2016","unstructured":"Takeshi Abekawa and Akiko Aizawa . 2016 . SideNoter: Scholarly Paper Browsing System based on PDF Restructuring and Text Annotation . In Proceedings of the International Conference on Computational Linguistics. International Conference on Computational Linguistics, 136–140 . Takeshi Abekawa and Akiko Aizawa. 2016. SideNoter: Scholarly Paper Browsing System based on PDF Restructuring and Text Annotation. In Proceedings of the International Conference on Computational Linguistics. International Conference on Computational Linguistics, 136–140."},{"key":"e_1_3_2_2_2_1","doi-asserted-by":"publisher","DOI":"10.1145/274644.274679"},{"key":"e_1_3_2_2_3_1","volume-title":"Proceedings of the Conference on Research in Undergraduate Mathematics Education. Special Interest Group of the Mathematical Association of America on Research in Undergraduate Mathematics Education.","author":"Alcock Lara","year":"2009","unstructured":"Lara Alcock . 2009 . e-Proofs: Student Experience of Online Resources to Aid Understanding of Mathematical Proofs . In Proceedings of the Conference on Research in Undergraduate Mathematics Education. Special Interest Group of the Mathematical Association of America on Research in Undergraduate Mathematics Education. Lara Alcock. 2009. e-Proofs: Student Experience of Online Resources to Aid Understanding of Mathematical Proofs. In Proceedings of the Conference on Research in Undergraduate Mathematics Education. Special Interest Group of the Mathematical Association of America on Research in Undergraduate Mathematics Education."},{"key":"e_1_3_2_2_4_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2018.2865144"},{"key":"e_1_3_2_2_5_1","doi-asserted-by":"publisher","DOI":"10.1177/1473871618799500"},{"key":"e_1_3_2_2_6_1","doi-asserted-by":"publisher","DOI":"10.18637/jss.v067.i01"},{"key":"e_1_3_2_2_7_1","doi-asserted-by":"publisher","DOI":"10.1177/0741088385002001001"},{"key":"e_1_3_2_2_8_1","doi-asserted-by":"publisher","DOI":"10.1145/1125451.1125570"},{"key":"e_1_3_2_2_9_1","first-page":"1","article-title":"As we may think","volume":"176","author":"Bush Vannevar","year":"1945","unstructured":"Vannevar Bush . 1945 . As we may think . The Atlantic 176 , 1 (July 1945), 101–108. Vannevar Bush. 1945. As we may think. The Atlantic 176, 1 (July 1945), 101–108.","journal-title":"The Atlantic"},{"key":"e_1_3_2_2_10_1","volume-title":"TLDR: Extreme Summarization of Scientific Documents. In Findings of the Association for Computational Linguistics: EMNLP","author":"Cachola Isabel","year":"2020","unstructured":"Isabel Cachola , Kyle Lo , Arman Cohan , and Daniel Weld . 2020 . TLDR: Extreme Summarization of Scientific Documents. In Findings of the Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics, 4766–4777. Isabel Cachola, Kyle Lo, Arman Cohan, and Daniel Weld. 2020. TLDR: Extreme Summarization of Scientific Documents. In Findings of the Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics, 4766–4777."},{"key":"e_1_3_2_2_11_1","doi-asserted-by":"publisher","DOI":"10.1145/288392.288585"},{"key":"e_1_3_2_2_12_1","doi-asserted-by":"publisher","DOI":"10.1145/2984511.2984538"},{"key":"e_1_3_2_2_13_1","volume-title":"L1 glosses: Effects on EFL learners","author":"Cheng Ying-Hsueh","year":"2009","unstructured":"Ying-Hsueh Cheng and Robert  L. Good . 2009. L1 glosses: Effects on EFL learners ’ reading comprehension and vocabulary retention. Reading in a Foreign Language 2009 , 2 (October 2009), 119–142. Ying-Hsueh Cheng and Robert L. Good. 2009. L1 glosses: Effects on EFL learners’ reading comprehension and vocabulary retention. Reading in a Foreign Language 2009, 2 (October 2009), 119–142."},{"key":"e_1_3_2_2_14_1","doi-asserted-by":"publisher","DOI":"10.1145/2207676.2208620"},{"key":"e_1_3_2_2_15_1","unstructured":"Rune Haubo B Christensen. 2018. Cumulative Link Models for Ordinal Regression with the R Package ordinal. (2018). http://cran.uni-muenster.de/web/packages/ordinal/vignettes/clm_article.pdf.  Rune Haubo B Christensen. 2018. Cumulative Link Models for Ordinal Regression with the R Package ordinal. (2018). http://cran.uni-muenster.de/web/packages/ordinal/vignettes/clm_article.pdf."},{"key":"e_1_3_2_2_16_1","doi-asserted-by":"publisher","DOI":"10.1002/(SICI)1097-0258(19971030)16:20<2349::AID-SIM667>3.0.CO;2-E"},{"key":"e_1_3_2_2_17_1","unstructured":"Joseph Paul Cohen Henry Z. Lo Tingting Lu and Wei Ding. 2016. Crater Detection via Convolutional Neural Networks. (2016). arxiv:1601.00978 [cs.CV]  Joseph Paul Cohen Henry Z. Lo Tingting Lu and Wei Ding. 2016. Crater Detection via Convolutional Neural Networks. (2016). arxiv:1601.00978 [cs.CV]"},{"key":"e_1_3_2_2_18_1","doi-asserted-by":"publisher","DOI":"10.1109/MC.1987.1663693"},{"key":"e_1_3_2_2_19_1","doi-asserted-by":"publisher","DOI":"10.1207/s15327906mbr3103_6"},{"key":"e_1_3_2_2_20_1","doi-asserted-by":"publisher","DOI":"10.1145/506443.506515"},{"key":"e_1_3_2_2_21_1","doi-asserted-by":"publisher","DOI":"10.1016/j.chb.2005.08.012"},{"key":"e_1_3_2_2_22_1","volume-title":"Proceedings of the Symposium on User Interface Software and Technology. ACM, 257–262","author":"Dragicevic Pierre","year":"2011","unstructured":"Pierre Dragicevic , Stéphane Huot , and Fanny Chevalier . 2011 . Gliimpse: Animating from Markup Code to Rendered Documents and Vice Versa . In Proceedings of the Symposium on User Interface Software and Technology. ACM, 257–262 . Pierre Dragicevic, Stéphane Huot, and Fanny Chevalier. 2011. Gliimpse: Animating from Markup Code to Rendered Documents and Vice Versa. In Proceedings of the Symposium on User Interface Software and Technology. ACM, 257–262."},{"key":"e_1_3_2_2_23_1","volume-title":"Fast Node Overlap Removal. In International Symposium on Graph Drawing. Springer, 153–164","author":"Dwyer Tim","year":"2005","unstructured":"Tim Dwyer , Kim Marriott , and Peter  J. Stuckey . 2005 . Fast Node Overlap Removal. In International Symposium on Graph Drawing. Springer, 153–164 . Tim Dwyer, Kim Marriott, and Peter J. Stuckey. 2005. Fast Node Overlap Removal. In International Symposium on Graph Drawing. Springer, 153–164."},{"key":"e_1_3_2_2_24_1","doi-asserted-by":"publisher","DOI":"10.1145/64789.64790"},{"key":"e_1_3_2_2_25_1","unstructured":"eLife. 2013. Seeing through the eLife Lens: A new way to view research. (2013). https://elifesciences.org/inside-elife/0414db99/seeing- through-the-elife-lens-a-new-way-to-view-research.  eLife. 2013. Seeing through the eLife Lens: A new way to view research. (2013). https://elifesciences.org/inside-elife/0414db99/seeing- through-the-elife-lens-a-new-way-to-view-research."},{"key":"e_1_3_2_2_26_1","volume-title":"https://fermatslibrary.com/. Last accessed","author":"Library Fermat’s","year":"2020","unstructured":"[ 26 ] Fermat’s Library . https://fermatslibrary.com/. Last accessed September 16, 2020 . [26] Fermat’s Library. https://fermatslibrary.com/. Last accessed September 16, 2020."},{"key":"e_1_3_2_2_27_1","volume-title":"Mathematical Markup Language (MathML). https://www.w3.org/Math/whatIsMathML.html. Last accessed","author":"Froumentin Max","year":"2020","unstructured":"Max Froumentin . Mathematical Markup Language (MathML). https://www.w3.org/Math/whatIsMathML.html. Last accessed September 16, 2020 . Max Froumentin. Mathematical Markup Language (MathML). https://www.w3.org/Math/whatIsMathML.html. Last accessed September 16, 2020."},{"key":"e_1_3_2_2_28_1","doi-asserted-by":"publisher","DOI":"10.1145/302979.303139"},{"key":"e_1_3_2_2_29_1","volume-title":"Proceedings of the CHI Conference on Human Factors in Computing Systems. ACM, 461–475","author":"Grossman Tovi","year":"2015","unstructured":"Tovi Grossman , Fanny Chevalier , and Rubaiat Habib Kazi . 2015 . Your Paper is Dead! Bringing Life to Research Articles with Animated Figures . In Proceedings of the CHI Conference on Human Factors in Computing Systems. ACM, 461–475 . Tovi Grossman, Fanny Chevalier, and Rubaiat Habib Kazi. 2015. Your Paper is Dead! Bringing Life to Research Articles with Animated Figures. In Proceedings of the CHI Conference on Human Factors in Computing Systems. ACM, 461–475."},{"key":"e_1_3_2_2_30_1","doi-asserted-by":"publisher","DOI":"10.1109/VLHCC.2015.7356972"},{"key":"e_1_3_2_2_31_1","unstructured":"Andrew Head Kyle Lo Daniel S. Weld and Marti A. Hearst. Forthcoming. Recognition of Composite Symbols Their Components and Their Locations in LaTeX-Based PDFs. (Forthcoming).  Andrew Head Kyle Lo Daniel S. Weld and Marti A. Hearst. Forthcoming. Recognition of Composite Symbols Their Components and Their Locations in LaTeX-Based PDFs. (Forthcoming)."},{"key":"e_1_3_2_2_32_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2019.2904683"},{"key":"e_1_3_2_2_33_1","doi-asserted-by":"publisher","DOI":"10.1145/142750.142751"},{"key":"e_1_3_2_2_34_1","doi-asserted-by":"publisher","DOI":"10.5210/fm.v15i4.2762"},{"key":"e_1_3_2_2_35_1","doi-asserted-by":"publisher","DOI":"10.1145/2207676.2208327"},{"key":"e_1_3_2_2_36_1","first-page":"65","article-title":"A Simple Sequentially Rejective Multiple Test Procedure","volume":"6","author":"Holm Sture","year":"1979","unstructured":"Sture Holm . 1979 . A Simple Sequentially Rejective Multiple Test Procedure . Scandinavian Journal of Statistics 6 , 2 (1979), 65 – 70 . Sture Holm. 1979. A Simple Sequentially Rejective Multiple Test Procedure. Scandinavian Journal of Statistics 6, 2 (1979), 65–70.","journal-title":"Scandinavian Journal of Statistics"},{"key":"e_1_3_2_2_37_1","doi-asserted-by":"publisher","DOI":"10.1145/3173574.3173608"},{"key":"e_1_3_2_2_38_1","doi-asserted-by":"publisher","DOI":"10.5951/jresematheduc.43.4.0358"},{"key":"e_1_3_2_2_39_1","doi-asserted-by":"publisher","DOI":"10.14236/ewic/HCI2014.52"},{"key":"e_1_3_2_2_40_1","doi-asserted-by":"publisher","DOI":"10.1145/3269206.3271694"},{"key":"e_1_3_2_2_41_1","volume-title":"Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 780–790","author":"Jin Yiping","year":"2013","unstructured":"Yiping Jin , Min-Yen Kan , Jun-Ping Ng , and Xiangnan He . 2013 . Mining Scientific Terms and their Definitions: A Study of the ACL Anthology . In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 780–790 . Yiping Jin, Min-Yen Kan, Jun-Ping Ng, and Xiangnan He. 2013. Mining Scientific Terms and their Definitions: A Study of the ACL Anthology. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 780–790."},{"key":"e_1_3_2_2_42_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/2020.sdp-1.22"},{"key":"e_1_3_2_2_43_1","volume-title":"https://katex.org. Last accessed","author":"X.","year":"2020","unstructured":"[ 43 ] KaTe X. https://katex.org. Last accessed September 16, 2020 . [43] KaTeX. https://katex.org. Last accessed September 16, 2020."},{"key":"e_1_3_2_2_44_1","doi-asserted-by":"publisher","DOI":"10.1145/1054972.1055047"},{"key":"e_1_3_2_2_45_1","doi-asserted-by":"publisher","DOI":"10.1145/3242587.3242617"},{"key":"e_1_3_2_2_46_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/D16-1114"},{"key":"e_1_3_2_2_47_1","volume-title":"Proceedings of the CHI Conference on Human Factors in Computing Systems. ACM, 1569–1578","author":"J.","unstructured":"Amy  J. Ko and Brad A. Myers. 2009. Finding Causes of Program Output with the Java Whyline . In Proceedings of the CHI Conference on Human Factors in Computing Systems. ACM, 1569–1578 . Amy J. Ko and Brad A. Myers. 2009. Finding Causes of Program Output with the Java Whyline. In Proceedings of the CHI Conference on Human Factors in Computing Systems. ACM, 1569–1578."},{"key":"e_1_3_2_2_48_1","volume-title":"Proceedings of the CHI Conference on Human Factors in Computing Systems. ACM. Paper 411","author":"Kocielnik Rafal","year":"2019","unstructured":"Rafal Kocielnik , Saleema Amershi , and Paul  N. Bennett . 2019 . Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-user Expectations of AI Systems . In Proceedings of the CHI Conference on Human Factors in Computing Systems. ACM. Paper 411 . Rafal Kocielnik, Saleema Amershi, and Paul N. Bennett. 2019. Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-user Expectations of AI Systems. In Proceedings of the CHI Conference on Human Factors in Computing Systems. ACM. Paper 411."},{"key":"e_1_3_2_2_49_1","doi-asserted-by":"publisher","DOI":"10.1007/978-3-319-96812-4_14"},{"key":"e_1_3_2_2_50_1","volume-title":"The Planetary System: Web 3.0 & Active Documents for STEM. Procedia Computer Science 4","author":"Kohlhase Michael","year":"2011","unstructured":"Michael Kohlhase , Joseph Corneli , Catalin David , Deyan Ginev , Constantin Jucovschi , Andrea Kohlhase , Christoph Lange , Bogdan Matican , Stefan Mirea , and Vyacheslav Zholudev . 2011. The Planetary System: Web 3.0 & Active Documents for STEM. Procedia Computer Science 4 ( 2011 ), 598–607. Michael Kohlhase, Joseph Corneli, Catalin David, Deyan Ginev, Constantin Jucovschi, Andrea Kohlhase, Christoph Lange, Bogdan Matican, Stefan Mirea, and Vyacheslav Zholudev. 2011. The Planetary System: Web 3.0 & Active Documents for STEM. Procedia Computer Science 4 (2011), 598–607."},{"key":"e_1_3_2_2_51_1","doi-asserted-by":"publisher","DOI":"10.1145/2556288.2557241"},{"key":"e_1_3_2_2_52_1","doi-asserted-by":"publisher","DOI":"10.18637/jss.v082.i13"},{"key":"e_1_3_2_2_53_1","volume-title":"https://twitter.github.io/labella.js/. Last accessed","year":"2020","unstructured":"[ 53 ] Labella.js. https://twitter.github.io/labella.js/. Last accessed September 16, 2020 . [53] Labella.js. https://twitter.github.io/labella.js/. Last accessed September 16, 2020."},{"key":"e_1_3_2_2_54_1","doi-asserted-by":"publisher","DOI":"10.1108/JD-11-2018-0178"},{"key":"e_1_3_2_2_55_1","unstructured":"Juho Lee Yoonho Lee and Yee Whye Teh. 2019. Deep Amortized Clustering. (2019). arxiv:1909.13433 [cs.LG]  Juho Lee Yoonho Lee and Yee Whye Teh. 2019. Deep Amortized Clustering. (2019). arxiv:1909.13433 [cs.LG]"},{"key":"e_1_3_2_2_56_1","volume-title":"Proceedings of the International Conference on Computational Linguistics. International Committee on Computational Linguistics, 949–960","author":"Li Minghao","year":"2020","unstructured":"Minghao Li , Yiheng Xu , Lei Cui , Shaohan Huang , Furu Wei , Zhoujun Li , and Ming Zhou . 2020 . DocBank: A Benchmark Dataset for Document Layout Analysis . In Proceedings of the International Conference on Computational Linguistics. International Committee on Computational Linguistics, 949–960 . Minghao Li, Yiheng Xu, Lei Cui, Shaohan Huang, Furu Wei, Zhoujun Li, and Ming Zhou. 2020. DocBank: A Benchmark Dataset for Document Layout Analysis. In Proceedings of the International Conference on Computational Linguistics. International Committee on Computational Linguistics, 949–960."},{"key":"e_1_3_2_2_57_1","doi-asserted-by":"publisher","DOI":"10.1109/ICDAR.2011.285"},{"key":"e_1_3_2_2_58_1","doi-asserted-by":"publisher","DOI":"10.2307/2532087"},{"key":"e_1_3_2_2_59_1","doi-asserted-by":"publisher","DOI":"10.1145/2766462.2767750"},{"key":"e_1_3_2_2_60_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/2020.acl-main.447"},{"key":"e_1_3_2_2_61_1","volume-title":"https://www.amazon.com/b?ie=UTF8&node=17717476011. Last accessed","author":"Words Look Up","year":"2020","unstructured":"[ 61 ] Look Up Words , People, and Places While You Read . https://www.amazon.com/b?ie=UTF8&node=17717476011. Last accessed September 16, 2020 . [61] Look Up Words, People, and Places While You Read. https://www.amazon.com/b?ie=UTF8&node=17717476011. Last accessed September 16, 2020."},{"key":"e_1_3_2_2_62_1","doi-asserted-by":"publisher","DOI":"10.1145/3173574.3173912"},{"key":"e_1_3_2_2_63_1","doi-asserted-by":"publisher","DOI":"10.1093/jamia/ocv044"},{"key":"e_1_3_2_2_64_1","doi-asserted-by":"publisher","DOI":"10.1145/3313831.3376559"},{"key":"e_1_3_2_2_65_1","volume-title":"https://mathjax.org/. Last accessed","year":"2021","unstructured":"[ 65 ] MathJax. https://mathjax.org/. Last accessed January 8, 2021 . [65] MathJax. https://mathjax.org/. Last accessed January 8, 2021."},{"key":"e_1_3_2_2_66_1","doi-asserted-by":"crossref","unstructured":"Elisa Mattiello. 2017. Analogy in Word-Formation: A Study of English Neologisms and Occasionalisms. De Gruyter Mouton.  Elisa Mattiello. 2017. Analogy in Word-Formation: A Study of English Neologisms and Occasionalisms. De Gruyter Mouton.","DOI":"10.1515/9783110551419"},{"key":"e_1_3_2_2_67_1","doi-asserted-by":"publisher","DOI":"10.1128/jmbe.v19i1.1439"},{"key":"e_1_3_2_2_68_1","volume-title":"https://www.mediawiki.org/wiki/Page_Previews. Last accessed","author":"Page Previews MediaWiki","year":"2020","unstructured":"MediaWiki contributors. Page Previews . https://www.mediawiki.org/wiki/Page_Previews. Last accessed September 16, 2020 . MediaWiki contributors. Page Previews. https://www.mediawiki.org/wiki/Page_Previews. Last accessed September 16, 2020."},{"key":"e_1_3_2_2_69_1","volume-title":"pdf.js. https://mozilla.github.io/pdf.js/. Last accessed","author":"Mozilla","year":"2020","unstructured":"Mozilla and individual contributors. pdf.js. https://mozilla.github.io/pdf.js/. Last accessed September 16, 2020 . Mozilla and individual contributors. pdf.js. https://mozilla.github.io/pdf.js/. Last accessed September 16, 2020."},{"key":"e_1_3_2_2_70_1","doi-asserted-by":"publisher","DOI":"10.1177/0165551510371883"},{"key":"e_1_3_2_2_71_1","first-page":"291","volume-title":"The design of everyday things","author":"Norman Don","unstructured":"Don Norman . 2013. The design of everyday things . Basic Books. See pages 288– 291 , section “The Future of Books” . Don Norman. 2013. The design of everyday things. Basic Books. See pages 288–291, section “The Future of Books”."},{"key":"e_1_3_2_2_73_1","volume-title":"Proceedings of the Conference on Intelligent Computer Mathematics.","author":"Pagel Robert","year":"2014","unstructured":"Robert Pagel and Moritz Schubotz . 2014 . Mathematical Language Processing Project . In Proceedings of the Conference on Intelligent Computer Mathematics. Robert Pagel and Moritz Schubotz. 2014. Mathematical Language Processing Project. In Proceedings of the Conference on Intelligent Computer Mathematics."},{"key":"e_1_3_2_2_74_1","volume-title":"https://peerlibrary.org/. Last accessed","year":"2020","unstructured":"[ 74 ] PeerLibrary. https://peerlibrary.org/. Last accessed September 16, 2020 . [74] PeerLibrary. https://peerlibrary.org/. Last accessed September 16, 2020."},{"key":"e_1_3_2_2_75_1","doi-asserted-by":"publisher","DOI":"10.1109/ACCESS.2020.2992067"},{"key":"e_1_3_2_2_76_1","doi-asserted-by":"publisher","DOI":"10.1037/0033-295X.106.4.643"},{"key":"e_1_3_2_2_77_1","doi-asserted-by":"publisher","DOI":"10.1145/2851581.2892334"},{"key":"e_1_3_2_2_78_1","volume-title":"Document Recognition and Retrieval","author":"Powley Brett","unstructured":"Brett Powley , Robert Dale , and Ilya Anisimoff . 2009. Enriching a Document Collection by Integrating Information Extraction and PDF Annotation . In Document Recognition and Retrieval . International Society for Optics and Photonics . Brett Powley, Robert Dale, and Ilya Anisimoff. 2009. Enriching a Document Collection by Integrating Information Extraction and PDF Annotation. In Document Recognition and Retrieval. International Society for Optics and Photonics."},{"key":"e_1_3_2_2_79_1","volume-title":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4765694/. Example document","year":"2020","unstructured":"[ 79 ] PubMed. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4765694/. Example document ; Last accessed September 16, 2020 . [79] PubMed. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4765694/. Example document; Last accessed September 16, 2020."},{"key":"e_1_3_2_2_80_1","doi-asserted-by":"publisher","DOI":"10.1145/3311957.3359455"},{"key":"e_1_3_2_2_81_1","volume-title":"What’s in a gloss?”: A commentary on Lara L. Lomicka’s ”To gloss or not to gloss”: An investigation of reading comprehension online. Language Learning & Technology 2, 2 (January","author":"Roby B.","year":"1999","unstructured":"Warren  B. Roby . 1999. ” What’s in a gloss?”: A commentary on Lara L. Lomicka’s ”To gloss or not to gloss”: An investigation of reading comprehension online. Language Learning & Technology 2, 2 (January 1999 ), 94–101. Warren B. Roby. 1999. ”What’s in a gloss?”: A commentary on Lara L. Lomicka’s ”To gloss or not to gloss”: An investigation of reading comprehension online. Language Learning & Technology 2, 2 (January 1999), 94–101."},{"key":"e_1_3_2_2_82_1","doi-asserted-by":"publisher","DOI":"10.1111/j.1467-9922.2007.00406.x"},{"key":"e_1_3_2_2_84_1","doi-asserted-by":"publisher","DOI":"10.1007/s10649-017-9754-7"},{"key":"e_1_3_2_2_85_1","volume-title":"Proceedings of the Second Workshop for NLP Open Source Software. Association for Computational Linguistics, 110–114","author":"Sadvilkar Nipun","year":"2020","unstructured":"Nipun Sadvilkar and Mark Neumann . 2020 . PySBD: Pragmatic Sentence Boundary Disambiguation . In Proceedings of the Second Workshop for NLP Open Source Software. Association for Computational Linguistics, 110–114 . Nipun Sadvilkar and Mark Neumann. 2020. PySBD: Pragmatic Sentence Boundary Disambiguation. In Proceedings of the Second Workshop for NLP Open Source Software. Association for Computational Linguistics, 110–114."},{"key":"e_1_3_2_2_86_1","doi-asserted-by":"publisher","DOI":"10.1145/274644.274680"},{"key":"e_1_3_2_2_87_1","volume-title":"https://www.scholarcy.com/scholarcy-features/. Last accessed","year":"2020","unstructured":"[ 87 ] Scholarcy. https://www.scholarcy.com/scholarcy-features/. Last accessed July 24, 2020 . [87] Scholarcy. https://www.scholarcy.com/scholarcy-features/. Last accessed July 24, 2020."},{"key":"e_1_3_2_2_88_1","volume-title":"Pacific Symposium on Biocomputing. World Scientific Press, 451–462","author":"S.","unstructured":"Ariel  S. Schwartz and Marti A. Hearst. 2003. A simple algorithm for identifying abbreviation definitions in biomedical text . In Pacific Symposium on Biocomputing. World Scientific Press, 451–462 . Ariel S. Schwartz and Marti A. Hearst. 2003. A simple algorithm for identifying abbreviation definitions in biomedical text. In Pacific Symposium on Biocomputing. World Scientific Press, 451–462."},{"key":"e_1_3_2_2_89_1","volume-title":"https://sciencedirect.com/science/article/pii/S0939388918301181. Example document","year":"2020","unstructured":"[ 89 ] ScienceDirect. https://sciencedirect.com/science/article/pii/S0939388918301181. Example document ; Last accessed September 16, 2020 . [89] ScienceDirect. https://sciencedirect.com/science/article/pii/S0939388918301181. Example document; Last accessed September 16, 2020."},{"key":"e_1_3_2_2_90_1","doi-asserted-by":"publisher","DOI":"10.1016/j.jmathb.2014.06.003"},{"key":"e_1_3_2_2_91_1","doi-asserted-by":"publisher","DOI":"10.1145/3197026.3197040"},{"key":"e_1_3_2_2_92_1","volume-title":"https://link.springer.com/chapter/10.1007/978-3-030-01424-7_27. Example document","year":"2020","unstructured":"[ 92 ] Springer. https://link.springer.com/chapter/10.1007/978-3-030-01424-7_27. Example document ; Last accessed September 16, 2020 . [92] Springer. https://link.springer.com/chapter/10.1007/978-3-030-01424-7_27. Example document; Last accessed September 16, 2020."},{"key":"e_1_3_2_2_93_1","doi-asserted-by":"crossref","unstructured":"Emma Strubell Patrick Verga Daniel Andor David Weiss and Andrew McCallum. 2018. Linguistically-Informed Self-Attention for Semantic Role Labeling. (2018). arxiv:1804.08199 [cs.CL]  Emma Strubell Patrick Verga Daniel Andor David Weiss and Andrew McCallum. 2018. Linguistically-Informed Self-Attention for Semantic Role Labeling. (2018). arxiv:1804.08199 [cs.CL]","DOI":"10.18653/v1/D18-1548"},{"key":"e_1_3_2_2_94_1","doi-asserted-by":"publisher","DOI":"10.1145/1978942.1979376"},{"key":"e_1_3_2_2_95_1","doi-asserted-by":"publisher","DOI":"10.1145/1978942.1979430"},{"key":"e_1_3_2_2_96_1","doi-asserted-by":"publisher","DOI":"10.1558/cj.v23i2.309-318"},{"key":"e_1_3_2_2_97_1","volume-title":"Electronic journals and changes in scholarly article seeking and reading patterns. 61, 1","author":"Tenopir Carol","year":"2009","unstructured":"Carol Tenopir , Donald  W. King , Sheri Edwards , and Lei Wu. 2009. Electronic journals and changes in scholarly article seeking and reading patterns. 61, 1 ( 2009 ), 5–32. Carol Tenopir, Donald W. King, Sheri Edwards, and Lei Wu. 2009. Electronic journals and changes in scholarly article seeking and reading patterns. 61, 1 (2009), 5–32."},{"key":"e_1_3_2_2_98_1","doi-asserted-by":"publisher","DOI":"10.1515/libri-2018-0120"},{"key":"e_1_3_2_2_99_1","unstructured":"Amir Pouran Ben Veyseh Franck Dernoncourt Thien Huu Nguyen Walter Chang and Leo Anthony Celi. 2020. Acronym Identification and Disambiguation Shared Tasks for Scientific Document Understanding. (2020). arxiv:2012.11760 [cs.CL]  Amir Pouran Ben Veyseh Franck Dernoncourt Thien Huu Nguyen Walter Chang and Leo Anthony Celi. 2020. Acronym Identification and Disambiguation Shared Tasks for Scientific Document Understanding. (2020). arxiv:2012.11760 [cs.CL]"},{"key":"e_1_3_2_2_100_1","volume-title":"https://code.visualstudio.com/. Last accessed","year":"2020","unstructured":"[ 100 ] VSCode. https://code.visualstudio.com/. Last accessed September 16, 2020 . [100] VSCode. https://code.visualstudio.com/. Last accessed September 16, 2020."},{"key":"e_1_3_2_2_101_1","first-page":"4","article-title":"How Mathematicians Determine if an Argument Is a Valid Proof","volume":"39","author":"Weber Keith","year":"2008","unstructured":"Keith Weber . 2008 . How Mathematicians Determine if an Argument Is a Valid Proof . Journal for Research in Mathematics Education 39 , 4 (July 2008), 431–459. Keith Weber. 2008. How Mathematicians Determine if an Argument Is a Valid Proof. Journal for Research in Mathematics Education 39, 4 (July 2008), 431–459.","journal-title":"Journal for Research in Mathematics Education"},{"key":"e_1_3_2_2_102_1","volume-title":"Teaching Language as Communication","author":"Widdowson G.","unstructured":"H.  G. Widdowson . 1978. Teaching Language as Communication . Oxford University Press . H. G. Widdowson. 1978. Teaching Language as Communication. Oxford University Press."},{"key":"e_1_3_2_2_103_1","unstructured":"Austin P. Wright Zijie J. Wang Haekyu Park Grace Guo Fabian Sperrle Mennatallah El-Assady Alex Endert Daniel Keim and Duen Horng (Polo) Chau. 2020. A Comparative Analysis of Industry Human-AI Interaction Guidelines. (2020). arxiv:2010.11761 [cs.HC]  Austin P. Wright Zijie J. Wang Haekyu Park Grace Guo Fabian Sperrle Mennatallah El-Assady Alex Endert Daniel Keim and Duen Horng (Polo) Chau. 2020. A Comparative Analysis of Industry Human-AI Interaction Guidelines. (2020). arxiv:2010.11761 [cs.HC]"},{"key":"e_1_3_2_2_104_1","doi-asserted-by":"publisher","DOI":"10.1017/S0272263119000688"},{"key":"e_1_3_2_2_105_1","doi-asserted-by":"publisher","DOI":"10.1145/3290605.3300509"},{"key":"e_1_3_2_2_106_1","doi-asserted-by":"publisher","DOI":"10.1145/2642918.2647390"},{"key":"e_1_3_2_2_107_1","doi-asserted-by":"publisher","DOI":"10.1145/1866029.1866035"},{"key":"e_1_3_2_2_108_1","doi-asserted-by":"publisher","DOI":"10.1145/276627.276633"},{"key":"e_1_3_2_2_109_1","doi-asserted-by":"publisher","DOI":"10.1145/1357054.1357161"},{"key":"e_1_3_2_2_110_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/2020.acl-demos.5"},{"key":"e_1_3_2_2_111_1","doi-asserted-by":"publisher","DOI":"10.1145/1240624.1240704"}],"event":"CHI '21: CHI Conference on Human Factors in Computing Systems","container-title":"Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/3411764.3445648","content-type":"application/pdf","content-version":"vor","intended-application":"syndication"},{"URL":"https://dl.acm.org/doi/pdf/10.1145/3411764.3445648","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,1,8]],"date-time":"2023-01-08T07:32:16Z","timestamp":1673163136000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/3411764.3445648"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2021,5,6]]},"references-count":109,"alternative-id":["10.1145/3411764.3445648","10.1145/3411764"],"URL":"http://dx.doi.org/10.1145/3411764.3445648","relation":{},"published":{"date-parts":[[2021,5,6]]},"assertion":[{"value":"2021-05-07","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/3411764.3445648"},{"indexed":{"date-parts":[[2023,10,11]],"date-time":"2023-10-11T11:57:55Z","timestamp":1697025475811},"publisher-location":"New York, NY, USA","reference-count":64,"publisher":"ACM","content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2022,4,29]]},"DOI":"10.1145/3491102.3501932","type":"proceedings-article","created":{"date-parts":[[2022,4,28]],"date-time":"2022-04-28T17:08:31Z","timestamp":1651165711000},"source":"Crossref","is-referenced-by-count":4,"title":"Math Augmentation: How Authors Enhance the Readability of Formulas using Novel Visual Design Practices","prefix":"10.1145","author":[{"given":"Andrew","family":"Head","sequence":"first","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Amber","family":"Xie","sequence":"additional","affiliation":[{"name":"UC Berkeley, United States"}]},{"given":"Marti A.","family":"Hearst","sequence":"additional","affiliation":[{"name":"UC Berkeley, United States"}]}],"member":"320","published-online":{"date-parts":[[2022,4,29]]},"reference":[{"key":"e_1_3_2_2_1_1","volume-title":"Reading mathematics: More than words can say. The Reading Teacher 56, 8","author":"Adams Thomasenia Lott","year":"2003","unstructured":"Thomasenia Lott Adams . 2003. Reading mathematics: More than words can say. The Reading Teacher 56, 8 ( 2003 ). Thomasenia Lott Adams. 2003. Reading mathematics: More than words can say. The Reading Teacher 56, 8 (2003)."},{"key":"e_1_3_2_2_2_1","volume-title":"e-Proofs: Design of a Resource to Support Proof Comprehension in Mathematics. Educational Designer 1, 4","author":"Alcock Lara","year":"2011","unstructured":"Lara Alcock and Nicola Wilkinson . 2011. e-Proofs: Design of a Resource to Support Proof Comprehension in Mathematics. Educational Designer 1, 4 ( 2011 ). Lara Alcock and Nicola Wilkinson. 2011. e-Proofs: Design of a Resource to Support Proof Comprehension in Mathematics. Educational Designer 1, 4 (2011)."},{"key":"e_1_3_2_2_3_1","volume-title":"http://www.andrusia.com/math/complex-numbers/eulers-identity.pdf Last accessed","author":"Alexander M.H.","year":"2021","unstructured":"Andrew  M.H. Alexander . Exponential Improvements . http://www.andrusia.com/math/complex-numbers/eulers-identity.pdf Last accessed December 27, 2021 . Andrew M.H. Alexander. Exponential Improvements. http://www.andrusia.com/math/complex-numbers/eulers-identity.pdf Last accessed December 27, 2021."},{"key":"e_1_3_2_2_4_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2018.2865119"},{"key":"e_1_3_2_2_5_1","volume-title":"Isaac Hayes Wallpaper Generator - Volumetric light scattering, 1 of 2. https://chuckleplant.github.io/2017/05/28/light-shafts.html Last accessed","author":"Basurco Sergio","year":"2021","unstructured":"Sergio Basurco . Isaac Hayes Wallpaper Generator - Volumetric light scattering, 1 of 2. https://chuckleplant.github.io/2017/05/28/light-shafts.html Last accessed December 27, 2021 . Sergio Basurco. Isaac Hayes Wallpaper Generator - Volumetric light scattering, 1 of 2. https://chuckleplant.github.io/2017/05/28/light-shafts.html Last accessed December 27, 2021."},{"key":"e_1_3_2_2_6_1","volume-title":"Build your own Tensorflow. https://taliesin.ai/projects/edu/indaba-2019/ Last accessed","author":"Benyon Tali","year":"2021","unstructured":"Tali Benyon . Build your own Tensorflow. https://taliesin.ai/projects/edu/indaba-2019/ Last accessed December 27, 2021 . Tali Benyon. Build your own Tensorflow. https://taliesin.ai/projects/edu/indaba-2019/ Last accessed December 27, 2021."},{"key":"e_1_3_2_2_7_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2016.2598876"},{"key":"e_1_3_2_2_8_1","volume-title":"Proceedings of the Symposium on Visual Languages and Human-Centric Computing.","author":"J.","unstructured":"Carrie  J. Cai and Philip J. Guo. 2019. Software Developers Learning Machine Learning: Motivations, Hurdles, and Desires . In Proceedings of the Symposium on Visual Languages and Human-Centric Computing. Carrie J. Cai and Philip J. Guo. 2019. Software Developers Learning Machine Learning: Motivations, Hurdles, and Desires. In Proceedings of the Symposium on Visual Languages and Human-Centric Computing."},{"key":"e_1_3_2_2_9_1","unstructured":"David P. Carlisle. Thecolorpackage CTAN-Archive.  David P. Carlisle. Thecolorpackage CTAN-Archive."},{"key":"e_1_3_2_2_10_1","volume-title":"Pixels and their neighbors: Finite volume. The Leading Edge 35, 8","author":"Cockett Rowan","year":"2016","unstructured":"Rowan Cockett , Lindsey Heagy , and Doug Oldenburg . 2016. Pixels and their neighbors: Finite volume. The Leading Edge 35, 8 ( 2016 ). Rowan Cockett, Lindsey Heagy, and Doug Oldenburg. 2016. Pixels and their neighbors: Finite volume. The Leading Edge 35, 8 (2016)."},{"key":"e_1_3_2_2_11_1","doi-asserted-by":"publisher","DOI":"10.1145/3242587.3242600"},{"key":"e_1_3_2_2_12_1","volume-title":"Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory","author":"Corbin Juliet","unstructured":"Juliet Corbin and Anselm Strauss . 2008. Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory ( 3 rd ed.). SAGE Publications . Juliet Corbin and Anselm Strauss. 2008. Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory (3rd ed.). SAGE Publications.","edition":"3"},{"key":"e_1_3_2_2_13_1","doi-asserted-by":"publisher","DOI":"10.1145/3411763.3451564"},{"key":"e_1_3_2_2_14_1","doi-asserted-by":"publisher","DOI":"10.1145/3290605.3300295"},{"key":"e_1_3_2_2_15_1","volume-title":"Proceedings of the International Conference on Intelligent User Interfaces.","author":"N.","unstructured":"Anton  N. Dragunov and Jonathan L. Herlocker. 2003. Designing intelligent and dynamic interfaces for communicating mathematics . In Proceedings of the International Conference on Intelligent User Interfaces. Anton N. Dragunov and Jonathan L. Herlocker. 2003. Designing intelligent and dynamic interfaces for communicating mathematics. In Proceedings of the International Conference on Intelligent User Interfaces."},{"key":"e_1_3_2_2_16_1","volume-title":"https://katex.org Last accessed","author":"Eisenberg Emily","year":"2020","unstructured":"Emily Eisenberg and Sophie Alpert . KaTe X. https://katex.org Last accessed September 16, 2020 . Emily Eisenberg and Sophie Alpert. KaTeX. https://katex.org Last accessed September 16, 2020."},{"key":"e_1_3_2_2_17_1","volume-title":"Canis: A High‐Level Language for Data‐Driven Chart Animations. Computer Graphics Forum 39","author":"Ge Tong","year":"2020","unstructured":"Tong Ge , Yue Zhao , Bongshin Lee , Donghao Ren , Baoquan Chen , and Yunhai Wang . 2020 . Canis: A High‐Level Language for Data‐Driven Chart Animations. Computer Graphics Forum 39 (2020). Tong Ge, Yue Zhao, Bongshin Lee, Donghao Ren, Baoquan Chen, and Yunhai Wang. 2020. Canis: A High‐Level Language for Data‐Driven Chart Animations. Computer Graphics Forum 39 (2020)."},{"key":"e_1_3_2_2_18_1","volume-title":"Why momentum really works. Distill 2, 4","author":"Goh Gabriel","year":"2017","unstructured":"Gabriel Goh . 2017. Why momentum really works. Distill 2, 4 ( 2017 ). http://distill.pub/2017/momentum Gabriel Goh. 2017. Why momentum really works. Distill 2, 4 (2017). http://distill.pub/2017/momentum"},{"key":"e_1_3_2_2_19_1","doi-asserted-by":"crossref","unstructured":"Sam Greydanus and Chris Olah. 2019. The Paths Perspective on Value Learning. In Distill. https://distill.pub/2019/paths-perspective-on-value-learning  Sam Greydanus and Chris Olah. 2019. The Paths Perspective on Value Learning. In Distill. https://distill.pub/2019/paths-perspective-on-value-learning","DOI":"10.23915/distill.00020"},{"key":"e_1_3_2_2_20_1","volume-title":"NeurIPs Poster Presentation. https://nips.cc/virtual/2020/protected/poster_0b1ec366924b26fc98fa7b71a9c249cf.html Last accessed","author":"He Bobby","year":"2021","unstructured":"Bobby He , Balaji Lakshminarayanan , and Yee Whye Teh . Bayesian Deep Ensembles via the Neural Tangent Kernel , NeurIPs Poster Presentation. https://nips.cc/virtual/2020/protected/poster_0b1ec366924b26fc98fa7b71a9c249cf.html Last accessed December 30, 2021 . Bobby He, Balaji Lakshminarayanan, and Yee Whye Teh. Bayesian Deep Ensembles via the Neural Tangent Kernel, NeurIPs Poster Presentation. https://nips.cc/virtual/2020/protected/poster_0b1ec366924b26fc98fa7b71a9c249cf.html Last accessed December 30, 2021."},{"key":"e_1_3_2_2_21_1","doi-asserted-by":"publisher","DOI":"10.1109/VLHCC.2015.7356972"},{"key":"e_1_3_2_2_22_1","doi-asserted-by":"publisher","DOI":"10.1145/3411764.3445648"},{"key":"e_1_3_2_2_23_1","doi-asserted-by":"crossref","unstructured":"Fred Hohman Matthew Conlen Jeffrey Heer and Duen Horng Chau. 2020. Communicating with Interactive Articles. distill.pub.  Fred Hohman Matthew Conlen Jeffrey Heer and Duen Horng Chau. 2020. Communicating with Interactive Articles. distill.pub.","DOI":"10.23915/distill.00028"},{"key":"e_1_3_2_2_24_1","doi-asserted-by":"publisher","DOI":"10.1145/3290605.3300809"},{"key":"e_1_3_2_2_25_1","unstructured":"Fred Hohman and other contributors. 2020. Awesome Mathematical Notation Design. https://github.com/fredhohman/awesome-mathematical-notation-design  Fred Hohman and other contributors. 2020. Awesome Mathematical Notation Design. https://github.com/fredhohman/awesome-mathematical-notation-design"},{"key":"e_1_3_2_2_26_1","volume-title":"Content Analysis for the Social Sciences and Humanities","author":"Holsti Ole","unstructured":"Ole Holsti . 1969. Content Analysis for the Social Sciences and Humanities . Addison-Wesley . Ole Holsti. 1969. Content Analysis for the Social Sciences and Humanities. Addison-Wesley."},{"key":"e_1_3_2_2_27_1","volume-title":"Visualization Rhetoric: Framing Effects in Narrative Visualization","author":"Hullman Jessica","year":"2011","unstructured":"Jessica Hullman and Nicholas Diakopoulos . 2011 . Visualization Rhetoric: Framing Effects in Narrative Visualization . IEEE Transactions on Visualization and Computer Graphics 17(2011). Jessica Hullman and Nicholas Diakopoulos. 2011. Visualization Rhetoric: Framing Effects in Narrative Visualization. IEEE Transactions on Visualization and Computer Graphics 17(2011)."},{"key":"e_1_3_2_2_28_1","doi-asserted-by":"publisher","DOI":"10.1145/2470654.2481374"},{"key":"e_1_3_2_2_29_1","doi-asserted-by":"publisher","DOI":"10.1145/3173574.3173608"},{"key":"e_1_3_2_2_30_1","volume-title":"Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations. https://eng.uber.com/uber-eats-graph-learning/ Last accessed","author":"Jain Ankit","year":"2021","unstructured":"Ankit Jain , Isaac Liu , Ankur Sarda , and Piero Molino . Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations. https://eng.uber.com/uber-eats-graph-learning/ Last accessed December 30, 2021 . Ankit Jain, Isaac Liu, Ankur Sarda, and Piero Molino. Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations. https://eng.uber.com/uber-eats-graph-learning/ Last accessed December 30, 2021."},{"key":"e_1_3_2_2_31_1","volume-title":"Proceedings of the Conference of the Cognitive Science Society.","author":"Jansen R.","year":"1999","unstructured":"Anthony  R. Jansen , Kim Marriott , and Greg Yelland . 1999 . Perceiving structure in mathematical expressions . In Proceedings of the Conference of the Cognitive Science Society. Anthony R. Jansen, Kim Marriott, and Greg Yelland. 1999. Perceiving structure in mathematical expressions. In Proceedings of the Conference of the Cognitive Science Society."},{"key":"e_1_3_2_2_32_1","doi-asserted-by":"publisher","DOI":"10.1145/3313831.3376252"},{"key":"e_1_3_2_2_33_1","doi-asserted-by":"publisher","DOI":"10.1145/3242587.3242617"},{"key":"e_1_3_2_2_34_1","doi-asserted-by":"publisher","DOI":"10.1109/VISUAL.2019.8933773"},{"key":"e_1_3_2_2_35_1","unstructured":"Donald Ervin Knuth. 1986. Computers & Typesetting Vol. A: The TeX book. Addison-Wesley Longman Publishing Co. Inc.  Donald Ervin Knuth. 1986. Computers & Typesetting Vol. A: The TeX book. Addison-Wesley Longman Publishing Co. Inc."},{"key":"e_1_3_2_2_36_1","doi-asserted-by":"crossref","unstructured":"Andrea Kohlhase Michael Kohlhase and Taweechai Ouypornkochagorn. 2018. Discourse Phenomena in Mathematical Documents. In Intelligent Computer Mathematics Florian Rabe William M. Farmer Grant O. Passmore and Abdou Youssef (Eds.).  Andrea Kohlhase Michael Kohlhase and Taweechai Ouypornkochagorn. 2018. Discourse Phenomena in Mathematical Documents. In Intelligent Computer Mathematics Florian Rabe William M. Farmer Grant O. Passmore and Abdou Youssef (Eds.).","DOI":"10.1007/978-3-319-96812-4_14"},{"key":"e_1_3_2_2_37_1","volume-title":"Proceedings of the CHI Conference on Human Factors in Computing Systems.","author":"Zhu Wenjie","year":"2019","unstructured":"Ha-kyung Kong, Wenjie Zhu , Zhicheng Liu , and Karrie Karahalios . 2019 . Understanding Visual Cues in Visualizations Accompanied by Audio Narrations . In Proceedings of the CHI Conference on Human Factors in Computing Systems. Ha-kyung Kong, Wenjie Zhu, Zhicheng Liu, and Karrie Karahalios. 2019. Understanding Visual Cues in Visualizations Accompanied by Audio Narrations. In Proceedings of the CHI Conference on Human Factors in Computing Systems."},{"key":"e_1_3_2_2_38_1","doi-asserted-by":"publisher","DOI":"10.1145/2556288.2557241"},{"key":"e_1_3_2_2_39_1","doi-asserted-by":"crossref","unstructured":"David Landy and Robert L. Goldstone. 2007. Formal notations are diagrams: Evidence from a production task. Memory & Cognition 35(2007).  David Landy and Robert L. Goldstone. 2007. Formal notations are diagrams: Evidence from a production task. Memory & Cognition 35(2007).","DOI":"10.3758/BF03192935"},{"key":"e_1_3_2_2_40_1","volume-title":"Proceedings of the IEEE Visualization Conference.","author":"Latif Shahid","year":"2021","unstructured":"Shahid Latif , Zheng Zhou , Yoon Kim , Fabian Beck , and Nam Wook Kim . 2021 . Kori: Interactive Synthesis of Text and Charts in Data Documents . In Proceedings of the IEEE Visualization Conference. Shahid Latif, Zheng Zhou, Yoon Kim, Fabian Beck, and Nam Wook Kim. 2021. Kori: Interactive Synthesis of Text and Charts in Data Documents. In Proceedings of the IEEE Visualization Conference."},{"key":"e_1_3_2_2_41_1","doi-asserted-by":"publisher","DOI":"10.1109/PacificVis52677.2021.00011"},{"key":"e_1_3_2_2_42_1","unstructured":"Lars Madsen Will Robertson and Joseph Wright. The mathtools package CTAN-Archive ctan.org.  Lars Madsen Will Robertson and Joseph Wright. The mathtools package CTAN-Archive ctan.org."},{"key":"e_1_3_2_2_43_1","volume-title":"NeurIPs Poster Presentation. https://nips.cc/virtual/2020/protected/poster_4a4526b1ec301744aba9526d78fcb2a6.html Last accessed","author":"Meng Chenlin","year":"2021","unstructured":"Chenlin Meng , Lantao Yu , Yang Song , Jiaming Song , and Stefano Ermon . Autoregressive Score Matching , NeurIPs Poster Presentation. https://nips.cc/virtual/2020/protected/poster_4a4526b1ec301744aba9526d78fcb2a6.html Last accessed December 30, 2021 . Chenlin Meng, Lantao Yu, Yang Song, Jiaming Song, and Stefano Ermon. Autoregressive Score Matching, NeurIPs Poster Presentation. https://nips.cc/virtual/2020/protected/poster_4a4526b1ec301744aba9526d78fcb2a6.html Last accessed December 30, 2021."},{"key":"e_1_3_2_2_44_1","volume-title":"ICML Poster Presentation. https://icml.cc/virtual/2020/poster/5851 Last accessed","author":"Moor Michael","year":"2021","unstructured":"Michael Moor , Max Horn , Bastian Rieck , and Karsten Borgwardt . Topological Autoencoders , ICML Poster Presentation. https://icml.cc/virtual/2020/poster/5851 Last accessed December 30, 2021 . Michael Moor, Max Horn, Bastian Rieck, and Karsten Borgwardt. Topological Autoencoders, ICML Poster Presentation. https://icml.cc/virtual/2020/poster/5851 Last accessed December 30, 2021."},{"key":"e_1_3_2_2_45_1","volume-title":"Derivation of the Navier-Stokes Equations. https://www.youtube.com/watch?v=zWdnf3Uh1RE Last accessed","author":"Murad Jousef","year":"2021","unstructured":"Jousef Murad . Derivation of the Navier-Stokes Equations. https://www.youtube.com/watch?v=zWdnf3Uh1RE Last accessed December 30, 2021 . Jousef Murad. Derivation of the Navier-Stokes Equations. https://www.youtube.com/watch?v=zWdnf3Uh1RE Last accessed December 30, 2021."},{"key":"e_1_3_2_2_46_1","volume-title":"Characterizing Reading Comprehension of Mathematical Texts. Educational Studies in Mathematics 63","author":"Österholm Magnus","year":"2006","unstructured":"Magnus Österholm . 2006. Characterizing Reading Comprehension of Mathematical Texts. Educational Studies in Mathematics 63 ( 2006 ). Magnus Österholm. 2006. Characterizing Reading Comprehension of Mathematical Texts. Educational Studies in Mathematics 63 (2006)."},{"key":"e_1_3_2_2_47_1","volume-title":"ICML Poster Presentation (slide 27). https://icml.cc/virtual/2020/poster/6425 Last accessed","author":"Pakman Ari","year":"2021","unstructured":"Ari Pakman , Yueqi Wang , Catalin Mitelut , and JinHyung Lee . Neural Clustering Processes , ICML Poster Presentation (slide 27). https://icml.cc/virtual/2020/poster/6425 Last accessed December 30, 2021 . Ari Pakman, Yueqi Wang, Catalin Mitelut, and JinHyung Lee. Neural Clustering Processes, ICML Poster Presentation (slide 27). https://icml.cc/virtual/2020/poster/6425 Last accessed December 30, 2021."},{"key":"e_1_3_2_2_48_1","volume-title":"Image Kernels Explained Visually. https://setosa.io/ev/image-kernels/ Last accessed","author":"Powell Victor","year":"2021","unstructured":"Victor Powell . Image Kernels Explained Visually. https://setosa.io/ev/image-kernels/ Last accessed December 30, 2021 . Victor Powell. Image Kernels Explained Visually. https://setosa.io/ev/image-kernels/ Last accessed December 30, 2021."},{"key":"e_1_3_2_2_49_1","unstructured":"Edward Raff. 2020. Inside Deep Learning: Math Algorithms Models. Manning.  Edward Raff. 2020. Inside Deep Learning: Math Algorithms Models. Manning."},{"key":"e_1_3_2_2_50_1","volume-title":"Proceedings of the IEEE Pacific Visualization Symposium (PacificVis).","author":"Ren Donghao","unstructured":"Donghao Ren , M. Brehmer , Bongshin Lee , Tobias Höllerer , and E. Choe . 2017. ChartAccent: Annotation for data-driven storytelling . In Proceedings of the IEEE Pacific Visualization Symposium (PacificVis). Donghao Ren, M. Brehmer, Bongshin Lee, Tobias Höllerer, and E. Choe. 2017. ChartAccent: Annotation for data-driven storytelling. In Proceedings of the IEEE Pacific Visualization Symposium (PacificVis)."},{"key":"e_1_3_2_2_51_1","volume-title":"https://www.c82.net/euclid/book1 Last accessed","author":"Rougeux Nicholas","year":"2021","unstructured":"Nicholas Rougeux . Byrne’s Euclid . https://www.c82.net/euclid/book1 Last accessed December 30, 2021 . Nicholas Rougeux. Byrne’s Euclid. https://www.c82.net/euclid/book1 Last accessed December 30, 2021."},{"key":"e_1_3_2_2_52_1","unstructured":"Grant Sanderson. Manim. https://3b1b.github.io/manim/  Grant Sanderson. Manim. https://3b1b.github.io/manim/"},{"key":"e_1_3_2_2_53_1","doi-asserted-by":"publisher","DOI":"10.1145/3411764.3445460"},{"key":"e_1_3_2_2_54_1","doi-asserted-by":"crossref","unstructured":"Alper Sarikaya M. Correll L. Bartram Melanie K. Tory and Danyel Fisher. 2019. What Do We Talk About When We Talk About Dashboards?IEEE Transactions on Visualization and Computer Graphics 25(2019).  Alper Sarikaya M. Correll L. Bartram Melanie K. Tory and Danyel Fisher. 2019. What Do We Talk About When We Talk About Dashboards?IEEE Transactions on Visualization and Computer Graphics 25(2019).","DOI":"10.1109/TVCG.2018.2864903"},{"key":"e_1_3_2_2_55_1","volume-title":"Authoring Narrative Visualizations with Ellipsis. Computer Graphics Forum 33","author":"Satyanarayan Arvind","year":"2014","unstructured":"Arvind Satyanarayan and Jeffrey Heer . 2014. Authoring Narrative Visualizations with Ellipsis. Computer Graphics Forum 33 ( 2014 ). Arvind Satyanarayan and Jeffrey Heer. 2014. Authoring Narrative Visualizations with Ellipsis. Computer Graphics Forum 33 (2014)."},{"key":"e_1_3_2_2_56_1","volume-title":"Vega-Lite: A Grammar of Interactive Graphics","author":"Satyanarayan Arvind","unstructured":"Arvind Satyanarayan , Dominik Moritz , Kanit Wongsuphasawat , and Jeffrey Heer . 2017. Vega-Lite: A Grammar of Interactive Graphics . In IEEE Transactions on Visualization and Computer Graphics, Vol . 23. Arvind Satyanarayan, Dominik Moritz, Kanit Wongsuphasawat, and Jeffrey Heer. 2017. Vega-Lite: A Grammar of Interactive Graphics. In IEEE Transactions on Visualization and Computer Graphics, Vol. 23."},{"key":"e_1_3_2_2_57_1","volume-title":" D. Sande","author":"Shepherd D.","year":"2014","unstructured":"Mary  D. Shepherd and Carla V .  D. Sande . 2014 . Reading mathematics for understanding—From novice to expert. The Journal of Mathematical Behavior 35 (2014). Mary D. Shepherd and Carla V. D. Sande. 2014. Reading mathematics for understanding—From novice to expert. The Journal of Mathematical Behavior 35 (2014)."},{"key":"e_1_3_2_2_58_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2018.2865145"},{"key":"e_1_3_2_2_59_1","volume-title":"The visual display of quantitative information","author":"Tufte Edward","unstructured":"Edward Tufte . 1985. The visual display of quantitative information . Graphics Press . Edward Tufte. 1985. The visual display of quantitative information. Graphics Press."},{"key":"e_1_3_2_2_60_1","unstructured":"Bret Victor. Tangle: a JavaScript library for reactive documents. http://worrydream.com/Tangle/ Last accessed August 15 2021.  Bret Victor. Tangle: a JavaScript library for reactive documents. http://worrydream.com/Tangle/ Last accessed August 15 2021."},{"key":"e_1_3_2_2_61_1","volume-title":"Iconicity in Mathematical Notation: Commutativity and Symmetry. Journal of Numerical Cognition 6","author":"Wege E.","year":"2020","unstructured":"Theresa  E. Wege , Sophie Batchelor , Matthew Inglis , Honali Mistry , and Dirk Schlimm . 2020. Iconicity in Mathematical Notation: Commutativity and Symmetry. Journal of Numerical Cognition 6 ( 2020 ). Theresa E. Wege, Sophie Batchelor, Matthew Inglis, Honali Mistry, and Dirk Schlimm. 2020. Iconicity in Mathematical Notation: Commutativity and Symmetry. Journal of Numerical Cognition 6 (2020)."},{"key":"e_1_3_2_2_62_1","doi-asserted-by":"publisher","DOI":"10.1145/3386569.3392375"},{"key":"e_1_3_2_2_63_1","volume-title":"Yung and Fred Paas","author":"I.","year":"2015","unstructured":"Hsin  I. Yung and Fred Paas . 2015 . Effects of Computer-Based Visual Representation on Mathematics Learning and Cognitive Load. J. Educ. Technol. Soc . 18 (2015). Hsin I. Yung and Fred Paas. 2015. Effects of Computer-Based Visual Representation on Mathematics Learning and Cognitive Load. J. Educ. Technol. Soc. 18 (2015)."},{"key":"e_1_3_2_2_64_1","doi-asserted-by":"publisher","DOI":"10.1145/1866029.1866035"}],"event":"CHI '22: CHI Conference on Human Factors in Computing Systems","container-title":"CHI Conference on Human Factors in Computing Systems","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/3491102.3501932","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2022,5,16]],"date-time":"2022-05-16T07:31:06Z","timestamp":1652686266000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/3491102.3501932"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2022,4,29]]},"references-count":64,"alternative-id":["10.1145/3491102.3501932","10.1145/3491102"],"URL":"http://dx.doi.org/10.1145/3491102.3501932","relation":{},"published":{"date-parts":[[2022,4,29]]},"id":"doi:10.1145/3491102.3501932"},{"indexed":{"date-parts":[[2023,10,10]],"date-time":"2023-10-10T12:52:30Z","timestamp":1696942350240},"reference-count":27,"publisher":"IEEE","license":[{"start":{"date-parts":[[2021,10,1]],"date-time":"2021-10-01T00:00:00Z","timestamp":1633046400000},"content-version":"stm-asf","delay-in-days":0,"URL":"https://doi.org/10.15223/policy-029"},{"start":{"date-parts":[[2021,10,1]],"date-time":"2021-10-01T00:00:00Z","timestamp":1633046400000},"content-version":"stm-asf","delay-in-days":0,"URL":"https://doi.org/10.15223/policy-037"}],"content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2021,10]]},"DOI":"10.1109/vis49827.2021.9623323","type":"proceedings-article","created":{"date-parts":[[2021,12,1]],"date-time":"2021-12-01T00:10:43Z","timestamp":1638317443000},"source":"Crossref","is-referenced-by-count":5,"title":"Fast &amp; Accurate Gaussian Kernel Density Estimation","prefix":"10.1109","author":[{"given":"Jeffrey","family":"Heer","sequence":"first","affiliation":[{"name":"University of Washiington"}]}],"member":"263","reference":[{"key":"ref10","author":"horst","year":"2020","journal-title":"palmerpenguins Palmer Archipelago (Antarctica) penguin data"},{"key":"ref11","doi-asserted-by":"publisher","DOI":"10.1080/00949658308810650"},{"key":"ref12","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2014.2346325"},{"key":"ref13","doi-asserted-by":"publisher","DOI":"10.1145/37402.37422"},{"key":"ref14","doi-asserted-by":"publisher","DOI":"10.1214/aoms/1177704472"},{"key":"ref15","first-page":"2825","article-title":"Scikit-learn: Machine learning in Python","volume":"12","author":"pedregosa","year":"2011","journal-title":"Journal of Machine Learning Research"},{"key":"ref16","author":"ramos","year":"1983","journal-title":"ASA Data Exposition dataset"},{"key":"ref17","doi-asserted-by":"publisher","DOI":"10.1214/aoms/1177728190"},{"key":"ref18","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2016.2599030"},{"key":"ref19","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2015.2467091"},{"key":"ref4","doi-asserted-by":"publisher","DOI":"10.1109/34.41386"},{"key":"ref27","author":"wickham","year":"2009","journal-title":"ggplot2 Elegant Graphics for Data Analysis"},{"key":"ref3","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2014.2346298"},{"key":"ref6","doi-asserted-by":"publisher","DOI":"10.5201/ipol.2013.87"},{"key":"ref5","author":"deriche","year":"1993","journal-title":"Recursively Implementing the Gaussian and Its Derivatives"},{"key":"ref8","first-page":"447","article-title":"Theoretical foundations of Gaussian convolution by extended box filtering","author":"gwosdek","year":"2011","journal-title":"Proc International Conference on Scale Space and Variational Methods inComputer Vision"},{"key":"ref7","doi-asserted-by":"publisher","DOI":"10.1137/1.9781611972733.19"},{"key":"ref2","doi-asserted-by":"publisher","DOI":"10.23919/ICIF.2018.8455686"},{"key":"ref9","doi-asserted-by":"publisher","DOI":"10.2307/2685478"},{"key":"ref1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2011.185"},{"key":"ref20","doi-asserted-by":"crossref","author":"scott","year":"1992","journal-title":"Multivariate Density Estimation Theory Practice and Visualization","DOI":"10.1002/9780470316849"},{"key":"ref22","doi-asserted-by":"publisher","DOI":"10.1111/j.2517-6161.1991.tb01857.x"},{"key":"ref21","doi-asserted-by":"publisher","DOI":"10.1080/03610928508828980"},{"key":"ref24","doi-asserted-by":"publisher","DOI":"10.1007/978-0-387-21706-2"},{"key":"ref23","doi-asserted-by":"publisher","DOI":"10.2307/2347084"},{"key":"ref26","doi-asserted-by":"publisher","DOI":"10.1109/TPAMI.1986.4767776"},{"key":"ref25","first-page":"433","article-title":"Fast computation of multivariate kernel estimators","volume":"3","author":"wand","year":"1994","journal-title":"Journal of Statistical Computation and Simulation"}],"event":"2021 IEEE Visualization Conference (VIS)","container-title":"2021 IEEE Visualization Conference (VIS)","original-title":[],"link":[{"URL":"http://xplorestaging.ieee.org/ielx7/9622895/9623263/09623323.pdf?arnumber=9623323","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,5,25]],"date-time":"2023-05-25T17:35:33Z","timestamp":1685036133000},"score":1,"resource":{"primary":{"URL":"https://ieeexplore.ieee.org/document/9623323/"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2021,10]]},"references-count":27,"URL":"http://dx.doi.org/10.1109/VIS49827.2021.9623323","relation":{},"published":{"date-parts":[[2021,10]]},"id":"doi:10.1109/VIS49827.2021.9623323"},{"indexed":{"date-parts":[[2023,10,18]],"date-time":"2023-10-18T06:57:30Z","timestamp":1697612250685},"publisher-location":"New York, New York, USA","reference-count":0,"publisher":"ACM Press","content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[1992]]},"DOI":"10.1145/142750.142751","type":"proceedings-article","created":{"date-parts":[[2003,11,13]],"date-time":"2003-11-13T16:10:21Z","timestamp":1068739821000},"source":"Crossref","is-referenced-by-count":274,"title":"Edit wear and read wear","prefix":"10.1145","author":[{"given":"William C.","family":"Hill","sequence":"first","affiliation":[]},{"given":"James D.","family":"Hollan","sequence":"additional","affiliation":[]},{"given":"Dave","family":"Wroblewski","sequence":"additional","affiliation":[]},{"given":"Tim","family":"McCandless","sequence":"additional","affiliation":[]}],"member":"320","event":"the SIGCHI conference","container-title":"Proceedings of the SIGCHI conference on Human factors in computing systems  - CHI '92","original-title":[],"link":[{"URL":"http://dl.acm.org/ft_gateway.cfm?id=142751&amp;ftid=23376&amp;dwn=1","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2021,1,29]],"date-time":"2021-01-29T15:23:44Z","timestamp":1611933824000},"score":1,"resource":{"primary":{"URL":"http://portal.acm.org/citation.cfm?doid=142750.142751"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[1992]]},"references-count":0,"URL":"http://dx.doi.org/10.1145/142750.142751","relation":{},"published":{"date-parts":[[1992]]},"id":"doi:10.1145/142750.142751"},{"indexed":{"date-parts":[[2023,10,17]],"date-time":"2023-10-17T14:53:44Z","timestamp":1697554424900},"update-to":[{"updated":{"date-parts":[[2019,7,5]],"date-time":"2019-07-05T00:00:00Z","timestamp":1562284800000},"DOI":"10.1371/journal.pcbi.1007128","type":"new_version","label":"New version"}],"reference-count":97,"publisher":"Public Library of Science (PLoS)","issue":"6","license":[{"start":{"date-parts":[[2019,6,24]],"date-time":"2019-06-24T00:00:00Z","timestamp":1561334400000},"content-version":"vor","delay-in-days":0,"URL":"http://creativecommons.org/licenses/by/4.0/"}],"funder":[{"DOI":"10.13039/100000879","name":"Alfred P. Sloan Foundation","doi-asserted-by":"publisher","award":["G-2018-11163"]},{"DOI":"10.13039/100000936","name":"Gordon and Betty Moore Foundation","doi-asserted-by":"publisher","award":["GBMF4552"]},{"DOI":"10.13039/100004917","name":"Cancer Prevention and Research Institute of Texas","doi-asserted-by":"publisher","award":["RP150596"]}],"content-domain":{"domain":["www.ploscompbiol.org"],"crossmark-restriction":false},"DOI":"10.1371/journal.pcbi.1007128","type":"journal-article","created":{"date-parts":[[2019,6,24]],"date-time":"2019-06-24T22:35:17Z","timestamp":1561415717000},"page":"e1007128","update-policy":"http://dx.doi.org/10.1371/journal.pcbi.corrections_policy","source":"Crossref","is-referenced-by-count":41,"title":"Open collaborative writing with Manubot","prefix":"10.1371","volume":"15","author":[{"ORCID":"http://orcid.org/0000-0002-3012-7446","authenticated-orcid":true,"given":"Daniel S.","family":"Himmelstein","sequence":"first","affiliation":[]},{"ORCID":"http://orcid.org/0000-0002-4655-3773","authenticated-orcid":true,"given":"Vincent","family":"Rubinetti","sequence":"additional","affiliation":[]},{"ORCID":"http://orcid.org/0000-0003-3928-5050","authenticated-orcid":true,"given":"David R.","family":"Slochower","sequence":"additional","affiliation":[]},{"given":"Dongbo","family":"Hu","sequence":"additional","affiliation":[]},{"ORCID":"http://orcid.org/0000-0002-0144-0564","authenticated-orcid":true,"given":"Venkat S.","family":"Malladi","sequence":"additional","affiliation":[]},{"ORCID":"http://orcid.org/0000-0001-8713-9213","authenticated-orcid":true,"given":"Casey S.","family":"Greene","sequence":"additional","affiliation":[]},{"ORCID":"http://orcid.org/0000-0002-5324-9833","authenticated-orcid":true,"given":"Anthony","family":"Gitter","sequence":"additional","affiliation":[]}],"member":"340","published-online":{"date-parts":[[2019,6,24]]},"reference":[{"key":"ref1","article-title":"Reinventing Discovery","author":"M Nielsen","year":"2011"},{"key":"ref2","unstructured":"National Academies of Sciences, Engineering, and Medicine. Open Science by Design: Realizing a Vision for 21st Century Research [Internet]. National Academies Press; 2018. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.17226/25116\" xlink:type=\"simple\">10.17226/25116</ext-link></comment>"},{"key":"ref3","unstructured":"Perkel J. TechBlog: “Manubot” powers a crowdsourced “deep-learning” review. In: Naturejobs [Internet]. 20 Feb 2018. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://blogs.nature.com/naturejobs/2018/02/20/techblog-manubot-powers-a-crowdsourced-deep-learning-review/\" xlink:type=\"simple\">http://blogs.nature.com/naturejobs/2018/02/20/techblog-manubot-powers-a-crowdsourced-deep-learning-review/</ext-link>"},{"key":"ref4","doi-asserted-by":"crossref","first-page":"23","DOI":"10.1093/bib/bbv021","article-title":"Crowdsourcing in biomedicine: challenges and opportunities","volume":"17","author":"R Khare","year":"2016","journal-title":"Brief Bioinform. Oxford University Press"},{"key":"ref5","doi-asserted-by":"crossref","first-page":"20170387","DOI":"10.1098/rsif.2017.0387","article-title":"Opportunities and obstacles for deep learning in biology and medicine","volume":"15","author":"T Ching","year":"2018","journal-title":"J R Soc Interface. The Royal Society"},{"key":"ref6","first-page":"127","article-title":"Scientific writing: the online cooperative","volume":"514","author":"JM Perkel","year":"2014","journal-title":"Nature. Springer Nature"},{"key":"ref7","doi-asserted-by":"crossref","first-page":"e1004668","DOI":"10.1371/journal.pcbi.1004668","article-title":"A Quick Introduction to Version Control with Git and GitHub","volume":"12","author":"JD Blischak","year":"2016","journal-title":"PLoS Comput Biol. Public Library of Science (PLoS)"},{"key":"ref8","doi-asserted-by":"crossref","first-page":"e1004947","DOI":"10.1371/journal.pcbi.1004947","article-title":"Ten Simple Rules for Taking Advantage of Git and GitHub","volume":"12","author":"Y Perez-Riverol","year":"2016","journal-title":"PLoS Comput Biol. Public Library of Science (PLoS"},{"key":"ref9","unstructured":"Israeli J. Opportunities And Obstacles For Deep Learning In Biology And Medicine. In: Towards Data Science [Internet]. 31 May 2017 [cited 11 Jun 2019]. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://towardsdatascience.com/opportunities-and-obstacles-for-deep-learning-in-biology-and-medicine-6ec914fe18c2\" xlink:type=\"simple\">https://towardsdatascience.com/opportunities-and-obstacles-for-deep-learning-in-biology-and-medicine-6ec914fe18c2</ext-link>"},{"key":"ref10","unstructured":"Ching T, Himmelstein DS, Beaulieu-Jones BK, Kalinin AA, Do BT, Way GP, et al. Opportunities And Obstacles For Deep Learning In Biology And Medicine [Internet]. bioRxiv. Cold Spring Harbor Laboratory; 2017. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.1101/142760\" xlink:type=\"simple\">10.1101/142760</ext-link></comment>"},{"key":"ref11","unstructured":"Project Jupyter, Bussonnier M, Forde J, Freeman J, Granger B, Head T, et al. Binder 2.0—Reproducible, interactive, sharable environments for science at scale. Proceedings of the 17th Python in Science Conference. SciPy; 2018. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.25080/majora-4af1f417-011\" xlink:type=\"simple\">10.25080/majora-4af1f417-011</ext-link></comment>"},{"key":"ref12","doi-asserted-by":"crossref","first-page":"e112","DOI":"10.7717/peerj-cs.112","article-title":"Formatting Open Science: agilely creating multiple document formats for academic manuscripts with Pandoc Scholar","volume":"3","author":"A Krewinkel","year":"2017","journal-title":"PeerJ Computer Science. PeerJ"},{"key":"ref13","first-page":"125","article-title":"Reference Management","author":"M Fenner","year":"2013","journal-title":"Opening Science. Springer International Publishing"},{"key":"ref14","doi-asserted-by":"crossref","first-page":"45","DOI":"10.1080/02763869.2012.641841","article-title":"Comparison of Select Reference Management Tools","volume":"31","author":"Y Zhang","year":"2012","journal-title":"Medical Reference Services Quarterly. Informa UK Limited"},{"key":"ref15","unstructured":"Lord P, Marshall L. Twenty-Five Shades of Greycite: Semantics for referencing and preservation [Internet]. arXiv. arXiv; 2013 Apr. Report No.: 1304.7151v1. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://arxiv.org/abs/1304.7151v1\" xlink:type=\"simple\">https://arxiv.org/abs/1304.7151v1</ext-link>"},{"key":"ref16","doi-asserted-by":"crossref","first-page":"221","DOI":"10.1016/j.tig.2015.03.006","article-title":"Reviewing post-publication peer review","volume":"31","author":"P Knoepfler","year":"2015","journal-title":"Trends Genet"},{"key":"ref17","unstructured":"Gipp B, Meuschke N, Gernandt A. Decentralized Trusted Timestamping using the Crypto Currency Bitcoin [Internet]. arXiv. arXiv; 2015 Feb. Report No.: 1502.04015v1. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://arxiv.org/abs/1502.04015v1\" xlink:type=\"simple\">https://arxiv.org/abs/1502.04015v1</ext-link>"},{"key":"ref18","doi-asserted-by":"crossref","unstructured":"Suber P. Open access. Cambridge, Mass: MIT Press; 2012.","DOI":"10.7551/mitpress/9286.001.0001"},{"key":"ref19","unstructured":"Gatto L. Open science and open science [Internet]. 5 Jun 2017. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://lgatto.github.io/open-and-open/\" xlink:type=\"simple\">https://lgatto.github.io/open-and-open/</ext-link>"},{"key":"ref20","unstructured":"cOAlition S. Plan S: Accelerating the transition to full and immediate Open Access to scientific publications [Internet]. 2018. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.wikidata.org/wiki/Q56458321\" xlink:type=\"simple\">https://www.wikidata.org/wiki/Q56458321</ext-link>"},{"key":"ref21","unstructured":"Schmitt J, producer and director. Paywall: The Business of Scholarship [Film]; 2018. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://paywallthemovie.com/paywall\" xlink:type=\"simple\">https://paywallthemovie.com/paywall</ext-link>"},{"key":"ref22","article-title":"Journal clubs in the time of preprints","volume":"7","author":"P Avasthi","year":"2018","journal-title":"eLife. eLife Sciences Publications, Ltd"},{"key":"ref23","unstructured":"Himmelstein D. On author versus numeric citation styles. Satoshi Village. 2018; <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://blog.dhimmel.com/citation-styles/\" xlink:type=\"simple\">https://blog.dhimmel.com/citation-styles/</ext-link>"},{"key":"ref24","unstructured":"Perkel J. TechBlog: Create the perfect bibliography with the CSL Editor. In: Naturejobs [Internet]. 3 May 2017. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://blogs.nature.com/naturejobs/2017/05/03/techblog-create-the-perfect-bibliography-with-the-csl-editor/\" xlink:type=\"simple\">http://blogs.nature.com/naturejobs/2017/05/03/techblog-create-the-perfect-bibliography-with-the-csl-editor/</ext-link>"},{"key":"ref25","unstructured":"National Information Standards Organization. ANSI/NISO Z39.96–2019, JATS: Journal Article Tag Suite, version 1.2 [Internet]. NISO; 2019 Feb. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.niso.org/publications/z3996-2019-jats\" xlink:type=\"simple\">https://www.niso.org/publications/z3996-2019-jats</ext-link>"},{"key":"ref26","first-page":"99","article-title":"Journal Article Tag Suite 1.0: National Information Standards Organization standard of journal extensible markup language","volume":"1","author":"S Huh","year":"2014","journal-title":"Sci Ed. Korean Council of Science Editors"},{"key":"ref27","doi-asserted-by":"crossref","first-page":"213","DOI":"10.1080/00987913.2012.10765464","article-title":"NISO Z39.96-201x, JATS: Journal Article Tag Suite","volume":"38","author":"MH Needleman","year":"2012","journal-title":"Serials Review. Informa UK Limited"},{"key":"ref28","first-page":"133","article-title":"Data visualization tools drive interactivity and reproducibility in online publishing","volume":"554","author":"JM Perkel","year":"2018","journal-title":"Nature. Springer Nature"},{"key":"ref29","first-page":"341","article-title":"Vega-Lite: A Grammar of Interactive Graphics","volume":"23","author":"A Satyanarayan","year":"2017","journal-title":"IEEE Trans Visual Comput Graphics. Institute of Electrical and Electronics Engineers (IEEE)"},{"key":"ref30","first-page":"143","article-title":"Collaborative software development made easy","volume":"550","author":"A Silver","year":"2017","journal-title":"Nature. Springer Nature"},{"key":"ref31","doi-asserted-by":"crossref","first-page":"342","DOI":"10.1038/nbt.3780","article-title":"Reproducibility of computational workflows is automated using continuous analysis","volume":"35","author":"BK Beaulieu-Jones","year":"2017","journal-title":"Nat Biotechnol. Springer Nature"},{"key":"ref32","unstructured":"Yenni GM, Christensen EM, Bledsoe EK, Supp SR, Diaz RM, White EP, et al. Developing a modern data workflow for evolving data [Internet]. bioRxiv. Cold Spring Harbor Laboratory; 2018. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.1101/344804\" xlink:type=\"simple\">10.1101/344804</ext-link></comment>"},{"key":"ref33","article-title":"Priority of discovery in the life sciences","volume":"5","author":"RD Vale","year":"2016","journal-title":"eLife. eLife Sciences Publications, Ltd"},{"key":"ref34","unstructured":"Carlisle BG. Proof of prespecified endpoints in medical research with the bitcoin blockchain. In: The Grey Literature [Internet]. 25 Aug 2014 [cited 11 Apr 2019]. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://www.bgcarlisle.com/blog/2014/08/25/proof-of-prespecified-endpoints-in-medical-research-with-the-bitcoin-blockchain/\" xlink:type=\"simple\">https://www.bgcarlisle.com/blog/2014/08/25/proof-of-prespecified-endpoints-in-medical-research-with-the-bitcoin-blockchain/</ext-link>"},{"key":"ref35","unstructured":"Himmelstein D. The most interesting case of scientific irreproducibility? Satoshi Village. 2017; <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://blog.dhimmel.com/irreproducible-timestamps/\" xlink:type=\"simple\">https://blog.dhimmel.com/irreproducible-timestamps/</ext-link>"},{"key":"ref36","first-page":"141","article-title":"Bitcoin for the biological literature","volume":"566","author":"D Heaven","year":"2019","journal-title":"Nature. Springer Nature"},{"key":"ref37","unstructured":"Nakamoto S. Bitcoin: A Peer-to-Peer Electronic Cash System [Internet]. 21 Mar 2019 [cited 11 Jun 2019]. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://git.dhimmel.com/bitcoin-whitepaper/\" xlink:type=\"simple\">https://git.dhimmel.com/bitcoin-whitepaper/</ext-link>"},{"key":"ref38","unstructured":"Todd P. OpenTimestamps: Scalable, Trust-Minimized, Distributed Timestamping with Bitcoin. In: Peter Todd [Internet]. 15 Sep 2016 [cited 11 Apr 2019]. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://petertodd.org/2016/opentimestamps-announcement\" xlink:type=\"simple\">https://petertodd.org/2016/opentimestamps-announcement</ext-link>"},{"key":"ref39","unstructured":"Packer E. eLife supports development of open technology stack for publishing reproducible manuscripts online. In: eLife Press Pack [Internet]. 7 Sep 2017. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://elifesciences.org/for-the-press/e6038800/elife-supports-development-of-open-technology-stack-for-publishing-reproducible-manuscripts-online\" xlink:type=\"simple\">https://elifesciences.org/for-the-press/e6038800/elife-supports-development-of-open-technology-stack-for-publishing-reproducible-manuscripts-online</ext-link>"},{"key":"ref40","article-title":"Sci-Hub provides access to nearly all scholarly literature","volume":"7","author":"DS Himmelstein","year":"2018","journal-title":"eLife. eLife Sciences Publications, Ltd"},{"key":"ref41","first-page":"304","article-title":"2017 in news: The science events that shaped the year","volume":"552","author":"E Callaway","year":"2017","journal-title":"Nature. Springer Nature"},{"key":"ref42","unstructured":"Bruse N, van Heeringen SJ. GimmeMotifs: an analysis framework for transcription factor motif analysis [Internet]. bioRxiv. Cold Spring Harbor Laboratory; 2018. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.1101/474403\" xlink:type=\"simple\">10.1101/474403</ext-link></comment>"},{"key":"ref43","article-title":"Plasmids for Independently Tunable, Low-Noise Expression of Two Genes","volume":"4","author":"JPN Silva","year":"2019","journal-title":"mSphere. American Society for Microbiology"},{"key":"ref44","doi-asserted-by":"crossref","unstructured":"Perrinet L. Illusions et hallucinations visuelles: une porte sur la perception. In: The Conversation [Internet]. 6 Jun 2019 [cited 13 Jun 2019]. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://theconversation.com/illusions-et-hallucinations-visuelles-une-porte-sur-la-perception-117389\" xlink:type=\"simple\">https://theconversation.com/illusions-et-hallucinations-visuelles-une-porte-sur-la-perception-117389</ext-link>","DOI":"10.1016/j.neurol.2019.01.031"},{"key":"ref45","article-title":"Scaling tree-based automated machine learning to biomedical big data with a feature set selector","author":"TT Le","year":"2019","journal-title":"Bioinformatics. Oxford University Press (OUP)"},{"key":"ref46","unstructured":"Hickey G, Heller D, Monlong J, Sibbesen JA, Siren J, Eizenga J, et al. Genotyping structural variants in pangenome graphs using the vg toolkit [Internet]. bioRxiv. Cold Spring Harbor Laboratory; 2019. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.1101/654566\" xlink:type=\"simple\">10.1101/654566</ext-link></comment>"},{"key":"ref47","unstructured":"Orviz P, López García Á, Duma DC, Donvito G, David M, Gomes J. A set of common software quality assurance baseline criteria for research projects. 2017; <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://digital.csic.es/handle/10261/160086\" xlink:type=\"simple\">https://digital.csic.es/handle/10261/160086</ext-link>"},{"key":"ref48","unstructured":"Zietz M. Vagelos Report Summer 2017. Figshare; 2017; <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.6084/m9.figshare.5346577\" xlink:type=\"simple\">10.6084/m9.figshare.5346577</ext-link></comment>"},{"key":"ref49","unstructured":"Himmelstein D. How I used the Manubot to reproduce the Bitcoin Whitepaper. In: Steem [Internet]. 20 Sep 2017. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://busy.org/@dhimmel/how-i-used-the-manubot-to-reproduce-the-bitcoin-whitepaper\" xlink:type=\"simple\">https://busy.org/@dhimmel/how-i-used-the-manubot-to-reproduce-the-bitcoin-whitepaper</ext-link>"},{"key":"ref50","article-title":"Systematic integration of biomedical knowledge prioritizes drugs for repurposing","volume":"6","author":"DS Himmelstein","year":"2017","journal-title":"eLife. eLife Sciences Publications, Ltd"},{"key":"ref51","first-page":"592","article-title":"The Kipoi repository accelerates community exchange and reuse of predictive models for genomics","volume":"37","author":"Ž Avsec","year":"2019","journal-title":"Nat Biotechnol. Springer Science and Business Media LLC"},{"key":"ref52","doi-asserted-by":"crossref","first-page":"e147","DOI":"10.7717/peerj-cs.147","article-title":"Journal of Open Source Software (JOSS): design and first-year review","volume":"4","author":"AM Smith","year":"2018","journal-title":"PeerJ Computer Science. PeerJ"},{"key":"ref53","doi-asserted-by":"crossref","first-page":"e23477","DOI":"10.1371/journal.pone.0023477","article-title":"A Systematic Review of Research on the Meaning, Ethics and Practices of Authorship across Scholarly Disciplines","volume":"6","author":"A Marušić","year":"2011","journal-title":"PLoS ONE. Public Library of Science (PLoS)"},{"key":"ref54","first-page":"e1000023","article-title":"What Should Be Done To Tackle Ghostwriting in the Medical Literature?","volume":"6","author":"PC Gøtzsche","year":"2009","journal-title":"PLoS Med. Public Library of Science (PLoS)"},{"key":"ref55","doi-asserted-by":"crossref","first-page":"e1006508","DOI":"10.1371/journal.pcbi.1006508","article-title":"Ten simple rules for collaboratively writing a multi-authored paper","volume":"14","author":"MA Frassl","year":"2018","journal-title":"PLoS Comput Biol. Public Library of Science (PLoS)"},{"key":"ref56","unstructured":"Brown CT. Revisiting authorship, and JOSS software publications. In: Living in an Ivory Basement [Internet]. 16 Jan 2019 [cited 11 Apr 2019]. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://ivory.idyll.org/blog/2019-authorship-revisiting.html\" xlink:type=\"simple\">http://ivory.idyll.org/blog/2019-authorship-revisiting.html</ext-link>"},{"key":"ref57","article-title":"Combined Measurement of the Higgs Boson Mass in pp Collisions at sqrt[s] = 7 and 8 TeV with the ATLAS and CMS Experiments","volume":"114","author":"G Aad","year":"2015","journal-title":"Phys Rev Lett. American Physical Society (APS)"},{"key":"ref58","first-page":"719","article-title":"Drosophila Muller F Elements Maintain a Distinct Set of Genomic Properties Over 40 Million Years of Evolution","volume":"5","author":"W Leung","year":"2015","journal-title":"G3. Genetics Society of America"},{"key":"ref59","first-page":"263","article-title":"Fruit-fly paper has 1,000 authors","volume":"521","author":"C Woolston","year":"2015","journal-title":"Nature. Springer Nature"},{"key":"ref60","article-title":"Physics paper sets record with more than 5,000 authors","author":"D Castelvecchi","year":"2015","journal-title":"Nature. Springer Nature"},{"key":"ref61","doi-asserted-by":"crossref","first-page":"e1003149","DOI":"10.1371/journal.pcbi.1003149","article-title":"Ten Simple Rules for Writing a Literature Review","volume":"9","author":"M Pautasso","year":"2013","journal-title":"PLoS Comput Biol. Public Library of Science (PLoS)"},{"key":"ref62","first-page":"e1001772","article-title":"A Stronger Post-Publication Culture Is Needed for Better Science","volume":"11","author":"H Bastian","year":"2014","journal-title":"PLoS Med. Public Library of Science (PLoS)"},{"key":"ref63","article-title":"Post-Publication Peer Review: Opening Up Scientific Conversation","volume":"6","author":"J Hunter","year":"2012","journal-title":"Front Comput Neurosci. Frontiers Media SA"},{"key":"ref64","doi-asserted-by":"crossref","first-page":"107","DOI":"10.1629/uksg.245","article-title":"Post-publication peer review, in all its guises, is here to stay","volume":"28","author":"M Markie","year":"2015","journal-title":"Insights the UKSG journal. Ubiquity Press, Ltd"},{"key":"ref65","unstructured":"The Univalent Foundations Program. Homotopy Type Theory: Univalent Foundations of Mathematics [Internet]. Institute for Advanced Study; 2013. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://homotopytypetheory.org/book/\" xlink:type=\"simple\">https://homotopytypetheory.org/book/</ext-link>"},{"key":"ref66","unstructured":"Bauer A. The HoTT book. In: Mathematics and Computation [Internet]. 20 Jun 2013. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://math.andrej.com/2013/06/20/the-hott-book/\" xlink:type=\"simple\">http://math.andrej.com/2013/06/20/the-hott-book/</ext-link>"},{"key":"ref67","first-page":"1151","article-title":"A multi-disciplinary perspective on emergent and future innovations in peer review","volume":"6","author":"JP Tennant","year":"2017","journal-title":"F1000Res. F1000 (Faculty of 1000 Ltd)"},{"key":"ref68","unstructured":"Vrieze J. Nearly 100 scientists spent 2 months on Google Docs to redefine the p-value. Here’s what they came up with. Science. American Association for the Advancement of Science (AAAS); 2018; <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.1126/science.aat0471\" xlink:type=\"simple\">10.1126/science.aat0471</ext-link></comment>"},{"key":"ref69","doi-asserted-by":"crossref","first-page":"168","DOI":"10.1038/s41562-018-0311-x","article-title":"Justify your alpha","volume":"2","author":"D Lakens","year":"2018","journal-title":"Nat Hum Behav. Springer Nature"},{"key":"ref70","unstructured":"Mobley DL, Zuckerman DM. A proposal for regularly updated review/survey articles: “Perpetual Reviews” [Internet]. arXiv. arXiv; 2015 Feb. Report No.: 1502.01329v2. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://arxiv.org/abs/1502.01329v2\" xlink:type=\"simple\">https://arxiv.org/abs/1502.01329v2</ext-link>"},{"key":"ref71","article-title":"Why we need the Living Journal of Computational Molecular Science","volume":"2031","author":"DL Mobley","year":"2017","journal-title":"LiveCoMS"},{"key":"ref72","unstructured":"Goodman A, Peek J, Accomazzi A, Beaumont C, Borgman CL, Chen H-HH, et al. The “Paper” of the Future [Internet]. Authorea. Authorea, Inc. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.22541/au.148769949.92783646\" xlink:type=\"simple\">10.22541/au.148769949.92783646</ext-link></comment>"},{"key":"ref73","unstructured":"Pepe A, Cantiello M, Nicholson J. The arXiv of the future will not look like the arXiv [Internet]. Authorea. Authorea, Inc. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.22541/au.149693987.70506124\" xlink:type=\"simple\">10.22541/au.149693987.70506124</ext-link></comment>"},{"key":"ref74","unstructured":"Brown CT. TechBlog: C. Titus Brown: Predicting the paper of the future. In: Naturejobs [Internet]. 1 Jun 2017. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://blogs.nature.com/naturejobs/2017/06/01/techblog-c-titus-brown-predicting-the-paper-of-the-future/\" xlink:type=\"simple\">http://blogs.nature.com/naturejobs/2017/06/01/techblog-c-titus-brown-predicting-the-paper-of-the-future/</ext-link>"},{"key":"ref75","unstructured":"Xie Y. bookdown [Internet]. Chapman &amp;Hall/CRC The R Series. CRC Press; 2016. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.1201/9781315204963\" xlink:type=\"simple\">10.1201/9781315204963</ext-link></comment>"},{"key":"ref76","first-page":"1656","article-title":"Orchestrating a community-developed computational workshop and accompanying training materials","volume":"7","author":"S Davis","year":"2018","journal-title":"F1000Res. F1000 (Faculty of 1000 Ltd)"},{"key":"ref77","unstructured":"Fenner M. Continuous Publishing. In: Gobbledygook [Internet]. 10 Mar 2014. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"http://blog.martinfenner.org/2014/03/10/continuous-publishing/\" xlink:type=\"simple\">http://blog.martinfenner.org/2014/03/10/continuous-publishing/</ext-link>"},{"key":"ref78","unstructured":"Bartling S, Friesike S, editors. Opening Science [Internet]. Springer International Publishing; 2014. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.1007/978-3-319-00026-8\" xlink:type=\"simple\">10.1007/978-3-319-00026-8</ext-link></comment>"},{"key":"ref79","article-title":"The Building Blocks of Interpretability","volume":"3","author":"C Olah","year":"2018","journal-title":"Distill. Distill Working Group"},{"key":"ref80","unstructured":"Conlen M, Osheroff A. Announcing idyll.pub. In: Idyll [Internet]. 26 Jun 2018. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://idyll.pub/post/announcing-idyll-pub-0a3eff0661df3446a915700d/\" xlink:type=\"simple\">https://idyll.pub/post/announcing-idyll-pub-0a3eff0661df3446a915700d/</ext-link>"},{"key":"ref81","unstructured":"Aufreiter M, Pawlik A, Bentley N. Stencila–an office suite for reproducible research. In: eLife Labs [Internet]. 2 Jul 2018. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://elifesciences.org/labs/c496b8bb/stencila-an-office-suite-for-reproducible-research\" xlink:type=\"simple\">https://elifesciences.org/labs/c496b8bb/stencila-an-office-suite-for-reproducible-research</ext-link>"},{"key":"ref82","unstructured":"Maciocci G, Aufreiter M, Bentley N. Introducing eLife’s first computationally reproducible article. In: eLife Labs [Internet]. 20 Feb 2019 [cited 11 Apr 2019]. <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://elifesciences.org/labs/ad58f08d/introducing-elife-s-first-computationally-reproducible-article\" xlink:type=\"simple\">https://elifesciences.org/labs/ad58f08d/introducing-elife-s-first-computationally-reproducible-article</ext-link>"},{"key":"ref83","doi-asserted-by":"crossref","first-page":"e142","DOI":"10.7717/peerj-cs.142","article-title":"Sustainable computational science: the ReScience initiative","volume":"3","author":"NP Rougier","year":"2017","journal-title":"PeerJ Computer Science. PeerJ"},{"key":"ref84","article-title":"Distill Update 2018","volume":"3","author":"D Editors","year":"2018","journal-title":"Distill. Distill Working Group"},{"key":"ref85","doi-asserted-by":"crossref","first-page":"e134","DOI":"10.7717/peerj-cs.134","article-title":"The appropriation of GitHub for curation","volume":"3","author":"Y Wu","year":"2017","journal-title":"PeerJ Computer Science. PeerJ"},{"key":"ref86","doi-asserted-by":"crossref","unstructured":"Wagner C, Prasarnphanich P. Innovating Collaborative Content Creation: The Role of Altruism and Wiki Technology. 2007 40th Annual Hawaii International Conference on System Sciences (HICSS’07). IEEE; 2007. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.1109/hicss.2007.277\" xlink:type=\"simple\">10.1109/hicss.2007.277</ext-link></comment>","DOI":"10.1109/HICSS.2007.277"},{"key":"ref87","doi-asserted-by":"crossref","unstructured":"Tourani P, Adams B, Serebrenik A. Code of conduct in open source projects. 2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE; 2017. <comment>doi: <ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" ext-link-type=\"uri\" xlink:href=\"https://doi.org/10.1109/saner.2017.7884606\" xlink:type=\"simple\">10.1109/saner.2017.7884606</ext-link></comment>","DOI":"10.1109/SANER.2017.7884606"},{"key":"ref88","first-page":"632","article-title":"The academic, economic and societal impacts of Open Access: an evidence-based review","volume":"5","author":"JP Tennant","year":"2016","journal-title":"F1000Res. F1000 (Faculty of 1000 Ltd)"},{"key":"ref89","article-title":"How open science helps researchers succeed","volume":"5","author":"EC McKiernan","year":"2016","journal-title":"eLife. eLife Sciences Publications, Ltd"},{"key":"ref90","first-page":"35","article-title":"The Legal Framework for Reproducible Scientific Research: Licensing and Copyright","volume":"11","author":"V Stodden","year":"2009","journal-title":"Comput Sci Eng. Institute of Electrical and Electronics Engineers (IEEE)"},{"key":"ref91","first-page":"16","article-title":"Legal confusion threatens to slow data science","volume":"536","author":"S Oxenham","year":"2016","journal-title":"Nature. Springer Nature"},{"key":"ref92","doi-asserted-by":"crossref","first-page":"1240","DOI":"10.1126/science.aah6168","article-title":"Enhancing reproducibility for computational methods","volume":"354","author":"V Stodden","year":"2016","journal-title":"Science. American Association for the Advancement of Science (AAAS)"},{"key":"ref93","first-page":"485","article-title":"The case for open computer programs","volume":"482","author":"DC Ince","year":"2012","journal-title":"Nature. Springer Nature"},{"key":"ref94","first-page":"e1001195","article-title":"The Open Knowledge Foundation: Open Data Means Better Science","volume":"9","author":"JC Molloy","year":"2011","journal-title":"PLoS Biol. Public Library of Science (PLoS)"},{"key":"ref95","doi-asserted-by":"crossref","first-page":"201","DOI":"10.1242/dmm.003285","article-title":"This revolution will be digitized: online tools for radical collaboration","volume":"2","author":"C Patil","year":"2009","journal-title":"Disease Models & Mechanisms. The Company of Biologists"},{"key":"ref96","first-page":"e7547","article-title":"Publishing the research process","volume":"1","author":"D Mietchen","year":"2015","journal-title":"RIO. Pensoft Publishers"},{"key":"ref97","article-title":"How to edit a manuscript on GitHub with Manubot","author":"D Slochower","year":"2019","journal-title":"Figshare"}],"container-title":"PLOS Computational Biology","original-title":[],"language":"en","link":[{"URL":"http://dx.plos.org/10.1371/journal.pcbi.1007128","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2022,9,21]],"date-time":"2022-09-21T19:35:14Z","timestamp":1663788914000},"score":1,"resource":{"primary":{"URL":"https://dx.plos.org/10.1371/journal.pcbi.1007128"}},"subtitle":[],"editor":[{"given":"Dina","family":"Schneidman-Duhovny","sequence":"first","affiliation":[]}],"short-title":[],"issued":{"date-parts":[[2019,6,24]]},"references-count":97,"journal-issue":{"issue":"6","published-online":{"date-parts":[[2019,6,24]]}},"URL":"http://dx.doi.org/10.1371/journal.pcbi.1007128","relation":{},"ISSN":["1553-7358"],"subject":["Computational Theory and Mathematics","Cellular and Molecular Neuroscience","Genetics","Molecular Biology","Ecology","Modeling and Simulation","Ecology, Evolution, Behavior and Systematics"],"container-title-short":"PLoS Comput Biol","published":{"date-parts":[[2019,6,24]]},"id":"doi:10.1371/journal.pcbi.1007128"},{"type":"article","id":"doi:10.48550/arXiv.2205.02007","categories":["Computation and Language (cs.CL)","Computers and Society (cs.CY)","Human-Computer Interaction (cs.HC)","Information Retrieval (cs.IR)","FOS: Computer and information sciences","FOS: Computer and information sciences"],"author":[{"family":"Hope","given":"Tom"},{"family":"Downey","given":"Doug"},{"family":"Etzioni","given":"Oren"},{"family":"Weld","given":"Daniel S."},{"family":"Horvitz","given":"Eric"}],"issued":{"date-parts":[[2022]]},"abstract":"We stand at the foot of a significant inflection in the trajectory of scientific discovery. As society continues on its fast-paced digital transformation, so does humankind's collective scientific knowledge and discourse. We now read and write papers in digitized form, and a great deal of the formal and informal processes of science are captured digitally -- including papers, preprints and books, code and datasets, conference presentations, and interactions in social networks and collaboration and communication platforms. The transition has led to the creation and growth of a tremendous amount of information -- much of which is available for public access -- opening exciting opportunities for computational models and systems that analyze and harness it. In parallel, exponential growth in data processing power has fueled remarkable advances in artificial intelligence, including large neural language models capable of learning powerful representations from unstructured text. Dramatic changes in scientific communication -- such as the advent of the first scientific journal in the 17th century -- have historically catalyzed revolutions in scientific thought. The confluence of societal and computational trends suggests that computer science is poised to ignite a revolution in the scientific process itself.","DOI":"10.48550/ARXIV.2205.02007","publisher":"arXiv","title":"A Computational Inflection for Scientific Discovery","URL":"https://arxiv.org/abs/2205.02007","copyright":"arXiv.org perpetual, non-exclusive license","version":"2"},{"author":[{"family":"Jupyter Book"}],"type":"document","id":"jupyterbook","citation-key":"jupyterbook","issued":{"date-parts":[[2023]]},"URL":"https://jupyterbook.org/"},{"type":"article","id":"doi:10.48550/arXiv.2010.05129","categories":["Computation and Language (cs.CL)","FOS: Computer and information sciences","FOS: Computer and information sciences"],"author":[{"family":"Kang","given":"Dongyeop"},{"family":"Head","given":"Andrew"},{"family":"Sidhu","given":"Risham"},{"family":"Lo","given":"Kyle"},{"family":"Weld","given":"Daniel S."},{"family":"Hearst","given":"Marti A."}],"issued":{"date-parts":[[2020]]},"abstract":"The task of definition detection is important for scholarly papers, because papers often make use of technical terminology that may be unfamiliar to readers. Despite prior work on definition detection, current approaches are far from being accurate enough to use in real-world applications. In this paper, we first perform in-depth error analysis of the current best performing definition detection system and discover major causes of errors. Based on this analysis, we develop a new definition detection system, HEDDEx, that utilizes syntactic features, transformer encoders, and heuristic filters, and evaluate it on a standard sentence-level benchmark. Because current benchmarks evaluate randomly sampled sentences, we propose an alternative evaluation that assesses every sentence within a document. This allows for evaluating recall in addition to precision. HEDDEx outperforms the leading system on both the sentence-level and the document-level tasks, by 12.7 F1 points and 14.4 F1 points, respectively. We note that performance on the high-recall document-level task is much lower than in the standard evaluation approach, due to the necessity of incorporation of document structure as features. We discuss remaining challenges in document-level definition detection, ideas for improvements, and potential issues for the development of reading aid applications.","DOI":"10.48550/ARXIV.2010.05129","publisher":"arXiv","title":"Document-Level Definition Detection in Scholarly Documents: Existing Models, Error Analyses, and Future Directions","URL":"https://arxiv.org/abs/2010.05129","copyright":"arXiv.org perpetual, non-exclusive license","version":"1"},{"indexed":{"date-parts":[[2023,10,12]],"date-time":"2023-10-12T02:55:07Z","timestamp":1697079307528},"publisher-location":"New York, NY, USA","reference-count":34,"publisher":"ACM","license":[{"start":{"date-parts":[[2018,10,11]],"date-time":"2018-10-11T00:00:00Z","timestamp":1539216000000},"content-version":"vor","delay-in-days":0,"URL":"http://www.acm.org/publications/policies/copyright_policy#Background"}],"funder":[{"name":"NSF award","award":["III-1714647"]},{"name":"Samsung Scholarship"},{"name":"Allen Distinguished Investigator award"}],"content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2018,10,11]]},"DOI":"10.1145/3242587.3242617","type":"proceedings-article","created":{"date-parts":[[2018,10,16]],"date-time":"2018-10-16T13:30:26Z","timestamp":1539696626000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":25,"title":"Facilitating Document Reading by Linking Text and Tables","prefix":"10.1145","author":[{"given":"Dae Hyun","family":"Kim","sequence":"first","affiliation":[{"name":"Stanford University, Stanford, CA, USA"}]},{"given":"Enamul","family":"Hoque","sequence":"additional","affiliation":[{"name":"Stanford University, Stanford, CA, USA"}]},{"given":"Juho","family":"Kim","sequence":"additional","affiliation":[{"name":"Korea Advanced Institute of Science and Technology, Daejeon, Rebublic of Korea"}]},{"given":"Maneesh","family":"Agrawala","sequence":"additional","affiliation":[{"name":"Stanford University, Stanford, CA, USA"}]}],"member":"320","published-online":{"date-parts":[[2018,10,11]]},"reference":[{"key":"e_1_3_2_2_1_1","volume-title":"Retrieved","year":"2018","unstructured":"2018. Adobe Acrobat Reader. (2018) . Retrieved April 02, 2018 from https://acrobat.adobe.com/us/en/acrobat/acrobat-pro.html. 2018. Adobe Acrobat Reader. (2018). Retrieved April 02, 2018 from https://acrobat.adobe.com/us/en/acrobat/acrobat-pro.html."},{"key":"e_1_3_2_2_2_1","volume-title":"Retrieved","year":"2018","unstructured":"2018. Economist Graphic Detail. (2018) . Retrieved April 02, 2018 from https://www.economist.com/blogs/graphicdetail. 2018. Economist Graphic Detail. (2018). Retrieved April 02, 2018 from https://www.economist.com/blogs/graphicdetail."},{"key":"e_1_3_2_2_3_1","volume-title":"Retrieved","author":"DataBlog Guardian","year":"2018","unstructured":"2018. Guardian DataBlog . ( 2018 ). Retrieved April 02, 2018 from https://www.theguardian.com/data. 2018. Guardian DataBlog. (2018). Retrieved April 02, 2018 from https://www.theguardian.com/data."},{"key":"e_1_3_2_2_4_1","volume-title":"Pew Research. (2018). Retrieved","year":"2018","unstructured":"2018. Pew Research. (2018). Retrieved April 02, 2018 from www.pewresearch.org/. 2018. Pew Research. (2018). Retrieved April 02, 2018 from www.pewresearch.org/."},{"key":"e_1_3_2_2_5_1","volume-title":"Retrieved","author":"Alpha Wolfram","year":"2018","unstructured":"2018. Wolfram Alpha . ( 2018 ). Retrieved April 02, 2018 from https://www.wolframalpha.com. 2018. Wolfram Alpha. (2018). Retrieved April 02, 2018 from https://www.wolframalpha.com."},{"key":"e_1_3_2_2_6_1","volume-title":"Retrieved","year":"2018","unstructured":"2018. Word embedding trained on Google News. (2018) . Retrieved April 02, 2018 from https://code.google.com/archive/p/word2vec/. 2018. Word embedding trained on Google News. (2018). Retrieved April 02, 2018 from https://code.google.com/archive/p/word2vec/."},{"key":"e_1_3_2_2_7_1","doi-asserted-by":"publisher","DOI":"10.5555/1785162.1785216"},{"key":"e_1_3_2_2_8_1","volume-title":"Split-attention effect","author":"Ayres Paul","unstructured":"Paul Ayres and Gabriele Cierniak . 2012. Split-attention effect . Springer US , Boston, MA , 3172--3175. Paul Ayres and Gabriele Cierniak. 2012. Split-attention effect. Springer US, Boston, MA, 3172--3175."},{"key":"e_1_3_2_2_9_1","doi-asserted-by":"publisher","DOI":"10.1145/1376616.1376746"},{"key":"e_1_3_2_2_10_1","doi-asserted-by":"publisher","DOI":"10.14778/1453856.1453916"},{"key":"e_1_3_2_2_11_1","doi-asserted-by":"publisher","DOI":"10.14778/2536274.2536276"},{"key":"e_1_3_2_2_12_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/P17-1005"},{"key":"e_1_3_2_2_13_1","volume-title":"Proceedings of the AAAI Conference on Artificial Intelligence. 599--605","author":"Fang Jing","year":"2012","unstructured":"Jing Fang , Prasenjit Mitra , Zhi Tang , and C Lee Giles . 2012 . Table header detection and classification . In Proceedings of the AAAI Conference on Artificial Intelligence. 599--605 . Jing Fang, Prasenjit Mitra, Zhi Tang, and C Lee Giles. 2012. Table header detection and classification. In Proceedings of the AAAI Conference on Artificial Intelligence. 599--605."},{"key":"e_1_3_2_2_14_1","doi-asserted-by":"publisher","DOI":"10.3115/1219840.1219885"},{"key":"e_1_3_2_2_15_1","doi-asserted-by":"publisher","DOI":"10.1016/j.learninstruc.2009.02.021"},{"key":"e_1_3_2_2_16_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/P17-1012"},{"key":"e_1_3_2_2_17_1","volume-title":"Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. 658--664","author":"Govindaraju Vidhya","year":"2013","unstructured":"Vidhya Govindaraju , Ce Zhang , and Christopher Ré . 2013 . Understanding tables in context using Standard NLP toolkits . In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. 658--664 . Vidhya Govindaraju, Ce Zhang, and Christopher Ré. 2013. Understanding tables in context using Standard NLP toolkits. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. 658--664."},{"key":"e_1_3_2_2_18_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/P16-1018"},{"key":"e_1_3_2_2_19_1","doi-asserted-by":"publisher","DOI":"10.1145/2642918.2647411"},{"key":"e_1_3_2_2_20_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2017.2659744"},{"key":"e_1_3_2_2_21_1","doi-asserted-by":"publisher","DOI":"10.1162/COLI_a_00226"},{"key":"e_1_3_2_2_22_1","doi-asserted-by":"publisher","DOI":"10.1145/3025453.3025957"},{"key":"e_1_3_2_2_23_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2012.229"},{"key":"e_1_3_2_2_24_1","doi-asserted-by":"publisher","DOI":"10.1145/2556288.2557241"},{"key":"e_1_3_2_2_25_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/P17-1014"},{"key":"e_1_3_2_2_26_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/P17-1001"},{"key":"e_1_3_2_2_27_1","volume-title":"The Stanford CoreNLP natural language processing toolkit","author":"Manning Christopher D.","unstructured":"Christopher D. Manning , Mihai Surdeanu , John Bauer , Jenny Finkel , Steven J. Bethard , and David McClosky . 2014. The Stanford CoreNLP natural language processing toolkit . In Association for Computational Linguistics (ACL) System Demonstrations . 55--60. Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David McClosky. 2014. The Stanford CoreNLP natural language processing toolkit. In Association for Computational Linguistics (ACL) System Demonstrations. 55--60."},{"key":"e_1_3_2_2_28_1","volume-title":"Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781","author":"Mikolov Tomas","year":"2013","unstructured":"Tomas Mikolov , Kai Chen , Greg Corrado , and Jeffrey Dean . 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 ( 2013 ). Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 (2013)."},{"key":"e_1_3_2_2_29_1","volume-title":"Anaphora resolution","author":"Mitkov Ruslan","unstructured":"Ruslan Mitkov . 2014. Anaphora resolution . Routledge . Ruslan Mitkov. 2014. Anaphora resolution. Routledge."},{"key":"e_1_3_2_2_30_1","volume-title":"Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics. 1470--1480","author":"Pasupat Panupong","unstructured":"Panupong Pasupat and Percy Liang . Compositional semantic parsing on semi-structured tables . In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics. 1470--1480 . Panupong Pasupat and Percy Liang. Compositional semantic parsing on semi-structured tables. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics. 1470--1480."},{"key":"e_1_3_2_2_31_1","doi-asserted-by":"publisher","DOI":"10.14778/2336664.2336665"},{"key":"e_1_3_2_2_32_1","doi-asserted-by":"publisher","DOI":"10.1111/cgf.13193"},{"key":"e_1_3_2_2_33_1","doi-asserted-by":"publisher","DOI":"10.1145/2047196.2047247"},{"key":"e_1_3_2_2_34_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/P17-1013"}],"event":"UIST '18: The 31st Annual ACM Symposium on User Interface Software and Technology","container-title":"Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/3242587.3242617","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,1,6]],"date-time":"2023-01-06T16:01:47Z","timestamp":1673020907000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/3242587.3242617"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2018,10,11]]},"references-count":34,"alternative-id":["10.1145/3242587.3242617","10.1145/3242587"],"URL":"http://dx.doi.org/10.1145/3242587.3242617","relation":{},"published":{"date-parts":[[2018,10,11]]},"assertion":[{"value":"2018-10-11","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/3242587.3242617"},{"type":"article","id":"doi:10.48550/arXiv.2301.10140","categories":["Digital Libraries (cs.DL)","Computation and Language (cs.CL)","FOS: Computer and information sciences","FOS: Computer and information sciences"],"author":[{"family":"Kinney","given":"Rodney"},{"family":"Anastasiades","given":"Chloe"},{"family":"Authur","given":"Russell"},{"family":"Beltagy","given":"Iz"},{"family":"Bragg","given":"Jonathan"},{"family":"Buraczynski","given":"Alexandra"},{"family":"Cachola","given":"Isabel"},{"family":"Candra","given":"Stefan"},{"family":"Chandrasekhar","given":"Yoganand"},{"family":"Cohan","given":"Arman"},{"family":"Crawford","given":"Miles"},{"family":"Downey","given":"Doug"},{"family":"Dunkelberger","given":"Jason"},{"family":"Etzioni","given":"Oren"},{"family":"Evans","given":"Rob"},{"family":"Feldman","given":"Sergey"},{"family":"Gorney","given":"Joseph"},{"family":"Graham","given":"David"},{"family":"Hu","given":"Fangzhou"},{"family":"Huff","given":"Regan"},{"family":"King","given":"Daniel"},{"family":"Kohlmeier","given":"Sebastian"},{"family":"Kuehl","given":"Bailey"},{"family":"Langan","given":"Michael"},{"family":"Lin","given":"Daniel"},{"family":"Liu","given":"Haokun"},{"family":"Lo","given":"Kyle"},{"family":"Lochner","given":"Jaron"},{"family":"MacMillan","given":"Kelsey"},{"family":"Murray","given":"Tyler"},{"family":"Newell","given":"Chris"},{"family":"Rao","given":"Smita"},{"family":"Rohatgi","given":"Shaurya"},{"family":"Sayre","given":"Paul"},{"family":"Shen","given":"Zejiang"},{"family":"Singh","given":"Amanpreet"},{"family":"Soldaini","given":"Luca"},{"family":"Subramanian","given":"Shivashankar"},{"family":"Tanaka","given":"Amber"},{"family":"Wade","given":"Alex D."},{"family":"Wagner","given":"Linda"},{"family":"Wang","given":"Lucy Lu"},{"family":"Wilhelm","given":"Chris"},{"family":"Wu","given":"Caroline"},{"family":"Yang","given":"Jiangjiang"},{"family":"Zamarron","given":"Angele"},{"family":"Van Zuylen","given":"Madeleine"},{"family":"Weld","given":"Daniel S."}],"issued":{"date-parts":[[2023]]},"abstract":"The volume of scientific output is creating an urgent need for automated tools to help scientists keep up with developments in their field. Semantic Scholar (S2) is an open data platform and website aimed at accelerating science by helping scholars discover and understand scientific literature. We combine public and proprietary data sources using state-of-the-art techniques for scholarly PDF content extraction and automatic knowledge graph construction to build the Semantic Scholar Academic Graph, the largest open scientific literature graph to-date, with 200M+ papers, 80M+ authors, 550M+ paper-authorship edges, and 2.4B+ citation edges. The graph includes advanced semantic features such as structurally parsed text, natural language summaries, and vector embeddings. In this paper, we describe the components of the S2 data processing pipeline and the associated APIs offered by the platform. We will update this living document to reflect changes as we add new data offerings and improve existing services.","DOI":"10.48550/ARXIV.2301.10140","publisher":"arXiv","title":"The Semantic Scholar Open Data Platform","URL":"https://arxiv.org/abs/2301.10140","copyright":"Creative Commons Attribution 4.0 International","version":"1"},{"indexed":{"date-parts":[[2023,10,19]],"date-time":"2023-10-19T15:03:44Z","timestamp":1697727824488},"publisher-location":"New York, NY, USA","reference-count":31,"publisher":"ACM","license":[{"start":{"date-parts":[[2015,11,5]],"date-time":"2015-11-05T00:00:00Z","timestamp":1446681600000},"content-version":"vor","delay-in-days":0,"URL":"http://www.acm.org/publications/policies/copyright_policy#Background"}],"funder":[{"name":"European Research Council","award":["321135"]},{"name":"Danish Strategic Research Council","award":["1311-00001B"]}],"content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2015,11,5]]},"DOI":"10.1145/2807442.2807446","type":"proceedings-article","created":{"date-parts":[[2015,11,6]],"date-time":"2015-11-06T15:04:29Z","timestamp":1446822269000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":88,"title":"<i>Webstrates</i>","prefix":"10.1145","author":[{"given":"Clemens N.","family":"Klokmose","sequence":"first","affiliation":[{"name":"Aarhus University, Aarhus, Denmark"}]},{"given":"James R.","family":"Eagan","sequence":"additional","affiliation":[{"name":"Télécom ParisTech -- CNRS LTCI UMR 5141, Paris, France"}]},{"given":"Siemen","family":"Baader","sequence":"additional","affiliation":[{"name":"Aarhus University, Aarhus, Denmark"}]},{"given":"Wendy","family":"Mackay","sequence":"additional","affiliation":[{"name":"INRIA &amp; Univ Paris-Sud, Paris, France"}]},{"given":"Michel","family":"Beaudouin-Lafon","sequence":"additional","affiliation":[{"name":"Univ Paris-Sud &amp; CNRS, Orsay, France"}]}],"member":"320","published-online":{"date-parts":[[2015,11,5]]},"reference":[{"key":"e_1_3_2_2_1_1","doi-asserted-by":"publisher","DOI":"10.1145/2669485.2669518"},{"key":"e_1_3_2_2_2_1","doi-asserted-by":"publisher","DOI":"10.1145/332040.332473"},{"key":"e_1_3_2_2_3_1","doi-asserted-by":"publisher","DOI":"10.1145/6592.6595"},{"key":"e_1_3_2_2_4_1","doi-asserted-by":"publisher","DOI":"10.1145/2047196.2047226"},{"key":"e_1_3_2_2_5_1","doi-asserted-by":"publisher","DOI":"10.1145/1753326.1753390"},{"key":"e_1_3_2_2_6_1","doi-asserted-by":"publisher","DOI":"10.1145/1502800.1502803"},{"key":"e_1_3_2_2_7_1","doi-asserted-by":"publisher","DOI":"10.1145/66926.66963"},{"key":"e_1_3_2_2_8_1","doi-asserted-by":"publisher","DOI":"10.1145/1978942.1979446"},{"key":"e_1_3_2_2_9_1","volume-title":"Smalltalk-80: the language and its implementation","author":"Goldberg A.","year":"1983","unstructured":"Goldberg , A. and Robson , D . ( 1983 ) Smalltalk-80: the language and its implementation . Addison-Wesley . Goldberg, A. and Robson, D. (1983) Smalltalk-80: the language and its implementation. Addison-Wesley."},{"key":"e_1_3_2_2_10_1","volume-title":"The complete HyperCard 2.2 handbook. Bantam books","author":"Goodman D.","year":"1993","unstructured":"Goodman , D. ( 1993 ) The complete HyperCard 2.2 handbook. Bantam books . Goodman, D. (1993) The complete HyperCard 2.2 handbook. Bantam books."},{"key":"e_1_3_2_2_11_1","doi-asserted-by":"publisher","DOI":"10.1145/358916.358993"},{"key":"e_1_3_2_2_12_1","doi-asserted-by":"publisher","DOI":"10.1145/2187836.2187978"},{"key":"e_1_3_2_2_13_1","doi-asserted-by":"publisher","DOI":"10.1145/800193.1971922"},{"key":"e_1_3_2_2_14_1","doi-asserted-by":"publisher","DOI":"10.1109/C-M.1977.217672"},{"key":"e_1_3_2_2_15_1","doi-asserted-by":"publisher","DOI":"10.1145/1518701.1518833"},{"key":"e_1_3_2_2_16_1","doi-asserted-by":"publisher","DOI":"10.1145/2607023.2610281"},{"key":"e_1_3_2_2_17_1","doi-asserted-by":"publisher","DOI":"10.1007/978-3-642-39200-9_10"},{"key":"e_1_3_2_2_18_1","doi-asserted-by":"publisher","DOI":"10.1145/1641309.1641324"},{"key":"e_1_3_2_2_19_1","doi-asserted-by":"publisher","DOI":"10.1145/344949.344959"},{"key":"e_1_3_2_2_20_1","volume-title":"Algorithmica. 1(1--4)","author":"Myers E.W.","year":"1986","unstructured":"Myers , E.W. ( 1986 ) An O(ND) difference algorithm and its variations . In Algorithmica. 1(1--4) . Springer . 251--266 Myers, E.W. (1986) An O(ND) difference algorithm and its variations. In Algorithmica. 1(1--4). Springer. 251--266"},{"key":"e_1_3_2_2_21_1","doi-asserted-by":"publisher","DOI":"10.1145/208344.208353"},{"key":"e_1_3_2_2_22_1","doi-asserted-by":"publisher","DOI":"10.1145/215585.215706"},{"key":"e_1_3_2_2_23_1","doi-asserted-by":"publisher","DOI":"10.1145/1294211.1294256"},{"key":"e_1_3_2_2_24_1","doi-asserted-by":"publisher","DOI":"10.1007/s10606-009-9105-z"},{"key":"e_1_3_2_2_25_1","doi-asserted-by":"publisher","DOI":"10.1145/120782.120786"},{"key":"e_1_3_2_2_26_1","doi-asserted-by":"publisher","DOI":"10.5555/2050613.2050642"},{"key":"e_1_3_2_2_27_1","doi-asserted-by":"publisher","DOI":"10.1109/C5.2003.1222325"},{"key":"e_1_3_2_2_28_1","volume-title":"SMLI TR-2008--175. Sun Microsystems","author":"Taivalsaari A.","year":"2008","unstructured":"Taivalsaari , A. , Mikkonen , T. , Ingalls , D. and Palacz , K . ( 2008 ) Web Browser As an Application Platform: The Lively Kernel Experience . In SMLI TR-2008--175. Sun Microsystems , Inc . Taivalsaari, A., Mikkonen, T., Ingalls, D. and Palacz, K. (2008) Web Browser As an Application Platform: The Lively Kernel Experience. In SMLI TR-2008--175. Sun Microsystems, Inc."},{"key":"e_1_3_2_2_29_1","doi-asserted-by":"publisher","DOI":"10.1038/scientificamerican0991-94"},{"key":"e_1_3_2_2_30_1","doi-asserted-by":"publisher","DOI":"10.1145/1518701.1518975"},{"key":"e_1_3_2_2_31_1","doi-asserted-by":"publisher","DOI":"10.1145/2556288.2557199"}],"event":"UIST '15: The 28th Annual ACM Symposium on User Interface Software and Technology","container-title":"Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/2807442.2807446","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,1,6]],"date-time":"2023-01-06T05:25:38Z","timestamp":1672982738000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/2807442.2807446"}},"subtitle":["Shareable Dynamic Media"],"short-title":[],"issued":{"date-parts":[[2015,11,5]]},"references-count":31,"alternative-id":["10.1145/2807442.2807446","10.1145/2807442"],"URL":"http://dx.doi.org/10.1145/2807442.2807446","relation":{},"published":{"date-parts":[[2015,11,5]]},"assertion":[{"value":"2015-11-05","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/2807442.2807446"},{"author":[{"given":"Thomas","family":"Kluyver"},{"given":"Benjamin","family":"Ragan-Kelley"},{"given":"Fernando","family":"Pérez"},{"given":"Brian E","family":"Granger"},{"given":"Matthias","family":"Bussonnier"},{"given":"Jonathan","family":"Frederic"},{"given":"Kyle","family":"Kelley"},{"given":"Jessica B","family":"Hamrick"},{"given":"Jason","family":"Grout"},{"given":"Sylvain","family":"Corlay"},{"family":"others"}],"type":"book","id":"jupyter","citation-key":"jupyter","issued":{"date-parts":[[2016]]},"title":"Jupyter Notebooks-a publishing format for reproducible computational workflows.","volume":"2016"},{"author":[{"given":"D. E.","family":"Knuth"}],"type":"book","id":"tex","citation-key":"tex","issued":{"date-parts":[[1979]]},"publisher":"American Mathematical Society","title":"TEX and METAFONT: New directions in typesetting"},{"indexed":{"date-parts":[[2023,10,12]],"date-time":"2023-10-12T11:14:29Z","timestamp":1697109269671},"reference-count":0,"publisher":"Oxford University Press (OUP)","issue":"2","content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[1984,2,1]]},"DOI":"10.1093/comjnl/27.2.97","type":"journal-article","created":{"date-parts":[[2005,4,28]],"date-time":"2005-04-28T00:07:39Z","timestamp":1114646859000},"page":"97-111","source":"Crossref","is-referenced-by-count":721,"title":"Literate Programming","prefix":"10.1093","volume":"27","author":[{"given":"D. E.","family":"Knuth","sequence":"first","affiliation":[]}],"member":"286","container-title":"The Computer Journal","original-title":[],"language":"en","link":[{"URL":"http://academic.oup.com/comjnl/article-pdf/27/2/97/981657/270097.pdf","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2017,8,22]],"date-time":"2017-08-22T20:45:00Z","timestamp":1503434700000},"score":1,"resource":{"primary":{"URL":"https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/27.2.97"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[1984,2,1]]},"references-count":0,"journal-issue":{"issue":"2","published-print":{"date-parts":[[1984,2,1]]}},"URL":"http://dx.doi.org/10.1093/comjnl/27.2.97","relation":{},"ISSN":["0010-4620","1460-2067"],"subject":["General Computer Science"],"container-title-short":"The Computer Journal","published":{"date-parts":[[1984,2,1]]},"id":"doi:10.1093/comjnl/27.2.97"},{"author":[{"given":"Leslie","family":"Lamport"}],"type":"book","id":"latex","citation-key":"latex","issued":{"date-parts":[[1985]]},"publisher":"Addison-Wesley Professional","title":"LaTeX: A Document Preparation System"},{"indexed":{"date-parts":[[2023,10,12]],"date-time":"2023-10-12T08:32:55Z","timestamp":1697099575208},"publisher-location":"Berlin, Heidelberg","reference-count":3,"publisher":"Springer Berlin Heidelberg","isbn-type":[{"value":"9783642043451","type":"print"},{"value":"9783642043468","type":"electronic"}],"license":[{"start":{"date-parts":[[2009,1,1]],"date-time":"2009-01-01T00:00:00Z","timestamp":1230768000000},"content-version":"unspecified","delay-in-days":0,"URL":"http://www.springer.com/tdm"}],"content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2009]]},"DOI":"10.1007/978-3-642-04346-8_62","type":"book-chapter","created":{"date-parts":[[2009,9,19]],"date-time":"2009-09-19T08:51:11Z","timestamp":1253350271000},"page":"473-474","source":"Crossref","is-referenced-by-count":87,"title":"GROBID: Combining Automatic Bibliographic Data Recognition and Term Extraction for Scholarship Publications","prefix":"10.1007","author":[{"given":"Patrice","family":"Lopez","sequence":"first","affiliation":[]}],"member":"297","reference":[{"key":"62_CR1","unstructured":"Peng, F., McCallum, A.: Accurate Information Extraction from Research Papers using Conditional Random Fields. In: Proceedings of HLT-NAACL (2004)"},{"key":"62_CR2","unstructured":"McCallum, A., Kachites, A.: MALLET: A Machine Learning for Language Toolkit (2002)"},{"key":"62_CR3","doi-asserted-by":"crossref","unstructured":"Tomokiyo, T., Hurst, M.: A language model approach to keyphrase extraction. In: Proceedings of ACL Workshop on Multiword Expressions (2003)","DOI":"10.3115/1119282.1119287"}],"container-title":"Research and Advanced Technology for Digital Libraries","original-title":[],"link":[{"URL":"http://link.springer.com/content/pdf/10.1007/978-3-642-04346-8_62","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2019,3,9]],"date-time":"2019-03-09T22:51:39Z","timestamp":1552171899000},"score":1,"resource":{"primary":{"URL":"http://link.springer.com/10.1007/978-3-642-04346-8_62"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2009]]},"ISBN":["9783642043451","9783642043468"],"references-count":3,"URL":"http://dx.doi.org/10.1007/978-3-642-04346-8_62","relation":{},"ISSN":["0302-9743","1611-3349"],"published":{"date-parts":[[2009]]},"id":"doi:10.1007/978-3-642-04346-8_62"},{"author":[{"given":"Bruce D.","family":"Lucas"},{"given":"Takeo","family":"Kanade"}],"container-title":"International Joint Conference on Artificial Intelligence","type":"paper-conference","id":"LucasKanade81","citation-key":"LucasKanade81","issued":{"date-parts":[[1981]]},"title":"An Iterative Image Registration Technique with an Application to Stereo Vision"},{"author":[{"given":"John","family":"MacFarlane"}],"type":"document","id":"pandoc","citation-key":"pandoc","issued":{"date-parts":[[2023]]},"title":"Pandoc: A Universal Document Converter","URL":"https://pandoc.org/"},{"author":[{"family":"Meta Open Source"}],"type":"document","id":"react","citation-key":"react","issued":{"date-parts":[[2023]]},"title":"React","URL":"https://react.dev/"},{"author":[{"family":"MyST Markdown"}],"type":"document","id":"myst","citation-key":"myst","issued":{"date-parts":[[2023]]},"URL":"https://myst-tools.org/"},{"indexed":{"date-parts":[[2023,10,17]],"date-time":"2023-10-17T11:11:06Z","timestamp":1697541066135},"publisher-location":"New York, New York, USA","reference-count":0,"publisher":"ACM Press","content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[1965]]},"DOI":"10.1145/800197.806036","type":"proceedings-article","created":{"date-parts":[[2003,11,13]],"date-time":"2003-11-13T20:18:27Z","timestamp":1068754707000},"source":"Crossref","is-referenced-by-count":151,"title":"Complex information processing","prefix":"10.1145","author":[{"given":"T. H.","family":"Nelson","sequence":"first","affiliation":[]}],"member":"320","event":"the 1965 20th national conference","container-title":"Proceedings of the 1965 20th national conference on   -","original-title":[],"link":[{"URL":"http://dl.acm.org/ft_gateway.cfm?id=806036&amp;ftid=58286&amp;dwn=1","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2016,12,16]],"date-time":"2016-12-16T01:50:09Z","timestamp":1481853009000},"score":1,"resource":{"primary":{"URL":"http://portal.acm.org/citation.cfm?doid=800197.806036"}},"subtitle":["a file structure for the complex, the changing and the indeterminate"],"short-title":[],"issued":{"date-parts":[[1965]]},"references-count":0,"URL":"http://dx.doi.org/10.1145/800197.806036","relation":{},"published":{"date-parts":[[1965]]},"id":"doi:10.1145/800197.806036"},{"author":[{"given":"T. H.","family":"Nelson"}],"type":"book","id":"Nelson:81","citation-key":"Nelson:81","issued":{"date-parts":[[1981]]},"publisher":"Mindful Press","title":"Literary Machines"},{"author":[{"family":"Observable Inputs"}],"type":"document","id":"obsinputs","citation-key":"obsinputs","issued":{"date-parts":[[2023]]},"URL":"https://github.com/observablehq/inputs"},{"author":[{"family":"Observable Runtime"}],"type":"document","id":"obsruntime","citation-key":"obsruntime","issued":{"date-parts":[[2023]]},"URL":"https://github.com/observablehq/runtime"},{"author":[{"family":"Observable"}],"type":"document","id":"observable","citation-key":"observable","issued":{"date-parts":[[2023]]},"URL":"https://observablehq.com/"},{"author":[{"family":"Overleaf"}],"type":"document","id":"overleaf","citation-key":"overleaf","issued":{"date-parts":[[2023]]},"title":"Online LaTeX Editor","URL":"https://www.overleaf.com/"},{"indexed":{"date-parts":[[2023,4,17]],"date-time":"2023-04-17T04:53:10Z","timestamp":1681707190509},"reference-count":19,"publisher":"Elsevier BV","issue":"1-6","license":[{"start":{"date-parts":[[2000,6,1]],"date-time":"2000-06-01T00:00:00Z","timestamp":959817600000},"content-version":"tdm","delay-in-days":0,"URL":"https://www.elsevier.com/tdm/userlicense/1.0/"}],"content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2000,6]]},"DOI":"10.1016/s1389-1286(00)00043-8","type":"journal-article","created":{"date-parts":[[2002,7,26]],"date-time":"2002-07-26T02:38:45Z","timestamp":1027651125000},"page":"105-118","source":"Crossref","is-referenced-by-count":28,"title":"Robust intra-document locations","prefix":"10.1016","volume":"33","author":[{"given":"Thomas A","family":"Phelps","sequence":"first","affiliation":[]},{"given":"Robert","family":"Wilensky","sequence":"additional","affiliation":[]}],"member":"78","reference":[{"key":"10.1016/S1389-1286(00)00043-8_BIB1","unstructured":"Adobe Systems, Acrobat 4.0, http://www.adobe.com/products/acrobat/main.html."},{"key":"10.1016/S1389-1286(00)00043-8_BIB2","unstructured":"P. Francis, T. Kambayashi, S. Sato and S. Shimizu, Ingrid: a self-configuring information navigation infrastructure, December 11–14, 1995, http://www.ingrid.org/francis/www4/Overview.html."},{"key":"10.1016/S1389-1286(00)00043-8_BIB3","doi-asserted-by":"crossref","unstructured":"K. Grønbæk, L. Sloth and P. Ørbæk, Webvise: browser and proxy support for open hypermedia structuring mechanisms on the WWW, in: Proc. Eighth World Wide Web Conference 1999, Toronto, Canada, http://www8.org/w8-papers/3a-search-query/webvise/webvise.html.","DOI":"10.1016/S1389-1286(99)00046-8"},{"key":"10.1016/S1389-1286(00)00043-8_BIB4","doi-asserted-by":"crossref","unstructured":"W. Hall, H. Davis and G. Hutchings, Rethinking Hypertext: A Microcosm Approach, Kluwer, Dordrecht, 1996.","DOI":"10.1007/978-1-4613-1335-9"},{"key":"10.1016/S1389-1286(00)00043-8_BIB5","doi-asserted-by":"crossref","unstructured":"D. Ingham, S. Caughey and M. Little, Fixing the ‘broken-link’ problem: the W3Objects approach, Comp. Networks ISDN Syst. 28 (7–11) (1996) 1255–1268, Proc. Fifth International World Wide Web Conference, Paris, France, 6–10 May 1996, http://arjuna.ncl.ac.uk/group/papers/p050.html.","DOI":"10.1016/0169-7552(96)00069-4"},{"key":"10.1016/S1389-1286(00)00043-8_BIB6","unstructured":"Insight Development, Hot off the Web software, http://www.hotofftheweb.com/."},{"key":"10.1016/S1389-1286(00)00043-8_BIB7","unstructured":"R. Kahn and R. Wilensky, A framework for distributed digital object services, cnri.dlib/tn95-01, May 13, 1995, http://www.cnri.reston.va.us/k-w.html."},{"key":"10.1016/S1389-1286(00)00043-8_BIB8","unstructured":"S. Macskassy and L. Shklar, Maintaining information resources, in: Proc. Third International Workshop on Next Generation Information Technologies (NGITS’97), June 30–July 3, 1997, Neve Ilan, Israel, http://www.cs.rutgers.edu/∼shklar/papers/ngits97/."},{"key":"10.1016/S1389-1286(00)00043-8_BIB9","unstructured":"Mind-it, http://www.netmind.com/html/individual.html."},{"key":"10.1016/S1389-1286(00)00043-8_BIB10","unstructured":"T.H. Nelson, Computer Lib/Dream Machines, 1974, also see the Xanadu home page, http://www.xanadu.net/."},{"key":"10.1016/S1389-1286(00)00043-8_BIB11","unstructured":"OCLC PURL Service, http://www.purl.org."},{"key":"10.1016/S1389-1286(00)00043-8_BIB12","unstructured":"F. Olken, private communication."},{"key":"10.1016/S1389-1286(00)00043-8_BIB13","unstructured":"T.A. Phelps, TkMan: a man born again, X Resource 1 (10) (1994) 33–46."},{"key":"10.1016/S1389-1286(00)00043-8_BIB14","doi-asserted-by":"crossref","unstructured":"T.A. Phelps, Multivalent Documents: Anytime, Anywhere, Any Type, Every Way User-Improvable Digital Documents and Systems, Ph.D. Dissertation, University of California, Berkeley, UC Berkeley Division of Computer Science Technical Report No. UCB/CSD-98-1026, December 1998, also see the general and technical home pages, http://www.cs.berkeley.edu/∼phelps/papers/dissertation-abstract.html, http://www.cs.berkeley.edu/∼wilensky/MVD.html, http://www.cs.berkeley.edu/∼phelps/Multivalent/.","DOI":"10.21236/ADA603917"},{"key":"10.1016/S1389-1286(00)00043-8_BIB15","unstructured":"T.A. Phelps and R. Wilensky, Robust hyperlinks cost just five words each, University of California, Berkeley Computer Science Technical Report, CSD-00-1091, 2000, http://www.cs.berkeley.edu/∼wilensky/robust-hyperlinks.html."},{"key":"10.1016/S1389-1286(00)00043-8_BIB16","doi-asserted-by":"crossref","unstructured":"M. Roscheisen, C. Mogensen and T. Winograd, Beyond browsing: shared comments, SOAPs, trails, and on-line communities, in: Proc. Third World Wide Web Conference: Technology, Tools and Applications, Darmstadt, April 1995.","DOI":"10.1016/0169-7552(95)00031-2"},{"key":"10.1016/S1389-1286(00)00043-8_BIB17","doi-asserted-by":"crossref","unstructured":"K. Sollins and L. Masinter, Functional requirements for uniform resource names, Network Working Group Request for Comments 1737, December 1994, http://www.w3.org/Addressing/rfc1737.txt.","DOI":"10.17487/rfc1737"},{"key":"10.1016/S1389-1286(00)00043-8_BIB18","unstructured":"R. Wilensky and T.A. Phelps, Multivalent documents: a new model for digital documents, University of California, Berkeley Computer Science Technical Report, CSD-98-999, March 13, 1998, http://www.cs.berkeley.edu/∼phelps/papers/techrep98-abstract.html."},{"key":"10.1016/S1389-1286(00)00043-8_BIB19","unstructured":"World Wide Web Consortium, Structured Vector Graphics (SVG), XPointer, XLink, Document Object Model (DOM), http://www.w3.org."}],"container-title":"Computer Networks","original-title":[],"language":"en","link":[{"URL":"https://api.elsevier.com/content/article/PII:S1389128600000438?httpAccept=text/xml","content-type":"text/xml","content-version":"vor","intended-application":"text-mining"},{"URL":"https://api.elsevier.com/content/article/PII:S1389128600000438?httpAccept=text/plain","content-type":"text/plain","content-version":"vor","intended-application":"text-mining"}],"deposited":{"date-parts":[[2023,4,17]],"date-time":"2023-04-17T04:04:44Z","timestamp":1681704284000},"score":1,"resource":{"primary":{"URL":"https://linkinghub.elsevier.com/retrieve/pii/S1389128600000438"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2000,6]]},"references-count":19,"journal-issue":{"issue":"1-6","published-print":{"date-parts":[[2000,6]]}},"alternative-id":["S1389128600000438"],"URL":"http://dx.doi.org/10.1016/S1389-1286(00)00043-8","relation":{},"ISSN":["1389-1286"],"subject":["Computer Networks and Communications"],"container-title-short":"Computer Networks","published":{"date-parts":[[2000,6]]},"id":"doi:10.1016/S1389-1286(00)00043-8"},{"author":[{"family":"Quarto"}],"type":"document","id":"quarto","citation-key":"quarto","issued":{"date-parts":[[2023]]},"URL":"https://quarto.org/"},{"author":[{"family":"RMarkdown"}],"type":"document","id":"rmarkdown","citation-key":"rmarkdown","issued":{"date-parts":[[2023]]},"URL":"https://rmarkdown.rstudio.com/"},{"indexed":{"date-parts":[[2023,10,18]],"date-time":"2023-10-18T23:18:53Z","timestamp":1697671133378},"publisher-location":"New York, NY, USA","reference-count":26,"publisher":"ACM","content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2022,3,22]]},"DOI":"10.1145/3490099.3511162","type":"proceedings-article","created":{"date-parts":[[2022,3,21]],"date-time":"2022-03-21T23:24:13Z","timestamp":1647905053000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":8,"title":"CiteRead: Integrating Localized Citation Contexts into Scientific Paper Reading","prefix":"10.1145","author":[{"given":"Napol","family":"Rachatasumrit","sequence":"first","affiliation":[{"name":"Human Computer Interaction Institute, Carnegie Mellon University, United States"}]},{"given":"Jonathan","family":"Bragg","sequence":"additional","affiliation":[{"name":"Allen Institute for Artificial Intelligence, United States"}]},{"given":"Amy X.","family":"Zhang","sequence":"additional","affiliation":[{"name":"CSE, University of Washington, United States"}]},{"given":"Daniel S","family":"Weld","sequence":"additional","affiliation":[{"name":"Semantic Scholar, Allen Institute for Artificial Intelligence, United States"}]}],"member":"320","published-online":{"date-parts":[[2022,3,22]]},"reference":[{"key":"e_1_3_2_1_1_1","volume-title":"Elastic documents: Coupling text and tables through contextual visualizations for enhanced document reading","author":"Badam Sriram Karthik","year":"2018","unstructured":"Sriram Karthik Badam , Zhicheng Liu , and Niklas Elmqvist . 2018. Elastic documents: Coupling text and tables through contextual visualizations for enhanced document reading . IEEE transactions on visualization and computer graphics 25, 1( 2018 ), 661–671. Sriram Karthik Badam, Zhicheng Liu, and Niklas Elmqvist. 2018. Elastic documents: Coupling text and tables through contextual visualizations for enhanced document reading. IEEE transactions on visualization and computer graphics 25, 1(2018), 661–671."},{"key":"e_1_3_2_1_2_1","volume-title":"SciBERT: A Pretrained Language Model for Scientific Text. In In Proceedings of the Conference on Empirical Methods in Natural Language Processing.","author":"Beltagy Iz","year":"2019","unstructured":"Iz Beltagy , Kyle Lo , and Arman Cohan . 2019 . SciBERT: A Pretrained Language Model for Scientific Text. In In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciBERT: A Pretrained Language Model for Scientific Text. In In Proceedings of the Conference on Empirical Methods in Natural Language Processing."},{"key":"e_1_3_2_1_3_1","volume-title":"TLDR: Extreme Summarization of Scientific Documents. In Findings of the Association for Computational Linguistics: EMNLP","author":"Cachola Isabel","year":"2020","unstructured":"Isabel Cachola , Kyle Lo , Arman Cohan , and Daniel  S. Weld . 2020 . TLDR: Extreme Summarization of Scientific Documents. In Findings of the Association for Computational Linguistics: EMNLP 2020. Isabel Cachola, Kyle Lo, Arman Cohan, and Daniel S. Weld. 2020. TLDR: Extreme Summarization of Scientific Documents. In Findings of the Association for Computational Linguistics: EMNLP 2020."},{"key":"e_1_3_2_1_4_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/2020.sdp-1.24"},{"key":"e_1_3_2_1_5_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/N19-1361"},{"key":"e_1_3_2_1_6_1","volume-title":"SPECTER: Document-level Representation Learning using Citation-informed Transformers. arxiv:2004.07180 [cs.CL]","author":"Cohan Arman","year":"2020","unstructured":"Arman Cohan , Sergey Feldman , Iz Beltagy , Doug Downey , and Daniel  S. Weld . 2020 . SPECTER: Document-level Representation Learning using Citation-informed Transformers. arxiv:2004.07180 [cs.CL] Arman Cohan, Sergey Feldman, Iz Beltagy, Doug Downey, and Daniel S. Weld. 2020. SPECTER: Document-level Representation Learning using Citation-informed Transformers. arxiv:2004.07180 [cs.CL]"},{"key":"e_1_3_2_1_7_1","volume-title":"Scientific Article Summarization Using Citation-Context and Article’s Discourse Structure. In In Proceedings of the Conference on Empirical Methods in Natural Language Processing.","author":"Cohan Arman","year":"2015","unstructured":"Arman Cohan and Nazli Goharian . 2015 . Scientific Article Summarization Using Citation-Context and Article’s Discourse Structure. In In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Arman Cohan and Nazli Goharian. 2015. Scientific Article Summarization Using Citation-Context and Article’s Discourse Structure. In In Proceedings of the Conference on Empirical Methods in Natural Language Processing."},{"key":"e_1_3_2_1_8_1","doi-asserted-by":"publisher","DOI":"10.1145/3077136.3080740"},{"key":"e_1_3_2_1_9_1","volume-title":"Do Peers See More in a Paper Than Its Authors?Advances in Bioinformatics 2012","author":"Divoli Anna","year":"2012","unstructured":"Anna Divoli , Preslav Nakov , and Marti  A. Hearst . 2012. Do Peers See More in a Paper Than Its Authors?Advances in Bioinformatics 2012 ( 2012 ). Anna Divoli, Preslav Nakov, and Marti A. Hearst. 2012. Do Peers See More in a Paper Than Its Authors?Advances in Bioinformatics 2012 (2012)."},{"key":"e_1_3_2_1_10_1","volume-title":"States, and Dragomir R. Radev","author":"Elkiss Aaron","year":"2008","unstructured":"Aaron Elkiss , Siwei Shen , Anthony Fader , Günes Erkan , David  J. States, and Dragomir R. Radev . 2008 . Blind men and elephants: What do citation summaries tell us about a research article?Journal of the Association for Information Science and Technology 59 (2008), 51–62. Aaron Elkiss, Siwei Shen, Anthony Fader, Günes Erkan, David J. States, and Dragomir R. Radev. 2008. Blind men and elephants: What do citation summaries tell us about a research article?Journal of the Association for Information Science and Technology 59 (2008), 51–62."},{"key":"e_1_3_2_1_11_1","doi-asserted-by":"publisher","DOI":"10.1145/22627.22342"},{"key":"e_1_3_2_1_12_1","doi-asserted-by":"publisher","DOI":"10.1145/3313831.3376842"},{"key":"e_1_3_2_1_13_1","volume-title":"Development of NASA-TLX (Task Load Index): Results of Empirical and Theoretical Research. Advances in psychology 52","author":"Hart G.","year":"1988","unstructured":"S.  G. Hart and Lowell  E. Staveland . 1988. Development of NASA-TLX (Task Load Index): Results of Empirical and Theoretical Research. Advances in psychology 52 ( 1988 ), 139–183. S. G. Hart and Lowell E. Staveland. 1988. Development of NASA-TLX (Task Load Index): Results of Empirical and Theoretical Research. Advances in psychology 52 (1988), 139–183."},{"key":"e_1_3_2_1_14_1","doi-asserted-by":"publisher","DOI":"10.1109/JCDL.2017.7991558"},{"key":"e_1_3_2_1_15_1","doi-asserted-by":"publisher","DOI":"10.1145/3411764.3445648"},{"key":"e_1_3_2_1_16_1","doi-asserted-by":"publisher","DOI":"10.1007/978-3-319-67008-9_23"},{"key":"e_1_3_2_1_17_1","doi-asserted-by":"publisher","DOI":"10.1145/3313831.3376559"},{"key":"e_1_3_2_1_18_1","volume-title":"In Proceedings of the Conference on Empirical Methods in Natural Language Processing.","author":"Mihalcea Rada","year":"2004","unstructured":"Rada Mihalcea and Paul Tarau . 2004 . TextRank: Bringing Order into Text . In In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Rada Mihalcea and Paul Tarau. 2004. TextRank: Bringing Order into Text. In In Proceedings of the Conference on Empirical Methods in Natural Language Processing."},{"key":"e_1_3_2_1_19_1","volume-title":"Citances: Citation Sentences for Semantic Analysis of Bioscience Text. In SIGIR’04 workshop on Search and Discovery in Bioinformatics.","author":"Nakov Preslav","year":"2004","unstructured":"Preslav Nakov , Ariel  S. Schwartz , and Marti  A. Hearst . 2004 . Citances: Citation Sentences for Semantic Analysis of Bioscience Text. In SIGIR’04 workshop on Search and Discovery in Bioinformatics. Preslav Nakov, Ariel S. Schwartz, and Marti A. Hearst. 2004. Citances: Citation Sentences for Semantic Analysis of Bioscience Text. In SIGIR’04 workshop on Search and Discovery in Bioinformatics."},{"key":"e_1_3_2_1_20_1","doi-asserted-by":"publisher","DOI":"10.1007/978-3-319-67008-9_48"},{"key":"e_1_3_2_1_21_1","volume-title":"Proceedings of the Workshop on Linking Natural Language Processing and Biology: Towards Deeper Biological Literature Analysis.","author":"S.","unstructured":"Ariel  S. Schwartz and Marti A. Hearst. 2006. Summarizing Key Concepts using Citation Sentences . In Proceedings of the Workshop on Linking Natural Language Processing and Biology: Towards Deeper Biological Literature Analysis. Ariel S. Schwartz and Marti A. Hearst. 2006. Summarizing Key Concepts using Citation Sentences. In Proceedings of the Workshop on Linking Natural Language Processing and Biology: Towards Deeper Biological Literature Analysis."},{"key":"e_1_3_2_1_22_1","volume-title":"VILA: Improving Structured Content Extraction from Scientific PDFs Using Visual Layout Groups. arxiv:2106.00676 [cs.CL]","author":"Shen Zejiang","year":"2022","unstructured":"Zejiang Shen , Kyle Lo , Lucy Lu Wang , Bailey Kuehl , Daniel  S. Weld , and Doug Downey . 2022 . VILA: Improving Structured Content Extraction from Scientific PDFs Using Visual Layout Groups. arxiv:2106.00676 [cs.CL] Zejiang Shen, Kyle Lo, Lucy Lu Wang, Bailey Kuehl, Daniel S. Weld, and Doug Downey. 2022. VILA: Improving Structured Content Extraction from Scientific PDFs Using Visual Layout Groups. arxiv:2106.00676 [cs.CL]"},{"key":"e_1_3_2_1_23_1","volume-title":"Identifying Meaningful Citations. In AAAI Workshop: Scholarly Big Data.","author":"Valenzuela Marco","year":"2015","unstructured":"Marco Valenzuela , Vu  A. Ha , and Oren Etzioni . 2015 . Identifying Meaningful Citations. In AAAI Workshop: Scholarly Big Data. Marco Valenzuela, Vu A. Ha, and Oren Etzioni. 2015. Identifying Meaningful Citations. In AAAI Workshop: Scholarly Big Data."},{"key":"e_1_3_2_1_24_1","doi-asserted-by":"publisher","DOI":"10.1145/2858036.2858466"},{"key":"e_1_3_2_1_25_1","doi-asserted-by":"publisher","DOI":"10.1145/3025453.3025496"},{"key":"e_1_3_2_1_26_1","doi-asserted-by":"publisher","DOI":"10.1145/2207676.2208326"}],"event":"IUI '22: 27th International Conference on Intelligent User Interfaces","container-title":"27th International Conference on Intelligent User Interfaces","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/3490099.3511162","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,3,22]],"date-time":"2023-03-22T10:37:35Z","timestamp":1679481455000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/3490099.3511162"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2022,3,22]]},"references-count":26,"alternative-id":["10.1145/3490099.3511162","10.1145/3490099"],"URL":"http://dx.doi.org/10.1145/3490099.3511162","relation":{},"published":{"date-parts":[[2022,3,22]]},"assertion":[{"value":"2022-03-22","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/3490099.3511162"},{"container-title":"The Guardian","author":[{"given":"Stuart","family":"Ritchie"}],"type":"article-journal","id":"ritchie2022big","citation-key":"ritchie2022big","issued":{"date-parts":[[2022]]},"title":"The Big Idea: Should we get rid of the scientific paper?","URL":"https://www.theguardian.com/books/2022/apr/11/the-big-idea-should-we-get-rid-of-the-scientific-paper","volume":"11"},{"indexed":{"date-parts":[[2023,10,19]],"date-time":"2023-10-19T15:10:56Z","timestamp":1697728256239},"publisher-location":"New York, NY, USA","reference-count":38,"publisher":"ACM","license":[{"start":{"date-parts":[[2019,4,19]],"date-time":"2019-04-19T00:00:00Z","timestamp":1555632000000},"content-version":"vor","delay-in-days":365,"URL":"http://www.acm.org/publications/policies/copyright_policy#Background"}],"funder":[{"name":"National Library of Medicine","award":["T15LM011271"]},{"DOI":"10.13039/100000001","name":"National Science Foundation","doi-asserted-by":"publisher","award":["1319829","1735234"]}],"content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2018,4,19]]},"DOI":"10.1145/3173574.3173606","type":"proceedings-article","created":{"date-parts":[[2018,4,20]],"date-time":"2018-04-20T12:01:00Z","timestamp":1524225660000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":144,"title":"Exploration and Explanation in Computational Notebooks","prefix":"10.1145","author":[{"given":"Adam","family":"Rule","sequence":"first","affiliation":[{"name":"University of California, San Diego, La Jolla, CA, USA"}]},{"given":"Aurélien","family":"Tabard","sequence":"additional","affiliation":[{"name":"Université de Lyon, Lyon, France"}]},{"given":"James D.","family":"Hollan","sequence":"additional","affiliation":[{"name":"University of California, San Diego, La Jolla, CA, USA"}]}],"member":"320","published-online":{"date-parts":[[2018,4,19]]},"reference":[{"key":"e_1_3_2_2_1_1","doi-asserted-by":"publisher","DOI":"10.1145/2160718.2160733"},{"key":"e_1_3_2_2_2_1","volume-title":"Retrieved","author":"Bostock Mike","year":"2017","unstructured":"Mike Bostock . 2017 . A Better Way to Code. (Apr. 2017) . Retrieved September 11, 2017 from https://medium.com/@mbostock/a-better-way-to-code2b1d2876a3a0 Mike Bostock. 2017. A Better Way to Code. (Apr. 2017). Retrieved September 11, 2017 from https://medium.com/@mbostock/a-better-way-to-code2b1d2876a3a0"},{"key":"e_1_3_2_2_3_1","doi-asserted-by":"publisher","DOI":"10.1145/1882362.1882373"},{"key":"e_1_3_2_2_4_1","doi-asserted-by":"publisher","DOI":"10.1145/157709.157715"},{"key":"e_1_3_2_2_5_1","doi-asserted-by":"publisher","DOI":"10.1038/nature13178"},{"key":"e_1_3_2_2_6_1","unstructured":"Distil. 2017. Retrieved September 11 2017 from https://distill.pub/  Distil. 2017. Retrieved September 11 2017 from https://distill.pub/"},{"key":"e_1_3_2_2_7_1","volume-title":"Retrieved","author":"Dunbar Brian","year":"2010","unstructured":"Brian Dunbar . 2010 . NASA - Shuttle Computers Navigate Record of Reliability. (June 2010) . Retrieved September 15, 2017 from https://www.nasa.gov/mission_pages/shuttle/flyout/flyf eature_shuttlecomputers.html Brian Dunbar. 2010. NASA - Shuttle Computers Navigate Record of Reliability. (June 2010). Retrieved September 15, 2017 from https://www.nasa.gov/mission_pages/shuttle/flyout/flyf eature_shuttlecomputers.html"},{"key":"e_1_3_2_2_8_1","volume-title":"Refactoring: improving the design of existing code","author":"Fowler Martin","unstructured":"Martin Fowler . 1999. Refactoring: improving the design of existing code . Addison-Wesley Professional , Reading, MA . Martin Fowler. 1999. Refactoring: improving the design of existing code. Addison-Wesley Professional, Reading, MA."},{"key":"e_1_3_2_2_9_1","doi-asserted-by":"publisher","DOI":"10.1145/381641.381653"},{"key":"e_1_3_2_2_10_1","volume-title":"JupyterLab: The next generation jupyter frontend. JupyterCon","author":"Granger Brian","year":"2017","unstructured":"Brian Granger , Chris Colbert , and Ian Rose . 2017. JupyterLab: The next generation jupyter frontend. JupyterCon 2017 . Brian Granger, Chris Colbert, and Ian Rose. 2017. JupyterLab: The next generation jupyter frontend. JupyterCon 2017."},{"key":"e_1_3_2_2_11_1","volume-title":"USENIX Workshop on the Theory and Practice of Provenance (TaPP '12)","author":"Guo Philip","year":"2012","unstructured":"Philip Guo and Margo Seltzer . 2012 . Burrito: Wrapping your lab notebook in computational infrastructure . USENIX Workshop on the Theory and Practice of Provenance (TaPP '12) . Philip Guo and Margo Seltzer. 2012. Burrito: Wrapping your lab notebook in computational infrastructure. USENIX Workshop on the Theory and Practice of Provenance (TaPP '12)."},{"key":"e_1_3_2_2_12_1","doi-asserted-by":"publisher","DOI":"10.1145/223904.223920"},{"key":"e_1_3_2_2_13_1","volume-title":"Does high public debt consistently stifle economic growth? A critique of Reinhart and Rogoff","author":"Herndon Thomas","year":"2013","unstructured":"Thomas Herndon , Michael Ash , and Robert Pollin . 2014. Does high public debt consistently stifle economic growth? A critique of Reinhart and Rogoff . Cambridge journal of economics, 38, 2 ( Dec 2013 ), 257--279. Thomas Herndon, Michael Ash, and Robert Pollin. 2014. Does high public debt consistently stifle economic growth? A critique of Reinhart and Rogoff. Cambridge journal of economics, 38, 2 (Dec 2013), 257--279."},{"key":"e_1_3_2_2_14_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2011.255"},{"key":"e_1_3_2_2_15_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2013.119"},{"key":"e_1_3_2_2_16_1","volume-title":"Retrieved","year":"2017","unstructured":"Jupyter. A gallery of interesting Jupyter Notebooks . Retrieved September 11, 2017 from https://github.com/jupyter/jupyter/wiki/A-gallery-ofinteresting-Jupyter-Notebooks Jupyter. A gallery of interesting Jupyter Notebooks. Retrieved September 11, 2017 from https://github.com/jupyter/jupyter/wiki/A-gallery-ofinteresting-Jupyter-Notebooks"},{"key":"e_1_3_2_2_17_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2012.219"},{"key":"e_1_3_2_2_18_1","doi-asserted-by":"publisher","DOI":"10.1145/3025453.3025626"},{"key":"e_1_3_2_2_19_1","doi-asserted-by":"publisher","DOI":"10.1145/191666.191740"},{"key":"e_1_3_2_2_20_1","doi-asserted-by":"publisher","DOI":"10.1093/comjnl/27.2.97"},{"key":"e_1_3_2_2_21_1","doi-asserted-by":"publisher","DOI":"10.1109/MC.2013.36"},{"key":"e_1_3_2_2_22_1","doi-asserted-by":"publisher","DOI":"10.1007/s10606-017-9285-x"},{"key":"e_1_3_2_2_23_1","doi-asserted-by":"publisher","DOI":"10.1145/2597008.2597149"},{"key":"e_1_3_2_2_24_1","volume-title":"Induction and Intuition in Scientific Thought","author":"Medawar Peter","unstructured":"Peter Medawar . 2008. Induction and Intuition in Scientific Thought . Routledge . Peter Medawar. 2008. Induction and Intuition in Scientific Thought. Routledge."},{"key":"e_1_3_2_2_25_1","doi-asserted-by":"publisher","DOI":"10.1109/TSE.2011.41"},{"key":"e_1_3_2_2_26_1","first-page":"7645","article-title":"Announcement","volume":"534","year":"2017","unstructured":"Nature. 2017 . Announcement : Transparency Upgrade for Nature Journals. Nature , 534 , 7645 (Mar 2017), 288. Nature. 2017. Announcement: Transparency Upgrade for Nature Journals. Nature, 534, 7645 (Mar 2017), 288.","journal-title":"Transparency Upgrade for Nature Journals. Nature"},{"key":"e_1_3_2_2_27_1","doi-asserted-by":"publisher","DOI":"10.1126/science.1213847"},{"key":"e_1_3_2_2_28_1","unstructured":"Fernando Perez and Brian Granger. 2015. Project Jupyter: Computational Narratives as the Engine of Collaborative Data Science. Retrieved September 11 207 from http://blog.jupyter.org/2015/07/07/projectjupyter-computational-narratives-as-the-engine-ofcollaborative-data-science/  Fernando Perez and Brian Granger. 2015. Project Jupyter: Computational Narratives as the Engine of Collaborative Data Science. Retrieved September 11 207 from http://blog.jupyter.org/2015/07/07/projectjupyter-computational-narratives-as-the-engine-ofcollaborative-data-science/"},{"key":"e_1_3_2_2_29_1","doi-asserted-by":"publisher","DOI":"10.1145/3126594.3126642"},{"key":"e_1_3_2_2_30_1","doi-asserted-by":"publisher","DOI":"10.1145/169059.169209"},{"key":"e_1_3_2_2_31_1","doi-asserted-by":"publisher","DOI":"10.1111/cgf.12392"},{"key":"e_1_3_2_2_32_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2010.179"},{"key":"e_1_3_2_2_33_1","volume-title":"Retrieved","author":"Shirokov Slava","year":"2015","unstructured":"Slava Shirokov . 2015 . GitHub + Jupyter Notebooks = <3. (May 2015) . Retrieved September 15, 2017 from https://github.com/blog/1995-github-jupyternotebooks-3 Slava Shirokov. 2015. GitHub + Jupyter Notebooks = <3. (May 2015). Retrieved September 15, 2017 from https://github.com/blog/1995-github-jupyternotebooks-3"},{"key":"e_1_3_2_2_34_1","doi-asserted-by":"publisher","DOI":"10.1145/1858996.1859006"},{"key":"e_1_3_2_2_35_1","doi-asserted-by":"publisher","DOI":"10.1145/1460563.1460653"},{"key":"e_1_3_2_2_36_1","volume-title":"Proceedings of the 37th International Conference on Software Engineering. IEEE Press, 403--414","author":"Tufano Michele","year":"2015","unstructured":"Michele Tufano , Fabio Palomba , Gabriele Bavota , Rocco Oliveto , Massimiliano Di Penta , Andrea De Lucia , Denys Poshyvanyk . 2015 , May. When and why your code starts to smell bad . In Proceedings of the 37th International Conference on Software Engineering. IEEE Press, 403--414 . Michele Tufano, Fabio Palomba, Gabriele Bavota, Rocco Oliveto, Massimiliano Di Penta, Andrea De Lucia, Denys Poshyvanyk. 2015, May. When and why your code starts to smell bad. In Proceedings of the 37th International Conference on Software Engineering. IEEE Press, 403--414."},{"key":"e_1_3_2_2_37_1","unstructured":"John Tukey. 1977. Exploratory data analysis. Pearson.  John Tukey. 1977. Exploratory data analysis. Pearson."},{"key":"e_1_3_2_2_38_1","volume-title":"Good enough practices in scientific computing. PLoS computational biology, 13, 6 (Jun","author":"Wilson Greg","year":"2017","unstructured":"Greg Wilson , Jennifer Bryan , Karen Cranston , Justin Kitzes , Lex Nederbragt , and Tracy Teal . 2017. Good enough practices in scientific computing. PLoS computational biology, 13, 6 (Jun , 2017 ). Greg Wilson, Jennifer Bryan, Karen Cranston, Justin Kitzes, Lex Nederbragt, and Tracy Teal. 2017. Good enough practices in scientific computing. PLoS computational biology, 13, 6 (Jun, 2017)."}],"event":"CHI '18: CHI Conference on Human Factors in Computing Systems","container-title":"Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/3173574.3173606","content-type":"application/pdf","content-version":"vor","intended-application":"syndication"},{"URL":"https://dl.acm.org/doi/pdf/10.1145/3173574.3173606","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,1,8]],"date-time":"2023-01-08T15:42:41Z","timestamp":1673192561000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/3173574.3173606"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2018,4,19]]},"references-count":38,"alternative-id":["10.1145/3173574.3173606","10.1145/3173574"],"URL":"http://dx.doi.org/10.1145/3173574.3173606","relation":{},"published":{"date-parts":[[2018,4,19]]},"assertion":[{"value":"2018-04-19","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/3173574.3173606"},{"indexed":{"date-parts":[[2023,10,15]],"date-time":"2023-10-15T02:59:24Z","timestamp":1697338764785},"reference-count":41,"publisher":"Institute of Electrical and Electronics Engineers (IEEE)","issue":"1","license":[{"start":{"date-parts":[[2016,1,31]],"date-time":"2016-01-31T00:00:00Z","timestamp":1454198400000},"content-version":"vor","delay-in-days":0,"URL":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html"}],"funder":[{"name":"SAP Stanford Graduate Fellowship, the Intel Big Data ISTC, the Moore Foundation, and DARPA XDATA"}],"content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2016,1,31]]},"DOI":"10.1109/tvcg.2015.2467091","type":"journal-article","created":{"date-parts":[[2015,8,13]],"date-time":"2015-08-13T22:35:03Z","timestamp":1439505303000},"page":"659-668","source":"Crossref","is-referenced-by-count":156,"title":"Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization","prefix":"10.1109","volume":"22","author":[{"given":"Arvind","family":"Satyanarayan","sequence":"first","affiliation":[]},{"given":"Ryan","family":"Russell","sequence":"additional","affiliation":[]},{"given":"Jane","family":"Hoffswell","sequence":"additional","affiliation":[]},{"given":"Jeffrey","family":"Heer","sequence":"additional","affiliation":[]}],"member":"263","reference":[{"key":"ref39","author":"wilkinson","year":"2005","journal-title":"The Grammar of Graphics"},{"key":"ref38","doi-asserted-by":"crossref","author":"wickham","year":"2009","journal-title":"ggplot2 Elegant Graphics for Data Analysis","DOI":"10.1007/978-0-387-98141-3"},{"key":"ref33","doi-asserted-by":"publisher","DOI":"10.1109/VISUAL.1996.567752"},{"key":"ref32","doi-asserted-by":"publisher","DOI":"10.1145/2642918.2647360"},{"key":"ref31","doi-asserted-by":"publisher","DOI":"10.1111/cgf.12391"},{"key":"ref30","doi-asserted-by":"publisher","DOI":"10.1057/ivs.2009.22"},{"key":"ref37","doi-asserted-by":"publisher","DOI":"10.1109/INFVIS.2004.12"},{"key":"ref36","doi-asserted-by":"crossref","first-page":"155","DOI":"10.1007/3-540-45587-6_11","article-title":"Event-driven FRP","author":"wan","year":"2002","journal-title":"Practical Aspects of Declarative Languages"},{"key":"ref35","year":"2015","journal-title":"Vega A visualization grammar"},{"key":"ref34","doi-asserted-by":"publisher","DOI":"10.1109/2945.981851"},{"key":"ref10","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2011.185"},{"key":"ref40","article-title":"Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations","author":"wongsuphasawat","year":"2015","journal-title":"IEEE Trans Visualization & Comp Graphics"},{"key":"ref11","first-page":"382","article-title":"An engineering model of human performance","volume":"3","author":"card","year":"2005","journal-title":"Ergonomics Psychological mechanisms and models in ergonomics"},{"key":"ref12","doi-asserted-by":"publisher","DOI":"10.1145/872757.872857"},{"key":"ref13","doi-asserted-by":"crossref","first-page":"294","DOI":"10.1007/11693024_20","article-title":"Embedding dynamic dataflow in a call-by-value language","author":"cooper","year":"2006","journal-title":"Programming Languages and Systems"},{"key":"ref14","doi-asserted-by":"publisher","DOI":"10.1109/IV.2008.66"},{"key":"ref15","year":"2015","journal-title":"css-layout"},{"key":"ref16","doi-asserted-by":"publisher","DOI":"10.1145/2491956.2462161"},{"key":"ref17","doi-asserted-by":"publisher","DOI":"10.1145/1639950.1640058"},{"key":"ref18","year":"2015","journal-title":"ggvis Interactive grammarof graphics for R"},{"key":"ref19","doi-asserted-by":"publisher","DOI":"10.1145/2445196.2445368"},{"key":"ref28","doi-asserted-by":"publisher","DOI":"10.1145/1639949.1640091"},{"key":"ref4","first-page":"2004","author":"arasu","year":"2004","journal-title":"Technical Report"},{"key":"ref27","year":"2015","journal-title":"MediaWiki Extension Graph"},{"key":"ref3","doi-asserted-by":"publisher","DOI":"10.1109/VISUAL.1995.480821"},{"key":"ref6","doi-asserted-by":"publisher","DOI":"10.1145/2501654.2501666"},{"key":"ref29","doi-asserted-by":"publisher","DOI":"10.1145/120782.120805"},{"key":"ref5","doi-asserted-by":"publisher","DOI":"10.1145/335191.335420"},{"key":"ref8","doi-asserted-by":"publisher","DOI":"10.1007/3-540-44617-6_31"},{"key":"ref7","article-title":"Dynamic generation and prefetching of data chunks for exploratory visualization","author":"battle","year":"0","journal-title":"IEEE InfoVis Posters Track 2014"},{"key":"ref2","doi-asserted-by":"publisher","DOI":"10.1007/s00778-003-0095-z"},{"key":"ref9","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2009.174"},{"key":"ref1","first-page":"277","article-title":"The design of the borealis stream processing engine","volume":"5","author":"abadi","year":"2005","journal-title":"CIDR"},{"key":"ref20","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2010.144"},{"key":"ref22","first-page":"93970n","article-title":"Reactive data visualizations","author":"kelleher","year":"2015","journal-title":"IS&T/SPIE Electronic Imaging"},{"key":"ref21","year":"2015","journal-title":"The IPython Notebook"},{"key":"ref24","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2013.179"},{"key":"ref41","doi-asserted-by":"crossref","first-page":"1224","DOI":"10.1109/TVCG.2007.70515","article-title":"Toward a deeper understanding of the role of interaction in information visualization","volume":"13","author":"yi","year":"2007","journal-title":"IEEE Transactions on Visualization and Computer Graphics"},{"key":"ref23","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2014.2346250"},{"key":"ref26","doi-asserted-by":"crossref","first-page":"999","DOI":"10.1109/TVCG.2010.177","article-title":"Mental models, visual reasoning and interaction in information visualization: A top-down perspective","volume":"16","author":"liu","year":"2010","journal-title":"IEEE Trans Visualization & Comp Graphics"},{"key":"ref25","doi-asserted-by":"publisher","DOI":"10.1111/cgf.12129"}],"container-title":"IEEE Transactions on Visualization and Computer Graphics","original-title":[],"link":[{"URL":"http://xplorestaging.ieee.org/ielx7/2945/4359476/07192704.pdf?arnumber=7192704","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,8,13]],"date-time":"2023-08-13T04:31:02Z","timestamp":1691901062000},"score":1,"resource":{"primary":{"URL":"http://ieeexplore.ieee.org/document/7192704/"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2016,1,31]]},"references-count":41,"journal-issue":{"issue":"1"},"URL":"http://dx.doi.org/10.1109/TVCG.2015.2467091","relation":{},"ISSN":["1077-2626"],"subject":["Computer Graphics and Computer-Aided Design","Computer Vision and Pattern Recognition","Signal Processing","Software"],"container-title-short":"IEEE Trans. Visual. Comput. Graphics","published":{"date-parts":[[2016,1,31]]},"id":"doi:10.1109/TVCG.2015.2467091"},{"indexed":{"date-parts":[[2023,10,20]],"date-time":"2023-10-20T05:44:30Z","timestamp":1697780670598},"reference-count":31,"publisher":"Institute of Electrical and Electronics Engineers (IEEE)","issue":"1","license":[{"start":{"date-parts":[[2017,1,1]],"date-time":"2017-01-01T00:00:00Z","timestamp":1483228800000},"content-version":"vor","delay-in-days":0,"URL":"https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html"}],"funder":[{"DOI":"10.13039/501100001744","name":"Intel Big Data ISTC","doi-asserted-by":"publisher"},{"DOI":"10.13039/100000936","name":"Moore Foundation","doi-asserted-by":"crossref"},{"DOI":"10.13039/100000185","name":"DARPA XDATA","doi-asserted-by":"publisher"}],"content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2017,1]]},"DOI":"10.1109/tvcg.2016.2599030","type":"journal-article","created":{"date-parts":[[2016,8,10]],"date-time":"2016-08-10T19:59:53Z","timestamp":1470859193000},"page":"341-350","source":"Crossref","is-referenced-by-count":382,"title":"Vega-Lite: A Grammar of Interactive Graphics","prefix":"10.1109","volume":"23","author":[{"given":"Arvind","family":"Satyanarayan","sequence":"first","affiliation":[]},{"given":"Dominik","family":"Moritz","sequence":"additional","affiliation":[]},{"given":"Kanit","family":"Wongsuphasawat","sequence":"additional","affiliation":[]},{"given":"Jeffrey","family":"Heer","sequence":"additional","affiliation":[]}],"member":"263","reference":[{"key":"ref31","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2007.70515"},{"key":"ref30","article-title":"Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations","author":"wongsuphasawat","year":"2015","journal-title":"IEEE Trans Visualization & Comp Graphics"},{"key":"ref10","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2014.2346260"},{"key":"ref11","doi-asserted-by":"publisher","DOI":"10.1145/1054972.1055012"},{"key":"ref12","doi-asserted-by":"publisher","DOI":"10.1145/1357054.1357203"},{"key":"ref13","doi-asserted-by":"publisher","DOI":"10.1145/2133806.2133821"},{"key":"ref14","doi-asserted-by":"publisher","DOI":"10.1145/1622176.1622217"},{"key":"ref15","doi-asserted-by":"publisher","DOI":"10.1145/253262.253335"},{"key":"ref16","doi-asserted-by":"crossref","first-page":"110","DOI":"10.1145/22949.22950","article-title":"Automating the design of graphical presentations of relational information","volume":"5","author":"mackinlay","year":"1986","journal-title":"ACM Transactions on Graphics (TOG)"},{"key":"ref17","doi-asserted-by":"publisher","DOI":"10.1016/B978-155860915-0/50043-3"},{"key":"ref18","doi-asserted-by":"publisher","DOI":"10.1109/VL.1998.706159"},{"key":"ref19","doi-asserted-by":"publisher","DOI":"10.1057/ivs.2009.22"},{"key":"ref28","doi-asserted-by":"publisher","DOI":"10.1016/S0167-9473(02)00288-8"},{"key":"ref4","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2011.185"},{"key":"ref27","doi-asserted-by":"publisher","DOI":"10.1198/jcgs.2009.07098"},{"key":"ref3","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2009.174"},{"key":"ref6","first-page":"181","article-title":"Compound brushing [dynamic data visualization]","author":"chen","year":"0","journal-title":"Information Visualization 2003 INFOVIS 2003 IEEE Symposium on"},{"key":"ref29","author":"wilkinson","year":"2005","journal-title":"The Grammar of Graphics"},{"key":"ref5","year":"2016","journal-title":"Brunel Visualization"},{"key":"ref8","doi-asserted-by":"publisher","DOI":"10.2307/2288400"},{"key":"ref7","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2015.2414454"},{"key":"ref2","author":"bertin","year":"1983","journal-title":"Semiology of Graphics Diagrams Networks Maps"},{"key":"ref9","doi-asserted-by":"publisher","DOI":"10.1145/263407.263545"},{"key":"ref1","first-page":"123","article-title":"The visual design and control of trellis display","volume":"5","author":"becker","year":"1996","journal-title":"Journal of Computational and Graphical Statistics"},{"key":"ref20","year":"2016"},{"key":"ref22","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2015.2467091"},{"key":"ref21","year":"2016"},{"key":"ref24","doi-asserted-by":"publisher","DOI":"10.1109/2945.981851"},{"key":"ref23","doi-asserted-by":"publisher","DOI":"10.1145/2642918.2647360"},{"key":"ref26","year":"2016"},{"key":"ref25","doi-asserted-by":"publisher","DOI":"10.1016/S0167-9473(02)00286-4"}],"container-title":"IEEE Transactions on Visualization and Computer Graphics","original-title":[],"link":[{"URL":"http://xplorestaging.ieee.org/ielx7/2945/7747554/07539624.pdf?arnumber=7539624","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2022,1,12]],"date-time":"2022-01-12T16:38:27Z","timestamp":1642005507000},"score":1,"resource":{"primary":{"URL":"http://ieeexplore.ieee.org/document/7539624/"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2017,1]]},"references-count":31,"journal-issue":{"issue":"1"},"URL":"http://dx.doi.org/10.1109/TVCG.2016.2599030","relation":{},"ISSN":["1077-2626"],"subject":["Computer Graphics and Computer-Aided Design","Computer Vision and Pattern Recognition","Signal Processing","Software"],"container-title-short":"IEEE Trans. Visual. Comput. Graphics","published":{"date-parts":[[2017,1]]},"id":"doi:10.1109/TVCG.2016.2599030"},{"indexed":{"date-parts":[[2023,10,19]],"date-time":"2023-10-19T14:22:17Z","timestamp":1697725337792},"publisher-location":"New York, NY, USA","reference-count":31,"publisher":"ACM","content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2011,10,16]]},"DOI":"10.1145/2047196.2047247","type":"proceedings-article","created":{"date-parts":[[2011,10,18]],"date-time":"2011-10-18T13:02:00Z","timestamp":1318942920000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":156,"title":"ReVision","prefix":"10.1145","author":[{"given":"Manolis","family":"Savva","sequence":"first","affiliation":[{"name":"Stanford University, Palo Alto, CA, USA"}]},{"given":"Nicholas","family":"Kong","sequence":"additional","affiliation":[{"name":"University of California, Berkeley, Berkeley, CA, USA"}]},{"given":"Arti","family":"Chhajta","sequence":"additional","affiliation":[{"name":"Stanford University, Palo Alto, CA, USA"}]},{"given":"Li","family":"Fei-Fei","sequence":"additional","affiliation":[{"name":"Stanford University, Palo Alto, CA, USA"}]},{"given":"Maneesh","family":"Agrawala","sequence":"additional","affiliation":[{"name":"University of California, Berkeley, Berkeley, CA, USA"}]},{"given":"Jeffrey","family":"Heer","sequence":"additional","affiliation":[{"name":"Stanford University, Palo Alto, CA, USA"}]}],"member":"320","published-online":{"date-parts":[[2011,10,16]]},"reference":[{"key":"e_1_3_2_1_1_1","doi-asserted-by":"publisher","DOI":"10.1007/11744085_40"},{"key":"e_1_3_2_1_2_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2009.174"},{"key":"e_1_3_2_1_3_1","volume-title":"Tech. Rep","author":"Boutell M.","year":"2002"},{"key":"e_1_3_2_1_4_1","doi-asserted-by":"publisher","DOI":"10.1016/j.patcog.2003.06.001"},{"key":"e_1_3_2_1_5_1","unstructured":"W. S. Cleveland. Visualizing Data. Hobart Press 1993.   W. S. Cleveland. Visualizing Data. Hobart Press 1993."},{"key":"e_1_3_2_1_6_1","doi-asserted-by":"publisher","DOI":"10.1080/01621459.1984.10478080"},{"key":"e_1_3_2_1_7_1","volume-title":"Advances in Neural Information Processing Systems","author":"Coates A.","year":"2010"},{"key":"e_1_3_2_1_8_1","doi-asserted-by":"publisher","DOI":"10.1023/A:1022627411411"},{"key":"e_1_3_2_1_9_1","doi-asserted-by":"publisher","DOI":"10.1109/CVPR.2005.177"},{"key":"e_1_3_2_1_10_1","doi-asserted-by":"publisher","DOI":"10.1023/B:VISI.0000029664.99615.94"},{"key":"e_1_3_2_1_11_1","volume-title":"Analytics Press","author":"Few S.","year":"2004"},{"key":"e_1_3_2_1_12_1","doi-asserted-by":"publisher","DOI":"10.1145/358669.358692"},{"key":"e_1_3_2_1_13_1","doi-asserted-by":"publisher","DOI":"10.1109/34.765658"},{"key":"e_1_3_2_1_14_1","first-page":"57","volume-title":"In Proc. of the New Zealand Computer Science Research Students Conference","author":"Garner S. R.","year":"1995"},{"key":"e_1_3_2_1_15_1","doi-asserted-by":"publisher","DOI":"10.1179/000870403235002042"},{"key":"e_1_3_2_1_16_1","doi-asserted-by":"publisher","DOI":"10.1145/1753326.1753357"},{"key":"e_1_3_2_1_17_1","doi-asserted-by":"publisher","DOI":"10.1145/1284420.1284427"},{"key":"e_1_3_2_1_18_1","series-title":"Lecture Notes in Computer Science","doi-asserted-by":"crossref","first-page":"87","DOI":"10.1007/978-3-540-25977-0_8","volume-title":"J. Lladós and Y.-B","author":"Huang W.","year":"2004"},{"key":"e_1_3_2_1_19_1","first-page":"521","volume-title":"Document Analysis & Recognition (ICDAR)","author":"Liu R.","year":"2007"},{"key":"e_1_3_2_1_20_1","doi-asserted-by":"publisher","DOI":"10.1145/22949.22950"},{"key":"e_1_3_2_1_21_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2007.70594"},{"key":"e_1_3_2_1_22_1","first-page":"85","volume-title":"Classifying Computer Generated Charts. In Content-Based Multimedia Indexing Workshop","author":"Prasad V.","year":"2007"},{"key":"e_1_3_2_1_23_1","doi-asserted-by":"publisher","DOI":"10.1007/11767978_21"},{"key":"e_1_3_2_1_24_1","doi-asserted-by":"publisher","DOI":"10.1080/01621459.1987.10478448"},{"key":"e_1_3_2_1_25_1","doi-asserted-by":"publisher","DOI":"10.1109/2945.981851"},{"key":"e_1_3_2_1_26_1","volume-title":"Peters","author":"Stone M.","year":"2003"},{"key":"e_1_3_2_1_27_1","doi-asserted-by":"publisher","DOI":"10.5555/938978.939190"},{"key":"e_1_3_2_1_28_1","volume-title":"Graphics Press","author":"Tufte E. R.","year":"1983"},{"key":"e_1_3_2_1_29_1","doi-asserted-by":"publisher","DOI":"10.1145/1290082.1290111"},{"key":"e_1_3_2_1_30_1","series-title":"Lecture Notes in Computer Science","doi-asserted-by":"crossref","first-page":"324","DOI":"10.1007/11669487_29","volume-title":"Document Analysis Systems VII","author":"Yang L.","year":"2006"},{"key":"e_1_3_2_1_31_1","first-page":"605","volume-title":"Intl Conf on Image Processing","author":"Zhou Y. P.","year":"2000"}],"event":"UIST '11: The 24th Annual ACM Symposium on User Interface Software and Technology","container-title":"Proceedings of the 24th annual ACM symposium on User interface software and technology","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/2047196.2047247","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,1,6]],"date-time":"2023-01-06T05:20:43Z","timestamp":1672982443000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/2047196.2047247"}},"subtitle":["automated classification, analysis and redesign of chart images"],"short-title":[],"issued":{"date-parts":[[2011,10,16]]},"references-count":31,"alternative-id":["10.1145/2047196.2047247","10.1145/2047196"],"URL":"http://dx.doi.org/10.1145/2047196.2047247","relation":{},"published":{"date-parts":[[2011,10,16]]},"assertion":[{"value":"2011-10-16","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/2047196.2047247"},{"indexed":{"date-parts":[[2023,10,12]],"date-time":"2023-10-12T02:59:48Z","timestamp":1697079588098},"reference-count":39,"publisher":"MIT Press - Journals","license":[{"start":{"date-parts":[[2022,4,7]],"date-time":"2022-04-07T00:00:00Z","timestamp":1649289600000},"content-version":"vor","delay-in-days":96,"URL":"https://creativecommons.org/licenses/by/4.0/"}],"content-domain":{"domain":["direct.mit.edu"],"crossmark-restriction":true},"published-print":{"date-parts":[[2022,4,6]]},"abstract":"<jats:title>Abstract</jats:title>\n               <jats:p>Accurately extracting structured content from PDFs is a critical first step for NLP over scientific papers. Recent work has improved extraction accuracy by incorporating elementary layout information, for example, each token’s 2D position on the page, into language model pretraining. We introduce new methods that explicitly model VIsual LAyout (VILA) groups, that is, text lines or text blocks, to further improve performance. In our I-VILA approach, we show that simply inserting special tokens denoting layout group boundaries into model inputs can lead to a 1.9% Macro F1 improvement in token classification. In the H-VILA approach, we show that hierarchical encoding of layout-groups can result in up to 47% inference time reduction with less than 0.8% Macro F1 loss. Unlike prior layout-aware approaches, our methods do not require expensive additional pretraining, only fine-tuning, which we show can reduce training cost by up to 95%. Experiments are conducted on a newly curated evaluation suite, S2-VLUE, that unifies existing automatically labeled datasets and includes a new dataset of manual annotations covering diverse papers from 19 scientific disciplines. Pre-trained weights, benchmark datasets, and source code are available at https://github.com/allenai/VILA.</jats:p>","DOI":"10.1162/tacl_a_00466","type":"journal-article","created":{"date-parts":[[2022,4,7]],"date-time":"2022-04-07T14:23:06Z","timestamp":1649341386000},"page":"376-392","update-policy":"http://dx.doi.org/10.1162/mitpressjournals.corrections.policy","source":"Crossref","is-referenced-by-count":6,"title":"VILA: Improving Structured Content Extraction from Scientific PDFs Using Visual Layout Groups","prefix":"10.1162","volume":"10","author":[{"given":"Zejiang","family":"Shen","sequence":"first","affiliation":[{"name":"Allen Institute for AI, USA. shannons@allenai.org"}]},{"given":"Kyle","family":"Lo","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, USA. kylel@allenai.org"}]},{"given":"Lucy Lu","family":"Wang","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, USA. lucyw@allenai.org"}]},{"given":"Bailey","family":"Kuehl","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, USA. baileyk@allenai.org"}]},{"given":"Daniel S.","family":"Weld","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, USA"},{"name":"University of Washington, USA. danw@allenai.org"}]},{"given":"Doug","family":"Downey","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, USA"},{"name":"Northwestern University, USA. dougd@allenai.org"}]}],"member":"281","published-online":{"date-parts":[[2022,4,6]]},"reference":[{"key":"2022040714222640000_bib1","article-title":"Grobid","year":"2008–2021"},{"key":"2022040714222640000_bib2","article-title":"ICDAR2021 competition on mathematical formula detection","year":"2021"},{"key":"2022040714222640000_bib3","doi-asserted-by":"publisher","first-page":"84","DOI":"10.18653/v1/N18-3011","article-title":"Construction of the literature graph in semantic scholar","volume-title":"Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)","author":"Ammar","year":"2018"},{"key":"2022040714222640000_bib4","first-page":"12526","article-title":"Segatron: Segment-aware transformer for language modeling and understanding","volume-title":"Proceedings of the AAAI Conference on Artificial Intelligence","author":"He","year":"2021"},{"key":"2022040714222640000_bib5","doi-asserted-by":"publisher","first-page":"3615","DOI":"10.18653/v1/D19-1371","article-title":"SciBERT: A pretrained language model for scientific text","volume-title":"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","author":"Iz","year":"2019"},{"issue":"1","key":"2022040714222640000_bib6","doi-asserted-by":"publisher","first-page":"5","DOI":"10.1023/A:1010933404324","article-title":"Random forests","volume":"45","author":"Breiman","year":"2001","journal-title":"Machine Learning"},{"key":"2022040714222640000_bib7","first-page":"4171","article-title":"BERT: Pre-training of deep bidirectional transformers for language understanding","volume-title":"Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)","author":"Devlin","year":"2019"},{"key":"2022040714222640000_bib8","first-page":"2961","article-title":"Mask R-CNN","volume-title":"Proceedings of the IEEE international conference on computer vision","author":"He","year":"2017"},{"issue":"8","key":"2022040714222640000_bib9","doi-asserted-by":"publisher","first-page":"1735","DOI":"10.1162/neco.1997.9.8.1735","article-title":"Long short-term memory","volume":"9","author":"Hochreiter","year":"1997","journal-title":"Neural Computation"},{"key":"2022040714222640000_bib10","article-title":"Adam: A method for stochastic optimization","volume-title":"3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings","author":"Kingma","year":"2015"},{"key":"2022040714222640000_bib11","first-page":"282","article-title":"Conditional random fields: Probabilistic models for segmenting and labeling sequence data","volume-title":"Proceedings of the Eighteenth International Conference on Machine Learning (ICML 2001), Williams College, Williamstown, MA, USA, June 28 – July 1, 2001","author":"Lafferty","year":"2001"},{"key":"2022040714222640000_bib12","doi-asserted-by":"crossref","first-page":"1551","DOI":"10.18653/v1/2020.emnlp-main.120","article-title":"SLM: Learning a discourse language representation with sentence unshuffling","volume-title":"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","author":"Lee","year":"2020"},{"key":"2022040714222640000_bib13","first-page":"949","article-title":"DocBank: A benchmark dataset for document layout analysis","volume-title":"Proceedings of the 28th International Conference on Computational Linguistics, COLING","author":"Li","year":"2020"},{"key":"2022040714222640000_bib14","first-page":"5652","article-title":"SelfDoc: Self-supervised document representation learning","volume-title":"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition","author":"Li","year":"2021"},{"key":"2022040714222640000_bib15","article-title":"RoBERTa: A robustly optimized BERT pretraining approach","volume":"cs.CL/1907.11692v1","author":"Liu","year":"2019","journal-title":"CoRR"},{"key":"2022040714222640000_bib16","first-page":"15137","article-title":"Robust PDF document conversion using recurrent neural networks","volume-title":"Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021","author":"Livathinos","year":"2021"},{"key":"2022040714222640000_bib17","doi-asserted-by":"crossref","first-page":"4969","DOI":"10.18653/v1/2020.acl-main.447","article-title":"S2ORC: The semantic scholar open research corpus","volume-title":"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","author":"Lo","year":"2020"},{"key":"2022040714222640000_bib18","article-title":"Decoupled weight decay regularization","volume-title":"7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6–9, 2019","author":"Loshchilov","year":"2019"},{"key":"2022040714222640000_bib19","article-title":"Mixed precision training","volume-title":"6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings","author":"Micikevicius","year":"2018"},{"key":"2022040714222640000_bib20","doi-asserted-by":"publisher","first-page":"258","DOI":"10.18653/v1/2021.acl-demo.31","article-title":"PAWLS: PDF annotation with labels and structure","volume-title":"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations","author":"Neumann","year":"2021"},{"key":"2022040714222640000_bib21","article-title":"PyTorch: An imperative style, high-performance deep learning library","volume-title":"Advances in Neural Information Processing Systems","author":"Paszke","year":"2019"},{"key":"2022040714222640000_bib22","first-page":"91","article-title":"Faster R-CNN: Towards real-time object detection with region proposal networks","volume":"28","author":"Ren","year":"2015","journal-title":"Advances in Neural Information Processing Systems"},{"key":"2022040714222640000_bib23","doi-asserted-by":"publisher","first-page":"110","DOI":"10.18653/v1/2020.nlposs-1.15","article-title":"PySBD: Pragmatic sentence boundary disambiguation","volume-title":"Proceedings of Second Workshop for NLP Open Source Software (NLP-OSS)","author":"Sadvilkar","year":"2020"},{"key":"2022040714222640000_bib24","article-title":"Distilbert, a distilled version of BERT: Smaller, faster, cheaper and lighter","author":"Sanh","year":"2019","journal-title":"CoRR"},{"issue":"12","key":"2022040714222640000_bib25","doi-asserted-by":"publisher","first-page":"54","DOI":"10.1145/3381831","article-title":"Green AI","volume":"63","author":"Schwartz","year":"2020","journal-title":"Communications of the ACM"},{"key":"2022040714222640000_bib26","doi-asserted-by":"publisher","first-page":"131","DOI":"10.1007/978-3-030-86549-8_9","article-title":"LayoutParser: A unified toolkit for deep learning based document image analysis","volume-title":"Document Analysis and Recognition – ICDAR 2021","author":"Shen","year":"2021"},{"key":"2022040714222640000_bib27","doi-asserted-by":"publisher","first-page":"223","DOI":"10.1145/3197026.3197040","article-title":"Extracting scientific figures with distantly supervised neural networks","volume-title":"Proceedings of the 18th ACM/IEEE on joint conference on digital libraries","author":"Siegel","year":"2018"},{"key":"2022040714222640000_bib28","doi-asserted-by":"publisher","first-page":"774","DOI":"10.1145/3219819.3219834","article-title":"Corpus conversion service: A machine learning platform to ingest documents at scale","volume-title":"Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","author":"Staar","year":"2018"},{"issue":"11/12","key":"2022040714222640000_bib29","doi-asserted-by":"publisher","DOI":"10.1045/november14-tkaczyk","article-title":"GROTOAP2 — the methodology of creating a large ground truth dataset of scientific articles","volume":"20","author":"Tkaczyk","year":"2014","journal-title":"D-Lib Magazine"},{"issue":"4","key":"2022040714222640000_bib30","doi-asserted-by":"publisher","first-page":"317","DOI":"10.1007/s10032-015-0249-8","article-title":"CERMINE: Automatic extraction of structured metadata from scientific literature","volume":"18","author":"Tkaczyk","year":"2015","journal-title":"International Journal on Document Analysis and Recognition (IJDAR)"},{"key":"2022040714222640000_bib31","article-title":"Attention is all you need","volume-title":"Advances in Neural Information Processing Systems","author":"Vaswani","year":"2017"},{"key":"2022040714222640000_bib32","article-title":"Improving the accessibility of scientific documents: Current state, user needs, and a system solution to enhance scientific PDF accessibility for blind and low vision users","author":"Wang","year":"2021","journal-title":"CoRR"},{"key":"2022040714222640000_bib33","article-title":"CORD-19: The covid-19 open research dataset","author":"Wang","year":"2020","journal-title":"CoRR"},{"key":"2022040714222640000_bib34","doi-asserted-by":"publisher","first-page":"38","DOI":"10.18653/v1/2020.emnlp-demos.6","article-title":"Transformers: State-of-the-art natural language processing","volume-title":"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations","author":"Wolf","year":"2020"},{"key":"2022040714222640000_bib35","first-page":"1192","article-title":"Layoutlm: Pre-training of text and layout for document image understanding","volume-title":"KDD ’20: The 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event, CA, USA, August 23–27, 2020","author":"Yiheng","year":"2020"},{"key":"2022040714222640000_bib36","first-page":"2579","article-title":"LayoutLMv2: Multi-modal pre-training for visually-rich document understanding","volume-title":"Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1–6, 2021","author":"Yang","year":"2021"},{"key":"2022040714222640000_bib37","doi-asserted-by":"publisher","first-page":"1725","DOI":"10.1145/3340531.3411908","article-title":"Beyond 512 tokens: Siamese multi-depth transformer-based hierarchical encoder for long-form document matching","volume-title":"Proceedings of the 29th ACM International Conference on Information & Knowledge Management","author":"Yang","year":"2020"},{"key":"2022040714222640000_bib38","doi-asserted-by":"publisher","first-page":"5059","DOI":"10.18653/v1/P19-1499","article-title":"HIBERT: Document level pre-training of hierarchical bidirectional transformers for document summarization","volume-title":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","author":"Zhang","year":"2019"},{"key":"2022040714222640000_bib39","doi-asserted-by":"publisher","first-page":"1015","DOI":"10.1109/ICDAR.2019.00166","article-title":"PubLayNet: Largest dataset ever for document layout analysis","volume-title":"2019 International Conference on Document Analysis and Recognition (ICDAR)","author":"Zhong","year":"2019"}],"container-title":"Transactions of the Association for Computational Linguistics","original-title":[],"language":"en","link":[{"URL":"https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00466/2006993/tacl_a_00466.pdf","content-type":"application/pdf","content-version":"vor","intended-application":"syndication"},{"URL":"https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00466/2006993/tacl_a_00466.pdf","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2022,4,7]],"date-time":"2022-04-07T14:23:34Z","timestamp":1649341414000},"score":1,"resource":{"primary":{"URL":"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00466/110438/VILA-Improving-Structured-Content-Extraction-from"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2022]]},"references-count":39,"URL":"http://dx.doi.org/10.1162/tacl_a_00466","relation":{},"ISSN":["2307-387X"],"subject":["Artificial Intelligence","Computer Science Applications","Linguistics and Language","Human-Computer Interaction","Communication"],"published-other":{"date-parts":[[2022]]},"published":{"date-parts":[[2022]]},"id":"doi:10.1162/tacl_a_00466"},{"indexed":{"date-parts":[[2023,10,12]],"date-time":"2023-10-12T02:54:21Z","timestamp":1697079261069},"publisher-location":"New York, NY, USA","reference-count":57,"publisher":"ACM","content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2021,5,6]]},"DOI":"10.1145/3411764.3445354","type":"proceedings-article","created":{"date-parts":[[2021,5,8]],"date-time":"2021-05-08T04:08:49Z","timestamp":1620446929000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":17,"title":"Leveraging Text-Chart Links to Support Authoring of Data-Driven Articles with VizFlow","prefix":"10.1145","author":[{"given":"Nicole","family":"Sultanum","sequence":"first","affiliation":[{"name":"University of Toronto, Canada"}]},{"given":"Fanny","family":"Chevalier","sequence":"additional","affiliation":[{"name":"University of Toronto, Canada, Canada"}]},{"given":"Zoya","family":"Bylinskii","sequence":"additional","affiliation":[{"name":"Creative Intelligence Lab Adobe Research, United States"}]},{"given":"Zhicheng","family":"Liu","sequence":"additional","affiliation":[{"name":"University of Maryland, United States"}]}],"member":"320","published-online":{"date-parts":[[2021,5,7]]},"reference":[{"key":"e_1_3_2_2_1_1","unstructured":"Adobe. 2020. Adobe Spark. https://spark.adobe.com/  Adobe. 2020. Adobe Spark. https://spark.adobe.com/"},{"key":"e_1_3_2_2_2_1","volume-title":"Authoring data-driven videos with dataclips","author":"Amini Fereshteh","year":"2016","unstructured":"Fereshteh Amini , Nathalie Henry Riche , Bongshin Lee , Andres Monroy-Hernandez , and Pourang Irani . 2016. Authoring data-driven videos with dataclips . IEEE transactions on visualization and computer graphics 23, 1( 2016 ), 501–510. Fereshteh Amini, Nathalie Henry Riche, Bongshin Lee, Andres Monroy-Hernandez, and Pourang Irani. 2016. Authoring data-driven videos with dataclips. IEEE transactions on visualization and computer graphics 23, 1(2016), 501–510."},{"key":"e_1_3_2_2_3_1","volume-title":"Data-Driven Storytelling","author":"Bach Benjamin","unstructured":"Benjamin Bach , D Stefaner , Jeremy Boy , Steven Drucker , Lyn Bartram , Jo Wood , Paolo Ciuccarelli , Yuri Engelhardt , Ulrike Koeppen , and Barbara Tversky . 2018. Narrative design patterns for data-driven storytelling . In Data-Driven Storytelling . CRC Press , Boca Raton, FL, USA , 107–133. Benjamin Bach, D Stefaner, Jeremy Boy, Steven Drucker, Lyn Bartram, Jo Wood, Paolo Ciuccarelli, Yuri Engelhardt, Ulrike Koeppen, and Barbara Tversky. 2018. Narrative design patterns for data-driven storytelling. In Data-Driven Storytelling. CRC Press, Boca Raton, FL, USA, 107–133."},{"key":"e_1_3_2_2_4_1","volume-title":"Elastic documents: Coupling text and tables through contextual visualizations for enhanced document reading","author":"Badam Sriram Karthik","year":"2018","unstructured":"Sriram Karthik Badam , Zhicheng Liu , and Niklas Elmqvist . 2018. Elastic documents: Coupling text and tables through contextual visualizations for enhanced document reading . IEEE transactions on visualization and computer graphics 25, 1( 2018 ), 661–671. Sriram Karthik Badam, Zhicheng Liu, and Niklas Elmqvist. 2018. Elastic documents: Coupling text and tables through contextual visualizations for enhanced document reading. IEEE transactions on visualization and computer graphics 25, 1(2018), 661–671."},{"key":"e_1_3_2_2_5_1","doi-asserted-by":"publisher","DOI":"10.1145/3382507.3418884"},{"key":"e_1_3_2_2_6_1","doi-asserted-by":"publisher","DOI":"10.1145/3173574.3174168"},{"key":"e_1_3_2_2_7_1","unstructured":"Mike Bostock. 2014. How to Scroll. https://bost.ocks.org/mike/scroll/  Mike Bostock. 2014. How to Scroll. https://bost.ocks.org/mike/scroll/"},{"key":"e_1_3_2_2_8_1","volume-title":"Usability evaluation in industry","author":"Brooke John","unstructured":"John Brooke . 1996. Usability evaluation in industry . CRC press , Boca Raton, FL, USA , Chapter SUS: a “quick and dirty” usability scale, 189. John Brooke. 1996. Usability evaluation in industry. CRC press, Boca Raton, FL, USA, Chapter SUS: a “quick and dirty” usability scale, 189."},{"key":"e_1_3_2_2_9_1","doi-asserted-by":"publisher","DOI":"10.1109/WACV45572.2020.9093269"},{"key":"e_1_3_2_2_10_1","volume-title":"Supporting story synthesis: Bridging the gap between visual analytics and storytelling","author":"Chen Siming","year":"2018","unstructured":"Siming Chen , Jie Li , Gennady Andrienko , Natalia Andrienko , Yun Wang , Phong  H Nguyen , and Cagatay Turkay . 2018. Supporting story synthesis: Bridging the gap between visual analytics and storytelling . IEEE transactions on visualization and computer graphics 26, 7( 2018 ), 2499–2516. Siming Chen, Jie Li, Gennady Andrienko, Natalia Andrienko, Yun Wang, Phong H Nguyen, and Cagatay Turkay. 2018. Supporting story synthesis: Bridging the gap between visual analytics and storytelling. IEEE transactions on visualization and computer graphics 26, 7(2018), 2499–2516."},{"key":"e_1_3_2_2_11_1","volume-title":"Data-Driven Storytelling.","author":"Chevalier Fanny","unstructured":"Fanny Chevalier , Melanie Tory , Bongshin Lee , Jarke van Wijk , Giuseppe Santucci , Marian Dörk , and Jessica Hullman . 2018. From Analysis to Communication: Supporting the Lifecycle of a Story . In Data-Driven Storytelling. AK Peters/CRC Press , Boca Raton, FL, USA , 169–202. Fanny Chevalier, Melanie Tory, Bongshin Lee, Jarke van Wijk, Giuseppe Santucci, Marian Dörk, and Jessica Hullman. 2018. From Analysis to Communication: Supporting the Lifecycle of a Story. In Data-Driven Storytelling. AK Peters/CRC Press, Boca Raton, FL, USA, 169–202."},{"key":"e_1_3_2_2_12_1","doi-asserted-by":"publisher","DOI":"10.1145/3242587.3242600"},{"key":"e_1_3_2_2_13_1","doi-asserted-by":"publisher","DOI":"10.1145/3290605.3300295"},{"key":"e_1_3_2_2_14_1","doi-asserted-by":"publisher","DOI":"10.1145/1391107.1391109"},{"key":"e_1_3_2_2_15_1","unstructured":"Honkytonk Films. 2020. Klynt. http://www.klynt.net/  Honkytonk Films. 2020. Klynt. http://www.klynt.net/"},{"key":"e_1_3_2_2_16_1","volume-title":"The Story. Thane & Prose","author":"Garcia Mario","unstructured":"Mario Garcia . 2019. The Story. Thane & Prose , New York, NY, USA . Mario Garcia. 2019. The Story. Thane & Prose, New York, NY, USA."},{"key":"e_1_3_2_2_17_1","doi-asserted-by":"publisher","DOI":"10.1080/21670811.2018.1488598"},{"key":"e_1_3_2_2_18_1","doi-asserted-by":"publisher","DOI":"10.1109/ICCV.2017.322"},{"key":"e_1_3_2_2_19_1","doi-asserted-by":"publisher","DOI":"10.1145/3313831.3376777"},{"key":"e_1_3_2_2_20_1","doi-asserted-by":"publisher","DOI":"10.23915/distill.00028"},{"key":"e_1_3_2_2_21_1","unstructured":"Observable HQ. 2020. Observable. https://observablehq.com/  Observable HQ. 2020. Observable. https://observablehq.com/"},{"key":"e_1_3_2_2_22_1","doi-asserted-by":"publisher","DOI":"10.1145/3242587.3242617"},{"key":"e_1_3_2_2_23_1","doi-asserted-by":"publisher","DOI":"10.1145/3290605.3300335"},{"key":"e_1_3_2_2_24_1","doi-asserted-by":"publisher","DOI":"10.1111/cgf.13207"},{"key":"e_1_3_2_2_25_1","doi-asserted-by":"publisher","DOI":"10.1145/2556288.2557241"},{"key":"e_1_3_2_2_26_1","unstructured":"Robert Kosara. 2016. The scrollytelling scourge. https://eagereyes.org/blog/2016/the-scrollytelling-scourge  Robert Kosara. 2016. The scrollytelling scourge. https://eagereyes.org/blog/2016/the-scrollytelling-scourge"},{"key":"e_1_3_2_2_27_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2019.2958540"},{"key":"e_1_3_2_2_28_1","volume-title":"Gaze-Driven Links for Magazine Style Narrative Visualizations. In 2020 IEEE Visualization Conference (VIS). IEEE","author":"Lallé Sébastien","year":"2020","unstructured":"Sébastien Lallé , Tiffany Wu , and Cristina Conati . 2020 . Gaze-Driven Links for Magazine Style Narrative Visualizations. In 2020 IEEE Visualization Conference (VIS). IEEE , Salt Lake City, UT, USA, 1–4. Sébastien Lallé, Tiffany Wu, and Cristina Conati. 2020. Gaze-Driven Links for Magazine Style Narrative Visualizations. In 2020 IEEE Visualization Conference (VIS). IEEE, Salt Lake City, UT, USA, 1–4."},{"key":"e_1_3_2_2_29_1","volume-title":"EuroVis (Short Papers)","author":"Latif Shahid","unstructured":"Shahid Latif , Diao Liu , and Fabian Beck . 2018. Exploring Interactive Linking Between Text and Visualization . In EuroVis (Short Papers) . IEEE, Brno, Czech Republic , 91–94. Shahid Latif, Diao Liu, and Fabian Beck. 2018. Exploring Interactive Linking Between Text and Visualization. In EuroVis (Short Papers). IEEE, Brno, Czech Republic, 91–94."},{"key":"e_1_3_2_2_30_1","volume-title":"Proc. Eurographics Conf. Visualization. IEEE","author":"Latif Shahid","year":"2019","unstructured":"Shahid Latif , Kaidie Su , and Fabian Beck . 2019 . Authoring Combined Textual and Visual Descriptions of Graph Data . In Proc. Eurographics Conf. Visualization. IEEE , Porto, Portugal, 1–5. Shahid Latif, Kaidie Su, and Fabian Beck. 2019. Authoring Combined Textual and Visual Descriptions of Graph Data. In Proc. Eurographics Conf. Visualization. IEEE, Porto, Portugal, 1–5."},{"key":"e_1_3_2_2_31_1","volume-title":"More than telling a story: Transforming data into visually shared stories","author":"Lee Bongshin","year":"2015","unstructured":"Bongshin Lee , Nathalie Henry Riche , Petra Isenberg , and Sheelagh Carpendale . 2015. More than telling a story: Transforming data into visually shared stories . IEEE computer graphics and applications 35, 5 ( 2015 ), 84–90. Bongshin Lee, Nathalie Henry Riche, Petra Isenberg, and Sheelagh Carpendale. 2015. More than telling a story: Transforming data into visually shared stories. IEEE computer graphics and applications 35, 5 (2015), 84–90."},{"key":"e_1_3_2_2_32_1","doi-asserted-by":"publisher","DOI":"10.1145/3173574.3173697"},{"key":"e_1_3_2_2_33_1","doi-asserted-by":"publisher","DOI":"10.1111/cgf.13195"},{"key":"e_1_3_2_2_34_1","doi-asserted-by":"publisher","DOI":"10.1016/j.jvlc.2017.10.001"},{"key":"e_1_3_2_2_35_1","doi-asserted-by":"publisher","DOI":"10.1145/3172944.3173007"},{"key":"e_1_3_2_2_36_1","doi-asserted-by":"publisher","DOI":"10.1111/cgf.13193"},{"key":"e_1_3_2_2_37_1","doi-asserted-by":"publisher","DOI":"10.1111/cgf.12392"},{"key":"e_1_3_2_2_38_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2019.2934281"},{"key":"e_1_3_2_2_39_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2016.2599030"},{"key":"e_1_3_2_2_40_1","doi-asserted-by":"publisher","DOI":"10.1145/2047196.2047247"},{"key":"e_1_3_2_2_41_1","volume-title":"Narrative visualization: Telling stories with data","author":"Segel Edward","year":"2010","unstructured":"Edward Segel and Jeffrey Heer . 2010. Narrative visualization: Telling stories with data . IEEE transactions on visualization and computer graphics 16, 6( 2010 ), 1139–1148. Edward Segel and Jeffrey Heer. 2010. Narrative visualization: Telling stories with data. IEEE transactions on visualization and computer graphics 16, 6(2010), 1139–1148."},{"key":"e_1_3_2_2_42_1","doi-asserted-by":"publisher","DOI":"10.1109/iV.2018.00075"},{"key":"e_1_3_2_2_43_1","unstructured":"Bill Shander. 2020. The Past Present and Future of Scrollytelling. https://medium.com/nightingale/the-past-present-and-future-of-scrollytelling-10dd37dc1003  Bill Shander. 2020. The Past Present and Future of Scrollytelling. https://medium.com/nightingale/the-past-present-and-future-of-scrollytelling-10dd37dc1003"},{"key":"e_1_3_2_2_44_1","doi-asserted-by":"publisher","DOI":"10.1145/1323688.1323689"},{"key":"e_1_3_2_2_45_1","unstructured":"Shorthand. 2020. Shorthand a digital storytelling platform. https://shorthand.com/  Shorthand. 2020. Shorthand a digital storytelling platform. https://shorthand.com/"},{"key":"e_1_3_2_2_46_1","volume-title":"The international conference on e-technologies and business on the web (ebw2013)","author":"Siricharoen V","year":"2013","unstructured":"Waralak  V Siricharoen . 2013 . Infographics: the new communication tools in digital age . In The international conference on e-technologies and business on the web (ebw2013) . IEEE, Bangkok, Thailand, 169–174. Waralak V Siricharoen. 2013. Infographics: the new communication tools in digital age. In The international conference on e-technologies and business on the web (ebw2013). IEEE, Bangkok, Thailand, 169–174."},{"key":"e_1_3_2_2_47_1","volume-title":"Pageflow: Interactive multimedia storytelling with ease. https://www.pageflow.io/","author":"Solutions Codevise","year":"2020","unstructured":"Codevise Solutions . 2020 . Pageflow: Interactive multimedia storytelling with ease. https://www.pageflow.io/ Codevise Solutions. 2020. Pageflow: Interactive multimedia storytelling with ease. https://www.pageflow.io/"},{"key":"e_1_3_2_2_48_1","doi-asserted-by":"publisher","DOI":"10.1080/17512786.2017.1386583"},{"key":"e_1_3_2_2_49_1","doi-asserted-by":"publisher","DOI":"10.1109/TVCG.2011.183"},{"key":"e_1_3_2_2_50_1","volume-title":"Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories","author":"Stolper D.","unstructured":"Charles  D. Stolper , Bongshin Lee , N.  Henry Riche , and John Stasko . 2016. Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories . Technical Report. Microsoft Research , Washington, USA. Charles D. Stolper, Bongshin Lee, N. Henry Riche, and John Stasko. 2016. Emerging and recurring data-driven storytelling techniques: Analysis of a curated collection of recent stories. Technical Report. Microsoft Research, Washington, USA."},{"key":"e_1_3_2_2_51_1","unstructured":"Tableau. 2020. Stories. https://help.tableau.com/current/pro/desktop/en-us/stories.htm  Tableau. 2020. Stories. https://help.tableau.com/current/pro/desktop/en-us/stories.htm"},{"key":"e_1_3_2_2_52_1","unstructured":"Tableau. 2020. Tableau. https://www.tableau.com/  Tableau. 2020. Tableau. https://www.tableau.com/"},{"key":"e_1_3_2_2_53_1","doi-asserted-by":"publisher","DOI":"10.1145/3172944.3173009"},{"key":"e_1_3_2_2_54_1","doi-asserted-by":"publisher","DOI":"10.3390/info9030065"},{"key":"e_1_3_2_2_55_1","unstructured":"Archie Tse. 2016. Why we are doing fewer interactives. https://github.com/archietse/malofiej-2016/blob/master/tse-malofiej-2016-slides.pdf  Archie Tse. 2016. Why we are doing fewer interactives. https://github.com/archietse/malofiej-2016/blob/master/tse-malofiej-2016-slides.pdf"},{"key":"e_1_3_2_2_56_1","doi-asserted-by":"publisher","DOI":"10.1145/3173574.3173797"},{"key":"e_1_3_2_2_57_1","doi-asserted-by":"publisher","DOI":"10.1111/cgf.13719"}],"event":"CHI '21: CHI Conference on Human Factors in Computing Systems","container-title":"Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/3411764.3445354","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,1,8]],"date-time":"2023-01-08T07:22:33Z","timestamp":1673162553000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/3411764.3445354"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2021,5,6]]},"references-count":57,"alternative-id":["10.1145/3411764.3445354","10.1145/3411764"],"URL":"http://dx.doi.org/10.1145/3411764.3445354","relation":{},"published":{"date-parts":[[2021,5,6]]},"assertion":[{"value":"2021-05-07","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/3411764.3445354"},{"indexed":{"date-parts":[[2022,4,1]],"date-time":"2022-04-01T04:29:31Z","timestamp":1648787371681},"reference-count":0,"publisher":"Distill Working Group","issue":"7","content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2021,7,2]]},"DOI":"10.23915/distill.00031","type":"journal-article","created":{"date-parts":[[2021,7,2]],"date-time":"2021-07-02T22:52:16Z","timestamp":1625266336000},"source":"Crossref","is-referenced-by-count":0,"title":"Distill Hiatus","prefix":"10.23915","volume":"6","author":[{"given":"Editorial","family":"Team","sequence":"first","affiliation":[{"name":"Distill"}]}],"member":"9999","container-title":"Distill","original-title":[],"deposited":{"date-parts":[[2021,7,2]],"date-time":"2021-07-02T22:52:17Z","timestamp":1625266337000},"score":1,"resource":{"primary":{"URL":"https://distill.pub/2021/distill-hiatus"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2021,7,2]]},"references-count":0,"journal-issue":{"issue":"7"},"URL":"http://dx.doi.org/10.23915/distill.00031","relation":{},"ISSN":["2476-0757"],"subject":["General Materials Science"],"container-title-short":"Distill","published":{"date-parts":[[2021,7,2]]},"id":"doi:10.23915/distill.00031"},{"author":[{"family":"The Alliance for Networking Visual Culture"}],"type":"document","id":"scalar","citation-key":"scalar","issued":{"date-parts":[[2023]]},"title":"Scalar","URL":"https://scalar.me/anvc/scalar/"},{"author":[{"family":"Typst"}],"type":"document","id":"typst","citation-key":"typst","issued":{"date-parts":[[2023]]},"title":"Typst: Compose papers faster","URL":"https://typst.app/"},{"author":[{"given":"Bret","family":"Victor"}],"type":"document","id":"expexp","citation-key":"expexp","issued":{"date-parts":[[2011]]},"title":"Explorable Explanations","URL":"http://worrydream.com/ExplorableExplanations/"},{"indexed":{"date-parts":[[2023,8,17]],"date-time":"2023-08-17T20:54:00Z","timestamp":1692305640511},"publisher-location":"New York, NY, USA","reference-count":19,"publisher":"ACM","license":[{"start":{"date-parts":[[2022,10,17]],"date-time":"2022-10-17T00:00:00Z","timestamp":1665964800000},"content-version":"vor","delay-in-days":365,"URL":"http://www.acm.org/publications/policies/copyright_policy#Background"}],"funder":[{"DOI":"10.13039/100007812","name":"University of Washington","doi-asserted-by":"publisher","award":["WRF/Cable Professorship"]},{"name":"ONR","award":["N00014-18-1-2193"]},{"name":"NSF RAPID","award":["2040196"]}],"content-domain":{"domain":[],"crossmark-restriction":false},"published-print":{"date-parts":[[2021,10,17]]},"DOI":"10.1145/3441852.3476545","type":"proceedings-article","created":{"date-parts":[[2021,10,17]],"date-time":"2021-10-17T18:53:21Z","timestamp":1634496801000},"source":"Crossref","is-referenced-by-count":2,"title":"SciA11y: Converting Scientific Papers to Accessible HTML","prefix":"10.1145","author":[{"given":"Lucy Lu","family":"Wang","sequence":"first","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Isabel","family":"Cachola","sequence":"additional","affiliation":[{"name":"The Johns Hopkins University, United States"}]},{"given":"Jonathan","family":"Bragg","sequence":"additional","affiliation":[{"name":"Allen Institute for Artificial Intelligence, United States"}]},{"given":"Evie Yu-Yen","family":"Cheng","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Chelsea","family":"Haupt","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Matt","family":"Latzke","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Bailey","family":"Kuehl","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Madeleine N","family":"van Zuylen","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Linda","family":"Wagner","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Daniel","family":"Weld","sequence":"additional","affiliation":[{"name":"Semantic Scholar Allen Institute for Artificial Intelligence, United States"}]}],"member":"320","published-online":{"date-parts":[[2021,10,17]]},"reference":[{"key":"e_1_3_2_2_1_1","doi-asserted-by":"crossref","unstructured":"Waleed Ammar Dirk Groeneveld Chandra Bhagavatula Iz Beltagy Miles Crawford Doug Downey Jason Dunkelberger Ahmed Elgohary Sergey Feldman Vu A. Ha Rodney Michael Kinney Sebastian Kohlmeier Kyle Lo Tyler C. Murray Hsu-Han Ooi Matthew E. Peters Joanna L. Power Sam Skjonsberg Lucy Lu Wang Christopher Wilhelm Zheng Yuan Madeleine van Zuylen and Oren Etzioni. 2018. Construction of the Literature Graph in Semantic Scholar. In NAACL-HLT.  Waleed Ammar Dirk Groeneveld Chandra Bhagavatula Iz Beltagy Miles Crawford Doug Downey Jason Dunkelberger Ahmed Elgohary Sergey Feldman Vu A. Ha Rodney Michael Kinney Sebastian Kohlmeier Kyle Lo Tyler C. Murray Hsu-Han Ooi Matthew E. Peters Joanna L. Power Sam Skjonsberg Lucy Lu Wang Christopher Wilhelm Zheng Yuan Madeleine van Zuylen and Oren Etzioni. 2018. Construction of the Literature Graph in Semantic Scholar. In NAACL-HLT.","DOI":"10.18653/v1/N18-3011"},{"key":"e_1_3_2_2_2_1","doi-asserted-by":"crossref","unstructured":"E. Bates and D. Fitzpatrick. 2010. Spoken Mathematics Using Prosody Earcons and Spearcons. In ICCHP.  E. Bates and D. Fitzpatrick. 2010. Spoken Mathematics Using Prosody Earcons and Spearcons. In ICCHP.","DOI":"10.1007/978-3-642-14100-3_61"},{"key":"e_1_3_2_2_3_1","volume-title":"Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems(2016)","author":"Bigham P.","unstructured":"Jeffrey  P. Bigham , E. Brady , Cole Gleason , Anhong Guo , and D. Shamma . 2016. An Uninteresting Tour Through Why Our Research Papers Aren’t Accessible . Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems(2016) . Jeffrey P. Bigham, E. Brady, Cole Gleason, Anhong Guo, and D. Shamma. 2016. An Uninteresting Tour Through Why Our Research Papers Aren’t Accessible. Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems(2016)."},{"key":"e_1_3_2_2_4_1","unstructured":"Stephanie Elzer E. J. Schwartz S. Carberry D. Chester Seniz Demir and Peng Wu. 2008. Accessible bar charts for visually impaired users.  Stephanie Elzer E. J. Schwartz S. Carberry D. Chester Seniz Demir and Peng Wu. 2008. Accessible bar charts for visually impaired users."},{"key":"e_1_3_2_2_5_1","unstructured":"Christin Engel David Gollasch Meinhardt Branig and G. Weber. 2017. Towards Accessible Charts for Blind and Partially Sighted People. In Mensch & Computer.  Christin Engel David Gollasch Meinhardt Branig and G. Weber. 2017. Towards Accessible Charts for Blind and Partially Sighted People. In Mensch & Computer."},{"key":"e_1_3_2_2_6_1","volume-title":"Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments(2019)","author":"Engel Christin","unstructured":"Christin Engel , E. Müller , and G. Weber . 2019. SVGPlott: an accessible tool to generate highly adaptable, accessible audio-tactile charts for and from blind and visually impaired people . Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments(2019) . Christin Engel, E. Müller, and G. Weber. 2019. SVGPlott: an accessible tool to generate highly adaptable, accessible audio-tactile charts for and from blind and visually impaired people. Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments(2019)."},{"key":"e_1_3_2_2_7_1","unstructured":"S. Flores M. Andrade-Aréchiga Alfonso Flores-Barriga and Juan Lazaro-Flores. 2010. MathML to ASCII-Braille and Hierarchical Tree Converter. In ICCHP.  S. Flores M. Andrade-Aréchiga Alfonso Flores-Barriga and Juan Lazaro-Flores. 2010. MathML to ASCII-Braille and Hierarchical Tree Converter. In ICCHP."},{"key":"e_1_3_2_2_8_1","volume-title":"ICDAR 2019 Competition on Table Detection and Recognition (cTDaR). 2019 International Conference on Document Analysis and Recognition (ICDAR)","author":"Gao L.","year":"2019","unstructured":"L. Gao , Yilun Huang , Hervé Déjean , Jean-Luc Meunier , Qinqin Yan , Yu Fang , Florian Kleber , and E. Lang . 2019 . ICDAR 2019 Competition on Table Detection and Recognition (cTDaR). 2019 International Conference on Document Analysis and Recognition (ICDAR) ( 2019 ), 1510–1515. L. Gao, Yilun Huang, Hervé Déjean, Jean-Luc Meunier, Qinqin Yan, Yu Fang, Florian Kleber, and E. Lang. 2019. ICDAR 2019 Competition on Table Detection and Recognition (cTDaR). 2019 International Conference on Document Analysis and Recognition (ICDAR) (2019), 1510–1515."},{"key":"e_1_3_2_2_9_1","doi-asserted-by":"publisher","DOI":"10.1145/3411764.3445648"},{"key":"e_1_3_2_2_10_1","doi-asserted-by":"publisher","DOI":"10.1145/2993420"},{"key":"e_1_3_2_2_11_1","doi-asserted-by":"publisher","DOI":"10.18653/v1/2020.acl-main.447"},{"key":"e_1_3_2_2_12_1","unstructured":"P. Lopez and Laurent Romary. 2015. GROBID - Information Extraction from Scientific Publications. ERCIM News 2015(2015).  P. Lopez and Laurent Romary. 2015. GROBID - Information Extraction from Scientific Publications. ERCIM News 2015(2015)."},{"key":"e_1_3_2_2_13_1","doi-asserted-by":"publisher","DOI":"10.1007/s11042-017-4526-z"},{"key":"e_1_3_2_2_14_1","unstructured":"Zejiang Shen Kyle Lo Lucy Lu Wang Bailey Kuehl Daniel S. Weld and Doug Downey. 2021. Incorporating Visual Layout Structures for Scientific Text Classification. ArXiv abs/2106.00676(2021).  Zejiang Shen Kyle Lo Lucy Lu Wang Bailey Kuehl Daniel S. Weld and Doug Downey. 2021. Incorporating Visual Layout Structures for Scientific Text Classification. ArXiv abs/2106.00676(2021)."},{"key":"e_1_3_2_2_15_1","doi-asserted-by":"publisher","DOI":"10.1145/3197026.3197040"},{"key":"e_1_3_2_2_16_1","doi-asserted-by":"crossref","unstructured":"V. Sorge C. Chen T. Raman and David Tseng. 2014. Towards making mathematics a first class citizen in general screen readers. In W4A.  V. Sorge C. Chen T. Raman and David Tseng. 2014. Towards making mathematics a first class citizen in general screen readers. In W4A.","DOI":"10.1145/2596695.2596700"},{"key":"e_1_3_2_2_17_1","volume-title":"Chelsea Hess Haupt, Matt Latzke, Bailey Kuehl, Madeleine van Zuylen, Linda M. Wagner, and Daniel S. Weld.","author":"Wang Lucy Lu","year":"2021","unstructured":"Lucy Lu Wang , Isabel Cachola , Jonathan Bragg , Evie Yu-Yen Cheng , Chelsea Hess Haupt, Matt Latzke, Bailey Kuehl, Madeleine van Zuylen, Linda M. Wagner, and Daniel S. Weld. 2021 . Improving the Accessibility of Scientific Documents: Current State, User Needs, and a System Solution to Enhance Scientific PDF Accessibility for Blind and Low Vision Users. ArXiv abs/2105.00076(2021). Lucy Lu Wang, Isabel Cachola, Jonathan Bragg, Evie Yu-Yen Cheng, Chelsea Hess Haupt, Matt Latzke, Bailey Kuehl, Madeleine van Zuylen, Linda M. Wagner, and Daniel S. Weld. 2021. Improving the Accessibility of Scientific Documents: Current State, User Needs, and a System Solution to Enhance Scientific PDF Accessibility for Blind and Low Vision Users. ArXiv abs/2105.00076(2021)."},{"key":"e_1_3_2_2_18_1","volume-title":"PingAn-VCGroup’s Solution for ICDAR 2021 Competition on Scientific Literature Parsing Task B: Table Recognition to HTML. ArXiv abs/2105","author":"Ye Jiaquan","year":"2021","unstructured":"Jiaquan Ye , X. Qi , Yelin He , Yihao Chen , Dengyi Gu , Peng Gao , and Rong Xiao . 2021 . PingAn-VCGroup’s Solution for ICDAR 2021 Competition on Scientific Literature Parsing Task B: Table Recognition to HTML. ArXiv abs/2105 .01848(2021). Jiaquan Ye, X. Qi, Yelin He, Yihao Chen, Dengyi Gu, Peng Gao, and Rong Xiao. 2021. PingAn-VCGroup’s Solution for ICDAR 2021 Competition on Scientific Literature Parsing Task B: Table Recognition to HTML. ArXiv abs/2105.01848(2021)."},{"key":"e_1_3_2_2_19_1","doi-asserted-by":"publisher","DOI":"10.1109/WACV48630.2021.00074"}],"event":"ASSETS '21: The 23rd International ACM SIGACCESS Conference on Computers and Accessibility","container-title":"The 23rd International ACM SIGACCESS Conference on Computers and Accessibility","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/3441852.3476545","content-type":"application/pdf","content-version":"vor","intended-application":"syndication"},{"URL":"https://dl.acm.org/doi/pdf/10.1145/3441852.3476545","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2022,10,17]],"date-time":"2022-10-17T11:42:04Z","timestamp":1666006924000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/3441852.3476545"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2021,10,17]]},"references-count":19,"alternative-id":["10.1145/3441852.3476545","10.1145/3441852"],"URL":"http://dx.doi.org/10.1145/3441852.3476545","relation":{},"published":{"date-parts":[[2021,10,17]]},"id":"doi:10.1145/3441852.3476545"},{"author":[{"given":"Lars","family":"Willighagen"}],"type":"document","id":"citejs","citation-key":"citejs","issued":{"date-parts":[[2023]]},"title":"Citation.js","URL":"https://citation.js.org/"},{"author":[{"given":"Gary","family":"Wolf"}],"container-title":"Wired","type":"paper-conference","id":"xanadu","citation-key":"xanadu","issued":{"date-parts":[[1995,6]]},"title":"The Curse of Xanadu","URL":"https://www.wired.com/1995/06/xanadu/"},{"author":[{"family":"Workshop on Visualization for AI Explainability"}],"type":"document","id":"visxai","citation-key":"visxai","issued":{"date-parts":[[2022]]},"URL":"http://visxai.io/"},{"indexed":{"date-parts":[[2023,1,14]],"date-time":"2023-01-14T19:14:50Z","timestamp":1673723690383},"publisher-location":"New York, NY, USA","reference-count":21,"publisher":"ACM","content-domain":{"domain":["dl.acm.org"],"crossmark-restriction":true},"published-print":{"date-parts":[[2000,4]]},"DOI":"10.1145/332040.332440","type":"proceedings-article","created":{"date-parts":[[2003,11,13]],"date-time":"2003-11-13T16:10:21Z","timestamp":1068739821000},"update-policy":"http://dx.doi.org/10.1145/crossmark-policy","source":"Crossref","is-referenced-by-count":29,"title":"The impact of fluid documents on reading and browsing","prefix":"10.1145","author":[{"given":"Polle T.","family":"Zellweger","sequence":"first","affiliation":[{"name":"Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CA"}]},{"given":"Susan Harkness","family":"Regli","sequence":"additional","affiliation":[{"name":"Baker Hall 259, Carnegie Mellon University, 5000 Forbes Ave. Pittsburgh, PA and Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CA"}]},{"given":"Jock D.","family":"Mackinlay","sequence":"additional","affiliation":[{"name":"Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CA"}]},{"given":"Bay-Wei","family":"Chang","sequence":"additional","affiliation":[{"name":"Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CA"}]}],"member":"320","published-online":{"date-parts":[[2000,4]]},"reference":[{"key":"e_1_3_2_1_1_2","doi-asserted-by":"publisher","DOI":"10.1145/274644.274664"},{"key":"e_1_3_2_1_2_2","doi-asserted-by":"publisher","DOI":"10.1145/192426.192435"},{"key":"e_1_3_2_1_3_2","volume-title":"Visual information processing.","author":"Bransford J.","year":"1973","unstructured":"J. Bransford , M. Johnson . Considerations of some problems of comprehension . In W.G. Chase (ed.), Visual information processing. New York : Academic Press , 1973 ,383-438. J. Bransford, M. Johnson. Considerations of some problems of comprehension. In W.G. Chase (ed.), Visual information processing. New York: Academic Press, 1973,383-438."},{"key":"e_1_3_2_1_4_2","doi-asserted-by":"publisher","DOI":"10.1145/288392.288585"},{"key":"e_1_3_2_1_5_2","doi-asserted-by":"publisher","DOI":"10.1109/MC.1987.1663693"},{"key":"e_1_3_2_1_6_2","doi-asserted-by":"publisher","DOI":"10.1145/22627.22342"},{"key":"e_1_3_2_1_7_2","doi-asserted-by":"publisher","DOI":"10.1145/258549.258800"},{"key":"e_1_3_2_1_8_2","volume-title":"Proc. Visual Languages '98","author":"Igarashi T.","unstructured":"T. Igarashi , J. Mackinlay , B. Chang , P. Zellweger . Fluid visualization of spreadsheet structures . Proc. Visual Languages '98 . T. Igarashi, J. Mackinlay, B. Chang, P. Zellweger. Fluid visualization of spreadsheet structures. Proc. Visual Languages '98."},{"key":"e_1_3_2_1_9_2","volume-title":"Comprehension: A paradigm for cognition","author":"Kintsch W.","year":"1998","unstructured":"W. Kintsch . Comprehension: A paradigm for cognition . Cambridge : Cambridge University Press , 1998 . W. Kintsch. Comprehension: A paradigm for cognition. Cambridge: Cambridge University Press, 1998."},{"key":"e_1_3_2_1_10_2","doi-asserted-by":"publisher","DOI":"10.1016/S1389-1286(99)00050-X"},{"key":"e_1_3_2_1_11_2","doi-asserted-by":"publisher","DOI":"10.1145/317426.317450"},{"key":"e_1_3_2_1_12_2","doi-asserted-by":"publisher","DOI":"10.1109/2.222119"},{"key":"e_1_3_2_1_13_2","volume-title":"A comparison of linear and hypertext formats in information retrieval","author":"McKnight C.","year":"1990","unstructured":"C. McKnight , A. Dillon , J. Richardson . A comparison of linear and hypertext formats in information retrieval . In R. McAlesse, C. Green (eds.), Hypertext : State of the art. Oxford : Intellect Books, Ltd. , 1990 , 10-19. C. McKnight, A. Dillon, J. Richardson. A comparison of linear and hypertext formats in information retrieval. In R. McAlesse, C. Green (eds.), Hypertext: State of the art. Oxford: Intellect Books, Ltd., 1990, 10-19."},{"key":"e_1_3_2_1_14_2","doi-asserted-by":"publisher","DOI":"10.1145/289444.289501"},{"key":"e_1_3_2_1_15_2","volume-title":"Jakob Nielsen's Alertbox for","author":"Nielsen J.","year":"1998","unstructured":"J. Nielsen . Jakob Nielsen's Alertbox for January 11, 1998 . http://www.useit.com/alertbox/980111 .html J. Nielsen. Jakob Nielsen's Alertbox for January 11, 1998. http://www.useit.com/alertbox/980111 .html"},{"key":"e_1_3_2_1_16_2","doi-asserted-by":"publisher","DOI":"10.1145/255950.153577"},{"key":"e_1_3_2_1_17_2","volume-title":"Contrast Analysis: Focused comparisons in the analysis of variance","author":"Rosenthal R.","year":"1985","unstructured":"R. Rosenthal , R.L. Rosnow . Contrast Analysis: Focused comparisons in the analysis of variance . Cambridge : Cambridge University Press , 1985 . R. Rosenthal, R.L. Rosnow. Contrast Analysis: Focused comparisons in the analysis of variance. Cambridge: Cambridge University Press, 1985."},{"key":"e_1_3_2_1_18_2","volume-title":"Lawrence Erlbaum Associates","author":"Rouet J.","year":"1996","unstructured":"J. Rouet , J. Levonen , A. Dillon , R. Spiro , eds. Hypertext and Cognition . Lawrence Erlbaum Associates , 1996 . J. Rouet, J. Levonen, A. Dillon, R. Spiro, eds. Hypertext and Cognition. Lawrence Erlbaum Associates, 1996."},{"key":"e_1_3_2_1_19_2","doi-asserted-by":"publisher","DOI":"10.1016/S1389-1286(99)00034-1"},{"key":"e_1_3_2_1_20_2","doi-asserted-by":"publisher","DOI":"10.1145/276627.276633"},{"key":"e_1_3_2_1_21_2","doi-asserted-by":"publisher","DOI":"10.1145/632716.632722"}],"event":"CHI00: Human Factors in Computing Systems","container-title":"Proceedings of the SIGCHI conference on Human Factors in Computing Systems","original-title":[],"link":[{"URL":"https://dl.acm.org/doi/pdf/10.1145/332040.332440","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,1,11]],"date-time":"2023-01-11T00:13:30Z","timestamp":1673396010000},"score":1,"resource":{"primary":{"URL":"https://dl.acm.org/doi/10.1145/332040.332440"}},"subtitle":["an observational study"],"short-title":[],"issued":{"date-parts":[[2000,4]]},"references-count":21,"alternative-id":["10.1145/332040.332440","10.1145/332040"],"URL":"http://dx.doi.org/10.1145/332040.332440","relation":{},"published":{"date-parts":[[2000,4]]},"assertion":[{"value":"2000-04-01","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1145/332040.332440"},{"indexed":{"date-parts":[[2023,10,19]],"date-time":"2023-10-19T15:08:28Z","timestamp":1697728108063},"reference-count":66,"publisher":"Wiley","issue":"3","license":[{"start":{"date-parts":[[2022,8,12]],"date-time":"2022-08-12T00:00:00Z","timestamp":1660262400000},"content-version":"vor","delay-in-days":72,"URL":"http://onlinelibrary.wiley.com/termsAndConditions#vor"}],"content-domain":{"domain":["onlinelibrary.wiley.com"],"crossmark-restriction":true},"published-print":{"date-parts":[[2022,6]]},"abstract":"<jats:title>Abstract</jats:title><jats:p>Current web accessibility guidelines ask visualization designers to support screen readers via basic non‐visual alternatives like textual descriptions and access to raw data tables. But charts do more than summarize data or reproduce tables; they afford interactive data exploration at varying levels of granularity—from fine‐grained datum‐by‐datum reading to skimming and surfacing high‐level trends. In response to the lack of comparable non‐visual affordances, we present a set of rich screen reader experiences for accessible data visualization and exploration. Through an iterative co‐design process, we identify three key design dimensions for expressive screen reader accessibility: <jats:italic>structure</jats:italic>, or how chart entities should be organized for a screen reader to traverse; <jats:italic>navigation</jats:italic>, or the structural, spatial, and targeted operations a user might perform to step through the structure; and, <jats:italic>description</jats:italic>, or the semantic content, composition, and verbosity of the screen reader's narration. We operationalize these dimensions to prototype screen‐reader‐accessible visualizations that cover a diverse range of chart types and combinations of our design dimensions. We evaluate a subset of these prototypes in a mixed‐methods study with 13 blind and visually impaired readers. Our findings demonstrate that these designs help users conceptualize data spatially, selectively attend to data of interest at different levels of granularity, and experience control and agency over their data analysis process. An accessible HTML version of this paper is available at: <jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"http://vis.csail.mit.edu/pubs/rich-screen-reader-vis-experiences\">http://vis.csail.mit.edu/pubs/rich-screen-reader-vis-experiences</jats:ext-link>.</jats:p>","DOI":"10.1111/cgf.14519","type":"journal-article","created":{"date-parts":[[2022,8,12]],"date-time":"2022-08-12T11:03:53Z","timestamp":1660302233000},"page":"15-27","update-policy":"http://dx.doi.org/10.1002/crossmark_policy","source":"Crossref","is-referenced-by-count":8,"title":"Rich Screen Reader Experiences for Accessible Data Visualization","prefix":"10.1111","volume":"41","author":[{"ORCID":"http://orcid.org/0000-0003-4811-4624","authenticated-orcid":false,"given":"Jonathan","family":"Zong","sequence":"first","affiliation":[{"name":"Massachusetts Institute of Technology"}]},{"ORCID":"http://orcid.org/0000-0001-6672-9118","authenticated-orcid":false,"given":"Crystal","family":"Lee","sequence":"additional","affiliation":[{"name":"Massachusetts Institute of Technology"}]},{"ORCID":"http://orcid.org/0000-0002-1352-3615","authenticated-orcid":false,"given":"Alan","family":"Lundgard","sequence":"additional","affiliation":[{"name":"Massachusetts Institute of Technology"}]},{"ORCID":"http://orcid.org/0000-0003-0469-9501","authenticated-orcid":false,"given":"JiWoong","family":"Jang","sequence":"additional","affiliation":[{"name":"Carnegie Mellon University"}]},{"ORCID":"http://orcid.org/0000-0002-2811-1197","authenticated-orcid":false,"given":"Daniel","family":"Hajas","sequence":"additional","affiliation":[{"name":"University College London"}]},{"ORCID":"http://orcid.org/0000-0001-5564-635X","authenticated-orcid":false,"given":"Arvind","family":"Satyanarayan","sequence":"additional","affiliation":[{"name":"Massachusetts Institute of Technology"}]}],"member":"311","published-online":{"date-parts":[[2022,8,12]]},"reference":[{"key":"e_1_2_8_2_2","unstructured":"Amick NancyandCorcoran Jane.Guidelines for Design of Tactile Graphics. Tech. rep. American Printing House for the Blind 1997. url:https://www.aph.org/research/guides/3."},{"key":"e_1_2_8_3_2","unstructured":"Accelerator SAS Graphics.SAS Graphics Accelerator Customer Product Page.2018. url:https://support.sas.com/software/products/graphics-accelerator/index.html#s1=12."},{"key":"e_1_2_8_4_2","doi-asserted-by":"crossref","unstructured":"Aldrich Frances K.andSheppard Linda. “Tactile Graphics In School Education: Perspectives From Pupils”.British Journal of Visual Impairment(2001). doi:10.1177/026461960101900204. url:https://doi.org/10.1177/0264619601019002043 9.","DOI":"10.1177/026461960101900204"},{"key":"e_1_2_8_5_2","doi-asserted-by":"crossref","unstructured":"Bagozzi Richard P.“The Legacy of the Technology Acceptance Model and a Proposal for a Paradigm Shift.”Journal of the Association for Information Systems(2007). doi:10.17705/1jais.00122. url:https://aisel.aisnet.org/jais/vol8/iss4/128.","DOI":"10.17705/1jais.00122"},{"key":"e_1_2_8_6_2","unstructured":"Boxhall Alice Craig James Mazzoni Dominic andSurkov Alexander.The Accessibility Object Model (AOM).2022. url:https://wicg.github.io/aom/2."},{"key":"e_1_2_8_7_2","unstructured":"Becker Richard A. Cleveland William S. andShyu Ming‐Jen. “The Visual Design and Control of Trellis Display”.Journal of Computational and Graphical Statistics(1996). doi:10.1080/10618600.1996.10474701. url:http://www.tandfonline.com/doi/abs/10.1080/10618600.1996.104747017."},{"key":"e_1_2_8_8_2","unstructured":"Bertin Jacques.Semiology of Graphics. University of Wisconsin Press 1983. url:https://dl.acm.org/doi/10.5555/10955975."},{"key":"e_1_2_8_9_2","doi-asserted-by":"crossref","unstructured":"Butler Matthew Holloway Leona M Reinders Samuel et al. “Technology Developments in Touch‐Based Accessible Graphics: A Systematic Review of Research 2010‐2020”.ACM Conference on Human Factors in Computing Systems (CHI).2021. url:https://doi.org/10.1145/3411764.34452073.","DOI":"10.1145/3411764.3445207"},{"key":"e_1_2_8_10_2","doi-asserted-by":"crossref","unstructured":"Barrass StephenandKramer Gregory. “Using Sonification”.Multimedia Systems(1999). doi:10.1007/s005300050108. url:https://doi.org/10.1007/s0053000501082.","DOI":"10.1007/s005300050108"},{"key":"e_1_2_8_11_2","unstructured":"Brehmer MatthewandMunzner Tamara. “A MultiLevel Typology of Abstract Visualization Tasks”.IEEE Transactions on Visualization & Computer Graphics (Proc. IEEE VIS).2013. doi:10.1109/TVCG.2013.124. url:http://ieeexplore.ieee.org/document/6634168/7 8."},{"key":"e_1_2_8_12_2","doi-asserted-by":"crossref","unstructured":"Baker Catherine M. Milne Lauren R. Drapeau Ryan et al. “Tactile Graphics with a Voice”.ACM Transactions on Accessible Computing (TACCESS)(2016). doi:10.1145/2854005. url:http://doi.org/10.1145/28540053.","DOI":"10.1145/2854005"},{"key":"e_1_2_8_13_2","doi-asserted-by":"crossref","unstructured":"Boger Tal Most Steven B. andFranconeri Steven L.“Jurassic Mark: Inattentional Blindness for a Datasaurus Reveals that Visualizations are Explored not Seen”.IEEE Transactions on Visualization & Computer Graphics (Proc. IEEE VIS).2021. doi:10.1109/VIS49827.2021.9623273. url:https://ieeexplore.ieee.org/abstract/document/962327310.","DOI":"10.1109/VIS49827.2021.9623273"},{"key":"e_1_2_8_14_2","doi-asserted-by":"crossref","unstructured":"Bostock Michael Ogievetsky Vadim andHeer Jeffrey. “D3: Data‐Driven Documents”.IEEE Trans. Visualization & Comp. Graphics (Proc. InfoVis)(2011). doi:10.1109/TVCG.2011.185. url:http://vis.stanford.edu/papers/d32.","DOI":"10.1109/TVCG.2011.185"},{"key":"e_1_2_8_15_2","doi-asserted-by":"crossref","unstructured":"Brock Anke Truillet Philippe Oriola Bernard andJouffrais Christophe. “Usage Of Multimodal Maps For Blind People: Why And How”.ACM International Conference on Interactive Tabletops and Surfaces (ISS).2010. doi:10.1145/1936652.1936699. url:https://doi.org/10.1145/1936652.19366993.","DOI":"10.1145/1936652.1936699"},{"key":"e_1_2_8_16_2","unstructured":"Charmaz Kathy.Constructing Grounded Theory. Sage Publications 2006. url:https://uk.sagepub.com/en-gb/eur/constructing-grounded-theory/book2359608."},{"key":"e_1_2_8_17_2","unstructured":"Cornwall AndreaandJewkes Rachel. “What Is Participatory Research?”:Social Science & Medicine(1995). doi:10.1016/0277‐9536(95)00127‐S. url:https://www.sciencedirect.com/science/article/pii/027795369500127S3."},{"key":"e_1_2_8_18_2","unstructured":"Choi Jinho Jung Sanghun Park Deok Gun et al. “Visualizing for the Non‐Visual: Enabling the Visually Impaired to Use Visualization”.Computer Graphics Forum (EuroVis)(June2019). doi:10.1111/cgf.13686. url:https://onlinelibrary.wiley.com/doi/10.1111/cgf.136862."},{"key":"e_1_2_8_19_2","unstructured":"Costanza‐Chock Sasha.Design Justice: Towards an Inter‐sectional Feminist Framework for Design Theory and Practice. MIT Press 2020. url:https://papers.ssrn.com/abstract=31896963."},{"key":"e_1_2_8_20_2","unstructured":"Chundury Pramod Patnaik Biswaksen Reyazuddin Yasmin et al. “Towards Understanding Sensory Substitution for Accessible Visualization: An Interview Study”.IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VIS)(2021). doi:10.1109/TVCG.2021.3114829. url:https://ieeexplore.ieee.org/document/9552177/3 5."},{"key":"e_1_2_8_21_2","unstructured":"Davert ScottandEditorial Team AppleVis.What's New In iOS 13 Accessibility For Individuals Who Are Blind or Deaf‐Blind.2019. url:https://www.applevis.com/blog/whats-new-ios-13-accessibility-individuals-who-are-blind-or-deaf-blind2 6."},{"key":"e_1_2_8_22_2","doi-asserted-by":"crossref","unstructured":"De Greef Lilian Moritz Dominik andBennett Cynthia. “Interdependent Variables: Remotely Designing Tactile Graphics for an Accessible Workflow”.ACM Conference on Computers and Accessibility (SIGACCESS). Association for Computing Machinery 2021. doi:10.1145/3441852.3476468. url:https://doi.org/10.1145/3441852.34764683.","DOI":"10.1145/3441852.3476468"},{"key":"e_1_2_8_23_2","doi-asserted-by":"crossref","unstructured":"Dimara EvanthiaandPerin Charles. “What is Interaction for Data Visualization?”:IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VIS)(2020). doi:10.1109/TVCG.2019.2934283. url:https://hal.archives-ouvertes.fr/hal-021970621.","DOI":"10.1109/TVCG.2019.2934283"},{"key":"e_1_2_8_24_2","doi-asserted-by":"crossref","unstructured":"Fujiyoshi Mamoru Fujiyoshi Akio Tanaka Hiroshi andIshida Toru. “Universal Design Tactile Graphics Production System BPLOT4 for Blind Teachers and Blind Staffs to Produce Tactile Graphics and Ink Print Graphics of High Quality”.Computers Helping People with Special Needs. Ed. by Miesenberger Klaus and Kouroupetroglou Georgios. Springer International Publishing 2018. url:http://link.springer.com/10.1007/978-3-319-94274-2_233.","DOI":"10.1007/978-3-319-94274-2_23"},{"key":"e_1_2_8_25_2","doi-asserted-by":"crossref","unstructured":"Fr⊘kjær ErikandHornbæk Kasper. “Cooperative Usability Testing: Complementing Usability Tests With User‐Supported Interpretation Sessions”.ACM Extended Abstracts on Human Factors in Computing Systems (CHI).2005. doi:10.1145/1056808.1056922. url:https://doi.org/10.1145/1056808.10569226 7.","DOI":"10.1145/1056808.1056922"},{"key":"e_1_2_8_26_2","unstructured":"Godfrey A.JonathanR.andLoots M. Theodor. “Advice From Blind Teachers on How to Teach Statistics to Blind Students”.Journal of Statistics Education(2015). doi:10.1080/10691898.2015.11889746. url:https://doi.org/10.1080/10691898.2015.118897463 8."},{"key":"e_1_2_8_27_2","unstructured":"Gould Bryan O'Connell Trisha andFreed Geoffrey.Effective Practices for Description of Science Content within Digital Talking Books. Tech. rep. The WGBH National Center for Accessible Media 2008. url:https://www.wgbh.org/foundation/ncam/guidelines/effective-practices-for-description-of-science-content-within-digital-talking-books1 2 5."},{"key":"e_1_2_8_28_2","doi-asserted-by":"crossref","unstructured":"Hamraie Aimi. “Designing Collective Access: A Feminist Disability Theory of Universal Design”.Disability Studies Quarterly(2013). doi:10.18061/dsq.v33i4.3871. url:http://dsq-sds.org/article/view/38713.","DOI":"10.18061/dsq.v33i4.3871"},{"key":"e_1_2_8_29_2","unstructured":"Horst Allison M. Hill Alison Presmanes andGorman Kristen B.Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data.2020. url:https://github.com/allisonhorst/palmerpenguins7."},{"key":"e_1_2_8_30_2","unstructured":"Higgins Tucker. “Supreme Court Hands Victory To Blind Man Who Sued Domino's Over Site Accessibility”.CNBC(2019). url:https://www.cnbc.com/2019/10/07/dominos-supreme-court.html1."},{"key":"e_1_2_8_31_2","unstructured":"Highcharts.Accessibility Module.2021. url:https://highcharts.com/docs/accessibility/accessibility-module2."},{"key":"e_1_2_8_32_2","unstructured":"Hasty Lucia Milbury Janet Miller Irene et al.Guidelines and Standards for Tactile Graphics. Tech. rep. Braille Authority of North America 2011. url:http://www.brailleauthority.org/tg/2 3 5 8."},{"key":"e_1_2_8_33_2","doi-asserted-by":"crossref","unstructured":"Hutchinson Hilary Mackay Wendy Westerlund Bo et al. “Technology Probes: Inspiring Design for and with Families”.ACM Conference on Human Factors in Computing Systems (CHI).2003. doi:10.1145/642611.642616. url:http://doi.acm.org/10.1145/642611.6426167.","DOI":"10.1145/642611.642616"},{"key":"e_1_2_8_34_2","unstructured":"Heer JeffreyandShneiderman Ben. “Interactive Dynamics for Visual Analysis”.Communications of the ACM(2012). doi:10.1145/2133806.2133821. url:https://dl.acm.org/doi/10.1145/2133806.21338211 10."},{"key":"e_1_2_8_35_2","unstructured":"Jackson Liz.Disability dongle: A well‐intended elegant yet useless solution to a problem we never knew we had. Disability dongles are most often conceived of and created in design schools and at IDEO. Tweet.2019. url:https://twitter.com/elizejackson/status/11106298182348185703."},{"key":"e_1_2_8_36_2","doi-asserted-by":"crossref","unstructured":"Jung Crescentia Mehta Shubham Kulkarni Atharva et al. “Communicating Visualizations without Visuals: Investigation of Visualization Alternative Text for People with Visual Impairments”.IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VIS).2021. doi:10.1109/TVCG.2021.3114846. url:https://ieeexplore.ieee.org/abstract/document/95529385.","DOI":"10.1109/TVCG.2021.3114846"},{"key":"e_1_2_8_37_2","unstructured":"Kim N. W. Joyner S. C. Riegelhuth A. andKim Y.“Accessible Visualization: Design Space Opportunities and Challenges”.Computer Graphics Forum (EuroVis)(2021). doi:10.1111/cgf.14298. url:https://onlinelibrary.wiley.com/doi/10.1111/cgf.142982 4 9."},{"key":"e_1_2_8_38_2","unstructured":"Koch Wolf Günther. “State of the Art of Tactile Maps for Visually Impaired People”.True‐3D in Cartography: Autostereoscopic and Solid Visualisation of Geodata. Ed. by Buchroithner Manfred. Springer 2012. doi:10.1007/978‐3‐642‐12272‐9_9. url:https://doi.org/10.1007/978-3-642-12272-9_93."},{"key":"e_1_2_8_39_2","unstructured":"Karahanna ElenaandStraub Detmar W.“The Psychological Origins of Perceived Usefulness and Ease‐of‐use”.Information and Management(1999). doi:10.1016/S0378‐7206(98)00096‐2. url:https://doi.org/10.1016/S0378-7206(98)00096‐2 8."},{"key":"e_1_2_8_40_2","doi-asserted-by":"crossref","unstructured":"Kaper H.G. Wiebel E. andTipei S.“Data Sonification And Sound Visualization”.Computing in Science Engineering(1999). doi:10.1109/5992.7748402.","DOI":"10.1109/5992.774840"},{"key":"e_1_2_8_41_2","doi-asserted-by":"crossref","unstructured":"Li Jingyi Kim Son Miele Joshua A. et al. “Editing Spatial Layouts through Tactile Templates for People with Visual Impairments”.ACM Conference on Human Factors in Computing Systems (CHI).2019. doi:10.1145/3290605.3300436. url:http://dl.acm.org/citation.cfm?doid=3290605.33004365.","DOI":"10.1145/3290605.3300436"},{"key":"e_1_2_8_42_2","doi-asserted-by":"crossref","unstructured":"Lundgard Alan Lee Crystal andSatyanarayan Arvind. “Sociotechnical Considerations for Accessible Visualization Design”.IEEE Transactions on Visualization & Computer Graphics (Proc. IEEE VIS).2019. doi:10.1109/VISUAL.2019.8933762. url:https://ieeexplore.ieee.org/abstract/document/89337622.","DOI":"10.1109/VISUAL.2019.8933762"},{"key":"e_1_2_8_43_2","unstructured":"Lundgard AlanandSatyanarayan Arvind. “Accessible Visualization via Natural Language Descriptions: A Four‐Level Model of Semantic Content”.IEEE Transactions on Visualization & Computer Graphics (Proc. IEEE VIS).2021. doi:10.1109/TVCG.2021.3114770. url:http://vis.csail.mit.edu/pubs/vis-text-model2 4 5."},{"key":"e_1_2_8_44_2","unstructured":"MDN Contributors.ARIA ‐ Accessibility. Nov.2021. url:https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA2."},{"key":"e_1_2_8_45_2","unstructured":"Morris Meredith Ringel Johnson Jazette Bennett Cynthia L. andCutrell Edward. “Rich Representations of Visual Content for Screen Reader Users”.ACM Conference on Human Factors in Computing Systems (CHI).2018. doi:10.1145/3173574.3173633. url:https://dl.acm.org/doi/10.1145/3173574.31736332 8."},{"key":"e_1_2_8_46_2","doi-asserted-by":"crossref","unstructured":"Martínez Rubén Alcaraz Turró Mireia Ribera andSaltiveri Toni Granollers. “Accessible Statistical Charts For People With Low Vision And Colour Vision Deficiency”.ACM International Conference on Human Computer Interaction. June2019. doi:10.1145/3335595.3335618. url:https://doi.org/10.1145/3335595.33356183.","DOI":"10.1145/3335595.3335618"},{"key":"e_1_2_8_47_2","doi-asserted-by":"crossref","unstructured":"Munzner Tamara. “A Nested Model for Visualization Design and Validation”.IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VIS)(2009). Conference Name: IEEE Transactions on Visualization and Computer Graphics. doi:10.1109/TVCG.2009.111. url:https://ieeexplore.ieee.org/abstract/document/52906959.","DOI":"10.1109/TVCG.2009.111"},{"key":"e_1_2_8_48_2","doi-asserted-by":"crossref","unstructured":"Pirolli PeterandCard Stuart. “Information Foraging”.Psychological Review(1999). doi:10.1037/0033‐295X.106.4.6434 5.","DOI":"10.1037/0033-295X.106.4.643"},{"key":"e_1_2_8_49_2","doi-asserted-by":"crossref","unstructured":"Potluri Venkatesh Grindeland Tadashi E Froehlich Jon E. andMankoff Jennifer. “Examining Visual Semantic Understanding in Blind and Low‐Vision Technology Users”.ACM Conference on Human Factors in Computing Systems (CHI).2021. doi:10.1145/3411764.3445040. url:https://dl.acm.org/doi/abs/10.1145/3411764.34450402.","DOI":"10.1145/3411764.3445040"},{"key":"e_1_2_8_50_2","doi-asserted-by":"crossref","unstructured":"Sheppard LindaandAldrich Frances K.“Tactile Graphics In School Education: Perspectives From Pupils”.British Journal of Visual Impairment(2001). doi:10.1177/026461960101900303. url:https://doi.org/10.1177/0264619601019003039.","DOI":"10.1177/026461960101900303"},{"key":"e_1_2_8_51_2","unstructured":"Sarah L.Fossheim.How (not) to make accessible data visualizations illustrated by the US presidential election.2020. url:https://fossheim.io/writing/posts/accessible-dataviz-us-elections/1 2."},{"key":"e_1_2_8_52_2","doi-asserted-by":"crossref","unstructured":"Sengers Phoebe Boehner Kirsten David Shay andKaye Joseph ‘Jofish’.“Reflective Design”.ACM Conference on Critical Computing: Between Sense and Sensibility.2005. doi:10.1145/1094562.1094569. url:http://doi.acm.org/10.1145/1094562.10945693.","DOI":"10.1145/1094562.1094569"},{"key":"e_1_2_8_53_2","unstructured":"Scientific Freedom.JAWS Web Verbosity.2021. url:https://www.freedomscientific.com/SurfsUp/Web_Verbosity.htm6."},{"key":"e_1_2_8_54_2","unstructured":"Sharif Ather Chintalapati Sanjana Shivani Wobbrock Jacob O. andReinecke Katharina. “Understanding Screen‐Reader Users' Experiences with Online Data Visualizations”.ACM Conference on Computers and Accessibility (SIGACCESS).2021. doi:10.1145/3441852.3471202. url:http://doi.org/10.1145/3441852.34712021 2 4 8 9."},{"key":"e_1_2_8_55_2","doi-asserted-by":"crossref","unstructured":"Shew Ashley. “Ableism Technoableism and Future AI”.IEEE Technology and Society Magazine(Mar.2020). doi:10.1109/MTS.2020.29674923.","DOI":"10.1109/MTS.2020.2967492"},{"key":"e_1_2_8_56_2","unstructured":"Shneiderman Ben. “The Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations”.The Craft of Information Visualization. Ed. by Bederson BENJAMIN B. and Shneiderman BEN. Morgan Kaufmann 2003. doi:10.1016/B978‐155860915‐0/50046‐9. url:https://www.sciencedirect.com/science/article/pii/B97815586091505004691 9."},{"key":"e_1_2_8_57_2","doi-asserted-by":"crossref","unstructured":"Saunders Benjamin Kitzinger Jenny andKitzinger Celia. “Anonymising Interview Data: Challenges And Compromise In Practice”.Qualitative Research(2015). doi:10.1177/1468794114550439. url:https://doi.org/10.1177/14687941145504397.","DOI":"10.1177/1468794114550439"},{"key":"e_1_2_8_58_2","doi-asserted-by":"crossref","unstructured":"Satyanarayan Arvind Moritz Dominik Wongsuphasawat Kanit andHeer Jeffrey. “Vega‐Lite: A Grammar of Interactive Graphics”.IEEE Transactions on Visualization & Computer Graphics (Proc. IEEE VIS).2017. doi:10.1109/TVCG.2016.2599030. url:https://ieeexplore.ieee.org/abstract/document/75396242 6.","DOI":"10.1109/TVCG.2016.2599030"},{"key":"e_1_2_8_59_2","unstructured":"W3C.WAI‐ARIA Graphics Module.2018. url:https://www.w3.org/TR/graphics-aria-1.0/2."},{"key":"e_1_2_8_60_2","unstructured":"W3C.Web Accessibility Laws & Policies.2018. url:https://www.w3.org/WAI/policies/1."},{"key":"e_1_2_8_61_2","unstructured":"W3C.WAI Web Accessibility Tutorials: Complex Images.2019. url:https://www.w3.org/WAI/tutorials/images/complex/1 2 5."},{"key":"e_1_2_8_62_2","unstructured":"WebAIM.Screen Reader User Survey #9 Results.2021. url:https://webaim.org/projects/screenreadersurvey9/7."},{"key":"e_1_2_8_63_2","unstructured":"Wiedel Joseph W.andGroves Paul A.Tactual Mapping: Design Reproduction Reading and Interpretation. Tech. rep. Department of Health Education and Welfare 1969. url:https://archive.org/details/tactualmappingde00jose_03 5 9."},{"key":"e_1_2_8_64_2","doi-asserted-by":"crossref","unstructured":"Weninger Markus Ortner Gerald Hahn Tobias et al. “ASVG Accessible Scalable Vector Graphics: Intention Trees To Make Charts More Accessible And Usable”.Journal of Assistive Technologies(2015). doi:10.1108/JAT‐10‐2015‐01243.","DOI":"10.1108/JAT-10-2015-0124"},{"key":"e_1_2_8_65_2","doi-asserted-by":"crossref","unstructured":"Wu Keke Petersen Emma Ahmad Tahmina et al. “Understanding Data Accessibility for People with Intellectual and Developmental Disabilities”.ACM Conference on Human Factors in Computing Systems (CHI).2021. doi:10.1145/3411764.3445743. url:https://dl.acm.org/doi/abs/10.1145/3411764.34457432.","DOI":"10.1145/3411764.3445743"},{"key":"e_1_2_8_66_2","doi-asserted-by":"crossref","unstructured":"Yi Ji Soo Kang Younah Stasko John and Jacko J.A. “Toward a Deeper Understanding of the Role of Interaction in Information Visualization”.IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VIS)(2007). Conference Name: IEEE Transactions on Visualization and Computer Graphics. doi:10.1109/TVCG.2007.70515. url:https://ieeexplore.ieee.org/abstract/document/43761441 10.","DOI":"10.1109/TVCG.2007.70515"},{"key":"e_1_2_8_67_2","unstructured":"Yu Wai Ramloll Ramesh andBrewster Stephen. “Haptic Graphs For Blind Computer Users”.Lecture Notes in Computer Science(2001). Ed. by Brewster Stephen and Murray‐Smith Roderick. doi:10.1007/3‐540‐44589‐7_5. url:http://link.springer.com/10.1007/3-540-44589-7_52."}],"container-title":"Computer Graphics Forum","original-title":[],"language":"en","link":[{"URL":"https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14519","content-type":"application/pdf","content-version":"vor","intended-application":"text-mining"},{"URL":"https://onlinelibrary.wiley.com/doi/full-xml/10.1111/cgf.14519","content-type":"application/xml","content-version":"vor","intended-application":"text-mining"},{"URL":"https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14519","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2023,8,21]],"date-time":"2023-08-21T01:25:20Z","timestamp":1692581120000},"score":1,"resource":{"primary":{"URL":"https://onlinelibrary.wiley.com/doi/10.1111/cgf.14519"}},"subtitle":[],"short-title":[],"issued":{"date-parts":[[2022,6]]},"references-count":66,"journal-issue":{"issue":"3","published-print":{"date-parts":[[2022,6]]}},"alternative-id":["10.1111/cgf.14519"],"URL":"http://dx.doi.org/10.1111/cgf.14519","relation":{},"ISSN":["0167-7055","1467-8659"],"subject":["Computer Graphics and Computer-Aided Design"],"container-title-short":"Computer Graphics Forum","published":{"date-parts":[[2022,6]]},"assertion":[{"value":"2022-08-12","order":2,"name":"published","label":"Published","group":{"name":"publication_history","label":"Publication History"}}],"id":"doi:10.1111/cgf.14519"}],"data":[{"id":"semreader","year":2023,"author":[{"family":"Allen Institute for Artificial Intelligence, Semantic Scholar Team"}],"title":"Semantic Reader","url":"https://www.semanticscholar.org/product/semantic-reader"},{"id":"doi:10.18653/v1/N18-3011","doi":"10.18653/v1/n18-3011","s2id":"649def34f8be52c8b66281af98ae884c09aef38b","year":2018,"author":[{"given":"Waleed","family":"Ammar","sequence":"first","affiliation":[]},{"given":"Dirk","family":"Groeneveld","sequence":"additional","affiliation":[]},{"given":"Chandra","family":"Bhagavatula","sequence":"additional","affiliation":[]},{"given":"Iz","family":"Beltagy","sequence":"additional","affiliation":[]},{"given":"Miles","family":"Crawford","sequence":"additional","affiliation":[]},{"given":"Doug","family":"Downey","sequence":"additional","affiliation":[]},{"given":"Jason","family":"Dunkelberger","sequence":"additional","affiliation":[]},{"given":"Ahmed","family":"Elgohary","sequence":"additional","affiliation":[]},{"given":"Sergey","family":"Feldman","sequence":"additional","affiliation":[]},{"given":"Vu","family":"Ha","sequence":"additional","affiliation":[]},{"given":"Rodney","family":"Kinney","sequence":"additional","affiliation":[]},{"given":"Sebastian","family":"Kohlmeier","sequence":"additional","affiliation":[]},{"given":"Kyle","family":"Lo","sequence":"additional","affiliation":[]},{"given":"Tyler","family":"Murray","sequence":"additional","affiliation":[]},{"given":"Hsu-Han","family":"Ooi","sequence":"additional","affiliation":[]},{"given":"Matthew","family":"Peters","sequence":"additional","affiliation":[]},{"given":"Joanna","family":"Power","sequence":"additional","affiliation":[]},{"given":"Sam","family":"Skjonsberg","sequence":"additional","affiliation":[]},{"given":"Lucy","family":"Wang","sequence":"additional","affiliation":[]},{"given":"Chris","family":"Willhelm","sequence":"additional","affiliation":[]},{"given":"Zheng","family":"Yuan","sequence":"additional","affiliation":[]},{"given":"Madeleine","family":"Zuylen","sequence":"additional","affiliation":[]},{"family":"oren","sequence":"additional","affiliation":[]}],"title":"Construction of the Literature Graph in Semantic Scholar","venue":"Proceedings of the 2018 Conference of the North American Chapter of\n          the Association for Computational Linguistics: Human Language\n          Technologies, Volume 3 (Industry Papers)","url":"http://dx.doi.org/10.18653/v1/N18-3011","abstract":"We describe a deployed scalable system for organizing published scientific literature into a heterogeneous graph to facilitate algorithmic manipulation and discovery. The resulting literature graph consists of more than 280M nodes, representing papers, authors, entities and various interactions between them (e.g., authorships, citations, entity mentions). We reduce literature graph construction into familiar NLP tasks (e.g., entity extraction and linking), point out research challenges due to differences from standard formulations of these tasks, and report empirical results for each task. The methods described in this paper are used to enable semantic features in www.semanticscholar.org.","tldr":"This paper reduces literature graph construction into familiar NLP tasks, point out research challenges due to differences from standard formulations of these tasks, and report empirical results for each task."},{"id":"doi:10.48550/arXiv.2203.00130","doi":"10.48550/ARXIV.2203.00130","year":2022,"author":[{"family":"August","given":"Tal"},{"family":"Wang","given":"Lucy Lu"},{"family":"Bragg","given":"Jonathan"},{"family":"Hearst","given":"Marti A."},{"family":"Head","given":"Andrew"},{"family":"Lo","given":"Kyle"}],"title":"Paper Plain: Making Medical Research Papers Approachable to Healthcare Consumers with Natural Language Processing","url":"https://arxiv.org/abs/2203.00130"},{"id":"doi:10.1109/TVCG.2018.2865119","doi":"10.1109/tvcg.2018.2865119","s2id":"c7f8316dcf12dc270cb6f1d825b7cd7155280a2d","year":2019,"author":[{"given":"Sriram Karthik","family":"Badam","sequence":"first","affiliation":[]},{"given":"Zhicheng","family":"Liu","sequence":"additional","affiliation":[]},{"given":"Niklas","family":"Elmqvist","sequence":"additional","affiliation":[]}],"title":"Elastic Documents: Coupling Text and Tables through Contextual Visualizations for Enhanced Document Reading","venue":"IEEE Transactions on Visualization and Computer Graphics","url":"http://dx.doi.org/10.1109/TVCG.2018.2865119","abstract":"Today's data-rich documents are often complex datasets in themselves, consisting of information in different formats such as text, figures, and data tables. These additional media augment the textual narrative in the document. However, the static layout of a traditional for-print document often impedes deep understanding of its content because of the need to navigate to access content scattered throughout the text. In this paper, we seek to facilitate enhanced comprehension of such documents through a contextual visualization technique that couples text content with data tables contained in the document. We parse the text content and data tables, cross-link the components using a keyword-based matching algorithm, and generate on-demand visualizations based on the reader's current focus within a document. We evaluate this technique in a user study comparing our approach to a traditional reading experience. Results from our study show that (1) participants comprehend the content better with tighter coupling of text and data, (2) the contextual visualizations enable participants to develop better summaries that capture the main data-rich insights within the document, and (3) overall, our method enables participants to develop a more detailed understanding of the document content.","tldr":"This paper parse the text content and data tables, cross-link the components using a keyword-based matching algorithm, and generate on-demand visualizations based on the reader's current focus within a document that couples text content with data tables contained in the document."},{"id":"doi:10.1145/179606.179671","doi":"10.1145/179606.179671","s2id":"bb31656a40655a5b8b0ee0d091881cc307b80c54","year":1992,"author":[{"given":"Tim","family":"Berners-Lee","sequence":"first","affiliation":[{"name":"CERN, Geneva, Switzerland"}]},{"given":"Robert","family":"Cailliau","sequence":"additional","affiliation":[{"name":"CERN, Geneva, Switzerland"}]},{"given":"Ari","family":"Luotonen","sequence":"additional","affiliation":[{"name":"CERN, Geneva, Switzerland"}]},{"given":"Henrik Frystyk","family":"Nielsen","sequence":"additional","affiliation":[{"name":"CERN, Geneva, Switzerland"}]},{"given":"Arthur","family":"Secret","sequence":"additional","affiliation":[{"name":"CERN, Geneva, Switzerland"}]}],"title":"The World-Wide Web","venue":"Communications of the ACM","url":"http://dx.doi.org/10.1145/179606.179671","abstract":"Abstract This paper describes the World-Wide Web (W3) global information system initiative, its protocols and data formats, and how it is used in practice. It discusses the plethora of different but similar information systems which exist, and how the web unifies them, creating a single information space. We describe the difficulties of information sharing between colleagues, and the basic W3 model of hypertext and searchable indexes. We list the protocols used by W3 and describe a new simple search and retrieve protocol (HTTP), and the SGML style document encoding used. We summarize the current status of the X11, NeXTStep, dumb terminal and other clients, and of the available server and gateway software.","tldr":"The difficulties of information sharing between colleagues, and the basic W3 model of hypertext and searchable indexes, are described, and a new simple search and retrieve protocol (HTTP), and the SGML style document encoding used are described."},{"id":"doi:10.1145/2851581.2892588","doi":"10.1145/2851581.2892588","s2id":"0ae334ac9609022524aeaf74d62d83fb52648402","year":2016,"author":[{"given":"Jeffrey P.","family":"Bigham","sequence":"first","affiliation":[{"name":"Carnegie Mellon University, Pittsburgh, PA, USA"}]},{"given":"Erin L.","family":"Brady","sequence":"additional","affiliation":[{"name":"Indiana University - Purdue University Indianapolis, Indianapolis, IN, USA"}]},{"given":"Cole","family":"Gleason","sequence":"additional","affiliation":[{"name":"Carnegie Mellon University, Pittsburgh, PA, USA"}]},{"given":"Anhong","family":"Guo","sequence":"additional","affiliation":[{"name":"Carnegie Mellon University, Pittsburgh, PA, USA"}]},{"given":"David A.","family":"Shamma","sequence":"additional","affiliation":[{"name":"Yahoo Labs, San Fransisco, CA, USA"}]}],"title":"An Uninteresting Tour Through Why Our Research Papers Aren't Accessible","venue":"Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems","url":"http://dx.doi.org/10.1145/2851581.2892588","abstract":"Our research is delivered as Portable Document Format (PDF) documents, and very few include basic metadata to make them accessible to people with disabilities. As a result, many people are either unable to read them efficiently or at all. Over the past few years, we have tried everything from writing guidelines and giving accessibility feedback, to enforcing accessibility standards and volunteering to make PDFs accessible ourselves. The problem with making PDFs accessible is in part due to the lack of good tools, but the complexity of the PDF format makes improving tools difficult. Making accessible research papers is as much about our choices as a community: our choice of publication format, and our choice to make accessibility a voluntary task for authors. In this paper, we overview the context in which PDFs became our publication format, the difficulty in making PDF documents accessible given current tools, what we have tried to make our PDFs more accessible, and potential options for doing better in the future.","tldr":"The context in which PDFs became their publication format, the difficulty in making PDF documents accessible given current tools, what the authors have tried to make their PDFs more accessible, and potential options for doing better in the future are overviewed."},{"id":"doi:10.1109/TVCG.2011.185","doi":"10.1109/tvcg.2011.185","s2id":"0d8d0aa31436ebe6cf926f86bc7a562ed1bd7a0d","year":2011,"author":[{"given":"M.","family":"Bostock","sequence":"first","affiliation":[]},{"given":"V.","family":"Ogievetsky","sequence":"additional","affiliation":[]},{"given":"J.","family":"Heer","sequence":"additional","affiliation":[]}],"title":"D³ Data-Driven Documents","venue":"IEEE Transactions on Visualization and Computer Graphics","url":"http://dx.doi.org/10.1109/TVCG.2011.185","abstract":"Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.","tldr":"This work shows how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components."},{"id":"csl","year":2023,"author":[{"family":"Citation Style Language"}],"title":"","url":"https://citationstyles.org/"},{"id":"doi:10.1145/3242587.3242600","doi":"10.1145/3242587.3242600","s2id":"bb287dc88d2ed2384d0af37d4ba7b3f4491cb506","year":2018,"author":[{"given":"Matthew","family":"Conlen","sequence":"first","affiliation":[{"name":"University of Washington, Seattle, WA, USA"}]},{"given":"Jeffrey","family":"Heer","sequence":"additional","affiliation":[{"name":"University of Washington, Seattle, WA, USA"}]}],"title":"Idyll: A Markup Language for Authoring and Publishing Interactive Articles on the Web","venue":"Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology","url":"http://dx.doi.org/10.1145/3242587.3242600"},{"id":"doi:10.1145/3472749.3474731","doi":"10.1145/3472749.3474731","s2id":"39e300a3c3179b1c0cb538070ac948cb2e63be7c","year":2021,"author":[{"given":"Matthew","family":"Conlen","sequence":"first","affiliation":[{"name":"University of Washington, United States"}]},{"given":"Megan","family":"Vo","sequence":"additional","affiliation":[{"name":"Idyll Collective, United States"}]},{"given":"Alan","family":"Tan","sequence":"additional","affiliation":[{"name":"Idyll Collective, United States"}]},{"given":"Jeffrey","family":"Heer","sequence":"additional","affiliation":[{"name":"Paul G. Allen School of Computer Science &amp; Engineering University of Washington, United States"}]}],"title":"Idyll Studio: A Structured Editor for Authoring Interactive & Data-Driven Articles","venue":"The 34th Annual ACM Symposium on User Interface Software and Technology","url":"http://dx.doi.org/10.1145/3472749.3474731","abstract":"Interactive articles are an effective medium of communication in education, journalism, and scientific publishing, yet are created using complex general-purpose programming tools. We present Idyll Studio, a structured editor for authoring and publishing interactive and data-driven articles. We extend the Idyll framework to support reflective documents, which can inspect and modify their underlying program at runtime, and show how this functionality can be used to reify the constituent parts of a reactive document model—components, text, state, and styles—in an expressive, interoperable, and easy-to-learn graphical interface. In a study with 18 diverse participants, all could perform basic editing and composition, use datasets and variables, and specify relationships between components. Most could choreograph interactive visualizations and dynamic text, although some struggled with advanced uses requiring unstructured code editing. Our findings suggest Idyll Studio lowers the threshold for non-experts to create interactive articles and allows experts to rapidly specify a wide range of article designs.","tldr":"The Idyll framework is extended to support reflective documents, which can inspect and modify their underlying program at runtime, and this functionality can be used to reify the constituent parts of a reactive document model in an expressive, interoperable, and easy-to-learn graphical interface."},{"id":"doi:10.48550/arXiv.2205.09858","doi":"10.48550/ARXIV.2205.09858","s2id":"8b369ad4d7f30a6ff84e7c12ac61d78da32837a2","year":2022,"author":[{"family":"Conlen","given":"Matthew"},{"family":"Heer","given":"Jeffrey"}],"title":"Fidyll: A Compiler for Cross-Format Data Stories & Explorable Explanations","venue":"arXiv.org","url":"https://arxiv.org/abs/2205.09858","abstract":"Narrative visualization is a powerful communicative tool that can take on various formats such as interactive articles, slideshows, and data videos. These formats each have their strengths and weaknesses, but existing authoring tools only support one output target. We conducted a series of formative interviews with seven domain experts to understand needs and practices around cross-format data stories, and developed Fidyll, a cross-format compiler for authoring interactive data stories and explorable explanations. Our open-source tool can be used to rapidly create formats including static articles, low-motion articles, interactive articles, slideshows, and videos. We evaluate our system through a series of real-world usage scenarios, showing how it benefits authors in the domains of data journalism, scientific publishing, and nonprofit advocacy. We show how Fidyll, provides expressive leverage by reducing the amount of non-narrative markup that authors need to write by 80-90% compared to Idyll, an existing markup language for authoring interactive articles.","tldr":"Fidyll, a cross-format compiler for authoring interactive data stories and explorable explanations, is developed and evaluated through a series of real-world usage scenarios, showing how it benefits authors in the domains of data journalism, scientific publishing, and nonprofit advocacy."},{"id":"nota","year":2023,"author":[{"given":"Will","family":"Crichton"}],"title":"A New Medium for Communicating Research on Programming Languages","url":"https://willcrichton.net/nota/"},{"id":"curvenote","year":2023,"author":[{"family":"Curvenote"}],"title":"","url":"https://curvenote.com/"},{"id":"doi:10.1145/3290605.3300295","doi":"10.1145/3290605.3300295","s2id":"badd5ed7bf6d6f0491a7b7ee612c1ce2a19c78ac","year":2019,"author":[{"given":"Pierre","family":"Dragicevic","sequence":"first","affiliation":[{"name":"Inria, Saclay, France"}]},{"given":"Yvonne","family":"Jansen","sequence":"additional","affiliation":[{"name":"CNRS - Sorbonne Université, Paris, France"}]},{"given":"Abhraneel","family":"Sarma","sequence":"additional","affiliation":[{"name":"University of Michigan, Ann Arbor, MI, USA"}]},{"given":"Matthew","family":"Kay","sequence":"additional","affiliation":[{"name":"University of Michigan, Ann Arbor, MI, USA"}]},{"given":"Fanny","family":"Chevalier","sequence":"additional","affiliation":[{"name":"University of Toronto, Toronto, ON, Canada"}]}],"title":"Increasing the Transparency of Research Papers with Explorable Multiverse Analyses","venue":"Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems","url":"http://dx.doi.org/10.1145/3290605.3300295","abstract":"We present explorable multiverse analysis reports, a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two recent ideas: i) multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and ii) explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation. Based on five examples and a design space analysis, we show how combining those two ideas can complement existing reporting approaches and constitute a step towards more transparent research papers.","tldr":"Explorable multiverse analysis reports is presented, a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself, a step towards more transparent research papers."},{"id":"katex","year":2023,"author":[{"given":"Emily","family":"Eisenberg"},{"given":"Sophie","family":"Alpert"}],"title":"KaTeX: The fastest math typesetting library for the web","url":"https://katex.org"},{"id":"doi:10.48550/arXiv.2205.04561","doi":"10.48550/ARXIV.2205.04561","s2id":"d1ca07561b24afe8b1bd18dd1c239dbbbd221964","year":2022,"author":[{"family":"Fok","given":"Raymond"},{"family":"Kambhamettu","given":"Hita"},{"family":"Soldaini","given":"Luca"},{"family":"Bragg","given":"Jonathan"},{"family":"Lo","given":"Kyle"},{"family":"Head","given":"Andrew"},{"family":"Hearst","given":"Marti A."},{"family":"Weld","given":"Daniel S."}],"title":"Scim: Intelligent Skimming Support for Scientific Papers","venue":"arXiv","url":"https://arxiv.org/abs/2205.04561","abstract":"Researchers are expected to keep up with an immense literature, yet often find it prohibitively time-consuming to do so. This paper ex-plores how intelligent agents can help scaffold in-situ information seeking across scientific papers. Specifically, we present Scim, an AI-augmented reading interface designed to help researchers skim papers by automatically identifying, classifying, and highlighting salient sentences, organized into rhetorical facets rooted in common information needs. Using Scim as a design probe, we explore the benefits and drawbacks of imperfect AI assistance within an augmented reading interface. We found researchers used Scim in several different ways: from reading primarily in the ‘highlight browser’ (side panel) to making multiple passes through the paper with different facets activated (e.g., focusing solely on objective and novelty in their first pass). From our study, we identify six key design recommendations and avenues for future research in augmented reading interfaces.","tldr":"Scim is presented, an AI-augmented reading interface designed to help researchers skim papers by automatically identifying, classifying, and highlighting salient sentences, organized into rhetorical facets rooted in common information needs."},{"id":"doi:10.1126/science.aao0185","doi":"10.1126/science.aao0185","s2id":"233e702fa7ccfd55061680e3af9bd2f7efe5e08f","year":2018,"author":[{"ORCID":"http://orcid.org/0000-0002-9039-4730","authenticated-orcid":true,"given":"Santo","family":"Fortunato","sequence":"first","affiliation":[{"name":"Center for Complex Networks and Systems Research, School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN 47408, USA."},{"name":"Indiana University Network Science Institute, Indiana University, Bloomington, IN 47408, USA."}]},{"given":"Carl T.","family":"Bergstrom","sequence":"additional","affiliation":[{"name":"Department of Biology, University of Washington, Seattle, WA 98195-1800, USA."}]},{"ORCID":"http://orcid.org/0000-0002-3321-6137","authenticated-orcid":true,"given":"Katy","family":"Börner","sequence":"additional","affiliation":[{"name":"Indiana University Network Science Institute, Indiana University, Bloomington, IN 47408, USA."},{"name":"Cyberinfrastructure for Network Science Center, School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN 47408, USA."}]},{"ORCID":"http://orcid.org/0000-0001-9838-0707","authenticated-orcid":true,"given":"James A.","family":"Evans","sequence":"additional","affiliation":[{"name":"Department of Sociology, University of Chicago, Chicago, IL 60637, USA."}]},{"given":"Dirk","family":"Helbing","sequence":"additional","affiliation":[{"name":"Computational Social Science, ETH Zurich, Zurich, Switzerland."}]},{"given":"Staša","family":"Milojević","sequence":"additional","affiliation":[{"name":"Center for Complex Networks and Systems Research, School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN 47408, USA."}]},{"ORCID":"http://orcid.org/0000-0002-0955-3483","authenticated-orcid":true,"given":"Alexander M.","family":"Petersen","sequence":"additional","affiliation":[{"name":"Ernest and Julio Gallo Management Program, School of Engineering, University of California, Merced, CA 95343, USA."}]},{"given":"Filippo","family":"Radicchi","sequence":"additional","affiliation":[{"name":"Center for Complex Networks and Systems Research, School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN 47408, USA."}]},{"ORCID":"http://orcid.org/0000-0002-7558-1028","authenticated-orcid":true,"given":"Roberta","family":"Sinatra","sequence":"additional","affiliation":[{"name":"Center for Network Science, Central European University, Budapest 1052, Hungary."},{"name":"Department of Mathematics, Central European University, Budapest 1051, Hungary."},{"name":"Institute for Network Science, Northeastern University, Boston, MA 02115, USA."}]},{"given":"Brian","family":"Uzzi","sequence":"additional","affiliation":[{"name":"Kellogg School of Management, Northwestern University, Evanston, IL 60208, USA."},{"name":"Northwestern Institute on Complex Systems, Northwestern University, Evanston, IL 60208, USA."}]},{"given":"Alessandro","family":"Vespignani","sequence":"additional","affiliation":[{"name":"Institute for Network Science, Northeastern University, Boston, MA 02115, USA."},{"name":"Laboratory for the Modeling of Biological and Sociotechnical Systems, Northeastern University, Boston, MA 02115, USA."},{"name":"ISI Foundation, Turin 10133, Italy."}]},{"ORCID":"http://orcid.org/0000-0001-8249-1752","authenticated-orcid":true,"given":"Ludo","family":"Waltman","sequence":"additional","affiliation":[{"name":"Centre for Science and Technology Studies, Leiden University, Leiden, Netherlands."}]},{"ORCID":"http://orcid.org/0000-0002-7054-2206","authenticated-orcid":true,"given":"Dashun","family":"Wang","sequence":"additional","affiliation":[{"name":"Kellogg School of Management, Northwestern University, Evanston, IL 60208, USA."},{"name":"Northwestern Institute on Complex Systems, Northwestern University, Evanston, IL 60208, USA."}]},{"ORCID":"http://orcid.org/0000-0002-4028-3522","authenticated-orcid":true,"given":"Albert-László","family":"Barabási","sequence":"additional","affiliation":[{"name":"Center for Network Science, Central European University, Budapest 1052, Hungary."},{"name":"Institute for Network Science, Northeastern University, Boston, MA 02115, USA."},{"name":"Center for Cancer Systems Biology, Dana-Farber Cancer Institute, Boston, MA 02115, USA."}]}],"title":"Science of science","venue":"Science","url":"http://dx.doi.org/10.1126/science.aao0185","abstract":"The whys and wherefores of SciSci The science of science (SciSci) is based on a transdisciplinary approach that uses large data sets to study the mechanisms underlying the doing of science—from the choice of a research problem to career trajectories and progress within a field. In a Review, Fortunato et al. explain that the underlying rationale is that with a deeper understanding of the precursors of impactful science, it will be possible to develop systems and policies that improve each scientist's ability to succeed and enhance the prospects of science as a whole. Science, this issue p. eaao0185 BACKGROUND The increasing availability of digital data on scholarly inputs and outputs—from research funding, productivity, and collaboration to paper citations and scientist mobility—offers unprecedented opportunities to explore the structure and evolution of science. The science of science (SciSci) offers a quantitative understanding of the interactions among scientific agents across diverse geographic and temporal scales: It provides insights into the conditions underlying creativity and the genesis of scientific discovery, with the ultimate goal of developing tools and policies that have the potential to accelerate science. In the past decade, SciSci has benefited from an influx of natural, computational, and social scientists who together have developed big data–based capabilities for empirical analysis and generative modeling that capture the unfolding of science, its institutions, and its workforce. The value proposition of SciSci is that with a deeper understanding of the factors that drive successful science, we can more effectively address environmental, societal, and technological problems. ADVANCES Science can be described as a complex, self-organizing, and evolving network of scholars, projects, papers, and ideas. This representation has unveiled patterns characterizing the emergence of new scientific fields through the study of collaboration networks and the path of impactful discoveries through the study of citation networks. Microscopic models have traced the dynamics of citation accumulation, allowing us to predict the future impact of individual papers. SciSci has revealed choices and trade-offs that scientists face as they advance both their own careers and the scientific horizon. For example, measurements indicate that scholars are risk-averse, preferring to study topics related to their current expertise, which constrains the potential of future discoveries. Those willing to break this pattern engage in riskier careers but become more likely to make major breakthroughs. Overall, the highest-impact science is grounded in conventional combinations of prior work but features unusual combinations. Last, as the locus of research is shifting into teams, SciSci is increasingly focused on the impact of team research, finding that small teams tend to disrupt science and technology with new ideas drawing on older and less prevalent ones. In contrast, large teams tend to develop recent, popular ideas, obtaining high, but often short-lived, impact. OUTLOOK SciSci offers a deep quantitative understanding of the relational structure between scientists, institutions, and ideas because it facilitates the identification of fundamental mechanisms responsible for scientific discovery. These interdisciplinary data-driven efforts complement contributions from related fields such as scientometrics and the economics and sociology of science. Although SciSci seeks long-standing universal laws and mechanisms that apply across various fields of science, a fundamental challenge going forward is accounting for undeniable differences in culture, habits, and preferences between different fields and countries. This variation makes some cross-domain insights difficult to appreciate and associated science policies difficult to implement. The differences among the questions, data, and skills specific to each discipline suggest that further insights can be gained from domain-specific SciSci studies, which model and identify opportunities adapted to the needs of individual research fields. The complexity of science. Science can be seen as an expanding and evolving network of ideas, scholars, and papers. SciSci searches for universal and domain-specific laws underlying the structure and dynamics of science. ILLUSTRATION: NICOLE SAMAY Identifying fundamental drivers of science and developing predictive models to capture its evolution are instrumental for the design of policies that can improve the scientific enterprise—for example, through enhanced career paths for scientists, better performance evaluation for organizations hosting research, discovery of novel effective funding vehicles, and even identification of promising regions along the scientific frontier. The science of science uses large-scale data on the production of science to search for universal and domain-specific patterns. Here, we review recent developments in this transdisciplinary field.","tldr":"SciSci has revealed choices and trade-offs that scientists face as they advance both their own careers and the scientific horizon, and offers a deep quantitative understanding of the relational structure between scientists, institutions, and ideas, which facilitates the identification of fundamental mechanisms responsible for scientific discovery."},{"id":"gscholar","year":2023,"author":[{"family":"Google Scholar"}],"title":"","url":"https://scholar.google.com/"},{"id":"puppeteer","year":2023,"author":[{"family":"Google, Inc."}],"title":"Puppeteer","url":"https://pptr.dev/"},{"id":"markdown","year":2004,"author":[{"given":"John","family":"Gruber"}],"title":"Markdown","url":"https://daringfireball.net/projects/markdown/"},{"id":"doi:10.1145/369825.369829","doi":"10.1145/369825.369829","s2id":"56f45398e48e2c9f2f61a046cd1a3a7ea84da8c0","year":2001,"author":[{"given":"Steve","family":"Harrison","sequence":"first","affiliation":[{"name":"Xerox Palo Alto, Reasearch Center, Palo Alto, CA"}]},{"given":"Scott","family":"Minneman","sequence":"additional","affiliation":[{"name":"Xerox Palo Alto, Reasearch Center, Palo Alto, CA"}]},{"given":"Maribeth","family":"Back","sequence":"additional","affiliation":[{"name":"Xerox Palo Alto, Reasearch Center, Palo Alto, CA"}]},{"given":"Anne","family":"Balsamo","sequence":"additional","affiliation":[{"name":"Xerox Palo Alto, Reasearch Center, Palo Alto, CA"}]},{"given":"Mark","family":"Chow","sequence":"additional","affiliation":[{"name":"Xerox Palo Alto, Reasearch Center, Palo Alto, CA"}]},{"given":"Rich","family":"Gold","sequence":"additional","affiliation":[]},{"given":"Matt","family":"Gorbet","sequence":"additional","affiliation":[]},{"given":"Dale","family":"Mac Donald","sequence":"additional","affiliation":[]}],"title":"Design: the what of XFR: eXperiments in the future of reading","venue":"Interactions","url":"http://dx.doi.org/10.1145/369825.369829","abstract":"Step up to the joystick on the exhibit to the right. A cartoon image of a young boy is projected on the screen. Kids crowd in around you as you read about Henry and his world. (See Figure 1.) There is a world of cartoon images. Lines trail off to small drawings falling away as though seen through a fisheye. As you push the joystick, another image of Henry rolls into view along one of the lines, and a comic-book dialog bubble appears. The story Henry tells is of the things in his imagination and his everyday world. One image leads to the next and then to the next. Over to the left of Henry is a sort of work bench with a touch-screen workstation sitting on it. No pictures on the screen this time, just a title (“Harry the Ape”) and a long paragraph of text. The story is about the creatures that live in Harry’s fur. Sprinkled around A Glimpse of XFR","tldr":"Step up to the joystick on the exhibit to the right and a cartoon image of a young boy is projected on the screen, and a comic-book dialog bubble appears, and the story Henry tells is of the things in his imagination and his everyday world."},{"id":"doi:10.1145/3411764.3445648","doi":"10.1145/3411764.3445648","s2id":"0079692cd41bbf56e27f0744ec0fd595007dc9e7","year":2020,"author":[{"given":"Andrew","family":"Head","sequence":"first","affiliation":[{"name":"Computer Science, UC Berkeley, United States"}]},{"given":"Kyle","family":"Lo","sequence":"additional","affiliation":[{"name":"Allen Institute for Artificial Intelligence, United States"}]},{"given":"Dongyeop","family":"Kang","sequence":"additional","affiliation":[{"name":"Computer Science, UC Berkeley, United States"}]},{"given":"Raymond","family":"Fok","sequence":"additional","affiliation":[{"name":"Paul G. Allen School of Computer Science &amp; Engineering University of Washington, United States"}]},{"given":"Sam","family":"Skjonsberg","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Daniel S.","family":"Weld","sequence":"additional","affiliation":[{"name":"Paul G. Allen School of Computer Science &amp; Engineering University of Washington and Allen Institute for AI, United States"}]},{"given":"Marti A.","family":"Hearst","sequence":"additional","affiliation":[{"name":"Computer Science, UC Berkeley, United States"}]}],"title":"Augmenting Scientific Papers with Just-in-Time, Position-Sensitive Definitions of Terms and Symbols","venue":"Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems","url":"http://dx.doi.org/10.1145/3411764.3445648","abstract":"Despite the central importance of research papers to scientific progress, they can be difficult to read. Comprehension is often stymied when the information needed to understand a passage resides somewhere else—in another section, or in another paper. In this work, we envision how interfaces can bring definitions of technical terms and symbols to readers when and where they need them most. We introduce ScholarPhi, an augmented reading interface with four novel features: (1) tooltips that surface position-sensitive definitions from elsewhere in a paper, (2) a filter over the paper that “declutters” it to reveal how the term or symbol is used across the paper, (3) automatic equation diagrams that expose multiple definitions in parallel, and (4) an automatically generated glossary of important terms and symbols. A usability study showed that the tool helps researchers of all experience levels read papers. Furthermore, researchers were eager to have ScholarPhi’s definitions available to support their everyday reading.","tldr":"This work introduces ScholarPhi, an augmented reading interface with four novel features: tooltips that surface position-sensitive definitions from elsewhere in a paper, a filter over the paper that “declutters” it to reveal how the term or symbol is used across the paper, automatic equation diagrams that expose multiple definitions in parallel, and an automatically generated glossary of important terms and symbols."},{"id":"doi:10.1145/3491102.3501932","doi":"10.1145/3491102.3501932","s2id":"083eb124828f2870c8e935f7d9938bcaddf8a24f","year":2022,"author":[{"given":"Andrew","family":"Head","sequence":"first","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Amber","family":"Xie","sequence":"additional","affiliation":[{"name":"UC Berkeley, United States"}]},{"given":"Marti A.","family":"Hearst","sequence":"additional","affiliation":[{"name":"UC Berkeley, United States"}]}],"title":"Math Augmentation: How Authors Enhance the Readability of Formulas using Novel Visual Design Practices","venue":"CHI Conference on Human Factors in Computing Systems","url":"http://dx.doi.org/10.1145/3491102.3501932","abstract":"With the increasing growth and impact of machine learning and other math-intensive fields, it is more important than ever to broaden access to mathematical notation. Can new visual and interactive displays help a wider readership successfully engage with notation? This paper provides the first detailed qualitative analysis of math augmentation—the practice of embellishing notation with novel visual design patterns to improve its readability. We present two qualitative studies of the practice of math augmentation. First is an analysis of 1.1k augmentations to 281 formulas in 47 blogs, textbooks, and other documents containing mathematical expressions. Second is an interview study with 12 authors who had previously designed custom math augmentations (“maugs”). This paper contributes a comprehensive inventory of the kinds of maugs that appear in math documents, and a detailed account of how authors’ tools ought to be redesigned to support efficient creation of math augmentations. These studies open a critical new design space for HCI researchers and interface designers.","tldr":"A comprehensive inventory of the kinds of maugs that appear in math documents, and a detailed account of how authors’ tools ought to be redesigned to support efficient creation of math augmentations are contributed."},{"id":"doi:10.1109/VIS49827.2021.9623323","doi":"10.1109/vis49827.2021.9623323","s2id":"c6c58c8f7138619830539e61f9b752347c16f2fe","year":2021,"author":[{"given":"Jeffrey","family":"Heer","sequence":"first","affiliation":[{"name":"University of Washiington"}]}],"title":"Fast & Accurate Gaussian Kernel Density Estimation","venue":"2021 IEEE Visualization Conference (VIS)","url":"http://dx.doi.org/10.1109/VIS49827.2021.9623323","abstract":"Kernel density estimation (KDE) models a discrete sample of data as a continuous distribution, supporting the construction of visualizations such as violin plots, heatmaps, and contour plots. This paper draws on the statistics and image processing literature to survey efficient and scalable density estimation techniques for the common case of Gaussian kernel functions. We evaluate the accuracy and running time of these methods across multiple visualization contexts and find that the combination of linear binning and a recursive filter approximation by Deriche efficiently produces pixel-perfect estimates across a compelling range of kernel bandwidths.","tldr":"Efficient and scalable density estimation techniques for the common case of Gaussian kernel functions are surveyed and it is found that the combination of linear binning and a recursive filter approximation by Deriche efficiently produces pixel-perfect estimates across a compelling range of kernel bandwidths."},{"id":"doi:10.1145/142750.142751","doi":"10.1145/142750.142751","s2id":"d3d61d8dd03347986484c3fdc8b3b0e3550049c5","year":1992,"author":[{"given":"William C.","family":"Hill","sequence":"first","affiliation":[]},{"given":"James D.","family":"Hollan","sequence":"additional","affiliation":[]},{"given":"Dave","family":"Wroblewski","sequence":"additional","affiliation":[]},{"given":"Tim","family":"McCandless","sequence":"additional","affiliation":[]}],"title":"Edit wear and read wear","venue":"Proceedings of the SIGCHI conference on Human factors in computing systems  - CHI '92","url":"http://dx.doi.org/10.1145/142750.142751","abstract":"We describe two applications that illustrate the idea of computational wear in the domain of document processing. By graphically depicting the history of author and reader interactions with documents, these applications offer otherwise unavailable information to guide work. We discuss how their design accords with a theory of professional work and an informational physics perspective on interface design.","tldr":"Two applications are described that illustrate the idea of computational wear in the domain of document processing by graphically depicting the history of author and reader interactions with documents by offering otherwise unavailable information to guide work."},{"id":"doi:10.1371/journal.pcbi.1007128","doi":"10.1371/journal.pcbi.1007128","s2id":"50a21d90ccf2b04c9ffa953387a16da4c9fba288","year":2019,"author":[{"ORCID":"http://orcid.org/0000-0002-3012-7446","authenticated-orcid":true,"given":"Daniel S.","family":"Himmelstein","sequence":"first","affiliation":[]},{"ORCID":"http://orcid.org/0000-0002-4655-3773","authenticated-orcid":true,"given":"Vincent","family":"Rubinetti","sequence":"additional","affiliation":[]},{"ORCID":"http://orcid.org/0000-0003-3928-5050","authenticated-orcid":true,"given":"David R.","family":"Slochower","sequence":"additional","affiliation":[]},{"given":"Dongbo","family":"Hu","sequence":"additional","affiliation":[]},{"ORCID":"http://orcid.org/0000-0002-0144-0564","authenticated-orcid":true,"given":"Venkat S.","family":"Malladi","sequence":"additional","affiliation":[]},{"ORCID":"http://orcid.org/0000-0001-8713-9213","authenticated-orcid":true,"given":"Casey S.","family":"Greene","sequence":"additional","affiliation":[]},{"ORCID":"http://orcid.org/0000-0002-5324-9833","authenticated-orcid":true,"given":"Anthony","family":"Gitter","sequence":"additional","affiliation":[]}],"title":"Open collaborative writing with Manubot","venue":"PLOS Computational Biology","url":"http://dx.doi.org/10.1371/journal.pcbi.1007128","abstract":"Open, collaborative research is a powerful paradigm that can immensely strengthen the scientific process by integrating broad and diverse expertise. However, traditional research and multi-author writing processes break down at scale. We present new software named Manubot, available at https://manubot.org, to address the challenges of open scholarly writing. Manubot adopts the contribution workflow used by many large-scale open source software projects to enable collaborative authoring of scholarly manuscripts. With Manubot, manuscripts are written in Markdown and stored in a Git repository to precisely track changes over time. By hosting manuscript repositories publicly, such as on GitHub, multiple authors can simultaneously propose and review changes. A cloud service automatically evaluates proposed changes to catch errors. Publication with Manubot is continuous: When a manuscript’s source changes, the rendered outputs are rebuilt and republished to a web page. Manubot automates bibliographic tasks by implementing citation by identifier, where users cite persistent identifiers (e.g. DOIs, PubMed IDs, ISBNs, URLs), whose metadata is then retrieved and converted to a user-specified style. Manubot modernizes publishing to align with the ideals of open science by making it transparent, reproducible, immediate, versioned, collaborative, and free of charge.","tldr":"Manubot modernizes publishing to align with the ideals of open science by making it transparent, reproducible, immediate, versioned, collaborative, and free of charge."},{"id":"doi:10.48550/arXiv.2205.02007","doi":"10.48550/ARXIV.2205.02007","year":2022,"author":[{"family":"Hope","given":"Tom"},{"family":"Downey","given":"Doug"},{"family":"Etzioni","given":"Oren"},{"family":"Weld","given":"Daniel S."},{"family":"Horvitz","given":"Eric"}],"title":"A Computational Inflection for Scientific Discovery","url":"https://arxiv.org/abs/2205.02007"},{"id":"jupyterbook","year":2023,"author":[{"family":"Jupyter Book"}],"title":"","url":"https://jupyterbook.org/"},{"id":"doi:10.48550/arXiv.2010.05129","doi":"10.48550/ARXIV.2010.05129","year":2020,"author":[{"family":"Kang","given":"Dongyeop"},{"family":"Head","given":"Andrew"},{"family":"Sidhu","given":"Risham"},{"family":"Lo","given":"Kyle"},{"family":"Weld","given":"Daniel S."},{"family":"Hearst","given":"Marti A."}],"title":"Document-Level Definition Detection in Scholarly Documents: Existing Models, Error Analyses, and Future Directions","url":"https://arxiv.org/abs/2010.05129"},{"id":"doi:10.1145/3242587.3242617","doi":"10.1145/3242587.3242617","s2id":"7fa1a358ca20d7d169fd57c163c3328d954965c7","year":2018,"author":[{"given":"Dae Hyun","family":"Kim","sequence":"first","affiliation":[{"name":"Stanford University, Stanford, CA, USA"}]},{"given":"Enamul","family":"Hoque","sequence":"additional","affiliation":[{"name":"Stanford University, Stanford, CA, USA"}]},{"given":"Juho","family":"Kim","sequence":"additional","affiliation":[{"name":"Korea Advanced Institute of Science and Technology, Daejeon, Rebublic of Korea"}]},{"given":"Maneesh","family":"Agrawala","sequence":"additional","affiliation":[{"name":"Stanford University, Stanford, CA, USA"}]}],"title":"Facilitating Document Reading by Linking Text and Tables","venue":"Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology","url":"http://dx.doi.org/10.1145/3242587.3242617","abstract":"Document authors commonly use tables to support arguments presented in the text. But, because tables are usually separate from the main body text, readers must split their attention between different parts of the document. We present an interactive document reader that automatically links document text with corresponding table cells. Readers can select a sentence (or tables cells) and our reader highlights the relevant table cells (or sentences). We provide an automatic pipeline for extracting such references between sentence text and table cells for existing PDF documents that combines structural analysis of tables with natural language processing and rule-based matching. On a test corpus of 330 (sentence, table) pairs, our pipeline correctly extracts 48.8% of the references. An additional 30.5% contain only false negatives (FN) errors -- the reference is missing table cells. The remaining 20.7% contain false positives (FP) errors -- the reference includes extraneous table cells and could therefore mislead readers. A user study finds that despite such errors, our interactive document reader helps readers match sentences with corresponding table cells more accurately and quickly than a baseline document reader.","tldr":"An automatic pipeline for extracting references between sentence text and table cells for existing PDF documents is provided that combines structural analysis of tables with natural language processing and rule-based matching."},{"id":"doi:10.48550/arXiv.2301.10140","doi":"10.48550/ARXIV.2301.10140","s2id":"cb92a7f9d9dbcf9145e32fdfa0e70e2a6b828eb1","year":2023,"author":[{"family":"Kinney","given":"Rodney"},{"family":"Anastasiades","given":"Chloe"},{"family":"Authur","given":"Russell"},{"family":"Beltagy","given":"Iz"},{"family":"Bragg","given":"Jonathan"},{"family":"Buraczynski","given":"Alexandra"},{"family":"Cachola","given":"Isabel"},{"family":"Candra","given":"Stefan"},{"family":"Chandrasekhar","given":"Yoganand"},{"family":"Cohan","given":"Arman"},{"family":"Crawford","given":"Miles"},{"family":"Downey","given":"Doug"},{"family":"Dunkelberger","given":"Jason"},{"family":"Etzioni","given":"Oren"},{"family":"Evans","given":"Rob"},{"family":"Feldman","given":"Sergey"},{"family":"Gorney","given":"Joseph"},{"family":"Graham","given":"David"},{"family":"Hu","given":"Fangzhou"},{"family":"Huff","given":"Regan"},{"family":"King","given":"Daniel"},{"family":"Kohlmeier","given":"Sebastian"},{"family":"Kuehl","given":"Bailey"},{"family":"Langan","given":"Michael"},{"family":"Lin","given":"Daniel"},{"family":"Liu","given":"Haokun"},{"family":"Lo","given":"Kyle"},{"family":"Lochner","given":"Jaron"},{"family":"MacMillan","given":"Kelsey"},{"family":"Murray","given":"Tyler"},{"family":"Newell","given":"Chris"},{"family":"Rao","given":"Smita"},{"family":"Rohatgi","given":"Shaurya"},{"family":"Sayre","given":"Paul"},{"family":"Shen","given":"Zejiang"},{"family":"Singh","given":"Amanpreet"},{"family":"Soldaini","given":"Luca"},{"family":"Subramanian","given":"Shivashankar"},{"family":"Tanaka","given":"Amber"},{"family":"Wade","given":"Alex D."},{"family":"Wagner","given":"Linda"},{"family":"Wang","given":"Lucy Lu"},{"family":"Wilhelm","given":"Chris"},{"family":"Wu","given":"Caroline"},{"family":"Yang","given":"Jiangjiang"},{"family":"Zamarron","given":"Angele"},{"family":"Van Zuylen","given":"Madeleine"},{"family":"Weld","given":"Daniel S."}],"title":"The Semantic Scholar Open Data Platform","venue":"arXiv.org","url":"https://arxiv.org/abs/2301.10140","abstract":"The volume of scientific output is creating an urgent need for automated tools to help scientists keep up with developments in their field. Semantic Scholar (S2) is an open data platform and website aimed at accelerating science by helping scholars discover and understand scientific literature. We combine public and proprietary data sources using state-of-theart techniques for scholarly PDF content extraction and automatic knowledge graph construction to build the Semantic Scholar Academic Graph, the largest open scientific literature graph to-date, with 200M+ papers, 80M+ authors, 550M+ paper-authorship edges, and 2.4B+ citation edges. The graph includes advanced semantic features such as structurally parsed text, natural language summaries, and vector embeddings. In this paper, we describe the components of the S2 data processing pipeline and the associated APIs offered by the platform. We will update this living document to reflect changes as we add new data offerings and improve existing services.","tldr":"This paper combines public and proprietary data sources using state-of-theart techniques for scholarly PDF content extraction and automatic knowledge graph construction to build the Semantic Scholar Academic Graph, the largest open scientific literature graph to-date."},{"id":"doi:10.1145/2807442.2807446","doi":"10.1145/2807442.2807446","s2id":"18feb72ae815f9127498a7a5b2f46d5b7fe7f45d","year":2015,"author":[{"given":"Clemens N.","family":"Klokmose","sequence":"first","affiliation":[{"name":"Aarhus University, Aarhus, Denmark"}]},{"given":"James R.","family":"Eagan","sequence":"additional","affiliation":[{"name":"Télécom ParisTech -- CNRS LTCI UMR 5141, Paris, France"}]},{"given":"Siemen","family":"Baader","sequence":"additional","affiliation":[{"name":"Aarhus University, Aarhus, Denmark"}]},{"given":"Wendy","family":"Mackay","sequence":"additional","affiliation":[{"name":"INRIA &amp; Univ Paris-Sud, Paris, France"}]},{"given":"Michel","family":"Beaudouin-Lafon","sequence":"additional","affiliation":[{"name":"Univ Paris-Sud &amp; CNRS, Orsay, France"}]}],"title":"<i>Webstrates</i>: Shareable Dynamic Media","venue":"Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology","url":"http://dx.doi.org/10.1145/2807442.2807446","abstract":"We revisit Alan Kay's early vision of dynamic media that blurs the distinction between documents and applications. We introduce shareable dynamic media that are malleable by users, who may appropriate them in idiosyncratic ways; shareable among users, who collaborate on multiple aspects of the media; and distributable across diverse devices and platforms. We present Webstrates, an environment for exploring shareable dynamic media. Webstrates augment web technology with real-time sharing. They turn web pages into substrates, i.e. software entities that act as applications or documents depending upon use. We illustrate Webstrates with two implemented case studies: users collaboratively author an article with functionally and visually different editors that they can personalize and extend at run-time; and they orchestrate its presentation and audience participation with multiple devices. We demonstrate the simplicity and generative power of Webstrates with three additional prototypes and evaluate it from a systems perspective.","tldr":"This work revisits Alan Kay's early vision of dynamic media that blurs the distinction between documents and applications and presents Webstrates, an environment for exploring shareable dynamicMedia, which turns web pages into substrates, i.e. software entities that act as applications or documents depending upon use."},{"id":"jupyter","year":2016,"author":[{"given":"Thomas","family":"Kluyver"},{"given":"Benjamin","family":"Ragan-Kelley"},{"given":"Fernando","family":"Pérez"},{"given":"Brian E","family":"Granger"},{"given":"Matthias","family":"Bussonnier"},{"given":"Jonathan","family":"Frederic"},{"given":"Kyle","family":"Kelley"},{"given":"Jessica B","family":"Hamrick"},{"given":"Jason","family":"Grout"},{"given":"Sylvain","family":"Corlay"},{"family":"others"}],"title":"Jupyter Notebooks-a publishing format for reproducible computational workflows."},{"id":"tex","year":1979,"author":[{"given":"D. E.","family":"Knuth"}],"title":"TEX and METAFONT: New directions in typesetting"},{"id":"doi:10.1093/comjnl/27.2.97","doi":"10.1093/comjnl/27.2.97","s2id":"d2742de7aa119517e2f9c254cd3ce3b90abf2ce1","year":1984,"author":[{"given":"D. E.","family":"Knuth","sequence":"first","affiliation":[]}],"title":"Literate Programming","venue":"The Computer Journal","url":"http://dx.doi.org/10.1093/comjnl/27.2.97","abstract":"From the Publisher: \nIncluding early papers on structured programming, as well as the Computer Journal article that launched its study, this anthology of essays from the inventor of literate programming also contains excerpts from the programs for TEX and METAFONT and CWEB, a system for literate programming in C and related languages.","tldr":"This anthology of essays from the inventor of literate programming also contains excerpts from the programs for TEX and METAFONT and CWEB, a system for Literate programming in C and related languages."},{"id":"latex","year":1985,"author":[{"given":"Leslie","family":"Lamport"}],"title":"LaTeX: A Document Preparation System"},{"id":"doi:10.1007/978-3-642-04346-8_62","doi":"10.1007/978-3-642-04346-8_62","s2id":"d55c8fbb7f314b5599c69d89f5993999cf5553af","year":2009,"author":[{"given":"Patrice","family":"Lopez","sequence":"first","affiliation":[]}],"title":"GROBID: Combining Automatic Bibliographic Data Recognition and Term Extraction for Scholarship Publications","venue":"Research and Advanced Technology for Digital Libraries","url":"http://dx.doi.org/10.1007/978-3-642-04346-8_62","tldr":"Based on state of the art machine learning techniques, GROBID (GeneRation Of BIbliographic Data) performs reliable bibliographic data extractions from scholar articles combined with multi-level term extractions."},{"id":"LucasKanade81","year":1981,"author":[{"given":"Bruce D.","family":"Lucas"},{"given":"Takeo","family":"Kanade"}],"title":"An Iterative Image Registration Technique with an Application to Stereo Vision","venue":"International Joint Conference on Artificial Intelligence"},{"id":"pandoc","year":2023,"author":[{"given":"John","family":"MacFarlane"}],"title":"Pandoc: A Universal Document Converter","url":"https://pandoc.org/"},{"id":"react","year":2023,"author":[{"family":"Meta Open Source"}],"title":"React","url":"https://react.dev/"},{"id":"myst","year":2023,"author":[{"family":"MyST Markdown"}],"title":"","url":"https://myst-tools.org/"},{"id":"doi:10.1145/800197.806036","doi":"10.1145/800197.806036","s2id":"ec17c284f1fb35ac2387630efa072b384cf03d84","year":1965,"author":[{"given":"T. H.","family":"Nelson","sequence":"first","affiliation":[]}],"title":"Complex information processing: a file structure for the complex, the changing and the indeterminate","venue":"Proceedings of the 1965 20th national conference on   -","url":"http://dx.doi.org/10.1145/800197.806036","abstract":"THE KINDS OF FILE structures required if we are to use the computer for personal files and as an adjunct to creativity are wholly different in character from those customary in business and scientific data processing. They need to provide the capacity for intricate and idiosyncratic arrangements, total modifiability, undecided alternatives, and thorough internal documentation.\n I want to explain how some ideas developed and what they are. The original problem was to specify a computer system for personal information retrieval and documentation, able to do some rather complicated things in clear and simple ways.\n In this paper I will explain the original problem. Then I will explain why the problem is not simple, and why the solution (a file structure) must yet be very simple. The file structure suggested here is the Evolutionary List File, to be built of zippered lists. A number of uses will be suggested for such a file, to show the breadth of its potential usefulness. Finally, I want to explain the philosophical implications of this approach for information retrieval and data structure in a changing world.","tldr":"The original problem was to specify a computer system for personal information retrieval and documentation, able to do some rather complicated things in clear and simple ways, and why the solution must yet be very simple."},{"id":"Nelson:81","year":1981,"author":[{"given":"T. H.","family":"Nelson"}],"title":"Literary Machines"},{"id":"obsinputs","year":2023,"author":[{"family":"Observable Inputs"}],"title":"","url":"https://github.com/observablehq/inputs"},{"id":"obsruntime","year":2023,"author":[{"family":"Observable Runtime"}],"title":"","url":"https://github.com/observablehq/runtime"},{"id":"observable","year":2023,"author":[{"family":"Observable"}],"title":"","url":"https://observablehq.com/"},{"id":"overleaf","year":2023,"author":[{"family":"Overleaf"}],"title":"Online LaTeX Editor","url":"https://www.overleaf.com/"},{"id":"doi:10.1016/S1389-1286(00)00043-8","doi":"10.1016/s1389-1286(00)00043-8","s2id":"bf3a9da17f9dbeb2d2d09f4d562c903e4e9b2f2e","year":2000,"author":[{"given":"Thomas A","family":"Phelps","sequence":"first","affiliation":[]},{"given":"Robert","family":"Wilensky","sequence":"additional","affiliation":[]}],"title":"Robust intra-document locations","venue":"Computer Networks","url":"http://dx.doi.org/10.1016/S1389-1286(00)00043-8","tldr":"This paper aims to begin a process to evolve a standard for ( normative) robust location descriptors and (non-normative) reattachment algorithms, and describes the implementation of robust locations within the Multivalent Document system."},{"id":"quarto","year":2023,"author":[{"family":"Quarto"}],"title":"","url":"https://quarto.org/"},{"id":"rmarkdown","year":2023,"author":[{"family":"RMarkdown"}],"title":"","url":"https://rmarkdown.rstudio.com/"},{"id":"doi:10.1145/3490099.3511162","doi":"10.1145/3490099.3511162","s2id":"277360f074e809135d4b49cf7fd2f572c0db6658","year":2022,"author":[{"given":"Napol","family":"Rachatasumrit","sequence":"first","affiliation":[{"name":"Human Computer Interaction Institute, Carnegie Mellon University, United States"}]},{"given":"Jonathan","family":"Bragg","sequence":"additional","affiliation":[{"name":"Allen Institute for Artificial Intelligence, United States"}]},{"given":"Amy X.","family":"Zhang","sequence":"additional","affiliation":[{"name":"CSE, University of Washington, United States"}]},{"given":"Daniel S","family":"Weld","sequence":"additional","affiliation":[{"name":"Semantic Scholar, Allen Institute for Artificial Intelligence, United States"}]}],"title":"CiteRead: Integrating Localized Citation Contexts into Scientific Paper Reading","venue":"27th International Conference on Intelligent User Interfaces","url":"http://dx.doi.org/10.1145/3490099.3511162","abstract":"When reading a scholarly paper, scientists oftentimes wish to understand how follow-on work has built on or engages with what they are reading. While a paper itself can only discuss prior work, some scientific search engines can provide a list of all subsequent citing papers; unfortunately, they are undifferentiated and disconnected from the contents of the original reference paper. In this work, we introduce a novel paper reading experience that integrates relevant information about follow-on work directly into a paper, allowing readers to learn about newer papers and see how a paper is discussed by its citing papers in the context of the reference paper. We built a tool, called CiteRead, that implements the following three contributions: 1) automated techniques for selecting important citing papers, building on results from a formative study we conducted, 2) an automated process for localizing commentary provided by citing papers to a place in the reference paper, and 3) an interactive experience that allows readers to seamlessly alternate between the reference paper and information from citing papers (e.g., citation sentences), placed in the margins. Based on a user study with 12 scientists, we found that in comparison to having just a list of citing papers and their citation sentences, the use of CiteRead while reading allows for better comprehension and retention of information about follow-on work.","tldr":"A novel paper reading experience that integrates relevant information about follow-on work directly into a paper, allowing readers to learn about newer papers and see how a paper is discussed by its citing papers in the context of the reference paper."},{"id":"ritchie2022big","year":2022,"author":[{"given":"Stuart","family":"Ritchie"}],"title":"The Big Idea: Should we get rid of the scientific paper?","venue":"The Guardian","url":"https://www.theguardian.com/books/2022/apr/11/the-big-idea-should-we-get-rid-of-the-scientific-paper"},{"id":"doi:10.1145/3173574.3173606","doi":"10.1145/3173574.3173606","s2id":"c2a9c50a41f79f6f860b1fe82581a59c06bdae65","year":2018,"author":[{"given":"Adam","family":"Rule","sequence":"first","affiliation":[{"name":"University of California, San Diego, La Jolla, CA, USA"}]},{"given":"Aurélien","family":"Tabard","sequence":"additional","affiliation":[{"name":"Université de Lyon, Lyon, France"}]},{"given":"James D.","family":"Hollan","sequence":"additional","affiliation":[{"name":"University of California, San Diego, La Jolla, CA, USA"}]}],"title":"Exploration and Explanation in Computational Notebooks","venue":"Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","url":"http://dx.doi.org/10.1145/3173574.3173606","abstract":"Computational notebooks combine code, visualizations, and text in a single document. Researchers, data analysts, and even journalists are rapidly adopting this new medium. We present three studies of how they are using notebooks to document and share exploratory data analyses. In the first, we analyzed over 1 million computational notebooks on GitHub, finding that one in four had no explanatory text but consisted entirely of visualizations or code. In a second study, we examined over 200 academic computational notebooks, finding that although the vast majority described methods, only a minority discussed reasoning or results. In a third study, we interviewed 15 academic data analysts, finding that most considered computational notebooks personal, exploratory, and messy. Importantly, they typically used other media to share analyses. These studies demonstrate a tension between exploration and explanation in constructing and sharing computational notebooks. We conclude with opportunities to encourage explanation in computational media without hindering exploration.","tldr":"Three studies of how academic data analysts are using notebooks to document and share exploratory data analyses demonstrate a tension between exploration and explanation in constructing and sharing computational notebooks."},{"id":"doi:10.1109/TVCG.2015.2467091","doi":"10.1109/tvcg.2015.2467091","s2id":"bab31ef6c37d54f0e1aa4666f0ccd4243354eb8f","year":2016,"author":[{"given":"Arvind","family":"Satyanarayan","sequence":"first","affiliation":[]},{"given":"Ryan","family":"Russell","sequence":"additional","affiliation":[]},{"given":"Jane","family":"Hoffswell","sequence":"additional","affiliation":[]},{"given":"Jeffrey","family":"Heer","sequence":"additional","affiliation":[]}],"title":"Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization","venue":"IEEE Transactions on Visualization and Computer Graphics","url":"http://dx.doi.org/10.1109/TVCG.2015.2467091","abstract":"We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.","tldr":"Reactive Vega is presented, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization and the results of benchmark studies indicate superior interactive performance to both D3 and the original, non-reactive Vega system."},{"id":"doi:10.1109/TVCG.2016.2599030","doi":"10.1109/tvcg.2016.2599030","s2id":"f3b851991e3490384100a2743aa800606990daeb","year":2018,"author":[{"given":"Arvind","family":"Satyanarayan","sequence":"first","affiliation":[]},{"given":"Dominik","family":"Moritz","sequence":"additional","affiliation":[]},{"given":"Kanit","family":"Wongsuphasawat","sequence":"additional","affiliation":[]},{"given":"Jeffrey","family":"Heer","sequence":"additional","affiliation":[]}],"title":"Vega-Lite: A Grammar of Interactive Graphics","venue":"IEEE Transactions on Visualization and Computer Graphics","url":"http://dx.doi.org/10.1109/TVCG.2016.2599030","abstract":"We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.","tldr":"Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction, that enables rapid specification of interactive data visualizations."},{"id":"doi:10.1145/2047196.2047247","doi":"10.1145/2047196.2047247","s2id":"df953c84062ac2dbefe8322babff8007df25a94a","year":2011,"author":[{"given":"Manolis","family":"Savva","sequence":"first","affiliation":[{"name":"Stanford University, Palo Alto, CA, USA"}]},{"given":"Nicholas","family":"Kong","sequence":"additional","affiliation":[{"name":"University of California, Berkeley, Berkeley, CA, USA"}]},{"given":"Arti","family":"Chhajta","sequence":"additional","affiliation":[{"name":"Stanford University, Palo Alto, CA, USA"}]},{"given":"Li","family":"Fei-Fei","sequence":"additional","affiliation":[{"name":"Stanford University, Palo Alto, CA, USA"}]},{"given":"Maneesh","family":"Agrawala","sequence":"additional","affiliation":[{"name":"University of California, Berkeley, Berkeley, CA, USA"}]},{"given":"Jeffrey","family":"Heer","sequence":"additional","affiliation":[{"name":"Stanford University, Palo Alto, CA, USA"}]}],"title":"ReVision: automated classification, analysis and redesign of chart images","venue":"Proceedings of the 24th annual ACM symposium on User interface software and technology","url":"http://dx.doi.org/10.1145/2047196.2047247","abstract":"Poorly designed charts are prevalent in reports, magazines, books and on the Web. Most of these charts are only available as bitmap images; without access to the underlying data it is prohibitively difficult for viewers to create more effective visual representations. In response we present ReVision, a system that automatically redesigns visualizations to improve graphical perception. Given a bitmap image of a chart as input, ReVision applies computer vision and machine learning techniques to identify the chart type (e.g., pie chart, bar chart, scatterplot, etc.). It then extracts the graphical marks and infers the underlying data. Using a corpus of images drawn from the web, ReVision achieves image classification accuracy of 96% across ten chart categories. It also accurately extracts marks from 79% of bar charts and 62% of pie charts, and from these charts it successfully extracts data from 71% of bar charts and 64% of pie charts. ReVision then applies perceptually-based design principles to populate an interactive gallery of redesigned charts. With this interface, users can view alternative chart designs and retarget content to different visual styles.","tldr":"ReVision is a system that automatically redesigns visualizations to improve graphical perception, and applies perceptually-based design principles to populate an interactive gallery of redesigned charts."},{"id":"doi:10.1162/tacl_a_00466","doi":"10.1162/tacl_a_00466","s2id":"f95620883ce631dcca296d6301ab094555a9b1c4","year":2021,"author":[{"given":"Zejiang","family":"Shen","sequence":"first","affiliation":[{"name":"Allen Institute for AI, USA. shannons@allenai.org"}]},{"given":"Kyle","family":"Lo","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, USA. kylel@allenai.org"}]},{"given":"Lucy Lu","family":"Wang","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, USA. lucyw@allenai.org"}]},{"given":"Bailey","family":"Kuehl","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, USA. baileyk@allenai.org"}]},{"given":"Daniel S.","family":"Weld","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, USA"},{"name":"University of Washington, USA. danw@allenai.org"}]},{"given":"Doug","family":"Downey","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, USA"},{"name":"Northwestern University, USA. dougd@allenai.org"}]}],"title":"VILA: Improving Structured Content Extraction from Scientific PDFs Using Visual Layout Groups","venue":"Transactions of the Association for Computational Linguistics","url":"http://dx.doi.org/10.1162/tacl_a_00466","abstract":"Accurately extracting structured content from PDFs is a critical first step for NLP over scientific papers. Recent work has improved extraction accuracy by incorporating elementary layout information, for example, each token’s 2D position on the page, into language model pretraining. We introduce new methods that explicitly model VIsual LAyout (VILA) groups, that is, text lines or text blocks, to further improve performance. In our I-VILA approach, we show that simply inserting special tokens denoting layout group boundaries into model inputs can lead to a 1.9% Macro F1 improvement in token classification. In the H-VILA approach, we show that hierarchical encoding of layout-groups can result in up to 47% inference time reduction with less than 0.8% Macro F1 loss. Unlike prior layout-aware approaches, our methods do not require expensive additional pretraining, only fine-tuning, which we show can reduce training cost by up to 95%. Experiments are conducted on a newly curated evaluation suite, S2-VLUE, that unifies existing automatically labeled datasets and includes a new dataset of manual annotations covering diverse papers from 19 scientific disciplines. Pre-trained weights, benchmark datasets, and source code are available at https://github.com/allenai/VILA.","tldr":"This work introduces new methods that explicitly model VIsual LAyout (VILA) groups, that is, text lines or text blocks, to further improve performance and shows that simply inserting special tokens denoting layout group boundaries into model inputs can lead to a 1.9% Macro F1 improvement in token classification."},{"id":"doi:10.1145/3411764.3445354","doi":"10.1145/3411764.3445354","s2id":"bcc673a68e752f837250ae914624dedf05472e75","year":2021,"author":[{"given":"Nicole","family":"Sultanum","sequence":"first","affiliation":[{"name":"University of Toronto, Canada"}]},{"given":"Fanny","family":"Chevalier","sequence":"additional","affiliation":[{"name":"University of Toronto, Canada, Canada"}]},{"given":"Zoya","family":"Bylinskii","sequence":"additional","affiliation":[{"name":"Creative Intelligence Lab Adobe Research, United States"}]},{"given":"Zhicheng","family":"Liu","sequence":"additional","affiliation":[{"name":"University of Maryland, United States"}]}],"title":"Leveraging Text-Chart Links to Support Authoring of Data-Driven Articles with VizFlow","venue":"Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems","url":"http://dx.doi.org/10.1145/3411764.3445354","abstract":"Data-driven articles—i.e., articles featuring text and supporting charts—play a key role in communicating information to the public. New storytelling formats like scrollytelling apply compelling dynamics to these articles to help walk readers through complex insights, but are challenging to craft. In this work, we investigate ways to support authors of data-driven articles using such storytelling forms via a text-chart linking strategy. From formative interviews with 6 authors and an assessment of 43 scrollytelling stories, we built VizFlow, a prototype system that uses text-chart links to support a range of dynamic layouts. We validate our text-chart linking approach via an authoring study with 12 participants using VizFlow, and a reading study with 24 participants comparing versions of the same article with different VizFlow intervention levels. Assessments showed our approach enabled a rapid and expressive authoring experience, and informed key design recommendations for future efforts in the space.","tldr":"This work built VizFlow, a prototype system that uses text-chart links to support a range of dynamic layouts and assesses the approach enabled a rapid and expressive authoring experience, and informed key design recommendations for future efforts in the space."},{"id":"doi:10.23915/distill.00031","doi":"10.23915/distill.00031","s2id":"0de3b6ef0dd2988de31a212fea0db94f45572929","year":2021,"author":[{"given":"Editorial","family":"Team","sequence":"first","affiliation":[{"name":"Distill"}]}],"title":"Distill Hiatus","venue":"Distill","url":"http://dx.doi.org/10.23915/distill.00031"},{"id":"scalar","year":2023,"author":[{"family":"The Alliance for Networking Visual Culture"}],"title":"Scalar","url":"https://scalar.me/anvc/scalar/"},{"id":"typst","year":2023,"author":[{"family":"Typst"}],"title":"Typst: Compose papers faster","url":"https://typst.app/"},{"id":"expexp","year":2011,"author":[{"given":"Bret","family":"Victor"}],"title":"Explorable Explanations","url":"http://worrydream.com/ExplorableExplanations/"},{"id":"doi:10.1145/3441852.3476545","doi":"10.1145/3441852.3476545","s2id":"582616fe83a85f095a16778c28297723e25b0ea7","year":2021,"author":[{"given":"Lucy Lu","family":"Wang","sequence":"first","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Isabel","family":"Cachola","sequence":"additional","affiliation":[{"name":"The Johns Hopkins University, United States"}]},{"given":"Jonathan","family":"Bragg","sequence":"additional","affiliation":[{"name":"Allen Institute for Artificial Intelligence, United States"}]},{"given":"Evie Yu-Yen","family":"Cheng","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Chelsea","family":"Haupt","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Matt","family":"Latzke","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Bailey","family":"Kuehl","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Madeleine N","family":"van Zuylen","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Linda","family":"Wagner","sequence":"additional","affiliation":[{"name":"Allen Institute for AI, United States"}]},{"given":"Daniel","family":"Weld","sequence":"additional","affiliation":[{"name":"Semantic Scholar Allen Institute for Artificial Intelligence, United States"}]}],"title":"SciA11y: Converting Scientific Papers to Accessible HTML","venue":"The 23rd International ACM SIGACCESS Conference on Computers and Accessibility","url":"http://dx.doi.org/10.1145/3441852.3476545","abstract":"We present SciA11y, a system that renders inaccessible scientific paper PDFs into HTML. SciA11y uses machine learning models to extract and understand the content of scientific PDFs, and reorganizes the resulting paper components into a form that better supports skimming and scanning for blind and low vision (BLV) readers. SciA11y adds navigation features such as tagged headings, a table of contents, and bidirectional links between inline citations and references, which allow readers to resolve citations without losing their context. A set of 1.5 million open access papers are processed and available at https://scia11y.org/. This system is a first step in addressing scientific PDF accessibility, and may significantly improve the experience of paper reading for BLV users.","tldr":"SciA11y uses machine learning models to extract and understand the content of scientific PDFs, and reorganizes the resulting paper components into a form that better supports skimming and scanning for blind and low vision readers."},{"id":"citejs","year":2023,"author":[{"given":"Lars","family":"Willighagen"}],"title":"Citation.js","url":"https://citation.js.org/"},{"id":"xanadu","year":1995,"author":[{"given":"Gary","family":"Wolf"}],"title":"The Curse of Xanadu","venue":"Wired","url":"https://www.wired.com/1995/06/xanadu/"},{"id":"visxai","year":2022,"author":[{"family":"Workshop on Visualization for AI Explainability"}],"title":"","url":"http://visxai.io/"},{"id":"doi:10.1145/332040.332440","doi":"10.1145/332040.332440","s2id":"56d1ff14097a1d3dbe7895c6f54eccc5684473b9","year":2000,"author":[{"given":"Polle T.","family":"Zellweger","sequence":"first","affiliation":[{"name":"Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CA"}]},{"given":"Susan Harkness","family":"Regli","sequence":"additional","affiliation":[{"name":"Baker Hall 259, Carnegie Mellon University, 5000 Forbes Ave. Pittsburgh, PA and Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CA"}]},{"given":"Jock D.","family":"Mackinlay","sequence":"additional","affiliation":[{"name":"Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CA"}]},{"given":"Bay-Wei","family":"Chang","sequence":"additional","affiliation":[{"name":"Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CA"}]}],"title":"The impact of fluid documents on reading and browsing: an observational study","venue":"Proceedings of the SIGCHI conference on Human Factors in Computing Systems","url":"http://dx.doi.org/10.1145/332040.332440","abstract":"Fluid Documents incorporate additional information into a page by adjusting typography using interactive animation. One application is to support hypertext browsing by providing glosses for link anchors. This paper describes an observational study of the impact of Fluid Documents on reading and browsing. The study involved six conditions that differ along several dimensions, including the degree of typographic adjustment and the distance glosses are placed from anchors. Six subjects read and answered questions about two hypertext corpora while being monitored by an eyetracker. The eyetracking data revealed no substantial differenccs in eye behavior between conditions. Gloss placement was significant: subjects required less time to use nearby glosses. Finally, the reaction to the conditions was highly varied, with several conditions receiving both a best and worst rating on the subjective questionnaires. These results suggest implications for the design of dynamic reading environments.","tldr":"An observational study of the impact of Fluid Documents on reading and browsing involved six conditions that differ along several dimensions, including the degree of typographic adjustment and the distance glosses are placed from anchors."},{"id":"doi:10.1111/cgf.14519","doi":"10.1111/cgf.14519","s2id":"ac47d785610ab432b59375f4b1c2d97379050132","year":2022,"author":[{"ORCID":"http://orcid.org/0000-0003-4811-4624","authenticated-orcid":false,"given":"Jonathan","family":"Zong","sequence":"first","affiliation":[{"name":"Massachusetts Institute of Technology"}]},{"ORCID":"http://orcid.org/0000-0001-6672-9118","authenticated-orcid":false,"given":"Crystal","family":"Lee","sequence":"additional","affiliation":[{"name":"Massachusetts Institute of Technology"}]},{"ORCID":"http://orcid.org/0000-0002-1352-3615","authenticated-orcid":false,"given":"Alan","family":"Lundgard","sequence":"additional","affiliation":[{"name":"Massachusetts Institute of Technology"}]},{"ORCID":"http://orcid.org/0000-0003-0469-9501","authenticated-orcid":false,"given":"JiWoong","family":"Jang","sequence":"additional","affiliation":[{"name":"Carnegie Mellon University"}]},{"ORCID":"http://orcid.org/0000-0002-2811-1197","authenticated-orcid":false,"given":"Daniel","family":"Hajas","sequence":"additional","affiliation":[{"name":"University College London"}]},{"ORCID":"http://orcid.org/0000-0001-5564-635X","authenticated-orcid":false,"given":"Arvind","family":"Satyanarayan","sequence":"additional","affiliation":[{"name":"Massachusetts Institute of Technology"}]}],"title":"Rich Screen Reader Experiences for Accessible Data Visualization","venue":"Computer Graphics Forum","url":"http://dx.doi.org/10.1111/cgf.14519","abstract":"Current web accessibility guidelines ask visualization designers to support screen readers via basic non‐visual alternatives like textual descriptions and access to raw data tables. But charts do more than summarize data or reproduce tables; they afford interactive data exploration at varying levels of granularity—from fine‐grained datum‐by‐datum reading to skimming and surfacing high‐level trends. In response to the lack of comparable non‐visual affordances, we present a set of rich screen reader experiences for accessible data visualization and exploration. Through an iterative co‐design process, we identify three key design dimensions for expressive screen reader accessibility: structure, or how chart entities should be organized for a screen reader to traverse; navigation, or the structural, spatial, and targeted operations a user might perform to step through the structure; and, description, or the semantic content, composition, and verbosity of the screen reader's narration. We operationalize these dimensions to prototype screen‐reader‐accessible visualizations that cover a diverse range of chart types and combinations of our design dimensions. We evaluate a subset of these prototypes in a mixed‐methods study with 13 blind and visually impaired readers. Our findings demonstrate that these designs help users conceptualize data spatially, selectively attend to data of interest at different levels of granularity, and experience control and agency over their data analysis process. An accessible HTML version of this paper is available at: http://vis.csail.mit.edu/pubs/rich-screen-reader-vis-experiences."}]},"definitions":[{"replace":"@F(x + @h)","symbol":"F(x + @h)","color":"blue","definition":"Best translated $@F(x)$ to approximate $@G(x)$"},{"replace":"@F'(x)","symbol":"F'(x)","color":"darkblue","definition":"Linear approximation of $@F(x)$ in the neighborhood of $@x$"},{"replace":"@F(x)","symbol":"F(x)","color":"blue","definition":"First stereo image"},{"replace":"@G(x)","symbol":"G(x)","color":"darkgreen","definition":"Second stereo image"},{"replace":"@x","symbol":"x","color":"red","definition":"Position vector in an image"},{"replace":"@h","symbol":"h","color":"purple","definition":"Disparity vector"},{"replace":"@F","symbol":"F","color":"blue","definition":"First stereo image"}]};
window.customElements.define('cell-view', CellView);
window.customElements.define('cite-ref', CiteRef);
window.customElements.define('cross-ref', CrossRef);
window.customElements.define('inline-note', InlineNote);
window.customElements.define('option-text', OptionText);
window.customElements.define('tex-math', TexMath);
window.customElements.define('toggle-text', ToggleText);
window.customElements.define('barnes-hut', BarnesHut);
window.addEventListener('DOMContentLoaded', () => {
  const root = document.querySelector('article');
  hydrate(new ObservableRuntime, root, module, {"_id":4,"attrs":[["1","src",0],["2","theta",1],["3","code",2],["4","code",3]],"events":[]});
});

    </script>
</html>